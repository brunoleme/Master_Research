{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of Calculate_BERT_FineTuned_Embeddings_Split3.ipynb","provenance":[{"file_id":"1iEtoUyt4l6WoYZKnFY4vMwGIaInqm1Z7","timestamp":1592589760254},{"file_id":"1jM_MQeWnqB4LrmlAc_rZ00W9zJK7Hw_d","timestamp":1590464112416}],"collapsed_sections":[],"authorship_tag":"ABX9TyN1NOwFxt9kJz6LDhDh7M7w"},"kernelspec":{"name":"python3","display_name":"Python 3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"b2d430149d344d16b5ddfad21d9256e4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_1c869b41da114a6b839224bea167ce89","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_2282fdeb86f64a148cda7adf079ad29c","IPY_MODEL_796992bd57a9451f83fb18420fcd4e9c"]}},"1c869b41da114a6b839224bea167ce89":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2282fdeb86f64a148cda7adf079ad29c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_d8a1f733df9f4f819a92db35d34b4f2f","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":33528,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":33528,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_cf2efae8e23b4bb581e4c73f7962b67b"}},"796992bd57a9451f83fb18420fcd4e9c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_e6533f9546dd429e9803adc4fc1810b1","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 33528/33528 [04:12&lt;00:00, 133.04it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_20d53650910d4cbdbc316908ee2bc789"}},"d8a1f733df9f4f819a92db35d34b4f2f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"cf2efae8e23b4bb581e4c73f7962b67b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e6533f9546dd429e9803adc4fc1810b1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"20d53650910d4cbdbc316908ee2bc789":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"43e1490ecc6746d394ad99b8d456b840":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_f6c7496e5e614512bf87689e63f51170","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_a085c92871d84b319f7827c4e9903932","IPY_MODEL_1ace1b837df14d579d995c2b8a742b30"]}},"f6c7496e5e614512bf87689e63f51170":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a085c92871d84b319f7827c4e9903932":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_aae5a174f88246009ff1fc218328f36e","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":14130,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":14130,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_afdd2a38de4441f187587964b7aed651"}},"1ace1b837df14d579d995c2b8a742b30":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d8f78a8d06b343baaa1c5d96f9e617e1","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 14130/14130 [01:13&lt;00:00, 191.27it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a42756168f0f4a9e8f8c7f2916763a21"}},"aae5a174f88246009ff1fc218328f36e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"afdd2a38de4441f187587964b7aed651":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d8f78a8d06b343baaa1c5d96f9e617e1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a42756168f0f4a9e8f8c7f2916763a21":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"837d1e32ef324503b4629cd712166dc2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_6d477d976ff64e06b6578516205eab57","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_bf3313db81e04a66b9f0092731845757","IPY_MODEL_e1c077a2c5de4c0facf95909e099850b"]}},"6d477d976ff64e06b6578516205eab57":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bf3313db81e04a66b9f0092731845757":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_16d6be1e9ebb49488d5efb8600b61da1","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":888,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":888,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_50a0e72fc2344edcb58dbf1952e30d05"}},"e1c077a2c5de4c0facf95909e099850b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_e6d1164fbb124c2c9c99b0743d23db81","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 888/888 [25:41&lt;00:00,  1.74s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_23079b3f8d764a25aea3cf5bd5767c50"}},"16d6be1e9ebb49488d5efb8600b61da1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"50a0e72fc2344edcb58dbf1952e30d05":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e6d1164fbb124c2c9c99b0743d23db81":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"23079b3f8d764a25aea3cf5bd5767c50":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fffa0d5a27f24fb6a740419a8fdf29b4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_3a15e0a567314123bc4cbbe69a4423b3","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_266c0ba45d0b42d09d9360ad37de066f","IPY_MODEL_bd985b33ef1541878f124b60c1ac8792"]}},"3a15e0a567314123bc4cbbe69a4423b3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"266c0ba45d0b42d09d9360ad37de066f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_83bc39542d804a75a489a573c0083ae3","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":381,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":381,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b24e64791c404fcea9d0e69417bd3153"}},"bd985b33ef1541878f124b60c1ac8792":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_5cfdbe5db84b4ff3a003d15d5f7c3023","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 381/381 [10:49&lt;00:00,  1.70s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8f82e01c92ae4c0a94dee8bb5ac55920"}},"83bc39542d804a75a489a573c0083ae3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"b24e64791c404fcea9d0e69417bd3153":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5cfdbe5db84b4ff3a003d15d5f7c3023":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"8f82e01c92ae4c0a94dee8bb5ac55920":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"KWy32B6i5zUX","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"executionInfo":{"status":"ok","timestamp":1593635105791,"user_tz":180,"elapsed":22002,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"5b09d99c-d48d-4201-8ab0-1838c2d34d93"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qG20-M6lZ5sD","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593635105792,"user_tz":180,"elapsed":21998,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["n_split = 3"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"uCC2fopD6JTj","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593635105793,"user_tz":180,"elapsed":21997,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["import pickle"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"LXHTiUtW6MJX","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593635108363,"user_tz":180,"elapsed":24564,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["with open('/content/drive/My Drive/Data Master/X_train_final', 'rb') as file:\n","    X_train_balanced = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/X_test_final', 'rb') as file:\n","    X_test = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/word_index_final', 'rb') as file:\n","    word_index = pickle.load(file)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"7cw3aVs0tNYu","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593635108364,"user_tz":180,"elapsed":24562,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["inv_word_index = {ix : w for w, ix in word_index.items()}"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"9hORlMAi41vy","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":615},"executionInfo":{"status":"ok","timestamp":1593635115476,"user_tz":180,"elapsed":31668,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"a08fddae-1ae6-42c0-8cda-8c3e390b79e3"},"source":["!pip install transformers"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/35/1c3f6e62d81f5f0daff1384e6d5e6c5758682a8357ebc765ece2b9def62b/transformers-3.0.0-py3-none-any.whl (754kB)\n","\u001b[K     |████████████████████████████████| 757kB 11.8MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Collecting sentencepiece\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n","\u001b[K     |████████████████████████████████| 1.1MB 51.3MB/s \n","\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 45.1MB/s \n","\u001b[?25hCollecting tokenizers==0.8.0-rc4\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e8/bd/e5abec46af977c8a1375c1dca7cb1e5b3ec392ef279067af7f6bc50491a0/tokenizers-0.8.0rc4-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n","\u001b[K     |████████████████████████████████| 3.0MB 47.7MB/s \n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.12.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.15.1)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=3b221917c29002f043033f0f05bfd20c4a53262e885c6a520ecf647d7ca5cc4c\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built sacremoses\n","Installing collected packages: sentencepiece, sacremoses, tokenizers, transformers\n","Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.0rc4 transformers-3.0.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FpY7GFWU6TLg","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593635120890,"user_tz":180,"elapsed":37079,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["import pandas as pd\n","import numpy as np\n","import itertools\n","\n","import torch\n","import torch.nn as nn\n","import transformers\n","import torch.utils.data as tdata\n","import torch.optim as optim\n","\n","import tqdm"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"vgxq4EIuEpg3","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593635120891,"user_tz":180,"elapsed":37077,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["import transformers"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"FDhmJ8RY4-St","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593635120891,"user_tz":180,"elapsed":37075,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"rMHHXY4YAQ2b","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593635120892,"user_tz":180,"elapsed":37074,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["fine_tuned_model_dir = '/content/drive/My Drive/Colab Notebooks/Torch/_FineTuningModels/SentenceClassification/model_save/bert_model_sentence_classification_tail_tuned_split_' + str(n_split) + '/'"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"ePBFYDYE5Io9","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593635151775,"user_tz":180,"elapsed":67955,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["bert_tokenizer = transformers.BertTokenizer.from_pretrained(fine_tuned_model_dir)\n","bert_config = transformers.BertConfig.from_pretrained(fine_tuned_model_dir, output_hidden_states=True)\n","bert_model = transformers.BertModel.from_pretrained(fine_tuned_model_dir, config=bert_config).to(device)"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"oRoJELU4uKD5","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593635151776,"user_tz":180,"elapsed":67954,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["def spilt_text(sent, sent_size = 350, overlapping_size = 100):\n","  res = []\n","  n_chunks = (len(sent) // sent_size) + 1\n","  for i in range(n_chunks):\n","    res.append(sent[i * sent_size : i * sent_size + (sent_size + overlapping_size)])\n","  return res"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"DUkQ_nwFFNyD","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593635154018,"user_tz":180,"elapsed":70193,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["data_train_balanced_chunked = [(i, spilt_text([inv_word_index[ix] for ix in X_train_balanced[i]])) for i, d in enumerate(X_train_balanced)]\n","data_test_chunked = [(i, spilt_text([inv_word_index[ix] for ix in X_test[i]])) for i, d in enumerate(X_test)]"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZIT-ZGCdFRHF","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593635154381,"user_tz":180,"elapsed":70554,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["data_train_balanced_chunked_splitted = [(i, [\" \".join(subsent) for subsent in chunked_sent]) for i, chunked_sent in data_train_balanced_chunked]\n","data_test_chunked_splitted = [(i, [\" \".join(subsent) for subsent in chunked_sent]) for i, chunked_sent in data_test_chunked]"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"HpgTgXR2mbOz","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593635154382,"user_tz":180,"elapsed":70553,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["df_train_balanced_chunked_splitted = pd.DataFrame(\n","    list(itertools.chain.from_iterable([[[doc, c] for c in chunks] for doc, chunks in data_train_balanced_chunked_splitted])),\n","    columns=['doc', 'chunk'])\n","\n","df_test_chunked_splitted = pd.DataFrame(\n","    list(itertools.chain.from_iterable([[[doc, c] for c in chunks] for doc, chunks in data_test_chunked_splitted])),\n","    columns=['doc', 'chunk'])"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q5LHi_yarFV-","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593635154383,"user_tz":180,"elapsed":70552,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["docs_train = df_train_balanced_chunked_splitted.doc.values\n","sentences_train = df_train_balanced_chunked_splitted.chunk.values\n","\n","docs_test = df_test_chunked_splitted.doc.values\n","sentences_test = df_test_chunked_splitted.chunk.values"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"ScaOKppIrLoC","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":987,"referenced_widgets":["b2d430149d344d16b5ddfad21d9256e4","1c869b41da114a6b839224bea167ce89","2282fdeb86f64a148cda7adf079ad29c","796992bd57a9451f83fb18420fcd4e9c","d8a1f733df9f4f819a92db35d34b4f2f","cf2efae8e23b4bb581e4c73f7962b67b","e6533f9546dd429e9803adc4fc1810b1","20d53650910d4cbdbc316908ee2bc789"]},"executionInfo":{"status":"ok","timestamp":1593635332902,"user_tz":180,"elapsed":249065,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"91727020-ffd7-4c08-830c-939310b28e22"},"source":["# Tokenize all of the sentences and map the tokens to thier word IDs.\n","input_ids_train = []\n","attention_masks_train = []\n","\n","# For every sentence...\n","for sent in tqdm.notebook.tqdm(sentences_train):\n","    # `encode_plus` will:\n","    #   (1) Tokenize the sentence.\n","    #   (2) Prepend the `[CLS]` token to the start.\n","    #   (3) Append the `[SEP]` token to the end.\n","    #   (4) Map tokens to their IDs.\n","    #   (5) Pad or truncate the sentence to `max_length`\n","    #   (6) Create attention masks for [PAD] tokens.\n","    encoded_dict = bert_tokenizer.encode_plus(\n","                        sent,                      # Sentence to encode.\n","                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                        max_length = 512,           # Pad & truncate all sentences.\n","                        pad_to_max_length = True,\n","                        return_attention_mask = True,   # Construct attn. masks.\n","                        return_tensors = 'pt',     # Return pytorch tensors.\n","                        truncation='longest_first'\n","                   )\n","    \n","    # Add the encoded sentence to the list.    \n","    input_ids_train.append(encoded_dict['input_ids'])\n","    \n","    # And its attention mask (simply differentiates padding from non-padding).\n","    attention_masks_train.append(encoded_dict['attention_mask'])\n","\n","# Convert the lists into tensors.\n","input_ids_train = torch.cat(input_ids_train, dim=0)\n","attention_masks_train = torch.cat(attention_masks_train, dim=0)\n","\n","# Print sentence 0, now as a list of IDs.\n","print('Original: ', sentences_train[10])\n","print('Token IDs:', input_ids_train[10])"],"execution_count":17,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b2d430149d344d16b5ddfad21d9256e4","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=33528.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Original:  foram transferidas para gss em 07 de fevereiro de 2014 a operação não foi sujeita à aprovação do cade em razão de não terem sido atingidos os critérios de faturamento previstos na lei no 12 529 2011 ato de concentração nº 08700 001301 2016 41 envolvendo serrana águas ltda serrana e aegea saneamento e participações s a a operação diz respeito à aquisição pela aegea de participação de 49 do capital social da empresa águas de penha saneamento spe ltda águas de penha anteriormente detida pela serrana operação aprovada sem restrições em 11 03 2016 11 8 informe todas as atividades econômicas desempenhadas pelas partes diretamente envolvidas na operação no brasil indicando o faturamento bruto obtido com cada uma das atividades no ano fiscal anterior ao da apresentação da notificação classifique as segundo a cnae 2 0 a 7 dígitos ou versão mais atual segue abaixo a lista das atividades econômicas desempenhadas pela aegea no brasil em 2015 com os faturamentos brutos obtidos com cada uma dessas atividades cnae descrição faturamento 43 99 1 99 serviços especializados para construção não especificados anteriormente 42 22 7 01 construção de redes de abastecimento de água coleta de esgoto e construções correlatas exceto obras de irrigação 36 00 6 01 captação tratamento e distribuição de água ' 37 01 1 00 gestão de redes de esgoto ' 77 11 0 00 locação de automóveis sem condutor 11 9 informe todas as atividades econômicas desempenhadas pelas demais empresas que fazem parte dos grupos econômicos envolvidos na operação no brasil classifique as segundo a cnae 2 0 a 7 dígitos ou versão mais atual segue abaixo quadro indicando as atividades econômicas desempenhadas pelas empresas pertencentes ao grupo aegea com atividades no brasil bem como os respectivos códigos cnae empresa descrição das atividades codigo cnae holdings de instituições não financeiras 64 62 0 00 fundos de investimento exceto 64 70 1 01 previdenciários e imobiliários holdings de instituições não financeiras 64 62 0 00 holdings de instituições não financeiras 64 62 0 00 holdings de instituições não financeiras 64 62 0 00 construção de rodovias e ferrovias 42 11 1 01 construção de rodovias e ferrovias 42 11 1 01 holdings de instituições não financeiras 64 62 0 00 concessionárias de rodovias pontes túneis e 52 21 4 00 serviços relacionados concessionárias de rodovias pontes túneis e 52 21 4 00 serviços relacionados concessionárias de rodovias pontes túneis e 52 21 4 00 serviços relacionados construção de rodovias e ferrovias 42 11 1 01 terminais rodoviários e ferroviários 52 22 00 terminais rodoviários e ferroviários 52 22 00 ' holdings de instituições não financeiras 64 62 0 00 ' gestão de redes de esgoto 37 01\n","Token IDs: tensor([  101,   506, 12287, 22281,   221,   237, 22281, 22281,   173, 18506,\n","          125,  1812,   125,  3843,   123,  4597,   346,   262, 22076,   353,\n","         7344,   171,  6846, 22279,   173,  4145,   125,   346,  4832,   908,\n","        10889, 22281,   259, 10252,   125, 19971,   310, 10155, 22281,   229,\n","         2241,   202,  1242, 10596, 22315,  3618,  5291,   125,  6755,   100,\n","        16394,  5554, 22307, 14736,  7793,  2051,  4284, 11662,  7389, 10530,\n","          324,  5341,   219, 22286,   285,   100,   122,   123, 22279,   640,\n","        22278,  2903, 22279,  1845,   122,  8751,   139,   123,   123,  4597,\n","         1331,  3953,   353,  9588,   412,   123, 22279,   640, 22278,   125,\n","         2490,   125,  9501,   171,  1855,  1979,   180,  1799,  5341,   125,\n","         2377,   252,  2903, 22279,  1845,   139,   269,   219, 22286,   285,\n","          100,   125,   100,  4870,   125,  3679,   412, 10530,   324,  4597,\n","        10999,   834, 11668,   173,  1433, 19148,  4284,  1433,  1015,  9325,\n","        22279,  1485,   260,  2734,  9894, 19005,   591,  1676,  2844,  4188,\n","        14906,   229,  4597,   202,  1010,   215, 12418,   146, 19971,   310,\n","        17634, 10473,   170,  1078,   230,   366,  2734,   202,   622, 13816,\n","         2095,   320,   180,  4689,   180,   202,  6398,  1548,   357,  3533,\n","          260,   995,   123,   127,   324, 22279,   245,  2297,   123,   977,\n","        18988,   721,   291,  1619,   325,  2233,  5229,  4133,   123,  2925,\n","          366,  2734,  9894, 19005,   591,   412,   123, 22279,   640, 22278,\n","          202,  1010,   215,   173,  4155,   170,   259, 19971,   579, 17634,\n","        22281, 12605,   170,  1078,   230,  4756,  2734,   127,   324, 22279,\n","         8274, 19971,   310, 11838, 16113,   205, 16113,  2654, 14780,   221,\n","         1803,   346, 17117,   442,  4870,  9716,  2336,   977, 13778,  1803,\n","          125,  4739,   125, 12228,   125,  1991, 12927,   125, 19970,   122,\n","         9227, 20915,   470,  7601,  1860,   125, 19276,   341,  6408, 14736,\n","          888, 13778,   853,  1068,  3896,   122,  4128,   125,  1991,   112,\n","         8157, 13778,   205, 14736,  4940,   125,  4739,   125, 19970,   112,\n","        14332,  1433,  2297, 14736,   817,   341,   125, 12013,   834, 21256,\n","         1433,  1117,  9325, 22279,  1485,   260,  2734,  9894, 19005,   591,\n","         1676,  3547,  2786,   179,  4366,   670,   298,  2201, 11720,  8612,\n","          229,  4597,   202,  1010,   215,  1548,   357,  3533,   260,   995,\n","          123,   127,   324, 22279,   245,  2297,   123,   977, 18988,   721,\n","          291,  1619,   325,  2233,  5229,  4133,  5634, 12418,   260,  2734,\n","         9894, 19005,   591,  1676,  2786, 11155,   320,   939,   123, 22279,\n","          640, 22278,   170,  2734,   202,  1010,   215,  1004,   271,   259,\n","        13329, 17545,   127,   324, 22279,  1799,  8274,   366,  2734,  9691,\n","         1039,   127,   324, 22279,   588,  2876,  4403,   125,  4600,   346,\n","        11692, 10140, 16659,  2297, 14736,  8001,   125,  8947,  7601, 10140,\n","         5011,   205, 13778,  9670, 13283,   218,   611,   122, 13175, 16990,\n","          588,  2876,  4403,   125,  4600,   346, 11692, 10140, 16659,  2297,\n","        14736,   588,  2876,  4403,   125,  4600,   346, 11692, 10140, 16659,\n","         2297, 14736,   588,  2876,  4403,   125,  4600,   346, 11692, 10140,\n","        16659,  2297, 14736,  1803,   125, 15468,   122, 21162,  9716,  1433,\n","          205, 13778,  1803,   125, 15468,   122, 21162,  9716,  1433,   205,\n","        13778,   588,  2876,  4403,   125,  4600,   346, 11692, 10140, 16659,\n","         2297, 14736, 21386, 16207, 22281,   125, 15468, 14607, 14603,   244,\n","        22281,   122, 10596,  2250,   678, 14736,  2654,  7001, 21386, 16207,\n","        22281,   125, 15468, 14607, 14603,   244, 22281,   122, 10596,  2250,\n","          678, 14736,  2654,  7001, 21386, 16207, 22281,   125, 15468, 14607,\n","        14603,   244, 22281,   122, 10596,  2250,   678, 14736,  2654,  7001,\n","         1803,   102])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DpTtBX_DzBPM","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":987,"referenced_widgets":["43e1490ecc6746d394ad99b8d456b840","f6c7496e5e614512bf87689e63f51170","a085c92871d84b319f7827c4e9903932","1ace1b837df14d579d995c2b8a742b30","aae5a174f88246009ff1fc218328f36e","afdd2a38de4441f187587964b7aed651","d8f78a8d06b343baaa1c5d96f9e617e1","a42756168f0f4a9e8f8c7f2916763a21"]},"executionInfo":{"status":"ok","timestamp":1593635406041,"user_tz":180,"elapsed":322198,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"ca952c90-7337-4945-8495-63e2c95280d0"},"source":["# Tokenize all of the sentences and map the tokens to thier word IDs.\n","input_ids_test = []\n","attention_masks_test = []\n","\n","# For every sentence...\n","for sent in tqdm.notebook.tqdm(sentences_test):\n","    # `encode_plus` will:\n","    #   (1) Tokenize the sentence.\n","    #   (2) Prepend the `[CLS]` token to the start.\n","    #   (3) Append the `[SEP]` token to the end.\n","    #   (4) Map tokens to their IDs.\n","    #   (5) Pad or truncate the sentence to `max_length`\n","    #   (6) Create attention masks for [PAD] tokens.\n","    encoded_dict = bert_tokenizer.encode_plus(\n","                        sent,                      # Sentence to encode.\n","                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                        max_length = 512,           # Pad & truncate all sentences.\n","                        pad_to_max_length = True,\n","                        return_attention_mask = True,   # Construct attn. masks.\n","                        return_tensors = 'pt',     # Return pytorch tensors.\n","                        truncation='longest_first'\n","                   )\n","    \n","    # Add the encoded sentence to the list.    \n","    input_ids_test.append(encoded_dict['input_ids'])\n","    \n","    # And its attention mask (simply differentiates padding from non-padding).\n","    attention_masks_test.append(encoded_dict['attention_mask'])\n","\n","# Convert the lists into tensors.\n","input_ids_test = torch.cat(input_ids_test, dim=0)\n","attention_masks_test = torch.cat(attention_masks_test, dim=0)\n","\n","# Print sentence 0, now as a list of IDs.\n","print('Original: ', sentences_test[10])\n","print('Token IDs:', input_ids_test[10])"],"execution_count":18,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"43e1490ecc6746d394ad99b8d456b840","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=14130.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Original:  0 a 7 dígitos ou versão mais atual que sejam horizontal ou verticalmente relacionadas às atividades objeto da operação nas quais pelo menos um dos integrantes do grupo detenha participação igual ou superior a 10 no capital social ou votante na resposta apresente também o organograma da estrutura societária das em oresas ue se em uadram nesse critério grupo micro focus em 2015 as seguintes empresas do grupo micro focus obtiveram receitas no brasil confidencial grupo hpe as empresas registradas no brasil do grupo hpe são as seguintes confidencial 11 11 no que diz respeito às empresas referidas nas respostas aos itens 11 5 e 11 10 forneça uma lista dos membros dos seus órgãos de gestão que sejam igualmente membros dos órgãos de gestão ou de fiscalização de quaisquer outras empresas atuantes nas mesmas atividades econômicas conforme cnae 2 0 a 7 dígitos indicando tais em resas 10 106 versão pública de acordo com as melhores informações disponíveis para as requerentes não existem membros dos órgãos de gestão do grupo micro focus que também sejam membros dos órgãos de gestão de concorrentes do grupo hpe no brasil 11 106 versão pública etapa iii  elementos relativos ã operação iii 1 informe se esta notificação refere se à primeira apresentação caso negativo informe o motivo elo ual o ato está sendo rea resentado emendado tratase da primeira apresentação da operação ao cade iii 2 descreva a operação notificada indicando a se a operação projetada consiste em um a 1 fusão 2 aquisição de controle 3 aquisição de quotas ações sem aquisição de controle 4 consolidação de controle 5 aquisição de ativos 6 incorporação 7 joint venture clássica criação de empresa para explorar outro mercado 8 joint venture concentracionista criação de empresa para explorar mercado já explorado pelas empresas associadas 9 outra forma de operação não coberta pelas alternativas anteriores especificar b se a operação abrange total ou parcialmente as atividades das partes c o valor da operação e a forma de pagamento d no caso de aquisição de ativos todos esses ativos tangíveis e ou intangíveis no caso dos ativos tangíveis indicar também suas localizações endereço e cep e no caso de aquisição de participação societária o dispositivo da seção iii desta resolução no qual a operação se enquadra f a estrutura societária da empresa alvo antes e após a realização da operação ou da nova empresa formada as informações deste item devem ser ilustradas com a utilização de mapas organogramas ou diagramas apresentam se as informações a seguir destacadas em cinza exclusivamente na versão de acesso restrito da presente notificação nos termos do art 53 iv e vii da resolução cade nº 1 2012 a operação consiste na proposta\n","Token IDs: tensor([  101,  2297,   123,   977, 18988,   721,   291,  1619,   325,  2233,\n","          179,  4694, 17118,   291, 14357,   246,  8026,  1000,  2734,  4947,\n","          180,  4597,   529,  1647,   423,  1528,   222,   298,  5938,   171,\n","          939,  4343, 13808,  2490,  4209,   291,  2886,   123,  1193,   202,\n","         1855,  1979,   291,   962,  1383,   229,  4299,  1020, 22279,   407,\n","          146,  1157,  4009,   148,   180,  2388,  6128, 16313,   366,   173,\n","          438,  3511,   169, 22279,   176,   173,   169,   142,   288,  3876,\n","        14762,   939,  5768, 21989,   249,   173,  4155,   260,  2575,  2786,\n","          171,   939,  5768, 21989,   249, 16772, 14565,   202,  1010,   215,\n","        14809,  2346,   550,   939,   349,   269,   260,  2786, 18300,   202,\n","         1010,   215,   171,   939,   349,   269,   453,   260,  2575, 14809,\n","         2346,   550,  1433,  1433,   202,   179,  1331,  3953,  1000,  2786,\n","        12101, 22281,   529, 12566,   712,  8262,  1433,   732,   122,  1433,\n","         1193,  4049,   356,   230,  2925,   298,  1823,   298,   532,  6625,\n","          125,  4940,   179,  4694,  6643,  1823,   298,  6625,   125,  4940,\n","          291,   125, 21508,   125, 10631,  1028,  2786,  6475,   358,   529,\n","         7477,  2734,  9894,  4762,   127,   324, 22279,   245,  2297,   123,\n","          977, 18988,   721, 12418,  2571,   173,   398,   138,  1193, 20663,\n","         1619,  3352,   125,  1365,   170,   260,  2980,  3476,  6176,   221,\n","          260,  7854,   639,   346,  3572,  1823,   298,  6625,   125,  4940,\n","          171,   939,  5768, 21989,   249,   179,   407,  4694,  1823,   298,\n","         6625,   125,  4940,   125, 12340,   171,   939,   349,   269,   202,\n","         1010,   215,  1433, 20663,  1619,  3352,  5665,   254,  8561,   100,\n","         2769, 17140,   100,  4597,   254,  8561,   205,  9325, 22279,   176,\n","          418,   202,  6398,  2885,   176,   353,   681,  4689,  1652, 13582,\n","         9325, 22279,   146,  5607,  4129,   169,   162,   146,  5291,   698,\n","          660,  3655,   398,   796,   243,   173,  3870,   201,   100,   180,\n","          681,  4689,   180,  4597,   320,  6846, 22279,   254,  8561,   245,\n","         2731,   256,   123,  4597,   202, 10503,   285, 12418,   123,   176,\n","          123,  4597, 15471,  4159,   173,   222,   123,   205,  7175,   245,\n","         9588,   125,  2499,   511,  9588,   125, 20633,   470,  3680,   834,\n","         9588,   125,  2499,   678, 16255,   125,  2499,   732,  9588,   125,\n","        11242,   888, 18107,   977,  4141,  1129,  9427,  3750,  7301,  2203,\n","          125,  1799,   221, 11589,  1342,  2918,  1015,  4141,  1129,  9427,\n","         3750, 14777, 17177,  2203,   125,  1799,   221, 11589,  2918,   770,\n","        16556,   243,  1676,  2786, 11995,  1117,  1858,   547,   125,  4597,\n","          346, 13218,  1676, 14568,  3860, 17117, 22282,   235,   176,   123,\n","         4597,  9579,  1437,   291,  8501,   260,  2734,   366,  2844,   127,\n","          146,  2261,   180,  4597,   122,   123,   547,   125,  7855,   121,\n","          202,  1652,   125,  9588,   125, 11242,   944,  3636, 11242,  6736,\n","        22293,  1686,   122,   291, 18826,   833,  1686,   202,  1652,   298,\n","        11242,  6736, 22293,  1686, 13144,   407,   675,  7752,   315, 14441,\n","          122,  2992, 22291,   122,   202,  1652,   125,  9588,   125,  2490,\n","         6128, 16313,   146,  8985,   180,  8014,   254,  8561,  1014,  8287,\n","          202,   615,   123,  4597,   176, 12663,   124,   153,   123,  2388,\n","         6128, 16313,   180,  1799,  6568,  1075,   122,   790,   123,  5225,\n","          180,  4597,   291,   180,   940,  1799,  4946,   260,  3476,  2166,\n","        18685,  3921,   333,  6119,   591,   170,   123,  5353,   125, 12926,\n","         1157,  4009,   486,   291, 21885, 22281,  5464,   176,   260,  3476,\n","          123,  3866,  5873,   591,   173, 15811,  6856,   229,  1619,   125,\n","         2831, 19950,   180,  2981,   202,  6398,   538,  3401,   171,  1328,\n","        13383,   102])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"m9xvnrQsEBWI","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593635406672,"user_tz":180,"elapsed":322825,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["doc_chunk_dict_train = {}\n","\n","for doc, chunk in zip(docs_train, input_ids_train):\n","  if doc not in doc_chunk_dict_train:\n","    doc_chunk_dict_train[doc] = [chunk]\n","  else:\n","    doc_chunk_dict_train[doc].append(chunk)"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"TCIzS5e-HVVx","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593635406673,"user_tz":180,"elapsed":322824,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["doc_chunk_dict_test = {}\n","\n","for doc, chunk in zip(docs_test, input_ids_test):\n","  if doc not in doc_chunk_dict_test:\n","    doc_chunk_dict_test[doc] = [chunk]\n","  else:\n","    doc_chunk_dict_test[doc].append(chunk)"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"CR75VkbFxWfh","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593635407045,"user_tz":180,"elapsed":323194,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["del word_index\n","del inv_word_index\n","\n","del data_train_balanced_chunked\n","del data_test_chunked\n","\n","del data_train_balanced_chunked_splitted\n","del data_test_chunked_splitted\n","\n","del df_train_balanced_chunked_splitted\n","del df_test_chunked_splitted\n","\n","del X_train_balanced\n","del X_test\n","\n","del docs_train\n","del sentences_train\n","\n","del docs_test\n","del sentences_test"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"IvuuLs0c1VBv","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593635407046,"user_tz":180,"elapsed":323193,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["import gc"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"YI6Bhd47zD-b","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593635407047,"user_tz":180,"elapsed":323188,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"38a40ac6-5e68-481c-da61-94d136353015"},"source":["gc.collect()"],"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"id":"kLsdohrpHlJY","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":120,"referenced_widgets":["837d1e32ef324503b4629cd712166dc2","6d477d976ff64e06b6578516205eab57","bf3313db81e04a66b9f0092731845757","e1c077a2c5de4c0facf95909e099850b","16d6be1e9ebb49488d5efb8600b61da1","50a0e72fc2344edcb58dbf1952e30d05","e6d1164fbb124c2c9c99b0743d23db81","23079b3f8d764a25aea3cf5bd5767c50"]},"executionInfo":{"status":"ok","timestamp":1593636945483,"user_tz":180,"elapsed":1861618,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"31de43ab-d3c0-46be-eb43-ec6e341770b4"},"source":["train_last_layer_embeddings = {}\n","train_all_layers_embeddings = {}\n","train_cls_token_embeddings = {}\n","\n","bert_model.eval()\n","with torch.no_grad():\n","  for doc, sents in tqdm.notebook.tqdm(doc_chunk_dict_train.items()):\n","    for x in sents:\n","      r = bert_model(torch.tensor(x).unsqueeze(0).to(device))\n","      if doc not in train_last_layer_embeddings:\n","        train_last_layer_embeddings[doc] = torch.sum(r[0], dim=1).cpu()\n","        train_cls_token_embeddings[doc] = [r[1].cpu()]\n","        train_all_layers_embeddings[doc] = torch.sum(torch.stack(r[2]), dim=2).cpu()\n","      else:\n","        train_last_layer_embeddings[doc] += torch.sum(r[0], dim=1).cpu()\n","        train_cls_token_embeddings[doc].append(r[1].cpu())\n","        train_all_layers_embeddings[doc] += torch.sum(torch.stack(r[2]), dim=2).cpu()"],"execution_count":24,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"837d1e32ef324503b4629cd712166dc2","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=888.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  if __name__ == '__main__':\n"],"name":"stderr"},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zQ7Nc1eXwAcm","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1593636952990,"user_tz":180,"elapsed":1869120,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"3b5f9f9f-5655-450a-a8ba-7bf56dc90d4d"},"source":["with open('/content/drive/My Drive/Data Master/train_cls_token_embeddings_tail_fine_tuned_split' + str(str(n_split)) + '.pkl', 'wb') as file:\n","    pickle.dump(train_cls_token_embeddings, file)\n","\n","with open('/content/drive/My Drive/Data Master/train_last_layer_embeddings_tail_fine_tuned_split' + str(str(n_split)) + '.pkl', 'wb') as file:\n","    pickle.dump(train_last_layer_embeddings, file)\n","\n","with open('/content/drive/My Drive/Data Master/train_all_layers_embeddings_tail_fine_tuned_split' + str(str(n_split)) + '.pkl', 'wb') as file:\n","    pickle.dump(train_all_layers_embeddings, file)"],"execution_count":25,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n","  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"bkeoe_bVI8nD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":120,"referenced_widgets":["fffa0d5a27f24fb6a740419a8fdf29b4","3a15e0a567314123bc4cbbe69a4423b3","266c0ba45d0b42d09d9360ad37de066f","bd985b33ef1541878f124b60c1ac8792","83bc39542d804a75a489a573c0083ae3","b24e64791c404fcea9d0e69417bd3153","5cfdbe5db84b4ff3a003d15d5f7c3023","8f82e01c92ae4c0a94dee8bb5ac55920"]},"executionInfo":{"status":"ok","timestamp":1593637602233,"user_tz":180,"elapsed":2518357,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"fedb02ff-e543-460f-9b71-f418a415f52a"},"source":["test_last_layer_embeddings = {}\n","test_all_layers_embeddings = {}\n","test_cls_token_embeddings = {}\n","\n","bert_model.eval()\n","with torch.no_grad():\n","  for doc, sents in tqdm.notebook.tqdm(doc_chunk_dict_test.items()):\n","    for x in sents:\n","      r = bert_model(torch.tensor(x).unsqueeze(0).to(device))\n","      if doc not in test_last_layer_embeddings:\n","        test_last_layer_embeddings[doc] = torch.sum(r[0], dim=1).cpu()\n","        test_cls_token_embeddings[doc] = [r[1].cpu()]\n","        test_all_layers_embeddings[doc] = torch.sum(torch.stack(r[2]), dim=2).cpu()\n","      else:\n","        test_last_layer_embeddings[doc] += torch.sum(r[0], dim=1).cpu()\n","        test_cls_token_embeddings[doc].append(r[1].cpu())\n","        test_all_layers_embeddings[doc] += torch.sum(torch.stack(r[2]), dim=2).cpu()"],"execution_count":26,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fffa0d5a27f24fb6a740419a8fdf29b4","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=381.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  if __name__ == '__main__':\n"],"name":"stderr"},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ixAvMTh8JZSD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1593637606436,"user_tz":180,"elapsed":2522554,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"91c7b383-93ae-4a07-870b-3f6ade3119b4"},"source":["with open('/content/drive/My Drive/Data Master/test_cls_token_embeddings_tail_fine_tuned_split' + str(str(n_split)) + '.pkl', 'wb') as file:\n","    pickle.dump(test_cls_token_embeddings, file)\n","\n","with open('/content/drive/My Drive/Data Master/test_last_layer_embeddings_tail_fine_tuned_split' + str(str(n_split)) + '.pkl', 'wb') as file:\n","    pickle.dump(test_last_layer_embeddings, file)\n","\n","with open('/content/drive/My Drive/Data Master/test_all_layers_embeddings_tail_fine_tuned_split' + str(str(n_split)) + '.pkl', 'wb') as file:\n","    pickle.dump(test_all_layers_embeddings, file)"],"execution_count":27,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n","  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"Qbh-533qOJ2M","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593637606437,"user_tz":180,"elapsed":2522553,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["#TESTAR SEM FINE TUNING"],"execution_count":28,"outputs":[]}]}