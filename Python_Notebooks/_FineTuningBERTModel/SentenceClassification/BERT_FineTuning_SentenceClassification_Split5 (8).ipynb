{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of BERT_FineTuning_SentenceClassification_Split5 (8).ipynb","provenance":[{"file_id":"1jM_MQeWnqB4LrmlAc_rZ00W9zJK7Hw_d","timestamp":1590464112416}],"collapsed_sections":[],"authorship_tag":"ABX9TyNsOTcMWOyrCvOj7pTERTTD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"de35140f62cd4dd6bcd91379856c17ce":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_0214d514039f4ef8b76c690cae546902","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_75aeb33ae6ad4666bb0a8c483d5d7a2d","IPY_MODEL_18e01872c85e4298bce678b9a6ade0c8"]}},"0214d514039f4ef8b76c690cae546902":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"75aeb33ae6ad4666bb0a8c483d5d7a2d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_d83bbb74ac134251a39a9f30ecfe6190","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":712,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":712,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e1169bfa46dc419c90e10c4e91af07b1"}},"18e01872c85e4298bce678b9a6ade0c8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_0fe180a9efef49c9a6b7416c26fce56f","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 712/712 [00:14&lt;00:00, 50.80it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_32e9e61bcea64529a97c2d3ac6a3425c"}},"d83bbb74ac134251a39a9f30ecfe6190":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"e1169bfa46dc419c90e10c4e91af07b1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0fe180a9efef49c9a6b7416c26fce56f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"32e9e61bcea64529a97c2d3ac6a3425c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b2de172849cf402ba55212984eadbb26":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_2c21ce1e03334fcbbc247165a9983365","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_f1ee09299adc41009f808777b61c9289","IPY_MODEL_395e6522ccb04f018a3216637964c3ab"]}},"2c21ce1e03334fcbbc247165a9983365":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f1ee09299adc41009f808777b61c9289":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_07ed788f9fc14cc38a8c5d1966a00702","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":712,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":712,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_aa0e30105dd0447794a73d7805e12998"}},"395e6522ccb04f018a3216637964c3ab":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ed693fc35e74450784258c2f757267ad","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 712/712 [00:09&lt;00:00, 71.26it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3523add0ce4441dd9848a910062a37e6"}},"07ed788f9fc14cc38a8c5d1966a00702":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"aa0e30105dd0447794a73d7805e12998":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ed693fc35e74450784258c2f757267ad":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"3523add0ce4441dd9848a910062a37e6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"57ee43bddbff4653af287d494eca84c1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_fccb7e53b0fd4ceaad1affc8c670c7fb","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_3e6fd06f07ab4c3ea9cae1768480872f","IPY_MODEL_1ab3a18fd85a4b6c90c6e2c80a839b97"]}},"fccb7e53b0fd4ceaad1affc8c670c7fb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3e6fd06f07ab4c3ea9cae1768480872f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_c80e8cd5affc4f3d97f3dfe9243e0148","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":176,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":176,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a96c16cc05e74a43a46b6bf31a30f745"}},"1ab3a18fd85a4b6c90c6e2c80a839b97":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a19027e6f26444a6b4aa8e6de007052f","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 176/176 [00:05&lt;00:00, 30.35it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2dac301a5cbf4d98ab7e409e3eb78c9a"}},"c80e8cd5affc4f3d97f3dfe9243e0148":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"a96c16cc05e74a43a46b6bf31a30f745":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a19027e6f26444a6b4aa8e6de007052f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"2dac301a5cbf4d98ab7e409e3eb78c9a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e94005367fd84fdebf1bf65dfd21c128":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_f2cb504cb764469798e3858e472b1739","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_3b54acbe5d9644d18c8bcb7802c1f1c4","IPY_MODEL_e7b2902a365846bb998e80fbbb0a7afd"]}},"f2cb504cb764469798e3858e472b1739":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3b54acbe5d9644d18c8bcb7802c1f1c4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_d21e353e066742da9d18ac8870b3a8c9","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":176,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":176,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_41a9142b46a94d3b8b5a83f3ef01daf5"}},"e7b2902a365846bb998e80fbbb0a7afd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_bb68d26f3a3a451abb2cd221b4f1067c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 176/176 [00:04&lt;00:00, 36.89it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f67eea21602c4e2697f1a15aa86e785c"}},"d21e353e066742da9d18ac8870b3a8c9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"41a9142b46a94d3b8b5a83f3ef01daf5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bb68d26f3a3a451abb2cd221b4f1067c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f67eea21602c4e2697f1a15aa86e785c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"KWy32B6i5zUX","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593632884024,"user_tz":180,"elapsed":1460,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"2f4b9d1c-9a10-4880-c5fd-d4afd3a418e5"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tLrptDIu6E6A","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593632884576,"user_tz":180,"elapsed":2004,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["n_split = 5"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"uCC2fopD6JTj","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593632884576,"user_tz":180,"elapsed":1999,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["import pickle\n","import numpy as np"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"LXHTiUtW6MJX","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593632885483,"user_tz":180,"elapsed":2902,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["with open('/content/drive/My Drive/Data Master/X_train_final', 'rb') as file:\n","    X_train_valid = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/Y_train_final', 'rb') as file:\n","    Y_train_valid = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/word_index_final', 'rb') as file:\n","    word_index = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/train_index_final_split_' + str(n_split), 'rb') as file:\n","    train_index = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/valid_index_final_split_' + str(n_split), 'rb') as file:\n","    valid_index = pickle.load(file)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"wNkyOT_HUgwN","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593632886032,"user_tz":180,"elapsed":3446,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["X_train = list(np.array(X_train_valid)[train_index])\n","X_valid = list(np.array(X_train_valid)[valid_index])\n","Y_train = list(np.array(Y_train_valid)[train_index])\n","Y_valid = list(np.array(Y_train_valid)[valid_index])"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"7cw3aVs0tNYu","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593632886033,"user_tz":180,"elapsed":3442,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["inv_word_index = {ix : w for w, ix in word_index.items()}"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"9hORlMAi41vy","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":340},"executionInfo":{"status":"ok","timestamp":1593632889451,"user_tz":180,"elapsed":6854,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"7c26c761-15ab-4db2-8180-795d37fe31ba"},"source":["!pip install transformers"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (3.0.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: tokenizers==0.8.0-rc4 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8.0rc4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.91)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.12.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.15.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FpY7GFWU6TLg","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593632892593,"user_tz":180,"elapsed":9989,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["import pandas as pd\n","import numpy as np\n","import itertools\n","\n","import torch\n","import torch.nn as nn\n","import transformers\n","import torch.utils.data as tdata\n","import torch.optim as optim\n","\n","import tqdm"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"vgxq4EIuEpg3","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593632892593,"user_tz":180,"elapsed":9985,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["from transformers import AutoModel, AutoTokenizer, BertForSequenceClassification"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"FDhmJ8RY4-St","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593632892594,"user_tz":180,"elapsed":9981,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"ePBFYDYE5Io9","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"executionInfo":{"status":"ok","timestamp":1593632902569,"user_tz":180,"elapsed":19949,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"180047ca-80d6-44ca-f591-70b867c2045f"},"source":["bert_tokenizer = AutoTokenizer.from_pretrained('neuralmind/bert-base-portuguese-cased')\n","#bert_model = BertForSequenceClassification.from_pretrained('neuralmind/bert-large-portuguese-cased').to(device)\n","bert_model = BertForSequenceClassification.from_pretrained(\n","    'neuralmind/bert-base-portuguese-cased', # Use the 12-layer BERT model, with an uncased vocab.\n","    num_labels = 2, # The number of output labels--2 for binary classification.\n","                    # You can increase this for multi-class tasks.   \n","    output_attentions = False, # Whether the model returns attentions weights.\n","    output_hidden_states = False, # Whether the model returns all hidden-states.\n",")"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Some weights of the model checkpoint at neuralmind/bert-base-portuguese-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at neuralmind/bert-base-portuguese-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"oRoJELU4uKD5","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593632902569,"user_tz":180,"elapsed":19942,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["def get_text_head(sent, head_size = 500):\n","  res = []\n","  res.append(sent[:head_size])\n","  return res\n","\n","def get_text_tail(sent, tail_size = 500):\n","  res = []\n","  res.append(sent[-tail_size:])\n","  return res"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"DUkQ_nwFFNyD","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593632904493,"user_tz":180,"elapsed":21862,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["data_train_chunked_head = [(i, get_text_head([inv_word_index[ix] for ix in X_train[i]]), Y_train[i]) for i, d in enumerate(X_train)]\n","data_valid_chunked_head = [(i, get_text_head([inv_word_index[ix] for ix in X_valid[i]]), Y_valid[i]) for i, d in enumerate(X_valid)]\n","\n","data_train_chunked_tail = [(i, get_text_tail([inv_word_index[ix] for ix in X_train[i]]), Y_train[i]) for i, d in enumerate(X_train)]\n","data_valid_chunked_tail = [(i, get_text_tail([inv_word_index[ix] for ix in X_valid[i]]), Y_valid[i]) for i, d in enumerate(X_valid)]"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZIT-ZGCdFRHF","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593632904494,"user_tz":180,"elapsed":21858,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["data_train_chunked_splitted_head = [(i, [\" \".join(subsent) for subsent in chunked_sent], y) for i, chunked_sent, y in data_train_chunked_head]\n","data_valid_chunked_splitted_head = [(i, [\" \".join(subsent) for subsent in chunked_sent], y) for i, chunked_sent, y in data_valid_chunked_head]\n","\n","data_train_chunked_splitted_tail = [(i, [\" \".join(subsent) for subsent in chunked_sent], y) for i, chunked_sent, y in data_train_chunked_tail]\n","data_valid_chunked_splitted_tail = [(i, [\" \".join(subsent) for subsent in chunked_sent], y) for i, chunked_sent, y in data_valid_chunked_tail]"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"HpgTgXR2mbOz","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593632904494,"user_tz":180,"elapsed":21854,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["df_train_chunked_splitted_head = pd.DataFrame(\n","    list(itertools.chain.from_iterable([[[doc, c, y] for c in chunks] for doc, chunks, y in data_train_chunked_splitted_head])),\n","    columns=['doc', 'chunk', 'FgOrdinario'])\n","\n","df_valid_chunked_splitted_head = pd.DataFrame(\n","    list(itertools.chain.from_iterable([[[doc, c, y] for c in chunks] for doc, chunks, y in data_valid_chunked_splitted_head])),\n","    columns=['doc', 'chunk', 'FgOrdinario'])\n","\n","df_train_chunked_splitted_tail = pd.DataFrame(\n","    list(itertools.chain.from_iterable([[[doc, c, y] for c in chunks] for doc, chunks, y in data_train_chunked_splitted_tail])),\n","    columns=['doc', 'chunk', 'FgOrdinario'])\n","\n","df_valid_chunked_splitted_tail = pd.DataFrame(\n","    list(itertools.chain.from_iterable([[[doc, c, y] for c in chunks] for doc, chunks, y in data_valid_chunked_splitted_tail])),\n","    columns=['doc', 'chunk', 'FgOrdinario'])"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q5LHi_yarFV-","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593632904495,"user_tz":180,"elapsed":21850,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["sentences_train_head = df_train_chunked_splitted_head.chunk.values\n","sentences_train_tail = df_train_chunked_splitted_tail.chunk.values\n","labels_train = df_train_chunked_splitted_head.FgOrdinario.values\n","\n","sentences_valid_head = df_valid_chunked_splitted_head.chunk.values\n","sentences_valid_tail = df_valid_chunked_splitted_tail.chunk.values\n","labels_valid = df_valid_chunked_splitted_head.FgOrdinario.values"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"ScaOKppIrLoC","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["de35140f62cd4dd6bcd91379856c17ce","0214d514039f4ef8b76c690cae546902","75aeb33ae6ad4666bb0a8c483d5d7a2d","18e01872c85e4298bce678b9a6ade0c8","d83bbb74ac134251a39a9f30ecfe6190","e1169bfa46dc419c90e10c4e91af07b1","0fe180a9efef49c9a6b7416c26fce56f","32e9e61bcea64529a97c2d3ac6a3425c"]},"executionInfo":{"status":"ok","timestamp":1593632908475,"user_tz":180,"elapsed":25824,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"f8e86ca0-2669-4225-bb6b-90cc7fbcc912"},"source":["# Tokenize all of the sentences and map the tokens to thier word IDs.\n","input_ids_train_head = []\n","attention_masks_train_head = []\n","\n","# For every sentence...\n","for sent in tqdm.notebook.tqdm(sentences_train_head):\n","    # `encode_plus` will:\n","    #   (1) Tokenize the sentence.\n","    #   (2) Prepend the `[CLS]` token to the start.\n","    #   (3) Append the `[SEP]` token to the end.\n","    #   (4) Map tokens to their IDs.\n","    #   (5) Pad or truncate the sentence to `max_length`\n","    #   (6) Create attention masks for [PAD] tokens.\n","    encoded_dict = bert_tokenizer.encode_plus(\n","                        sent,                      # Sentence to encode.\n","                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                        pad_to_max_length = True,\n","                        return_attention_mask = True,   # Construct attn. masks.\n","                        return_tensors = 'pt',     # Return pytorch tensors.\n","                   )\n","    \n","    # Add the encoded sentence to the list.    \n","    input_ids_train_head.append(encoded_dict['input_ids'])\n","    \n","    # And its attention mask (simply differentiates padding from non-padding).\n","    attention_masks_train_head.append(encoded_dict['attention_mask'])"],"execution_count":17,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"de35140f62cd4dd6bcd91379856c17ce","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=712.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IyhujdKuAQ4t","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["b2de172849cf402ba55212984eadbb26","2c21ce1e03334fcbbc247165a9983365","f1ee09299adc41009f808777b61c9289","395e6522ccb04f018a3216637964c3ab","07ed788f9fc14cc38a8c5d1966a00702","aa0e30105dd0447794a73d7805e12998","ed693fc35e74450784258c2f757267ad","3523add0ce4441dd9848a910062a37e6"]},"executionInfo":{"status":"ok","timestamp":1593632912723,"user_tz":180,"elapsed":30064,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"f7741257-3f18-441f-e034-07bf0b46de4e"},"source":["# Tokenize all of the sentences and map the tokens to thier word IDs.\n","input_ids_train_tail = []\n","attention_masks_train_tail = []\n","\n","# For every sentence...\n","for sent in tqdm.notebook.tqdm(sentences_train_tail):\n","    # `encode_plus` will:\n","    #   (1) Tokenize the sentence.\n","    #   (2) Prepend the `[CLS]` token to the start.\n","    #   (3) Append the `[SEP]` token to the end.\n","    #   (4) Map tokens to their IDs.\n","    #   (5) Pad or truncate the sentence to `max_length`\n","    #   (6) Create attention masks for [PAD] tokens.\n","    encoded_dict = bert_tokenizer.encode_plus(\n","                        sent,                      # Sentence to encode.\n","                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                        return_attention_mask = True,   # Construct attn. masks.\n","                        return_tensors = 'pt',     # Return pytorch tensors.\n","                   )\n","    \n","    # Add the encoded sentence to the list.    \n","    input_ids_train_tail.append(encoded_dict['input_ids'])\n","    \n","    # And its attention mask (simply differentiates padding from non-padding).\n","    attention_masks_train_tail.append(encoded_dict['attention_mask'])"],"execution_count":18,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b2de172849cf402ba55212984eadbb26","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=712.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"TlVUDKvLAQxO","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593632912723,"user_tz":180,"elapsed":30057,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["input_ids_train = torch.cat([torch.cat([h[:,:128], t[:,-384:]], dim=1) for h, t in zip(input_ids_train_head, input_ids_train_tail)])\n","attention_masks_train = torch.cat([torch.cat([h[:,:128], t[:,-384:]], dim=1) for h, t in zip(attention_masks_train_head, attention_masks_train_tail)])\n","labels_train = torch.tensor(labels_train)"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"pPmKdyJ0AQmz","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593632912724,"user_tz":180,"elapsed":30052,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"abbb06ab-cf97-437c-85de-2743635084c6"},"source":["input_ids_train.shape"],"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([712, 512])"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"8LzCfyg3AQdr","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593632912724,"user_tz":180,"elapsed":30044,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"1b794fbe-4d51-4d27-d3a3-743d67ea8218"},"source":["attention_masks_train.shape"],"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([712, 512])"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"id":"PrHwGqtPLStR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":938},"executionInfo":{"status":"ok","timestamp":1593632912725,"user_tz":180,"elapsed":30037,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"f1cfecc6-8d3a-45d6-8b44-f34418b18fdf"},"source":["# Print sentence 0, now as a list of IDs.\n","print('Original: ', sentences_train_head[10], sentences_train_tail[10])\n","print('Token IDs:', input_ids_train[10])"],"execution_count":22,"outputs":[{"output_type":"stream","text":["Original:  ao conselho administrativo de defesa económica  cade superintendéncia geral do cade  sg m dias branco s a indústria e comercio de alimentos 'mdb ou compradora sociedade anônima de capital aberto inscrita no cadastro nacional da pessoa jurídica cnpj mf sob nº 07 206 816 0001 15 com sede em jabuti estado no ceará na rodovia br116 km 18 cep º 61 760 000 e indústria de produtos alimentícios piraquê s a piraquê ou vendedora e seus acionistas sociedade anônima de capital fechado com sede na cidade do rio de janeiro estado do rio de janeiro na rua leopoldino de oliveira 335 turiaçu cep nº 21360060 conjuntamente requerentes por meio de seus advogados que estas subscrevem vêm respeitosamente nos termos do artigo 88 da lei nº 12 529 2011 e da resolução cade nº 01 2012 anexo i e resolução 02 2012 anexo ii submeter ao conselho administrativo de defesa econômica cade o presente ato de concentração económica consubstanciado no contrato de compra e venda de ações e outras avenças assinado na data de 29 de janeiro de 2018 f 1 das partes a mdb é uma empresa brasileira que atua no ramo alimentício presente em todo o território nacional a mdb é ativa principalmente na fabricação e comercialização de biscoitos e massas atuando também nos segmentos de torradas moagem de trigo margarina bolos salgadinhos e mistura para bolos a piraquê também é uma empresa brasileira que atua no ramo alimentício através da fabricação e comercialização de massas biscoitos e refrescos 2 da presente operação tratase da aquisição pela mdb de 100 das ações ordinárias nominativas de emissão da piraquê ou representativas da integralidade do capital social da piraquê a operação proposta gerará sobreposições horizontais nos mercados de biscoitos e massas e possíveis integrações verticais entre os mercados de i farinha e massas ii farinha e biscoito e iii gordura vegetal e biscoitos outra consequência da operação proposta será a entrada da mdb no mercado de refrescos que será irrelevante por conta da pequena participação de mercado detida pela piraquê e em última análise representará uma mera substituição de agente econômico com relação à análise concorrencial dos pontos acima as concentrações e integrações decorrentes da operação proposta são incapazes de gerar qualquer tipo de preocupação concorrencial conforme será demonstrado no formulário de notificação 3 dos documentos anexos as requerentes pugnam pela juntada aos autos dos documentos abaixo relacionados i  m iv v w vii viii ix xi xii xiii xiv versão pública do formulário procedimento sumário em conformidade com as resoluções nº 2 2012 e nº 9 2014 versão de acesso restrito do formulário procedimento ordinário em conformidade com as resoluções nº 2 2012 e 9 2014 acesso restrito cópias dos comprovantes de pagamento da taxa processual devida ao cade no valor total de r 85 000 00 oitenta e cinco mil reais nos termos do art 110 do regimento interno do cade resolução nº 1 2012 anexo público n 01 cópia da procuração outorgada por mdb anexo de contrapartida 50 670 60 vigência 28 12 2015 a 02 02 2019 data de assinatura 07 02 2018 assina pelo ministerio da justica carlos felipe alencastro fernandes de carvalho diretor geral j oão alberto tomacheski departamento de polícia federal extrato do contrato nº 3 2018 uasg 200334 processo 08200000021201818 pregão srp nº 1 2017 contratante ministerio da justica e seguranca publica cnpj contratado 01017250000105 contratado voetur turismo e representacoes ltda objeto contratacao de serviços de agenciamento de viagens para voos domesticos conforme pregao 01 2017 mpgo fundamento legal lei 10520 2002 e 8666 1993 e suas alteracoes vigência 31 01 2018 a 31 01 2019 valor total r 768 231 68 fonte 100000000 2018ne800078 fonte 174020227 2018ne800075 fonte 100000000 2018ne800064 fonte 100000000 2018ne800065 fonte 100000000 2018ne800066 fonte 100000000 2018ne800067 fonte 100000000 2018ne800068 fonte 100000000 2018ne800069 fonte 100000000 2018ne800070 fonte 174020227 2018ne800071 fonte 174020227 2018ne800072 fonte 174020227 2018ne800073 fonte 174020227 2018ne800074 fonte 174020227 2018ne800076 fonte 174020227 2018ne800077 data de assinatura 31 01 2018 sicon 07 02 2018 200334 00001 2018ne000019 diretoria técnico científica instituto nacional de criminalística aviso de alteração concorrencia nº 1 2018 comunicamos que o edital da licitação supracitada publicada no dou de 30 01 2018 foi alterado objeto contratação de empresa de engenharia especializada em instalações reforma e equipamentos inerentes à 3ª parcela da reforma e ampliação do instituto nacional de criminalística com a implantação do centro nacional de difusão de ciências forenses conforme condições quantidades e exigências estabelecidas no edital total de itens licitados 00001 novo edital 08 02 2018 das 09h00 às 12h00 e de13h00 às 17h00 endereço setor de areas isoladas sul quadra 07 lotes 9 10 asa sul brasilia df entrega das propostas 13 03 2018 às 09h00 amaury alan martins de souza junior diretor técnico cicntíflco sidec 07 02 2018 200406 00001 2018ne800003 retificação no extrato de contrato nº 34 2017 publicado no do de 07 02 2018 seção 3 pág 100 onde se lê vigência 07 02 2018 a 07 02 2018 leia se vigência 07 02 2018 a 07 02 2019 sicon 07 02 2018 200406 00001 2018ne800003 diretoria de administração e logística policial coordenação de administração divisão de licitacoes e contratos serviço de contratos e convenios extrato de contrato termo de compromisso processo 08375 008071 2017 61 partes superintendência regional do departamento polícia federal do estado da paraíba cnpj 00 394 494 0031 51 e imprensa nacional cnpj 04 196 645 0001 00 objeto prestação de serviços de publicação de matérias de caráter oficial nas edições normais e extras do diário oflcial da união valor estimado r 10 320 00 dez mil trezentos e vinte reais fundamento legal lei º 8 666 93 vigência 01 01 2018 a 31 12 2018 assinatura 22 de dezembro de 2017 n data da este documento pode ser verificado no endereço eletrônico http www in govbr eutenticidade hrml pelo código 00032018020800083 documento assinado digitalmente conforme mp nº 2 200 2 de 24 08 2001 que institui infraestrutura de chaves públicas brasileira icp brasil\n","Token IDs: tensor([  101,   320,  6865, 13233,   125,  3573, 14662,   100,  6846, 22279,\n","         1229,  1017,   158,  3423,   351,  1250,   171,  6846, 22279,   100,\n","          139, 22293,   174,  1564,  4712,   139,   123,  3807,   122,  1847,\n","          523,   125,  6571,   100,   112,   174, 22284, 22295,   291,   100,\n","         2707,   360, 15962,   125,  1855,  5370,  5813,   154,   202, 22150,\n","          552,  1772,   180,  2760, 10629,   127, 22285, 22291, 22314,   174,\n","        22294,   425,   100, 18506,   297, 22338, 18064, 22338,  6324, 22302,\n","          997,   170,  2496,   173,  1941,   694,   193,  1177,   202,  2992,\n","         2732,   229, 12951,   100,  2150,   542,  2992, 22291,   100, 16915,\n","        16444, 22307,  6324,   122,  3807,   125,  3169,  9177,  2580,  8685,\n","        20971,   139,   123,   100,   291,   100,   122,   532, 12280,   676,\n","         2707,   360, 15962,   125,  1855, 10371,   170,  2496,   229,   651,\n","          171,  2187,   125,  1543,  1177,   171,  2187,   125, 14609,  1772,\n","          125, 18939,  2117,   170,   123,  9158,   171,  1997,  1772,   125,\n","        13934,   125,  8670,   344,  4604,  4762,  2955, 10393,   122, 14281,\n","        15066,   202,   902,  1013,  1437,   125,  8262,  4073,  5760,  6324,\n","         2051,  1160,   902,  1013, 16394, 16956,  6437,   366, 17791, 22296,\n","          554,  1000,  1242, 22296,   554,   122,   125,  7793, 22296,   554,\n","         1000,  1040, 22296,   554, 14441,  4572,   125, 12346,   138, 21888,\n","         1567, 14142, 18506, 22037,  1117,  1193, 14114,  1567,  1010,  4146,\n","          121, 22294,  9358,   366,  8658,  1492, 19148,  6437,  1000, 17791,\n","        22296,   554,  3330,  7966,  6603, 22285,   528, 20157,   125,  7206,\n","          852, 17267,   414,  2481,  4022,  3131,   129,  1913, 22290,   303,\n","          898,   272, 22289, 18506, 16956,  6437,  4591, 22307, 22338,  6324,\n","         2051,  6437,   514, 21702,   554, 22335,  2582,  9818,   202,  3084,\n","          183,   125,  3031,   100,  8047,  5096,  3565,   202,   171,   125,\n","        18506, 16956,  6437,  8014,   511,  4592,  2334,   582,   176, 19267,\n","         3459,   399, 18506, 16956,  6437,   123, 18506, 16956,  6437,  2241,\n","        22278,   176,  3459,   399, 18506, 16956,  6437,   123, 18506, 16956,\n","        13625,   898,   865, 18506, 16956,  6437,  4591, 22307, 22338,  6324,\n","         2051,  6437,   514, 21702,   554, 22335, 11896,   125,  3918,   122,\n","        19890,  8132, 14531,   125,  3918,  3007,   125,  4073,   343,   303,\n","          143,   122, 11725,  2576,   125, 11725,   122,  3038,   501,  3084,\n","          183,   125,  3031,  2476,   125, 11798,  1673, 16394,  9330, 22334,\n","        14736,  5067, 22337, 22302,  5096, 16915,  2844,  1229,  1017, 21245,\n","         6570,   171,  8040,  4522,  4015,   171,  1177,   180,   221,  5983,\n","          127, 22285, 22291, 22314, 14736,  9331, 22336,  9501, 22336, 14736,\n","        12763, 13633,   122,  4471,  1772,   127, 22285, 22291, 22314, 16720,\n","          970, 10140, 22334,  6324, 22302, 14736,  4947, 15498,   125,  2654,\n","          125,  4733,   125, 12556,   125,  5571,  1538,   529,  5596, 13998,\n","          122, 17499,   171, 10635,   586, 22290,   550,   180,  6350,  2261,\n","        14031,  1335,  1193,  5875, 22307, 14736,  1027,   592,  9967,   850,\n","          122,  4698,  4420,  2807,   310,  7103,  2241,   100,  1015, 15672,\n","        22338, 20693,  3459,   399, 13778, 13778,  6437,   123,  3199,  1242,\n","         6437,  8526,  2336,   125,  1512,   125,  5096,   149,  2788,   180,\n","          860,  6875,   706,   333, 19586,   243,   202, 14441, 10660, 14305,\n","         2702, 11740,   238,  3746, 22292,  1197,  2779, 10246,  4625,   349,\n","        22282, 22287, 22290,   423,  5552,  6324,  9304,  2051,  5067,  4533,\n","        21702, 22212, 22335,  6875,  8210,  4876,   246,  4762,   174, 22291,\n","          100,   245,   422,   245,   125,  2235, 16394,  5568,   179,  2035,\n","        22283, 10352,   125, 15947,  5449,  2509,   254, 22289, 22291,  1010,\n","          215,   102])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NHFUuvXUrLfr","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["57ee43bddbff4653af287d494eca84c1","fccb7e53b0fd4ceaad1affc8c670c7fb","3e6fd06f07ab4c3ea9cae1768480872f","1ab3a18fd85a4b6c90c6e2c80a839b97","c80e8cd5affc4f3d97f3dfe9243e0148","a96c16cc05e74a43a46b6bf31a30f745","a19027e6f26444a6b4aa8e6de007052f","2dac301a5cbf4d98ab7e409e3eb78c9a"]},"executionInfo":{"status":"ok","timestamp":1593632913167,"user_tz":180,"elapsed":30471,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"5bdb6fd6-89e3-4913-a159-4e05ba2b08d5"},"source":["# Tokenize all of the sentences and map the tokens to thier word IDs.\n","input_ids_valid_head = []\n","attention_masks_valid_head = []\n","\n","# For every sentence...\n","for sent in tqdm.notebook.tqdm(sentences_valid_head):\n","    # `encode_plus` will:\n","    #   (1) Tokenize the sentence.\n","    #   (2) Prepend the `[CLS]` token to the start.\n","    #   (3) Append the `[SEP]` token to the end.\n","    #   (4) Map tokens to their IDs.\n","    #   (5) Pad or truncate the sentence to `max_length`\n","    #   (6) Create attention masks for [PAD] tokens.\n","    encoded_dict = bert_tokenizer.encode_plus(\n","                        sent,                      # Sentence to encode.\n","                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                        pad_to_max_length = True,\n","                        return_attention_mask = True,   # Construct attn. masks.\n","                        return_tensors = 'pt',     # Return pytorch tensors.\n","                   )\n","    \n","    # Add the encoded sentence to the list.    \n","    input_ids_valid_head.append(encoded_dict['input_ids'])\n","    \n","    # And its attention mask (simply differentiates padding from non-padding).\n","    attention_masks_valid_head.append(encoded_dict['attention_mask'])"],"execution_count":23,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"57ee43bddbff4653af287d494eca84c1","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=176.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"teTPrvcPA1OM","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["e94005367fd84fdebf1bf65dfd21c128","f2cb504cb764469798e3858e472b1739","3b54acbe5d9644d18c8bcb7802c1f1c4","e7b2902a365846bb998e80fbbb0a7afd","d21e353e066742da9d18ac8870b3a8c9","41a9142b46a94d3b8b5a83f3ef01daf5","bb68d26f3a3a451abb2cd221b4f1067c","f67eea21602c4e2697f1a15aa86e785c"]},"executionInfo":{"status":"ok","timestamp":1593632914625,"user_tz":180,"elapsed":31921,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"4eda3a78-221d-4254-8009-fad398afab77"},"source":["# Tokenize all of the sentences and map the tokens to thier word IDs.\n","input_ids_valid_tail = []\n","attention_masks_valid_tail = []\n","\n","# For every sentence...\n","for sent in tqdm.notebook.tqdm(sentences_valid_tail):\n","    # `encode_plus` will:\n","    #   (1) Tokenize the sentence.\n","    #   (2) Prepend the `[CLS]` token to the start.\n","    #   (3) Append the `[SEP]` token to the end.\n","    #   (4) Map tokens to their IDs.\n","    #   (5) Pad or truncate the sentence to `max_length`\n","    #   (6) Create attention masks for [PAD] tokens.\n","    encoded_dict = bert_tokenizer.encode_plus(\n","                        sent,                      # Sentence to encode.\n","                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                        return_attention_mask = True,   # Construct attn. masks.\n","                        return_tensors = 'pt',     # Return pytorch tensors.\n","                   )\n","    \n","    # Add the encoded sentence to the list.    \n","    input_ids_valid_tail.append(encoded_dict['input_ids'])\n","    \n","    # And its attention mask (simply differentiates padding from non-padding).\n","    attention_masks_valid_tail.append(encoded_dict['attention_mask'])"],"execution_count":24,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e94005367fd84fdebf1bf65dfd21c128","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=176.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"TOLsAOT5A1GR","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593632914626,"user_tz":180,"elapsed":31914,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["input_ids_valid = torch.cat([torch.cat([h[:,:128], t[:,-384:]], dim=1) for h, t in zip(input_ids_valid_head, input_ids_valid_tail)])\n","attention_masks_valid = torch.cat([torch.cat([h[:,:128], t[:,-384:]], dim=1) for h, t in zip(attention_masks_valid_head, attention_masks_valid_tail)])\n","labels_valid = torch.tensor(labels_valid)"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"hTVq1davA0_J","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593632914627,"user_tz":180,"elapsed":31908,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"c91596b4-6538-4940-cc20-ddba3ce63c95"},"source":["input_ids_valid.shape"],"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([176, 512])"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"code","metadata":{"id":"Lk2WfHR_A07X","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593632914627,"user_tz":180,"elapsed":31901,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"07e32e6a-8fab-4c77-b3ca-78eb82952682"},"source":["attention_masks_valid.shape"],"execution_count":27,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([176, 512])"]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"code","metadata":{"id":"4cQY90AWLmWh","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":938},"executionInfo":{"status":"ok","timestamp":1593632914628,"user_tz":180,"elapsed":31894,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"7a9f562f-50ba-41f7-b4e2-d6aed2b06c53"},"source":["print('Original: ', sentences_valid_head[10], sentences_valid_tail[10])\n","print('Token IDs:', input_ids_valid[10])"],"execution_count":28,"outputs":[{"output_type":"stream","text":["Original:  stocche forbes ilustríssimo senhor eduardo frade rodrigues superintendente geral do conselho administrativo de defesa económica cade brazil steel investimentos e participaçóes s a brazil steel sociedade por ações de capital fechado devidamente constituída e existente de acordo com as 3 i ' 5 leis da república federativa do brasil com sede na cidade de são paulo estado de são paulo º na avenida cidade jardim nº 803 9º andar sala c cep 01453 000 inscrita no cnpj mf sob 0 número 20 512 148 0001 12 dánica termoindustrial brasil s a dánica brasil 'é sociedade por ações de capital fechado devidamente constituída e existente de acordo com asªs leis da república f ederativa do brasil com sede na cidade de joinville estado de santa catatinaãã na rua noruega nº 99 boa vista inscrita no cnpj mf sob o número 42 506 618 0001 78 e zípco sistemas construtivos s a zipco sociedade por ações de capital fechadofiíª r devidamente constituída e existente de acordo com as lels da repubhca federativa do brasmªª com sede no município de paulista estado de pernambuco na br 101 norte s n km 53 8 galpão a l centro empresarial inscrita no cnpj mf sob o nº 08 274 949 0001 91 por seusf'â é advogados submetem à apreciação do conselho administrativo de defesa econômica cade em observância aos artigos 53 88 e 90 da lei nº 12 529 de 30 de novembro de 2011 a operação de reestruturação societám'a que resultará na consolidação das atividades e negócios delª ' dãnica brasil e da zipco em uma única sociedade requer se inicialmente que a presente operação seja analisada por meio de procedimento sumário nos termos do artigo 8º iii v e vi da resolução nº 2 2012 do cade e pelas razões expostas nos documentos e infomações contidos nesta notificação incluindose o anexo ii seja aprovada sem restrições pelo superintendente geral do cade nos termos do art 57 inciso i da lei nº 12 529 11 devido à inexistência de riscos à concorrência dela decorrentes requerse ademais de acordo com o artigo 53 incisos ii iii iv vi vii viii ix x e xiv da resolução nº 1 do cade o deferimento de acesso restrito às informações e documentos destacados em cinza nos itens 11 1 11 4 11 5 11 8 11 9 111 2 3 111 2 são paulo rio de janeiro centro empresarial cidade jardim rua da assembleia 10 sala 3201 av magalhães de castro 4800 18º andar torre 2 edifício park tower 2001 1901 centro rio de janeiro rj 05676 120 são paulo sp 55 11 3755 5400 ' 55 21 3974 1250 stoccheforbes com br 107793 sv2 stocche forbes c 1112 f 111 6 iv 1 e vi 2 do anexo ii formulário procedimento sumário esses dados têm caráter estratégico e a divulgação a terceiros sobretudo concorrentes pode resultar em sérios prejuízos às empresas a versão completa da notificação bem como os documentos de acesso restrito estão sendo apresentados em de telefone e fax e endereço eletrônico parte a investidor não aplicável parte b  incogporadora estão indicados a seguir os dados de contato das entidades de classe de que a dânica brasil é membro no brasil en'l'idades de classe denominação social dados de contato av brig faria lima 1931 9º andar associação brasileira da constru 01452 000  são paulo  sp ção metálica www abcemorgbr mvwconsu'umetalcombr ' veja a esse respeito a publicação 20 147 peng da cadeia pt'o i'i livu ía comtmyãa ln indliyl izz le aízzteriaíx e equipa men ax disponível em htt www abram or br site lista 11 secaoi9 página 16 stocche forbes entidades m cmssra denominação social associação brasileira de máqui dados de contato avenida jabaquara 2925 04045902  são paulo  sp http www abimaq org br rua sebastião humel 171 sala 402 sociedade brasileira de controle centro de contaminação 12210200  sãojosé dos campos  sp http sbcc com br nas e equipamentos rua samuel morse 74 º andar assoclação brasúelra de shopplng 04576060  sao paulo  sp httpz www p0rtaldoshoppmg com br avenida dos ferroviários 573 sala 03 associação brasileira da indústria vila xavier centers de armazenagem ftigoriflcada 14810 214 araraquara  sp http wmv abiaf org br parte c incogporada estão indicados a seguir os dados de contato da única entidade de classe de que zipco membro no brasil entidades mº classe denominação socw dados de contato av brig faria lima 1931 9º andar 014520001  são paulo  sp contatos fátima financeiro tel 11 38166597 11 38165530 patrícia nunes davidsohn diretora executiva tel 55 11 38166597 www abcemorgbr associação brasileira da constru ção metálica www cons trumetalcombr stocche forbes etapa vii obsi«liwa r 15 finais vii 1 apresente quaisquer outros comentários ou informações que julgue relevantes para a análise da operação as requerentes solicitam que correspondências relacionadas ao presente ato de concentração sejam remetidas aos advogados abaixo indicados stocche forbes padís filizzola clápis passaro meyer e reflnetti advogados av magalhães de castro 4800 23 andar  torre 2 edifício park tower  05676120 são paulo  sp fabricio antonio cardim de almeida fcardim©stocchcforbcs com br tel 55 11 37555471 ana paula paschoalini apaschoalini©stocchcforbcs com br tel 55 11 37555412 marcela junqueira cesar pirola mpirola©stoccheforbes com br tel 11 37555460 º97 segundª fºifª 25 de mªiº dº 2015 diário oficial da união seção 3 issn 1677 7069 ministério da justiça nº 168 nos termos do art 53 «5 2 da lei nº 12 529 2011 dztse publicidade no seguinte um de concentração ato de con centração nélos700 0 4259 2015 39 requerentes brazil steel in vestimentos e participações s a dânicn termoindustrial brasil s a e zipcn sistemas construtivos s a advogados fabricio antonin cardim de almeida marcela junqueira cesar pirola outros na tureza da operação aquisição de ações setor econômico envolvido fabricação de estruturas metálicas e serviços de engenharia cnae 255110 00 publica ão no dou edital nº 168 2015 0064562 sei 08700004259 2015 39 u 34\n","Token IDs: tensor([  101,   139,  6961,  2041,   344,  4891, 20676,  3226, 22281, 14908,\n","        22280,  7258,  2393,  2222,  1925,   272,  4583,   906,  3897, 22281,\n","         1229,  1017,  1930,  1250,   171,  6865, 13233,   125,  3573, 14662,\n","         6846, 22279,  4332, 11112,   139,   185,   178,  9159,   122,  1520,\n","        22299, 22316,   143,   139,   123,   100,   100,  2707,   240,  3680,\n","          125,  1855, 10371, 20793,  9113,   122,  7835,   125,  1365,   170,\n","          260,   511,   254,   112,   732,  4971,   180,  9844,  7791,  8865,\n","          171,  1010,   215,   170,  2496,   229,   651,   125,   453,  4735,\n","        22280,  1177,   125,   453,  4735, 22280,   100,   229, 11810,   651,\n","         9186,   100,  4538, 22335,   100,  8054,  4767,   127,  2992, 22291,\n","        13778,  7375, 22335,  6324,  5813,   154,   202,   127, 22285, 22291,\n","        22314,   174, 22294,   425,  2297,  1189,   297, 13633, 22313, 15504,\n","         6324, 22302,  1242,  3306, 20345,  2476, 21677,  1542,  1433,   100,\n","         2702, 11740,   472,  2812,  7473,  1197,  6139,  2509,   180,   893,\n","          100,  8753,  1436,  2702, 11740,   380, 13182, 18377,   162, 20038,\n","        22282,   139,  6961,  2041,   344,  4891,  5665,  1976, 22283,  1670,\n","        22283,   208, 19449,  1954,  1335,   997,  4578,  1976, 22283,   205,\n","         1020, 22279, 10631,   736,  9314,   291,  3476,   179,  4031,  1537,\n","        13342,   221,   123,  4115,   180,  4597,   260,  7854,   639,  6358,\n","         7327,   179, 14726, 22281,  8026,   320,  2981,  5291,   125,  6755,\n","         4694, 11935,  7111,   712, 18436,  4133, 19954,   139,  6961,  2041,\n","          344,  4891,  1852,   431,   450, 19744,   715,   674, 22303, 17573,\n","         3852, 22280,   311,  4563,   122,  1314, 22290, 15793, 22283, 18436,\n","         1938,  5923,  9914,   125,   504,   552,  8659,   554,  2506,  8054,\n","          100,  5982,   245,  3591,   332, 22331,   374,  5311,   100,   100,\n","          453,  4735, 22280,   100,   139, 22291,  8000,   247,   856,  8723,\n","        22280,  7200,   314,   125,   313,   155,   328,   153,   934,  1125,\n","        22287, 23113,  7485,   451,   493, 22289,   512, 22295, 18980,   170,\n","          235, 22282,  4117,  9812,  1433,   100,  9480,  4735, 22278,  1063,\n","         2014,  8397,  4029,   305,   138,  2014,  8397,  4029, 23113,  7485,\n","          451,   493, 22289,   512, 22295, 18980,   170,   235, 22282,  4117,\n","         9812,  1433,   100,   528,  1927, 22278, 17267, 14139,  2992,  8889,\n","        13425,   715,   174,  6720, 12954, 23113,  7485,   451,  2041,   512,\n","         4891,   170,   235, 22282,  4117,  1433,   100,   100,   100,   100,\n","         1906,   125,   100,   100,  4155, 10635,  1538,   180,  6350,  8014,\n","          511,   847, 22281, 22285, 11958, 22337,  5011, 10852, 12080,   180,\n","         6722,   100, 11627,   538,  3401,   171,  1328, 13383,   208,   732,\n","          100,   180,  2241,   100,  1242, 10596, 22315,  3618,   121, 22305,\n","         1355, 22279, 10834,   202,  1457,   222,   125,  6755,  5291,   125,\n","          100,  1070,   737,   149,  1625,   128,  5554, 22307,  2297,  9716,\n","        22334, 22315,  4155,  9331,  7854,   639,  4332, 11112,   139,   185,\n","          178,   100, 12232,   579,   122,  8751,   139,   123,   121,   704,\n","          156, 22285,  2476, 21677,  1542, 22290,  1010,   215,   139,   123,\n","          122,  1757,   559, 22289, 22285,  3184,   893,  1100,   139,   123,\n","        18436,  8000,   247,   856,  8723, 22285,  7200,   314,   125,   313,\n","          155,   328,   528,  1927, 22278, 17267, 14139,  2992,  8889, 13425,\n","          715,   736,   100,  1356,  2993,   180,  4597,  9588,   125,  3680,\n","         4572,  5912,  9417,  9875,   125,  5518,  8753, 21014,   122,  2654,\n","          125,  7504,   127,   324, 22279,   100, 14736, 10033,   100,   202,\n","         3687,   902,  1013,   100, 11627,  4155, 14736,  9320, 20690, 22313,\n","        18661, 16394,  5554,  1523, 15132, 22334, 22315,  4155,  9331,   169,\n","         8047,   102])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2AB9VTMoLKyM","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593632914628,"user_tz":180,"elapsed":31887,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["from torch.utils.data import TensorDataset"],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"id":"RfR77GFwvQlT","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593632914629,"user_tz":180,"elapsed":31883,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["train_dataset = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n","valid_dataset = TensorDataset(input_ids_valid, attention_masks_valid, labels_valid)"],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"id":"YqtCmYr7vQde","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593632914629,"user_tz":180,"elapsed":31879,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n","\n","# The DataLoader needs to know our batch size for training, so we specify it \n","# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n","# size of 16 or 32.\n","batch_size = 6\n","\n","# Create the DataLoaders for our training and validation sets.\n","# We'll take training samples in random order. \n","train_dataloader = DataLoader(\n","            train_dataset,  # The training samples.\n","            sampler = RandomSampler(train_dataset), # Select batches randomly\n","            batch_size = batch_size # Trains with this batch size.\n","        )\n","\n","# For validation the order doesn't matter, so we'll just read them sequentially.\n","validation_dataloader = DataLoader(\n","            valid_dataset, # The validation samples.\n","            sampler = SequentialSampler(valid_dataset), # Pull out batches sequentially.\n","            batch_size = batch_size # Evaluate with this batch size.\n","        )"],"execution_count":31,"outputs":[]},{"cell_type":"code","metadata":{"id":"fsfcBSBtvy2J","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1593632918342,"user_tz":180,"elapsed":35587,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"28fc4109-aefd-4956-a45d-bc4add114f9f"},"source":["from transformers import AdamW, BertConfig\n","\n","# Tell pytorch to run this model on the GPU.\n","bert_model.to(device)"],"execution_count":32,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(29794, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":32}]},{"cell_type":"code","metadata":{"id":"_Dqyh7rlvysS","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593632918343,"user_tz":180,"elapsed":35581,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n","# I believe the 'W' stands for 'Weight Decay fix\"\n","optimizer = AdamW(bert_model.parameters(),\n","                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n","                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n","                )"],"execution_count":33,"outputs":[]},{"cell_type":"code","metadata":{"id":"qdxqlnX8xMzE","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593632918343,"user_tz":180,"elapsed":35576,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["from transformers import get_linear_schedule_with_warmup\n","\n","# Number of training epochs. The BERT authors recommend between 2 and 4. \n","# We chose to run for 4, but we'll see later that this may be over-fitting the\n","# training data.\n","epochs = 3\n","\n","# Total number of training steps is [number of batches] x [number of epochs]. \n","# (Note that this is not the same as the number of training samples).\n","total_steps = len(train_dataloader) * epochs\n","\n","# Create the learning rate scheduler.\n","scheduler = get_linear_schedule_with_warmup(optimizer, \n","                                            num_warmup_steps = 0, # Default value in run_glue.py\n","                                            num_training_steps = total_steps)"],"execution_count":34,"outputs":[]},{"cell_type":"code","metadata":{"id":"JzsE8SsyxMsL","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593632918344,"user_tz":180,"elapsed":35573,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["import numpy as np\n","\n","# Function to calculate the accuracy of our predictions vs labels\n","def flat_accuracy(preds, labels):\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)"],"execution_count":35,"outputs":[]},{"cell_type":"code","metadata":{"id":"Qt6CaozrxMjf","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593632918344,"user_tz":180,"elapsed":35568,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["import time\n","import datetime\n","\n","def format_time(elapsed):\n","    '''\n","    Takes a time in seconds and returns a string hh:mm:ss\n","    '''\n","    # Round to the nearest second.\n","    elapsed_rounded = int(round((elapsed)))\n","    \n","    # Format as hh:mm:ss\n","    return str(datetime.timedelta(seconds=elapsed_rounded))"],"execution_count":36,"outputs":[]},{"cell_type":"code","metadata":{"id":"aQ1W3r0D0ov0","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593632918345,"user_tz":180,"elapsed":35564,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["del data_train_chunked_head\n","del data_valid_chunked_head\n","del data_train_chunked_tail\n","del data_valid_chunked_tail\n","del data_train_chunked_splitted_head\n","del data_valid_chunked_splitted_head\n","del data_train_chunked_splitted_tail\n","del data_valid_chunked_splitted_tail\n","\n","del input_ids_valid_head\n","del input_ids_valid_tail\n","\n","del attention_masks_train_head\n","del attention_masks_valid_tail"],"execution_count":37,"outputs":[]},{"cell_type":"code","metadata":{"id":"YSeF8-MZ0ncR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593632918346,"user_tz":180,"elapsed":35560,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"11c0f0c9-b474-4e57-d176-034894b5bd2f"},"source":["import gc\n","gc.collect()"],"execution_count":38,"outputs":[{"output_type":"execute_result","data":{"text/plain":["333"]},"metadata":{"tags":[]},"execution_count":38}]},{"cell_type":"code","metadata":{"id":"OnNBpOR9zfzB","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":731},"executionInfo":{"status":"ok","timestamp":1593633207259,"user_tz":180,"elapsed":324466,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"591e5027-f6a9-483f-dafb-b0022e230aeb"},"source":["import random\n","import numpy as np\n","\n","# This training code is based on the `run_glue.py` script here:\n","# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n","\n","# Set the seed value all over the place to make this reproducible.\n","seed_val = 42\n","\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)\n","\n","# We'll store a number of quantities such as training and validation loss, \n","# validation accuracy, and timings.\n","training_stats = []\n","\n","# Measure the total training time for the whole run.\n","total_t0 = time.time()\n","\n","# For each epoch...\n","for epoch_i in range(0, epochs):\n","    \n","    # ========================================\n","    #               Training\n","    # ========================================\n","    \n","    # Perform one full pass over the training set.\n","\n","    print(\"\")\n","    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n","    print('Training...')\n","\n","    # Measure how long the training epoch takes.\n","    t0 = time.time()\n","\n","    # Reset the total loss for this epoch.\n","    total_train_loss = 0\n","\n","    # Put the model into training mode. Don't be mislead--the call to \n","    # `train` just changes the *mode*, it doesn't *perform* the training.\n","    # `dropout` and `batchnorm` layers behave differently during training\n","    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n","    bert_model.train()\n","\n","    # For each batch of training data...\n","    for step, batch in enumerate(train_dataloader):\n","\n","        # Progress update every 40 batches.\n","        if step % 40 == 0 and not step == 0:\n","            # Calculate elapsed time in minutes.\n","            elapsed = format_time(time.time() - t0)\n","            \n","            # Report progress.\n","            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n","\n","        # Unpack this training batch from our dataloader. \n","        #\n","        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n","        # `to` method.\n","        #\n","        # `batch` contains three pytorch tensors:\n","        #   [0]: input ids \n","        #   [1]: attention masks\n","        #   [2]: labels \n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","\n","        # Always clear any previously calculated gradients before performing a\n","        # backward pass. PyTorch doesn't do this automatically because \n","        # accumulating the gradients is \"convenient while training RNNs\". \n","        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n","        bert_model.zero_grad()        \n","\n","        # Perform a forward pass (evaluate the model on this training batch).\n","        # The documentation for this `model` function is here: \n","        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n","        # It returns different numbers of parameters depending on what arguments\n","        # arge given and what flags are set. For our useage here, it returns\n","        # the loss (because we provided labels) and the \"logits\"--the model\n","        # outputs prior to activation.\n","        loss, logits = bert_model(b_input_ids, \n","                             token_type_ids=None, \n","                             attention_mask=b_input_mask, \n","                             labels=b_labels)\n","\n","        # Accumulate the training loss over all of the batches so that we can\n","        # calculate the average loss at the end. `loss` is a Tensor containing a\n","        # single value; the `.item()` function just returns the Python value \n","        # from the tensor.\n","        total_train_loss += loss.item()\n","\n","        # Perform a backward pass to calculate the gradients.\n","        loss.backward()\n","\n","        # Clip the norm of the gradients to 1.0.\n","        # This is to help prevent the \"exploding gradients\" problem.\n","        torch.nn.utils.clip_grad_norm_(bert_model.parameters(), 1.0)\n","\n","        # Update parameters and take a step using the computed gradient.\n","        # The optimizer dictates the \"update rule\"--how the parameters are\n","        # modified based on their gradients, the learning rate, etc.\n","        optimizer.step()\n","\n","        # Update the learning rate.\n","        scheduler.step()\n","\n","    # Calculate the average loss over all of the batches.\n","    avg_train_loss = total_train_loss / len(train_dataloader)            \n","    \n","    # Measure how long this epoch took.\n","    training_time = format_time(time.time() - t0)\n","\n","    print(\"\")\n","    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n","    print(\"  Training epcoh took: {:}\".format(training_time))\n","        \n","    # ========================================\n","    #               Validation\n","    # ========================================\n","    # After the completion of each training epoch, measure our performance on\n","    # our validation set.\n","\n","    print(\"\")\n","    print(\"Running Validation...\")\n","\n","    t0 = time.time()\n","\n","    # Put the model in evaluation mode--the dropout layers behave differently\n","    # during evaluation.\n","    bert_model.eval()\n","\n","    # Tracking variables \n","    total_eval_accuracy = 0\n","    total_eval_loss = 0\n","    nb_eval_steps = 0\n","\n","    # Evaluate data for one epoch\n","    for batch in validation_dataloader:\n","        \n","        # Unpack this training batch from our dataloader. \n","        #\n","        # As we unpack the batch, we'll also copy each tensor to the GPU using \n","        # the `to` method.\n","        #\n","        # `batch` contains three pytorch tensors:\n","        #   [0]: input ids \n","        #   [1]: attention masks\n","        #   [2]: labels \n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","        \n","        # Tell pytorch not to bother with constructing the compute graph during\n","        # the forward pass, since this is only needed for backprop (training).\n","        with torch.no_grad():        \n","\n","            # Forward pass, calculate logit predictions.\n","            # token_type_ids is the same as the \"segment ids\", which \n","            # differentiates sentence 1 and 2 in 2-sentence tasks.\n","            # The documentation for this `model` function is here: \n","            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n","            # Get the \"logits\" output by the model. The \"logits\" are the output\n","            # values prior to applying an activation function like the softmax.\n","            (loss, logits) = bert_model(b_input_ids, \n","                                   token_type_ids=None, \n","                                   attention_mask=b_input_mask,\n","                                   labels=b_labels)\n","            \n","        # Accumulate the validation loss.\n","        total_eval_loss += loss.item()\n","\n","        # Move logits and labels to CPU\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","\n","        # Calculate the accuracy for this batch of test sentences, and\n","        # accumulate it over all batches.\n","        total_eval_accuracy += flat_accuracy(logits, label_ids)\n","        \n","\n","    # Report the final accuracy for this validation run.\n","    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n","    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n","\n","    # Calculate the average loss over all of the batches.\n","    avg_val_loss = total_eval_loss / len(validation_dataloader)\n","    \n","    # Measure how long the validation run took.\n","    validation_time = format_time(time.time() - t0)\n","    \n","    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n","    print(\"  Validation took: {:}\".format(validation_time))\n","\n","    # Record all statistics from this epoch.\n","    training_stats.append(\n","        {\n","            'epoch': epoch_i + 1,\n","            'Training Loss': avg_train_loss,\n","            'Valid. Loss': avg_val_loss,\n","            'Valid. Accur.': avg_val_accuracy,\n","            'Training Time': training_time,\n","            'Validation Time': validation_time\n","        }\n","    )\n","\n","print(\"\")\n","print(\"Training complete!\")\n","\n","print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"],"execution_count":39,"outputs":[{"output_type":"stream","text":["\n","======== Epoch 1 / 3 ========\n","Training...\n","  Batch    40  of    119.    Elapsed: 0:00:29.\n","  Batch    80  of    119.    Elapsed: 0:00:59.\n","\n","  Average training loss: 0.47\n","  Training epcoh took: 0:01:28\n","\n","Running Validation...\n","  Accuracy: 0.81\n","  Validation Loss: 0.49\n","  Validation took: 0:00:07\n","\n","======== Epoch 2 / 3 ========\n","Training...\n","  Batch    40  of    119.    Elapsed: 0:00:30.\n","  Batch    80  of    119.    Elapsed: 0:01:00.\n","\n","  Average training loss: 0.40\n","  Training epcoh took: 0:01:30\n","\n","Running Validation...\n","  Accuracy: 0.81\n","  Validation Loss: 0.53\n","  Validation took: 0:00:07\n","\n","======== Epoch 3 / 3 ========\n","Training...\n","  Batch    40  of    119.    Elapsed: 0:00:30.\n","  Batch    80  of    119.    Elapsed: 0:01:00.\n","\n","  Average training loss: 0.28\n","  Training epcoh took: 0:01:30\n","\n","Running Validation...\n","  Accuracy: 0.87\n","  Validation Loss: 0.44\n","  Validation took: 0:00:07\n","\n","Training complete!\n","Total training took 0:04:48 (h:mm:ss)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VV1NBjHLSB_G","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":173},"executionInfo":{"status":"ok","timestamp":1593633207260,"user_tz":180,"elapsed":324459,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"7a4920f5-82f3-4e4d-f8e3-9c385e7b1ef7"},"source":["import pandas as pd\n","\n","# Display floats with two decimal places.\n","pd.set_option('precision', 2)\n","\n","# Create a DataFrame from our training statistics.\n","df_stats = pd.DataFrame(data=training_stats)\n","\n","# Use the 'epoch' as the row index.\n","df_stats = df_stats.set_index('epoch')\n","\n","# A hack to force the column headers to wrap.\n","#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n","\n","# Display the table.\n","df_stats"],"execution_count":40,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Training Loss</th>\n","      <th>Valid. Loss</th>\n","      <th>Valid. Accur.</th>\n","      <th>Training Time</th>\n","      <th>Validation Time</th>\n","    </tr>\n","    <tr>\n","      <th>epoch</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>0.47</td>\n","      <td>0.49</td>\n","      <td>0.81</td>\n","      <td>0:01:28</td>\n","      <td>0:00:07</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.40</td>\n","      <td>0.53</td>\n","      <td>0.81</td>\n","      <td>0:01:30</td>\n","      <td>0:00:07</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.28</td>\n","      <td>0.44</td>\n","      <td>0.87</td>\n","      <td>0:01:30</td>\n","      <td>0:00:07</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n","epoch                                                                         \n","1               0.47         0.49           0.81       0:01:28         0:00:07\n","2               0.40         0.53           0.81       0:01:30         0:00:07\n","3               0.28         0.44           0.87       0:01:30         0:00:07"]},"metadata":{"tags":[]},"execution_count":40}]},{"cell_type":"code","metadata":{"id":"MowdU-X4wzSI","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":481},"executionInfo":{"status":"ok","timestamp":1593633207261,"user_tz":180,"elapsed":324454,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"146c5b17-b223-4c37-ff21-ccafb89a48e4"},"source":["import matplotlib.pyplot as plt\n","% matplotlib inline\n","\n","import seaborn as sns\n","\n","# Use plot styling from seaborn.\n","sns.set(style='darkgrid')\n","\n","# Increase the plot size and font size.\n","sns.set(font_scale=1.5)\n","plt.rcParams[\"figure.figsize\"] = (12,6)\n","\n","# Plot the learning curve.\n","plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n","plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n","\n","# Label the plot.\n","plt.title(\"Training & Validation Loss\")\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Loss\")\n","plt.legend()\n","plt.xticks([1, 2, 3, 4])\n","\n","plt.show()"],"execution_count":41,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n","  import pandas.util.testing as tm\n"],"name":"stderr"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAvUAAAGaCAYAAACPCLyfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd2BUVfrw8e+k915Jn0AChBBCjwmdFCCAhaKyYFsVFfHVtf7s7LoFUVRQdsWOKEoPLZTQpAgCSpEAmkYCSQjpCaTOff8IjIwJkEAmkwnP5y/mzL3nPjPkJM+cec65KkVRFIQQQgghhBBGy8TQAQghhBBCCCFujiT1QgghhBBCGDlJ6oUQQgghhDByktQLIYQQQghh5CSpF0IIIYQQwshJUi+EEEIIIYSRk6ReCHHLy8nJITQ0lHnz5t1wHy+++CKhoaGtGFXHdbX3OzQ0lBdffLFZfcybN4/Q0FBycnJaPb4VK1YQGhrKvn37Wr1vIYTQFzNDByCEEH/WkuQ4JSUFX19fPUZjfC5cuMB///tf1q9fz7lz53BxcaFPnz48/vjjBAcHN6uPmTNnsnHjRlatWkW3bt2aPEZRFEaMGEFZWRm7du3CysqqNV+GXu3bt4/9+/dz33334eDgYOhwGsnJyWHEiBFMmTKF1157zdDhCCGMgCT1Qoh2Z/bs2TqPDx48yHfffcfkyZPp06ePznMuLi43fT0fHx+OHDmCqanpDffx97//nTfffPOmY2kNr7zyCuvWrSMxMZH+/ftTUFDA1q1bOXz4cLOT+gkTJrBx40aWL1/OK6+80uQxP/74I2fOnGHy5MmtktAfOXIEE5O2+QJ5//79zJ8/nzvuuKNRUj9+/HjGjBmDubl5m8QihBCtQZJ6IUS7M378eJ3H9fX1fPfdd/Tq1avRc39WUVGBnZ1di66nUqmwtLRscZxXai8J4MWLF0lOTiYmJoZ33nlH2z5jxgxqamqa3U9MTAze3t6sWbOG559/HgsLi0bHrFixAmj4ANAabvb/oLWYmpre1Ac8IYQwBKmpF0IYreHDhzN16lSOHz/OQw89RJ8+fRg3bhzQkNzPnTuXiRMnMmDAAHr06EFsbCxz5szh4sWLOv00VeN9Zdu2bdu46667CA8PJyYmhv/85z/U1dXp9NFUTf3ltvLycl5//XWioqIIDw/n7rvv5vDhw41eT3FxMS+99BIDBgwgMjKSadOmcfz4caZOncrw4cOb9Z6oVCpUKlWTHzKaSsyvxsTEhDvuuIOSkhK2bt3a6PmKigo2bdpESEgIPXv2bNH7fTVN1dRrNBr+97//MXz4cMLDw0lMTCQpKanJ89PS0njjjTcYM2YMkZGRREREcOedd7J06VKd41588UXmz58PwIgRIwgNDdX5/79aTX1RURFvvvkmQ4YMoUePHgwZMoQ333yT4uJineMun793714+/fRTRo4cSY8ePYiPj2flypXNei9a4sSJEzzxxBMMGDCA8PBwRo8ezcKFC6mvr9c5Ljc3l5deeolhw4bRo0cPoqKiuPvuu3Vi0mg0fPHFF4wdO5bIyEh69+5NfHw8//d//0dtbW2rxy6EaD0yUy+EMGpnz57lvvvuIyEhgbi4OC5cuABAfn4+y5YtIy4ujsTERMzMzNi/fz+ffPIJqampfPrpp83qf8eOHXzzzTfcfffd3HXXXaSkpPDZZ5/h6OjI9OnTm9XHQw89hIuLC0888QQlJSV8/vnnPPLII6SkpGi/VaipqeGBBx4gNTWVO++8k/DwcE6ePMkDDzyAo6Njs98PKysrbr/9dpYvX87atWtJTExs9rl/duedd7JgwQJWrFhBQkKCznPr1q2jqqqKu+66C2i99/vP/vWvf/HVV1/Rr18/7r//fgoLC5k1axZ+fn6Njt2/fz8HDhxg6NCh+Pr6ar+1eOWVVygqKuLRRx8FYPLkyVRUVLB582ZeeuklnJ2dgWuv5SgvL+eee+4hKyuLu+66i+7du5Oamsq3337Ljz/+yNKlSxt9QzR37lyqqqqYPHkyFhYWfPvtt7z44ov4+/s3KiO7UUePHmXq1KmYmZkxZcoU3Nzc2LZtG3PmzOHEiRPab2vq6up44IEHyM/P59577yUwMJCKigpOnjzJgQMHuOOOOwBYsGABH3zwAcOGDePuu+/G1NSUnJwctm7dSk1NTbv5RkoI0QRFCCHaueXLlyshISHK8uXLddqHDRumhISEKN9//32jc6qrq5WamppG7XPnzlVCQkKUw4cPa9uys7OVkJAQ5YMPPmjUFhERoWRnZ2vbNRqNMmbMGCU6Olqn3xdeeEEJCQlpsu3111/XaV+/fr0SEhKifPvtt9q2r7/+WgkJCVE++ugjnWMvtw8bNqzRa2lKeXm58vDDDys9evRQunfvrqxbt65Z513NtGnTlG7duin5+fk67ZMmTVLCwsKUwsJCRVFu/v1WFEUJCQlRXnjhBe3jtLQ0JTQ0VJk2bZpSV1enbT927JgSGhqqhISE6PzfVFZWNrp+fX298pe//EXp3bu3TnwffPBBo/Mvu/zz9uOPP2rb3n33XSUkJET5+uuvdY69/P8zd+7cRuePHz9eqa6u1rbn5eUpYWFhytNPP93omn92+T168803r3nc5MmTlW7duimpqanaNo1Go8ycOVMJCQlR9uzZoyiKoqSmpiohISHKxx9/fM3+br/9dmXUqFHXjU8I0f5I+Y0Qwqg5OTlx5513Nmq3sLDQzirW1dVRWlpKUVERt912G0CT5S9NGTFihM7uOiqVigEDBlBQUEBlZWWz+rj//vt1Hg8cOBCArKwsbdu2bdswNTVl2rRpOsdOnDgRe3v7Zl1Ho9Hw1FNPceLECTZs2MDgwYN59tlnWbNmjc5xr776KmFhYc2qsZ8wYQL19fWsWrVK25aWlsYvv/zC8OHDtQuVW+v9vlJKSgqKovDAAw/o1LiHhYURHR3d6HgbGxvtv6urqykuLqakpITo6GgqKipIT09vcQyXbd68GRcXFyZPnqzTPnnyZFxcXNiyZUujc+69916dkidPT0+CgoLIzMy84TiuVFhYyM8//8zw4cPp2rWrtl2lUvHYY49p4wa0P0P79u2jsLDwqn3a2dmRn5/PgQMHWiVGIUTbkfIbIYRR8/Pzu+qixsWLF7NkyRJ+//13NBqNznOlpaXN7v/PnJycACgpKcHW1rbFfVwu9ygpKdG25eTk4OHh0ag/CwsLfH19KSsru+51UlJS2LVrF2+//Ta+vr68//77zJgxg+eff566ujpticXJkycJDw9vVo19XFwcDg4OrFixgkceeQSA5cuXA2hLby5rjff7StnZ2QCo1epGzwUHB7Nr1y6dtsrKSubPn8+GDRvIzc1tdE5z3sOrycnJoUePHpiZ6f7ZNDMzIzAwkOPHjzc652o/O2fOnLnhOP4cE0Dnzp0bPadWqzExMdG+hz4+PkyfPp2PP/6YmJgYunXrxsCBA0lISKBnz57a85555hmeeOIJpkyZgoeHB/3792fo0KHEx8e3aE2GEKLtSVIvhDBq1tbWTbZ//vnn/Pvf/yYmJoZp06bh4eGBubk5+fn5vPjiiyiK0qz+r7ULys320dzzm+vyws5+/foBDR8I5s+fz2OPPcZLL71EXV0dXbt25fDhw7z11lvN6tPS0pLExES++eYbDh06REREBElJSXh5eTFo0CDtca31ft+Mv/3tb2zfvp1JkybRr18/nJycMDU1ZceOHXzxxReNPmjoW1ttz9lcTz/9NBMmTGD79u0cOHCAZcuW8emnn/LXv/6V5557DoDIyEg2b97Mrl272LdvH/v27WPt2rUsWLCAb775RvuBVgjR/khSL4TokFavXo2Pjw8LFy7USa527txpwKiuzsfHh71791JZWakzW19bW0tOTk6zbpB0+XWeOXMGb29voCGx/+ijj5g+fTqvvvoqPj4+hISEcPvttzc7tgkTJvDNN9+wYsUKSktLKSgoYPr06Trvqz7e78sz3enp6fj7++s8l5aWpvO4rKyM7du3M378eGbNmqXz3J49exr1rVKpWhxLRkYGdXV1OrP1dXV1ZGZmNjkrr2+Xy8J+//33Rs+lp6ej0WgaxeXn58fUqVOZOnUq1dXVPPTQQ3zyySc8+OCDuLq6AmBra0t8fDzx8fFAwzcws2bNYtmyZfz1r3/V86sSQtyo9jWNIIQQrcTExASVSqUzQ1xXV8fChQsNGNXVDR8+nPr6er766iud9u+//57y8vJm9TFkyBCgYdeVK+vlLS0teffdd3FwcCAnJ4f4+PhGZSTXEhYWRrdu3Vi/fj2LFy9GpVI12pteH+/38OHDUalUfP755zrbM/7666+NEvXLHyT+/I3AuXPnGm1pCX/U3ze3LGjkyJEUFRU16uv777+nqKiIkSNHNquf1uTq6kpkZCTbtm3j1KlT2nZFUfj4448BiI2NBRp27/nzlpSWlpba0qbL70NRUVGj64SFhekcI4Ron2SmXgjRISUkJPDOO+/w8MMPExsbS0VFBWvXrm1RMtuWJk6cyJIlS3jvvfc4ffq0dkvL5ORkAgICGu2L35To6GgmTJjAsmXLGDNmDOPHj8fLy4vs7GxWr14NNCRoH374IcHBwYwaNarZ8U2YMIG///3v/PDDD/Tv37/RDLA+3u/g4GCmTJnC119/zX333UdcXByFhYUsXryYrl276tSx29nZER0dTVJSElZWVoSHh3PmzBm+++47fH19ddYvAERERAAwZ84cxo4di6WlJV26dCEkJKTJWP7617+SnJzMrFmzOH78ON26dSM1NZVly5YRFBSktxnsY8eO8dFHHzVqNzMz45FHHuHll19m6tSpTJkyhXvvvRd3d3e2bdvGrl27SExMJCoqCmgozXr11VeJi4sjKCgIW1tbjh07xrJly4iIiNAm96NHj6ZXr1707NkTDw8PCgoK+P777zE3N2fMmDF6eY1CiNbRPv+6CSHETXrooYdQFIVly5bx1ltv4e7uzqhRo7jrrrsYPXq0ocNrxMLCgi+//JLZs2eTkpLChg0b6NmzJ1988QUvv/wyVVVVzernrbfeon///ixZsoRPP/2U2tpafHx8SEhI4MEHH8TCwoLJkyfz3HPPYW9vT0xMTLP6HTt2LLNnz6a6urrRAlnQ3/v98ssv4+bmxvfff8/s2bMJDAzktddeIysrq9Hi1Lfffpt33nmHrVu3snLlSgIDA3n66acxMzPjpZde0jm2T58+PPvssyxZsoRXX32Vuro6ZsyYcdWk3t7enm+//ZYPPviArVu3smLFClxdXbn77rt58sknW3wX4+Y6fPhwkzsHWVhY8MgjjxAeHs6SJUv44IMP+Pbbb7lw4QJ+fn48++yzPPjgg9rjQ0NDiY2NZf/+/axZswaNRoO3tzePPvqoznEPPvggO3bsYNGiRZSXl+Pq6kpERASPPvqozg47Qoj2R6W0xeolIYQQN6S+vp6BAwfSs2fPG76BkxBCiI5PauqFEKKdaGo2fsmSJZSVlTW5L7sQQghxmZTfCCFEO/HKK69QU1NDZGQkFhYW/Pzzz6xdu5aAgAAmTZpk6PCEEEK0Y1J+I4QQ7cSqVatYvHgxmZmZXLhwAVdXV4YMGcJTTz2Fm5ubocMTQgjRjklSL4QQQgghhJGTmnohhBBCCCGMnCT1QgghhBBCGDlZKNtCxcWVaDStW7Hk6mpHYWFFq/YphGgg40sI/ZHxJYR+mJiocHa2bdE5ktS3kEajtHpSf7lfIYR+yPgSQn9kfAnRPkj5jRBCCCGEEEZOknohhBBCCCGMnCT1QgghhBBCGDlJ6oUQQgghhDByktQLIYQQQghh5GT3GyGEEEKIVnDxYiUVFaXU19caOhTRjpmammNn54i1dcu2rLweSeqFEEIIIW5SbW0N5eXFODm5YW5uiUqlMnRIoh1SFIXa2mpKSs5jZmaOublFq/Ut5TdCCCGEEDepvLwEOztHLCysJKEXV6VSqbCwsMLW1pGKipJW7VuSeiGEEEKIm1RXV4OlpbWhwxBGwsrKmtramlbtU8pvhBAd0v68QySlJVNSXYKTpRPjghPo79Xb0GEJIToojaYeExNTQ4chjISJiSkaTX2r9ilJvRCiw9mfd4hvTiynVtOwWK24uoRvTiwHkMReCKE3UnYjmksfPytSfiOE6FBqNXWs+H2tNqH/o72WpLRkA0UlhBBC6JfM1AshjFpZTTnppVmkl2aSUZrF6bIc6pSmv9Isrm7dRUlCCCFu3owZjwAwf/7HbXpuRyNJvRDCaGgUDbmV+dokPr00i/MXCwEwU5ni7+DLEL9o9uUepKK2ssk+1qQlMzJgCNZmsqBNCCGuJSamb7OOW7o0CW/vTnqORlyPSlEUxdBBGJPCwgo0mtZ9y9zd7SkoKG/VPoXoCKrqqsgsy9Ym8Bmlp6mqrwLA3twOtVMgascA1I4B+Nn7Ym7SME/x55p6AHMTM3xsvcksz8bWzIa4wGEM8bkNc1Nzg7w2IToC+fv1h7y8LLy8AgwdRqvauHG9zuPvv/+W/PxcnnzyGZ32wYOHYW194xMltbUNv6vNzVv++/hmzjW0a/3MmJiocHW1a1F/MlMvhGgXFEWhqKpYZxb+TEUuCgoqVHjbetLXqxdqhwDUjoG4WbtcdaHR5cWwTe1+k11+hqS0ZFb+vo5t2bsYExTHAK/emMquFUIIoSM+frTO4+3bUygtLWnU/mdVVVVYWVk1+zo3k5AbYzKvL5LUCyEMok5TR3b5WTIuJfDppZmU1jTM+FmaWhDkEEBC4AiCHQMJdPRrcblMf6/e9Pfq3Wgm0c/ehyd6PcSp4jRWp21g8YmlbDm9g3HqeCLce8juFUII0QIzZjxCRUUFzz//f8ybN5eTJ08wZco0HnroUX74YTtJSSs5deokZWWluLt7MHr0WKZOfQBTU1OdPuCPuvhDhw4wc+Z03nprNhkZ6axatZyyslLCwyN47rn/w9fXr1XOBVi+/HuWLFlMYeF5goODmTHjaRYuXKDTp7GQpF4I0SYqaiq1M/DppVmcLs+mVlMHgKuVMyHOnVE7BhDkGIiPnRcmKv1uzhXiHMyzfZ7gyPlfSUpLZuGxRQQ4+HF78ChCnDvr9dpCCNEce3/NY8WONArLqnF1sOTOIcFEhXkZOqxGSkqKef75p4mLSyAhYQyeng0xrl+/FmtrGyZPnoKNjTUHDx7gk0/+S2VlJU888dR1+/3yy08xMTHl3nunUV5exrffLuLNN19h4cIvW+XclSuXMXfubHr16s3kyfeQm5vLSy89i729Pe7uHjf+hhiIJPVCiFanUTTkXyhoSOJLskgvy+TchfMAmKpM8bP3YZBPFGrHQIIc/XGydDRInCqVigj3HvRw7cb+vEOsy9jM+z9/TDeXEMYFJ+Bv72uQuIQQYu+veXy54QQ1dRoACsuq+XLDCYB2l9ifP1/Aiy++SmLieJ32N974B5aWf5Th3H77BN5++5+sXLmUhx9+DAsLi2v2W1dXx2effYmZWUO66uDgyPvvzyE9/XfU6mtPvlzv3NraWj75ZAFhYeG8995H2uM6d+7CW2+9IUm9EOLWVF1fQ1bZae0sfEZpFhfqLgJgZ25LkGMAUd79UDsG4m/vi0U7W5xqamJKVKd+9PXsxc4ze9mYtZX//PQBfTwiSFTH4WHjbugQhRBGavfRXHYdyW3xeWlnS6mr192Yo6ZOw+frU9n5y9kW9xfT05vocO8Wn9ccVlZWJCSMadR+ZUJ/4UIlNTW1REREsnr1CrKyMunSJeSa/Y4ZM06bbANERPQC4OzZM9dN6q937okTxyktLeXxx+/QOS42NoEPPnj3mn23V5LUCyFarLiqhDTtjjSZ5FTkolEaZpO8bD2J9AgnyLFhZxoPazejqVM3NzVnhP9gbuvUj5TTO0nJ/oGfC45yW6f+jAocYbBvFIQQt54/J/TXazckd3cPncT4svT0NBYuXMChQz9RWam7zXBlZcV1+71cxnOZvb0DAOXl199x6Xrn5uU1fND6c429mZkZ3t76+fCjb5LUCyGuqV5TT07FWZ1daUqqSwGwMDEn0MGfOP+hqJ0CCXLwx8bcxsAR3zxrM2sS1fEM9r2N5MwUdp3Zx77cgwzziyHWfyg25rLHvRCieaLDb2yG/LmPdlNYVt2o3dXBkhem9G6N0FrNlTPyl5WXl/Pkk49gY2PHQw9Nx8fHFwsLC06dOsGCBfPQaDTX7dfkKruSNWc39ps511hJUi+E0FFZe4GMS2U06aWZZJVlU3Npv3dnSyeCHQNRX5qF97Hz7tBbQTpY2DMp5HaG+w1ibfomNmdtZ9eZH4kLGMYQ3+h2V0YkhOg47hwSrFNTD2BhZsKdQ4INGFXz/fzzQUpLS3nrrbfp1euPDyG5uS0vHdIHL6+GD1o5OdlERERq2+vq6sjNzSU42Pg2TJCkXohbmKIonLtQoDMLn3fhHAAmKhN87TpxW6f+2iTe2crJwBEbhpu1K/eH3cNI/yEkpSezKm39pT3uYxno3bdDf7ARQhjG5cWwxrD7TVNMTBp2MLtyZry2tpaVK5caKiQdXbt2x9HRkaSklcTHj9aWD23enEx5eZmBo7sxktQLcQupqa8hqyyHjNIs0kozySjLorL2AgA2ZtaoHQPo59WbYMcA/B38sDS99s4Etxpf+048HvEgvxWnk5S+gW9OLmdL9g7GqhOIdA83mrUDQgjjEBXmZTRJ/J+Fh/fE3t6Bt956gwkTJqNSqdi4cT3tpfrF3NycBx98hLlz3+b//b/HGTZsBLm5uWzYsAYfH1+j/H0uSb0QHVhJdanOLHx2+RntglZPG3d6uoWhdgxoWNBq4673veE7ii7Oap7p/TjHClNZnbaBT499jb+9D+ODR9PVpYuhwxNCCINzdHRi9uy5zJ//HgsXLsDe3oG4uFH07dufZ56ZYejwALjrrskoisKSJYv58MP3CQ7uwr///S7vvTcHCwtLQ4fXYiqlI68Y0IPCwgo0mtZ9y/58x0shbkS9pp6zlXk6SXxRVTEA5iZmBDj4actoghwCsLOwNXDEbUPf40ujaPgp72fWZmyiqKqYrs5dGBecQICD3/VPFsLIyd+vP+TlZeHlFWDoMMRN0mg0JCbGMmTIMF544RW9XutaPzMmJipcXe1a1J/M1AthpC7UXiSj7DQZlxL4zLLTVNfXAOBo4YDaKZBhfjGoHQPwteuEmYkMd30wUZkwwLsPvT0j2HXmR5IzU5h9YB6R7uGMVcfjaWt8NzARQohbQXV1NZaWujPyycnrKCsrJTKyj4GiunHyV14II6AoCgUXC/+ohS/NIrcyHwUFFSp87bwZ6N0XtUMAQY6BuFg5GWU9oDEzNzFjmF8MUd59Scn+gZTTOzh8/leivPsyOihW9rgXQoh25siRX1iwYB5Dhw7HwcGRU6dOsG5dEmp1MMOGjTR0eC0mSb0Q7VBtfS2ny89oy2jSSzOpqG24cYe1mRVBDgH09uiJ2jGQAAc/rMyMr/avo7Iys2JMUCyDfaLYmLmVnWf2sj/vEEN9Y4gNGIptB9jHXwghOoJOnXxwc3Nn2bLvKCsrxcHBkYSEMUyfPgNzc+Pbslhq6ltIauqFPpRWl2vLaBoWtOZQp9QD4G7tqq2FVzsG4mXrIQtaW8DQ46vwYhHrMjazP+8QVmaWxPoPZahfjOwsJDoEQ4+v9kRq6kVLSU29EEZOo2jIrcwnraQhic8ozeR8VREAZiZm+Nv7MtQvRpvI21u0bFCL9sXV2oVp3Sdr97hPSk9me85uRgeN5Dbv/rLHvRBCiFYhSb0QenaxrorMstMNs/AlmWSWnaaqvuHW3/YWdgQ7BjLINwq1YyB+9j6Yy4LWDqmTnRfTe95PWkkmq9PWs+TkSlJO72SsOp5Ij57y7YsQQoibItmDEK1IURQKq4p1auHPVuRpF7R2svOin1dv7d7wrlYusqD1FhPsFMjTvR/j18ITrE7bwGe/foNf1nbGBY+im0uI/DwIIYS4IZLUC3ETajV15JSf0dkbvqymob7UytSSQAd/RgWOQO0USKCDP9ZmVgaOWLQHKpWKHm7d6O4ayoH8X1ibvokPD39KFyc144NHE+Tob+gQhRBCGBlJ6oVogfKaikt18A1JfFZ5DnWaOgBcrVwIde6inYXvZOclJRXimkxUJvT36k1vj57sOruP5IwU5hycT4R7D8ap4/Gy9TR0iEIIIYyEJPVCXIVG0ZBXeU47A59RmsW5i+cBMFWZ4m/vw2CfKIIdAwlyDMDR0sHAEQtjZWZixlDfaAZ69WVb9g9sOb2DfxT8ykDvvowJisXZysnQIQohhGjnJKkX4pKqumqyyrK1pTQZZVlcrKsCwM7cFrVjILd16k+QYwAB9r6YmxrfHraifbMys2RU0EgG+USxMWsrO3P28FP+zwz2iSI+cDh25raGDlEIIUQ7JUm9uCUpikJxdQnpJZmklzXsDX+mIheNogHA29aT3h4R2lIad2s3WcAo2oydhS13dRnLML8Y1mVsZlv2Lvac/YmR/kMY5hcjNxsTQhil9evX8M9/vsnSpUl4e3cCYMKEsURG9uHll99o8bk369ChA8ycOZ0PPvgvvXv3bZU+DUmSenFLqNfUk1NxlvTSLNJKM8kozaKkuhQAC1MLAh38iQsYhtoxkCAHP2zkrp+iHXCxcmZqt0mM9B/CmrRk1mZsZMeZ3YwKHEl0p/6YyfanQgg9ev75pzl06CfWrNmMtbV1k8c888wMfv31KElJm7C0bJ8TDlu2bKSoqJBJk+41dCh6JX8RRIdUUVt5aTFrQy18Zlk2tZpaAJwtnejsFETQpVl4H1tvuQGQaNe8bT15pOd9ZJRmsTptA9+fWkXK6Z0kquPo69lLFmQLIfQiNjaePXt+YNeuHcTGJjR6vri4iIMHfyIubtQNJ/TffLMcExP9/g5LSdnEb7+dapTU9+rVm5SU3Zibd4xyWknqhdFTFIX8CwVX7A2fRf6Fc0DD7iJ+dj7EdBqA2imQIAd/WXQojFaQYwBPRT5KatEpVqdt4MvjS9hyegfj1AmEuXaVEjEhRKsaNGgo1tY2bNmyscmkfuvWLdTX1xMX1/i55rKwsLiZEJlgVzMAACAASURBVG+KiYlJu/124UZIUi+MTk19je6C1tLTVNZdAMDWzIYgxwAGXLrBU4CDHxamhvuFIURrU6lUdHcNpatLFw6dO8Ka9I0sOPI5nZ2CGB88CrVjoKFDFEJ0EFZWVgwaNIRt27ZQVlaGg4PuLm9btmzE1dUVP78A5sz5NwcP7ic/Px8rKyt69+7LE088dd3696Zq6tPT03jvvbc5duwojo6OjB9/J25u7o3O/eGH7SQlreTUqZOUlZXi7u7B6NFjmTr1AUxNG76BnzHjEX755RAAMTENdfNeXt4sW7bmqjX1KSmb+PrrL8jKysTGxpbo6EE89thMnJz+mBScMeMRKioqeO21Wbz77mxSU3/F3t6BiRPvZsqU+1r2RrcSSepFu1dcVXLF3vBZZFec0S5o9bTxoKd7GGrHQNSOAXjauMtspbglmKhM6OvZi17uPdhz9ic2ZG7hnYMfEe7WnXHqBDrZeRk6RCHETdqfd4iktGSKq0twtnRiXHAC/b16t2kMsbEJbNq0ge3bUxg37g5te15eLseOHWHChLtJTf2VY8eOMHJkPO7uHuTmnmXVquU8+eSjfP31Uqysmn/jxcLC88ycOR2NRsNf/nIfVlbWJCWtbHJGff36tVhb2zB58hRsbKw5ePAAn3zyXyorK3niiacAuO++B7l48SL5+bk8+eQzAFhbX33d3OUFuWFh4Tz22EzOnctn+fLvSE39lYULv9KJo6yslL/9bSbDho1gxIg4tm3bwoIF81CrOxMVFd3s19xaDJrU19TU8P7777N69WrKysro2rUrTz/9NFFRUdc8b968ecyfP79Ru5ubG7t3727UvnTpUj777DNycnLo1KkT06ZNY8qUKa32OkTrqdfUc6Yyl/SSP+7QWlxdAoC5iTmBDn6M9B9CsGMggY7+ssWfuOWZmZgx2DeKAd592Ja9i81Z2/nn/rn09+rNmKA4XK2dDR2iEOIG7M87xDcnlmvXgxVXl/DNieUAbZrY9+s3ACcnZ7Zs2aiT1G/ZshFFUYiNjSc4uDPDho3UOS86ejDTpz/A9u0pJCSMafb1Fi/+ktLSEj75ZBGhoV0BGDUqkXvuuaPRsW+88Q8sLf/4wHD77RN4++1/snLlUh5++DEsLCzo128gK1YspbS0hPj40de8dl1dHQsWzKNz5xDmzfuftjQoNLQrb7zxMmvWrGTChLu1x587l8/rr/9DW5qUmDieCRMSWbdu9a2X1L/44ots2rSJadOmERAQwMqVK3n44YdZtGgRkZGR1z1/1qxZOp/+mvokuGTJEl5//XUSEhJ44IEHOHDgALNmzaK6upoHH3ywVV+PaLkLtRfIKDutrYXPLDtNTX0NAE6WjqgdAxjhOBi1YwC+dp1kQasQV2FpakFC4HBifAawOWs723N2czD/Fwb5RhEfMBx7CztDhyjELWlf7kH25v7U4vMySk9Tp9TptNVqalmcuow9Z/e3uL8o734M8O7T4vPMzMwYPnwkq1Yt5/z587i5uQGwZcsmfH396N69h87xdXV1VFZW4Ovrh52dPadOnWhRUr93727CwyO0CT2As7MzsbGjWLlyqc6xVyb0Fy5UUlNTS0REJKtXryArK5MuXUJa9FpPnDhOcXGR9gPBZcOHx/Lhh++zZ89unaTezs6OkSPjtY/Nzc3p1i2Ms2fPtOi6rcVgSf2RI0dYt24dL730Evfffz8At99+O4mJicyZM4fFixdft49Ro0Y1qu+6UlVVFXPnzmXEiBG8//77AEyaNAmNRsP8+fOZOHEi9vb2rfJ6xPUpikLBxfOklWaRcWkWPrcyH2goJfCx8ybKu6+2lMbZ0klKaYRoITtzW+7oPIahvtGsz9jC9uzd7Dm7nxH+QxjhNwgrs+Z/DS6EMJw/J/TXa9en2NgEVqxYytatm5g06V4yMzP4/fdTPPDAwwBUV1exaNEXrF+/hoKCcyiKoj23oqKiRdfKz88jPDyiUbu/f0CjtvT0NBYuXMChQz9RWVmp81xlZcuuCw0lRU1dy8TEBF9fP/Lzc3XaPTw8G+Up9vYOpKX93uJrtwaDJfXJycmYm5szceJEbZulpSUTJkxg7ty5nDt3Dg8Pj2v2oSgKFRUV2NraNpn87du3j5KSEu69V3cLoylTprBmzRp27tzJmDHN//QoWqamvpbT5TlkXLE3fEVtw6CzNrMmyNGfPh69CHYKwN/eT26oI0QrcrZyYkq3CYzwH8ya9I2sz9jMzpw9JASOIMZnIOayx70QbWKAd58bmiF/Zfc/teWnV3K2dOL/9Z7eGqE1W3h4BN7ePmzenMykSfeyeXMygLbsZO7ct1m/fg0TJ95Djx7h2NnZASreeOP/dBL81lReXs6TTz6CjY0dDz00HR8fXywsLDh16gQLFsxDo9Ho5bpXMrlK9YC+XvP1GOy3empqKkFBQdja6tZE9+zZE0VRSE1NvW5SP3ToUC5cuICtrS3x8fG88MILOiuTjx8/DkCPHrpfDYWFhWFiYsLx48clqW9FpdVlV+xIk8Xp8jPUK/UAeFi70cO1G2rHAIIcA/Cy9ZC9tYVoA162HjwcPpWssmxWpW1g2W9JbMv+gTFBcfTzipRxKEQ7NS44QaemHhrWlo0LvvHtI2/GyJFxLFr0OTk52aSkbCI0tJt2Rvty3fyTTz6tPb66urrFs/QAnp5e5ORkN2o/fTpL5/HPPx+ktLSUt956m169/lhjkJt7tolem/etv5eXt/ZaV/apKAo5OdkEBQU3qx9DMVhSX1BQgKenZ6N2d/eGLYvOnTt31XMdHByYOnUqERERmJub8+OPP/Ldd99x/Phxli5dqq2DKigowMLCQifRB7Rt17qGuDaNouFsRZ7O3vCFVUVAw8K9AHtfhvsN0ibxUs8rhGEFOPgxs9fDnCj+jdVpG/gq9buGPe6DE+jh2k1K3YRoZy4vhjX07jeXxcWNYtGiz5k/fy45Odk6CXxTM9bLl39HfX19i68TFRXN0qVLOHnyhLauvri4mM2bN+gcd/mGVVfOitfW1jaquwewtrZu1geMrl274+zswqpVyxg1KlF7U6pt21IoKDjHlCnTWvx62pLBkvqqqqom7+B1eaug6urqq5573326+38mJCTQpUsXZs2axapVq5g0adI1r3H5Ote6xtW4uuonOXV3b9+1/RdqLvJbUQYnz6dz8nwavxVmUFXX8P45WTkQ6hbMGLdhhLiqUTv7Y2YqX+2L9qO9j6+25OHRh5iQSPbl/MySI0n898gXhLoFM6Xn7XR172zo8IQRkvHV4Nw5E8zMWvebr9t8+3Kbb9/rH9gGunTpTJcuIezatRMTExPi4xO0rzcmZhAbN67H3t6OoCA1R48e4aef9uPo2LA27vJxJiYNkwemprrv1ZXHTJt2Pxs3buCZZ2YwadLdWFlZsWrVCry8vPn999+050ZG9sLBwYG33nqDSZPuQaWCDRvWa/u88hrdunVj06YNzJ8/l+7dw7C2tmbQoCGYmproHGtmZsETT8zkH/94g5kzHyU2NoH8/DyWLl1CcHBn7rjjLm2fKpUKlYpG/+eXJ0ia87NgYmLSquPHYJmXlZUVtbW1jdovJ9otvcPXPffcw9tvv83evXu1Sb2VlRU1NTVNHl9dXX1DdxErLKxAo2ndWil3d3sKCspbtc+boSgKhVVFpJVkkl7WsD/82Yo8FBRUqOhk50U/z4abO6kdA3G1cv5jlk+B4qKLhn0BQlyhvY2v9qKzVQgv9X2avbk/sT5jM69tfYcerl0ZFzwKHztvQ4cnjISMrz9oNBrq6vRfx21IsbEJ/PbbKSIj++Dk5Kp9vU8++TdAxcaNG6iuriE8PIL33vuQZ555EkVRtMddzp/q63XfqyuPcXJy5YMP/svcubP58svPdW4+9e9//117rq2tA//5z1zmz3+P//3vQ+ztHYiLG0Xfvv155pkZOtcYO/ZOTpxIZd26NSxZshgvL2+iogZRX69pFE9CQiJmZuYsXvwl8+bNxdbWltjYBKZPfxJTU3PtcYqioCg0+j+//M1Bc34WNBrNVcePiYmqxRPJKsVA1fwPPPAA58+fZ82aNTrte/fu5f777+fjjz9myJAhLeozPj4eHx8fPvvsMwAWLFjAe++9x759+3RKcGpqaoiIiODBBx/kueeea9E1OmJSX6upI7v8zBWlNJmU1zR8TWVlaknQpRIatWMAgQ7+WMvuGcKIGHp8GYOa+hq25+xmU9Z2quqq6OsZSaI6DjdrF0OHJto5GV9/yMvLwsur8Q4tQlzNtX5mbiSpN9hMfdeuXVm0aBGVlZU6i2UPHz6sfb4lamtryc3N1VkU261bNwCOHTtGTEyMtv3YsWNoNBrt87ea8poKnQT+dFkOdZcWtLpZudDVOYRgp4ZZeG9bT1lIJ0QHZ2FqQVzAMGI6DWDz6R1sy97FoXOHifEZSELgcBwspLxCCCHaO4Ml9QkJCXz22WcsXbpUu099TU0NK1asoHfv3tpFtGfPnuXixYsEB/+x4rioqAgXF90ZpE8//ZTq6moGDRqkbRs4cCBOTk588803Okn9t99+i42NDYMHD9bjK2wfNIqGvMpz2i0l00szKbhYCICZyhQ/e1+G+EajdgokyCEAR0v54y3ErcrG3IbxwaMY4nsbGzK28MOZvezN/YkRfoMY4T9EvqUTQoh2zGBJfUREBAkJCcyZM4eCggL8/f1ZuXIlZ8+e5V//+pf2uBdeeIH9+/dz8uRJbduwYcMYPXo0ISEhWFhYsG/fPjZu3EifPn1ITEzUHmdlZcXMmTOZNWsWTz31FDExMRw4cICkpCSeffbZa964ylhV1VWRWZat3Rs+s+w0F+uqgIab0gQ7BhLdaQBqx0D87X0wN216IbEQ4tblZOnIPV3vYrj/YNamb2RDZgo7z+wlIWA4g3yi5PeGEEK0QwbdomT27Nm89957rF69mtLSUkJDQ/n444/p0+faN2kYO3Yshw4dIjk5mdraWnx8fHj88cd59NFHMTPTfUlTpkzB3Nyczz77jJSUFLy9vXn55ZeZNq19b0vUHIqiUFRVoi2lySjNJKciV7ug1dvWk94eEQQ7BhLkGIC7tatsWyeEaDZPG3ce6vEXYstySEpPZvnva9mavYsx6jgGePWW0jwhhGhHDLZQ1lgZcqFsnaaOnIqzDbXwJQ2JfGlNGdBQExvk4H9pX/hAghz8sTG3btU4hTBGspCv9Zws+p3VaRvIKs/Gy9aTcep4erqFyWTBLUzG1x9koaxoqQ6zUFbA/rxDJKUlU1JdglMTN5WoqKkko6zhxk5pJZmcLs+mVlMHgIuVM12c1agdA1E7BtDJ1gvTq9yuWAghWkOoS2eec57BLwXHWJOezMdHvyLIwZ/xwaPo4ty+77QohBAdnczUt1BrzdTvzzvUxO2fzejrGYmCQkZpFvkXCgAwUZngZ++j3Rde7RiAk6XjTccgxK1AZhL1o15Tz768g6zL2ExJdSndXUIZFzwKP/tOhg5NtCEZX3+QmXrRUjJT30EkpSXrJPTQsF/83tyfsDW3Qe0YwECvvgQ5BhDg4IeFLEwTQrQjpiam3NapP309I9l5Zg8bM7fy75/eo69nLxKD4nG3cTV0iEK0OUVRpBxNNIs+5tQlqTeQ4uqSqz73n5jX5ZeCEMIoWJiaM9J/CLd592fL6R1sy/6BQ+eOENNpAAmBI2WbXHHLMDU1o7a2BguLlt+tXtx6amtrMDVt3TRcknoDcbZ0ajKxd7Z0koReCGF0bMytGRecwBDf20jOTGHX2X38mHuAYX6DiA0YgrWZLNwXHZudnRMlJQU4Obljbm4hf8tFkxRFoba2hpKSAuztnVu1b6mpbyH91tSbc2/Xu3QWywohbo7U/BpGwYVC1mZs5ED+L9ia2RAXOIzBPrdJKWEHI+NL18WLlVRUlFBfX2foUEQ7Zmpqhp2dE9bWtlc95kZq6iWpb6HW3NLyervfCCFuniQdhpVdfpaktA0cLzqJk6UjY4JiGeDVR3br6iBkfAmhH5LUtwFD7lMvhGg5GV/tw6niNJLSNpBRdhpPG3fGqhPo5d5DShSMnIwvIfRDkvo2IEm9EMZFxlf7oSgKR84fJyk9mbzKfALs/RgfPIpQl86GDk3cIBlfQuiHbGkphBCi3VKpVES4hxHu1o19eYdYl76JD375mK7OXRgfPAp/B19DhyiEEEZLZupbSGbqhTAuMr7ar9r6Wn44s5fkrK1U1l6gt0dPEtXxeNq4Gzo00UwyvoTQD5mpF0IIYTTMTc0Z7j+YqE79STm9k5TsnfxScIzbvPsxKmik3DlbCCFaQJJ6IYQQBmVtZkWiOo7BvlEkZ25l15kf2Zd3iKG+0cQFDMXG3MbQIQohRLsn5TctJOU3QhgXGV/G5/zFQtamb+ZA/s9YmVkRFzCUob7RWJhaGDo08ScyvoTQD9n9pg1IUi+EcZHxZbzOVOSSlLaBY4UncLRwYHTQSKK8+8ke9+2IjC8h9EOS+jYgSb0QxkXGl/H7vSSD1WnrSS/NwsPajUR1PJEe4ZioTAwd2i1PxpcQ+iFJfRuQpF4I4yLjq2NQFIVjhakkpSVztjIPf3sfxgWPoptLiKFDu6XJ+BJCP2T3GyGEEB2SSqUi3K07Ya5d+SnvZ9ZmbGL+L58Q6tyZ8cGjCHDwM3SIQghhUDJT30IyUy+EcZHx1THVaurYdeZHkjNTqKitpJd7OOPU8Xjaehg6tFuKjC8h9ENm6oUQQtwSzE3MGOYXQ5R3X1KyfyDl9A6OnP+VgV59GR00EmcrJ0OHKIQQbUqSeiGEEEbLysyKMUGxDPaJYmPWVn7I2ctP+YcY4htNXMAwbGWPeyHELULKb1pIym+EMC4yvm4thReLWJexmf15h7Ays2Sk/1CG+cVgKXvc64WMLyH0Q3a/aQOS1AthXGR83ZrOVuSRlJ7M0fPHcbCwZ1TgSKI79Zc97luZjC8h9EOS+jYgSb0QxkXG160tvTSTVb9vIK00AzdrV8aq4+nt0VP2uG8lMr6E0A9J6tuAJPVCGBcZX0JRFH4tPEFSejJnKnLxtevEuOBRdHcJQaVSGTo8oybjSwj9kN1vhBBCiD9RqVT0cOtGd9dQDuT/wtr0TXx0+FO6OKkZHzyKIMcAQ4cohBA3TWbqW0hm6oUwLjK+xJ/VaerYfXY/GzK2UF5bQYRbGGODE/C29TR0aEZHxpcQ+iHlN21AknohjIuML3E1VXXVbMvexZbT26mur2GAdx/GBMXiYuVs6NCMhowvIfRDkvo20JpJ/d5f81ixI42ismpcHCy5c0gwUWFerdK3EKKBJB3ieipqKtmYtZWdZ/aCojDY9zbiA4ZjZ2Fr6NDaPRlfQuiHJPVtoLWS+r2/5vHlhhPU1Gm0bRZmJtw3qqsk9kK0Ikk6RHMVVRWzPmMLP+YewNLUgpH+QxjmNwgrM0tDh9ZuyfgSQj9uJKmXPb0MZMWONJ2EHqCmTsOKHWkGikgIIW5tLlbO/KXbRF4Z8AyhLl1Ym7GJN/b+h+05u6nT1Bk6PCGEuCbZ/cZACsuqr9peVlmDg63c/VAIIQzBy9aTR8KnkVF6mtVp61l6ajVbT/9AojqOvp69ZI97IUS7JOU3LdRa5TfPfbT7qom9qYmKnsGuRId70zPYFTNT+QMixI2S8gBxMxRFIbXoFElpG8iuOIuPnTfj1AmEuXaVPe6R8SWEvkhNfRvQd0392OhAKi/WsefXPMoqa7CzNmdgmCcx4d74e9rf9HWFuNVI0iFag0bR8PO5I6xJ30jBxUKCHYMYHzyKYKdAQ4dmUDK+hNAPSerbQFvtflOv0fBrRhG7jubxy28F1NUr+LrbERPuxcAwLynPEaKZJOkQraleU8+e3P2sz9hCWU054W7dGKceRSe7W3ODAxlfQuiHJPVtwBD71FdcrGV/aj67j+aSkVuOqYmKcHVDeU5EZynPEeJaJOkQ+lBdX8P27F1sPr2dqrpq+nv1ZkxQLK7WLoYOrU3J+BJCPySpbwOGvvnUmYIKdh/LY++xPEovl+d09yQ63Bt/Tzup8RTiTyTpEPpUWXuBzVnb2Z6zC0VRGOQTRXzgcOwtWvbH2FjJ+BJCPySpbwOGTuovk/IcIZpHkg7RFoqrStiQuYW9uQcwNzFjhN9ghvsPxtrMytCh6ZWMLyH0Q5L6NtBekvor/VGek0dGbtkV5TleRHR2k/IccUuTpEO0pbzKc6xN38jPBUexM7clIXAEMT4DMTfpmDtIy/gSQj8kqW8D7TGpv9KZ85XsOZrLnl/zKK1oKM8Z0P3y7jlSniNuPZJ0CEPIKstmddoGThb/jouVM4lBcfTziuxwe9zL+BJCPySpbwPtPam/rKE8p5jdR3P5WVueY0t0uDcDw7xwlPIccYuQpEMY0omi31idtp7T5WfwtvVknDqBcLfuHWaCRcaXEPohSX0bMJak/koVF2v5KTWfXZfKc0xUKsLVLpd2z3HD3KxjzRwJcSVJOoShaRQNvxQcY01aMucunkftGMD44NF0dgoydGg3TcaXEPohSX0bMMak/kpnz1ey+1gue441lOfYWpkxsLsX0T29CPC07zCzR0JcJkmHaC/qNfX8mHuAdRmbKa0pI8y1K+ODR+Fj523o0G6YjC8h9EOS+jZg7En9ZfUaDcczG8pzDp06T129Bh93W6J7eBMV5omjnWWbxiOEvkjSIdqbmvoaduTsYWPWNqrqqujr2YtEdRxu1q6GDq3FZHwJoR+S1LeBjpLUX6myqpb9qefYfTSX9LNSniM6FkOPLyGu5kLtBTaf3sG27F1oFA0xPgNICByBg4W9oUNrNhlfQuiHJPVtoCMm9VfKLaxk99E89hzLpeRSec6ASze3CvSS8hxhfNrT+BKiKSXVpWzITGHP2f2YmZgxwm8QI/wHY21mbejQrkvGlxD6YXRJfU1NDe+//z6rV6+mrKyMrl278vTTTxMVFdWifh5++GF27tzJtGnTePnll3WeCw0NbfKcN954g3vuuafFMXf0pP4yjUbheGYRu64sz3Fr2D1HynOEMWmP40uIppy7UMDa9E0cPHcYW3Mb4gOGM9gnCnNTc0OHdlUyvoTQjxtJ6g16N4wXX3yRTZs2MW3aNAICAli5ciUPP/wwixYtIjIysll9bN++nQMHDlzzmJiYGMaNG6fTFhERccNx3wpMTFT0ULvSQ+3KhSvKc77f9jvLtqfRQ+1CjJTnCCFEq/GwcefBHlMYWTaEpPRkVvy+lm3ZuxgTFEt/r96YmpgaOkQhRDtmsJn6I0eOMHHiRF566SXuv/9+AKqrq0lMTMTDw4PFixdft4+amhrGjh3L2LFjmTdv3lVn6ptqv1G3ykz91TRVntP/0s2tpDxHtEfGNL6EuNLJot9Znb6BrLJsvGw8GBecQE+3sHb1e1bGlxD6cSMz9QabYk1OTsbc3JyJEydq2ywtLZkwYQIHDx7k3Llz1+3jq6++oqqqioceeui6x1ZVVVFdXX1TMQvwdrVlwtBg5jwezTOTI+ihdmXXkVz+/uUBXv10Pxv2ZVFSIe+zEELcrFCXzjzXZwYP95iKgsLHR79izsEPOVWcZujQhBDtkMHKb1JTUwkKCsLW1lanvWfPniiKQmpqKh4eHlc9v6CggI8++ojXXnsNa+trLyZatmwZixYtQlEUQkJCmDlzJrGxsa3yOm5VJiYqegS50iPoUnnOiYbynKXb0li2PY1wtSvR4d706uyKuZl8ZSyEEDdCpVLRyyOccLfu7Ms7yLqMzbz/8//o5hLC+OBR+Nn7GDpEIUQ7YbCkvqCgAE9Pz0bt7u7uANedqX/33XcJCgpi/Pjx1zwuMjKS0aNH4+vrS25uLl999RUzZszgnXfeITEx8cZfgNCysTJnaC8fhvbyIbewkj3H8thzLI8Fq45JeY4QQrQCUxNTbuvUn76ekew8s4dNmdv490/v08cjgkR1PB42boYOUQhhYAZL6quqqjA3b7yi39KyYVeVa5XKHDlyhFWrVrFo0aLrJolLlizReXzHHXeQmJjI22+/zZgxY1qcZLa0vqm53N2NZ1/ia3F3t6dnVy8evlPh8G8FbP0pm91HzrLt0Bn8PO0Y0defoX18cXVs/1u1iY6jo4wvIQDu8UpkfPgIkk5uYt3JrfxScJQR6hjuChuNs7Vjm8cj40uI9sFgSb2VlRW1tbWN2i8n85eT+z9TFIW33nqLuLg4+vbt2+Lr2tjYcPfdd/POO++Qnp5OcHBwi86/1RfKtoSfizX3xYcwcYian07ks/toHl+sO86X64/TI8iV6HAvIru4SXmO0KuOOr6EGOE1nL7O/UjO3MKW9F1sy9jLML8YYv2HYmPeNhMnMr6E0A+j2tLS3d29yRKbgoICgKvW02/evJkjR47w9NNPk5OTo/NcRUUFOTk5uLm5YWVlddVre3t7A1BaWnqj4YsWsLEyY0gvH4b08iGv6AK7j+ay51ge/139KzaWf9zcKshbynOEEKIlHC3tmRx6B8P9BrM2YyObsrax68yPxAUMY4hvNBbteI97IUTrMlhS37VrVxYtWkRlZaXOYtnDhw9rn2/K2bNn0Wg03HfffY2eW7FiBStWrGDhwoUMHjz4qtfOzs4GwMXF5WZegrgBXi423DUkmDsGqUnNKmb30Vx2Hc1l289n8Ha1uXRzKy+c7eXmVkII0VzuNq48EHYvI/2HkpS+gVVp69mes5vRQSMZ6NVX9rgX4hZgsH3qDx8+zKRJk3T2qa+pqSExMRFXV1e+/fZboCGJv3jxorZM5vTp05w6dapRf0888QTDhg1jwoQJREZG4urqSlFRUaPEvbi4mLFjx2JpaUlKSkqL45bym9Z3oaqOAyfPsetoLr/nlKJSQVhQw82tpDxH3KxbfXyJW9NvxWmsTttARtlpPG3cSVTHE+ke3urfhsr4EkI/jKr8JiIigoSEBObMmUNBZ2cpIwAAIABJREFUQQH+/v6sXLmSs2fP8q9//Ut73AsvvMD+/fs5efIkAP7+/vj7+zfZp5+fHyNHjtQ+Xrx4MSkpKQwdOpROnTqRn5/Pd999R1FRER9++KF+X6BoNhsrMwZHdGJwRCfyii6w51guu4/+UZ7Tv7sn0eFeqL0dpDxHCCGaoYtzMH/r8wRHzh8nKT2ZT499jb+9L+ODR9HVpYuhwxNC6IHBknqA2bNn895777F69WpKS0sJDQ3l448/pk+fPq3Sf2RkJIcOHWLp0qWUlpZiY2NDr169ePTRR1vtGqJ1ebnYcOfgYG6PUZN6uqE8Z8/RXLZLeY4QQrSISqUiwj2McLdu7M87xNr0Tcz7ZSFdnbswPngU/g6+hg5RCNGKDFZ+Y6yk/KbtNVmeE+hC9KXyHAtzKc8RVyfjS4gGtfW1/HD2R5IzU6isvUCkR0/GquPxtHG/4T5lfAmhHzdSfiNJfQtJUm9Y+UUX2H0sjz3Hcikqq8ba0owB3TyIDvdG3UnKc0RjMr6E0HWxroqU0ztJyd5JnaaOKO9+jA4aiZNly/e4l/ElhH5IUt8GJKlvHzSKwolLu+ccPFlATZ0GLxcbosO9uK2Ht5TnCC0ZX0I0rbymguTMFH448yMmKhVDfWOICxiKjblNs/uQ8SWEfkhS3wYkqW9/LlbX8dOJc+w+mstvV5Tn3BbuRe8u7lKec4uT8SXEtZ2/WMS6jE38lPczVmZWxPkPZahfNBamFtc9V8aXEPohSX0bkKS+fcsvvsCeow3lOYWXynP6XyrPCZbynFuSjC8hmudMRS5JackcK0zF0cKeUUGx3Obd75p73Mv4EkI/JKlvA5LUGweNonAyq5hdR/M4ePIcNXUaPF1siAn3IirMCxeHq99xWHQsMr6EaJnfSzJYnbaB9NJMPKzdGva49wjHRGXS6FgZX0LohyT1bUCSeuNzsbqOA5fKc07llKICuge5EC3lObcEGV9CtJyiKBwrTCUpLZmzlXn42fswXt2wx/2V33jK+BJCPySpbwOS1Bu3xuU5pvTr6klMuDfBPv+/vTuPi7Lc/z/+nmEVlU1BUBZ3UEDFFdQ0swVNsyxbXFBTT+drndNy7JTH8pTWabN+dSxbXCrNMhfMpTRNTUsNc0lRwQWXJEQQBBRlEeb3h8qJMBVluJnh9fyP+77nvj/T43E57675zHXRnmOPGF/A9SuxlOjntB36+vAqZeafUkvPZhrQvI/Sz57U0uSVyi7IlqeLp+5qFqPOfu2NLhewG4T6KkCotw8lFov2/ZqtjQnHtXVfugqLStTAq5a6RfirazjtOfaE8QXcuKKS89r4W7xWHPlOZ4ryZJJJFv3vs9DJ7KTBofcS7IFKQqivAoR6+3Ou4MLmVhsT0rT/WPaF9pzGXhc2t2rpIxfac2wa4wuoPPnn8/Xcxv/oXHF+uXNeLp56qdu/DKgKsD/XE+odrVQLYDNquTjqpjYNdVObhko/dVabdqdpY0KaPlq2t7Q9p1uEn5o38qA9B0CN5uroetlAL0mnCrKruBoAv0eoB37H18tNd9/UVHd1b6L9F9tzftqbpg07U9XAq5a6Rvira5if6nnQngOgZvJy8bxsgPdy8TSgGgCX0H5TQbTf1DznCs5r274MbUw4rn0X23NaXWzPaU97TrXH+AIq15a07fo8aZGKSopKj9FTD1QueuqrAKG+ZkvPPqdNCce1aXeaTubky9XZoXRzK9pzqifGF1D5tqRtZ/UbwIoI9VWAUA/pwuo5+0tXz8lQQVGxfL1qqVu4n7qG+9OeU40wvgDrYXwB1kGorwKEevxRfuH/2nOSfr3QnhMa7KXuEf5qH0J7jtEYX4D1ML4A6yDUVwFCPa4kI/vcxdVzjpe253QKvdCe0yKA9hwjML4A62F8AdZBqK8ChHpcixKLRQeOZevHhOPamnSxPcezlrpF+Ck63E/1PWoZXWKNwfgCrIfxBVgHob4KEOpRUX9sz5GkVsFe6hbhpw4tfeXiTHuONTG+AOthfAHWQaivAoR63IiTF9tzfrzYnuNysT2nO+05VsP4AqyH8QVYB6G+ChDqURkutedsTEjTz0npKigqlo+nq7pF+Ksr7TmVivEFWA/jC7AOQn0VINSjsl2uPSc0yFPdIvzVMYT2nBvF+AKsh/EFWAehvgoQ6mFNJ7PPadOeC6vnZGRfbM8J8VW3CD+1DPSkPec6ML4A62F8AdZBqK8ChHpUBYvFogMpOfox4fiF9pzCi+054Rfbczxpz7lWjC/AehhfgHUQ6qsAoR5VraCwWNv2p2tjQpoSj56S9L/2nA4hPnJ1djS4wuqN8QVYD+MLsA5CfRUg1MNIJ3POafPuNG1MSFN69jm5ODmoY6jPhdVzAj1lpj2nHMYXYD2ML8A6CPVVgFCP6uBSe87GhOPacrE9p77H/1bP8aE9pxTjC7AexhdgHYaF+vPnz2vNmjXKyclRr1695OPjc6O3rLYI9ahuCgqLtX1/hn5MOK6ko6dkEe05v8f4AqyH8QVYR5WE+tdff13x8fFatGiRpAszhrGxsdq6dassFos8PT01f/58BQUFVagQW0GoR3V22facEB91i/BXy6Ca2Z7D+AKsh/EFWMf1hPoKT+H98MMP6tq1a+nfa9eu1c8//6zRo0erVatWmjx5sj766CO99NJLFb01gBtU36OW+ndron5dG+vgbxfbcxLTtXF3mup7uKpruJ+6RvjLl/YcAADsSoVDfVpamoKDg0v/XrdunQICAjRu3DhJ0oEDB7Rs2bLKqxBAhZlMJrUI8FSLAE89dGtLbd9/YXOrZRuPaOnGIwoJvLi5VSjtOQAA2IMKf5oXFRXJ0fF/L4uPjy8zcx8YGKiMjIzKqQ7ADXNxclB0mJ+iw/yUmZNfurnVrG8SNXf1fnUM8VHXCH+F1ND2HAAA7EGFQ72fn5927Nih+++/XwcOHNCxY8f097//vfR8Zmam3NzcKrVIAJWjnoer+ndtrH7RweXac+q5u6pbBO05AADYogqH+jvvvFPTpk1TVlaWDhw4oDp16qhnz56l5xMTE+32R7KAvfhje86OP7TntAz0VLcIP3UM8VUtF9pzAACo7ir8af3II4/o+PHjWrNmjerUqaPXXntN7u7ukqTTp09r7dq1GjFiRGXXCcBKXJwcFBXmp6gwP2Xl5mvT7gvtOR9/k3SxPcdX3WjPAQCgWqvUzadKSkqUl5cnV1dXOTk5VdZtqxWWtERNYLFYlPxbrn5MOK6fk07oXEHx/9pzwv3k62U7LXaML8B6GF+AdRi+o2xhYaGcnZ0r63bVEqEeNU1hUbG2H8jQxoQ07T2cJYuklgEeF1fPqf7tOYwvwHoYX4B1VEmoX79+vXbt2qW//e1vpcfmzp2rN998U/n5+erTp49effVVZuorgH8UYSuycvO1eU+afkxI04mss3J2MqtDS191j/BTSLBXtWzPYXwB1sP4AqyjSjafmjlzpurVq1f6d3Jysv7zn/8oMDBQAQEB+uabbxQREUFfPWCHvN1ddWd0Y/WNClZyau7F1XNOaPOeNNVzd1HXcH91jfBTAxtqzwEAwB5UONQfOnSozGo333zzjVxcXLRw4ULVqVNH//jHP/TVV18R6gE7ZjKZ1LyRh5o38tBDvVto+4EMbUpI0/JNR7Rs0xG1uNie08kG2nMAALAHFf60zcnJkZeXV+nfmzZtUlRUlOrUufAVQefOnbV+/frKqxBAtebs5KCo1n6Kau1X2p6zMSFNn6xI0uer96tDiI+6RfgrtJq25wAAYA8qHOq9vLyUmpoqSTpz5owSEhL01FNPlZ4/f/68iouLK69CADbj9+05hy6258QnpmvznhPyvtie0432HAAAKl2FQ327du00b948NW/eXBs2bFBxcbF69OhRev7o0aPy9fWt1CIB2BaTyaRmjTzUrJGHHuzdQjsOnNTGhOP6evMRLac9BwCASlfh1W8OHjyo2NhYZWVlSZLuuecevfLKK5IurG3du3dvdenSpfSYvWH1G+D6nTpdcLE957iOZ56Vs6NZ7S+257QK8pLZXPntOYwvwHoYX4B1VNk69dnZ2dq+fbvq1q2rTp06lR7PycnRV199pS5duig0NLSit7UJhHrgxlksFh06nquNCWmK33tC5wrOX2zP8VO3cH818K689hzGF2A9jC/AOgzffKomINQDlavofLF2HDipHxOOa8/hLFksUvMAD3UL91On0AZyc72x9hzGF2A9jC/AOqo01P/6669as2aNjh07JkkKDAxU7969FRQUdD23sxmEesB6/tie4+RoVoeWF9tzgq+vPYfxBVgP4wuwjioL9W+//bamT59ebpUbs9msRx55RI8//vg13aewsFDvvPOOlixZotzcXIWGhurJJ59UdHR0heoZM2aMNmzYoNjYWE2YMKHc+QULFmjWrFlKSUlRw4YNFRsbqyFDhlToGZcQ6gHrs1gsOnz89IXVc/ae0NmC8/Kqe7E9J8JffhVoz2F8AdbD+AKso0p2lF24cKE++OADRUZGavTo0WrRooUk6cCBA5o5c6Y++OADBQYGauDAgVe917PPPqtVq1YpNjZWwcHBWrx4scaMGaM5c+YoMjLymur5/vvvtXXr1j89P2/ePP373/9WTEyMRo4cqa1bt2rSpEkqKCjQww8/fG1vGkCVMplMatrQXU0buuvB3s0vrp6Tpm9+OqqvNx9V80Ye6hZROe05AADYgwrP1A8cOFBOTk6aO3euHB3LfpieP39eQ4YMUVFRkeLi4q54n127dmnQoEEaP3586e6zBQUF6tevn3x9fTV37tyr1lJYWKj+/furf//+mjp1armZ+vz8fPXs2VMdOnTQtGnTSo+PGzdOa9eu1fr161W3bt0KvHtm6gEjnTpdoJ/2pOnHCrTnML4A62F8AdZxPTP15oo+JDk5WX379i0X6CXJ0dFRffv2VXJy8lXvs3LlSjk5OWnQoEGlx1xcXHTfffdp27ZtSk9Pv+o9Zs+erfz8fI0aNeqy5+Pj45Wdna3BgweXOT5kyBDl5eVpw4YNV30GgOrDq66L+kQF66XRXfT88I7q3sZfu5Iz9eaXv+jp9zdp0fpkHc/MkyRt3pOmp6dt1F3/WKKnp23U5j1pBlcPAID1VPh7aycnJ509e/ZPz+fl5cnJyemq90lMTFSTJk1Uu3btMsfbtGkji8WixMTEK25ilZGRoWnTpmnixImqVavWZa/Zu3evJCk8PLzM8bCwMJnNZu3du1d33nnnVWsFUL2YTCY18XdXE393PXhLc/1yMFMbE46Xtuf4eroqM7dAxRe/VcvMLdCnK5IkSdFhfkaWDgCAVVR4pj4iIkJffvmlTp48We5cZmam5s+fr7Zt2171PhkZGZcN7T4+PpJ01Zn6t956S02aNNGAAQOu+AxnZ2d5enqWOX7p2LV8GwCgenNydFCnUF89Mait3ny0mwb1alYm0F9SeL5Eceuv/i0iAAC2qMIz9WPHjtWIESPUt29f3XvvvWrevLmkCzvNxsXFKS8vT1OmTLnqffLz8y87o+/i4iLpQn/9n9m1a5e++uorzZkzRybTny9x92fPuPScKz3jz1S0v+la+fhUrLcfQHk+PnXVokl9LVx3+fCelVvAWAMqGWMKqB4qHOo7deqkqVOnavLkyfr444/LnGvYsKFee+01dezY8ar3cXV1VVFRUbnjl4L2pXD/RxaLRS+//LJuv/32qz7H1dVVhYWFlz1XUFDwp8+4En4oC1R/3u4uyswt/z/tjo5m7UvOkLe7qwFVAfaHzy/AOqpkSUtJuuWWW3TzzTdr9+7dSklJkXRh86mwsDDNnz9fffv21TfffHPFe/j4+Fy2/SUjI0OS/rSffvXq1dq1a5eefPLJ0mdfcubMGaWkpKh+/fpydXWVj4+PioqKlJ2dXaYFp7CwUNnZ2Vfs2Qdguwb2bKZPVySp8HxJ6TEHs0klxSV6bka8Bt3cTD0jG8l8hW/6AACwJde9wLPZbFabNm3Upk2bMsdPnTqlw4cPX/X1oaGhmjNnjvLy8sr8WHbnzp2l5y8nNTVVJSUlGj58eLlzcXFxiouL0/Tp09WjRw+1atVKkrR7925179699Lrdu3erpKSk9DwA+3Lpx7Bx65OVlVsgb3cXDezZTM0aeWj2yiTNWbVfm/ee0Mg+ofKvV/sqdwMAoPozbNeWmJgYzZo1SwsWLChdp76wsFBxcXFq3769GjRoIOlCiD937pyaNWsm6cK3BAEBAeXu9+ijj6pXr1667777FBYWJkmKioqSp6enPv/88zKh/osvvpCbm5t69Ohh5XcJwCjRYX6KDvMr1x7wjwfaadPuNM1bc0D/nrVF/bs2Vp+oYDk6VHjdAAAAqg3DQn3btm0VExOjKVOmKCMjQ0FBQVq8eLFSU1P1yiuvlF73zDPPaMuWLdq3b58kKSgoSEFBQZe9Z2BgoG699dbSv11dXfX3v/9dkyZN0uOPP67u3btr69atWrp0qcaNGyd3d3frvkkA1Y7JZFK3CH+FN62nL77br8U/HNaWpHSN6BOqZg09jC4PAIDrYuj+6q+//rrefvttLVmyRDk5OQoJCdFHH32kDh06VNozhgwZIicnJ82aNUtr1qyRv7+/JkyYoNjY2Ep7BgDb41HbWX8dEK6osJOa8+0+/Wf2NvXuGKCBPZrK1dnQfxoBAKgwk8ViqdSlXN5//33997//VWJiYmXettpg9RvAtlzL+DpXcF6L1idr3fbf5O3uotiYUEU0rVdFFQK2i88vwDqstvrNH5euvJLt27dXqAAAMFotF0cNvT1EXVo30CcrkvT/5u9UVFgDPdS7heq6ORtdHgAAV3VNM/V/thLNn97UZGKmvgKY6QCsp6Ljq+h8ib7efERfbz6qWi6OeujWFopq3eCKG90BNRWfX4B1WG2mfvbs2ddVEADYGidHs+6+qak6hfrqkxVJmr5srzbvSVPsHSGq71HL6PIAALisSu+pt3fM1AO25UbGV0mJRWu3p2jR+kOSpIE9mqp3hwCZzczaAxKfX4C1XM9MPQszA8CfMJtNurVjoF4a3UUhQZ76Ys0BvTxnm1LSzxhdGgAAZRDqAeAq6nm46vH72ugvd7VWRvY5vfjJz4rbcEhF54uNLg0AAEkGr1MPALbCZDIpqrWfwhp768u1B7V80xFt25eu4TGhahnoaXR5AIAajpl6AKiAum7OGt2vtZ66v60Ki0r06tztmvPtPp0rOG90aQCAGoxQDwDXIbxpPU0e3Vm3dwrU97/8pudmxGvHgQyjywIA1FCEegC4Tq7OjnqwdwtNGNZRtV0dNXVRgqZ9tVs5ZwqMLg0AUMMQ6gHgBjVt6K6JIzppYI+m+uXASU2YHq8fdqaKFYMBAFWFUA8AlcDRwax+XRvrxYc7KcC3jj5ekaQp835R+qmzRpcGAKgBCPUAUIn869XWPwdHKjYmREfScvX8zC1aEX9UxSUlRpcGALBjLGkJAJXMbDLp5naN1LZZfX22ap8WrEtW/N4TGtmnlYL96hpdHgDADjFTDwBW4lXXRY8NjNDYu8OVc6ZQkz/dqgXrDqqwiE2rAACVi5l6ALAik8mkjqG+atXYSwvWHdSK+F+1bV+GhseEqFVjb6PLAwDYCWbqAaAK1HZ10og+rfT0Q5GSSXpj3i+a9U2i8vKLjC4NAGAHCPUAUIVaBXtp0sOd1ScqSJsS0jRhery2JqWz/CUA4IYQ6gGgijk7OWjQzc31/PCO8qrjomlf7da7cQk6dZpNqwAA14dQDwAGCfarq+eGd9D9vZprz+EsPTfjJ63b8ZtKmLUHAFQQoR4ADORgNiumS5Amjeqsxn7umvPtPr0+d7uOZ+YZXRoAwIYQ6gGgGvD1ctO4B9tpZN9Q/XYyT/+etUXLNh3R+WI2rQIAXB1LWgJANWEymXRTm4Zq07SePv/ugBZvOKSfE09oRJ9WatrQ3ejyAADVGDP1AFDNeNRx0f/dHa6/3RuhvPzzenn2Vn3x3QHlF543ujQAQDXFTD0AVFORLXwUGuSlheuTtXrrMW3ff2HTqvCm9YwuDQBQzTBTDwDVWC0XRw27PUTPDmkvZyez3pq/U9OX7dXps4VGlwYAqEYI9QBgA1oGeuqFkZ11V7fG2pJ4QhOmx+unPWlsWgUAkESoBwCb4eRo1t03NdW/R3aSr1ctfbRsr95esEsnc84ZXRoAwGCEegCwMQE+dfSvoR300K0ttP9Ytp6fsUWrtx5TSQmz9gBQUxHqAcAGmc0m3dYxUJNHd1bLQE998d0B/eezbUrJOGN0aQAAAxDqAcCG1feopScGtdFf+rdW+qlzevHjn7V4wyEVnWfTKgCoSVjSEgBsnMlkUlSYn8KaeGvemgNatumItu5L14g+oWoR4Gl0eQCAKsBMPQDYibpuzhrTP0xP3d9WhUUleuWz7Zqzap/OFbBpFQDYO0I9ANiZ8Kb1NHl0Z93WMVDfb/9Nz82I1y8HThpdFgDAigj1AGCHXJ0d9dCtLfSv2A5yc3XUfxft0vtf7VZOHptWAYA9ItQDgB1r1tBD/x7RSff0aKodBzL03PSf9OOu42xaBQB2hlAPAHbO0cGs/l0b68WHO6tR/dqa9U2ipsz7RemnzhpdGgCgkhDqAaCG8K9XW/8c0l7D7gjR4eO5mjhzi1bG/6riEpa/BABbx5KWAFCDmE0m9YpspHbN62vOt/s0f91Bxe89oZF9QxXUoK7R5QEArhMz9QBQA3nVddHf7o3Q2LvDdepMgSZ9slULv09WYVGx0aUBAK4DM/UAUEOZTCZ1DPVVq8Zemr/2oL756ai27kvX8JhQtQr2Mro8AEAFMFMPADVcbVcnjezbSk8/2E6ySG98sUOfrEhUXn6R0aUBAK4RoR4AIElq1dhbL47qrD5dgvTjrjQ9Nz1eW5PSjS4LAHANCPUAgFIuTg4a1Ku5nh/eUR51nDXtq92aumiXTp0uMLo0AMAVEOoBAOUE+9XV88M7alCvZtp9OEvPzfhJ3+/4TSVsWgUA1RKhHgBwWQ5ms/p0CdakUZ3V2M9ds7/dp9c/36HjmXlGlwYA+AOTxcC9wgsLC/XOO+9oyZIlys3NVWhoqJ588klFR0df8XVLly7VwoULlZycrJycHPn6+qpLly567LHH1KhRozLXhoSEXPYeL7zwgh566KEK15yZeUYlJZX7n8zHp64yMk5X6j0BXMD4qhwWi0U/7jquL9ceVOH5Et3VrbFiugTJ0YG5oZqM8QVYh9lsUr16dSr0GkOXtHz22We1atUqxcbGKjg4WIsXL9aYMWM0Z84cRUZG/unrkpKS1KBBA/Xs2VMeHh5KTU3V/Pnz9f3332vp0qXy8fEpc3337t111113lTnWtm1bq7wnALBHJpNJN7VtqDbN6mnudwcUt+GQtiSma2TfUDXxdze6PACo8Qybqd+1a5cGDRqk8ePHa8SIEZKkgoIC9evXT76+vpo7d26F7rdnzx4NHDhQ//znPzVq1KjS4yEhIYqNjdWECRMqpW5m6gHbwviyjh37MzRn1T7l5BXqto6BuuempnJxdjC6LFQxxhdgHdczU2/Y96YrV66Uk5OTBg0aVHrMxcVF9913n7Zt26b09Ioto9awYUNJUm5u7mXP5+fnq6CA1RsAoDJEtvTRS6OjdHO7Rlr18zE9PzNeuw9nGl0WANRYhoX6xMRENWnSRLVr1y5zvE2bNrJYLEpMTLzqPbKzs5WZmamEhASNHz9eki7bj79w4UK1a9dObdq0Uf/+/bV69erKeRMAUIO5uTpq2B0henZIezk6mPXWlzs1Y/lenTnHplUAUNUM66nPyMhQgwYNyh2/1A9/LTP1d9xxh7KzsyVJnp6emjhxoqKiospcExkZqb59+yogIEDHjx/X7Nmz9dhjj+nNN99Uv379Klx3Rb8KuVY+PnWtcl8AjC9r8/Gpq04RDTX/u/1auPaA9hzJ0pgBEeoR2Ugmk8no8mBljC+gejAs1Ofn58vJyanccRcXF0m6plaZd999V2fPntXhw4e1dOlS5eWVX2Zt3rx5Zf6+55571K9fP73xxhu68847K/yBQ089YFsYX1Xnjo4BCgvy1McrkjRl7jat+umIht0eonoerkaXBithfAHWYVM99a6urioqKv8V7aUwfyncX0mnTp3Us2dPjRgxQu+8846mTZumzz777IqvcXNz04MPPqi0tDQdOnTo+ooHAFxWgG8dTRjWQQ/1bqF9v2bruZnxWrMtpdInQwAAZRkW6n18fC7bYpORkSFJ8vX1rdD9AgMDFRYWpmXLll31Wn9/f0lSTk5OhZ4BALg6s9mk2zoFavKozmrRyENzV+/XK3O36beMM0aXBgB2y7BQHxoaqsOHD5drmdm5c2fp+YrKz8/X6dNX/xrw2LFjkiRvb+8KPwMAcG3qe9bSk/e31Zj+rXUi65xe+PhnffXDIRWdLzG6NACwO4aF+piYGBUVFWnBggWlxwoLCxUXF6f27duX/og2NTVVycnJZV6blZVV7n67d+9WUlKSwsLCrnjdqVOn9PnnnysgIECNGzeupHcDALgck8mk6DA/vTSmizq18tXSjUf0wsdbdDCFb0oBoDIZ9kPZtm3bKiYmRlOmTFFGRoaCgoK0ePFipaam6pVXXim97plnntGWLVu0b9++0mO9evVSnz591LJlS7m5uengwYNatGiRateurbFjx5ZeN3fuXK1Zs0Y333yzGjZsqBMnTujLL79UVlaW3nvvvSp9vwBQk7m7Oesv/cMU1dpPc75N0iufbVOv9o10b89mquVi6ObmAGAXDP2X9PXXX9fbb7+tJUuWKCcnRyEhIfroo4/UoUOHK75u8ODB2rx5s7777jvl5+fLx8dHMTExGjt2rAIDA0uvi4yM1Pbt27VgwQLl5OTIzc1N7dq10yOPPHLVZwAAKl+bZvU0eXQXxW04pDWnRxSGAAAYfElEQVRbU7TjwEkNuyNE7ZrXN7o0ALBpJovFwpIEFcCSloBtYXxVX8mpOfpkRZJ+y8hT51a+GnxrS7nXdja6LFQA4wuwDpta0hIAULM1a+ihf4/opHtuaqLt+zM0YfpP2phwXMw1AUDFEeoBAIZxdDCrf7cmevHhzmpYv7Zmfp2oN7/8RenZ54wuDQBsCqEeAGA4/3q19cyQ9hp2e0sdSs3VxBnxWhn/q4pLWP4SAK4FSw4AAKoFs8mkXu0D1LZ5fX22ar/mrzuoLYknNKJPqIIa1DW6PACo1pipBwBUK97urvrbvRH6v7vDlZWbr0mfbNWi9ckqLCo2ujQAqLaYqQcAVDsmk0mdQn3VKthL89cd1Nebj2prUrpG9AlVSJCX0eUBQLXDTD0AoNqqU8tJD/dtpXEPtlOJxaLXPt+hT1Yk6Wx+kdGlAUC1QqgHAFR7rRt7a9KoLorpEqQfdqVqwox4bduXYXRZAFBtEOoBADbBxclB9/dqrueHd5SHm7PeW5yg9+ISdOp0gdGlAYDhCPUAAJvS2M9dzw3vqEE3N9OuQ5l6bka81v/ym0rYtApADUaoBwDYHEcHs/pEBWvSw50V3KCOPl25T298vkNpWWeNLg0ADEGoBwDYrAbebnr6oUiN6BOqY+lnNHHmFn29+YjOF7NpFYCahSUtAQA2zWQyqUfbhmrTrJ4+X71fi9Yf0pbEC8tfNvF3N7o8AKgSzNQDAOyCZx0Xjb0nQo8NjNDps4V6afZWfbn2gAoK2bQKgP1jph4AYFfat/RRaJCXFn5/UN9uOaZt+zI0PCZUYU28jS4NAKyGmXoAgN1xc3VUbEyonhkcKQcHs9788hfNXL5XZ86xaRUA+0SoBwDYrZAgL016uJP6dQ3WT3tPaML0nxS/94QsLH8JwM4Q6gEAds3J0UEDezTTxBGdVN/DVR8u3aP/LtylrNx8o0sDgEpDqAcA1AiBvnU0YVhHPdi7hRJ/PaUJM+K1ZlsKm1YBsAuEegBAjWE2m3R7p0C9NKqLmjfy0NzV+/XqZ9v128k8o0sDgBtCqAcA1Dj1PWvpqfvbanS/VjqemacXZm3Rkh8Pq+g8m1YBsE0saQkAqJFMJpO6hvsrvEk9zVtzQEt+PKyfky5sWtW8kYfR5QFAhTBTDwCo0dxrO+svd4XpiUFtlF94Xq/M2aa5q/frXMF5o0sDgGtGqAcAQFKbZvU1eVQX9e4QoLXbUvT8zHjtPHjS6LIA4JoQ6gEAuKiWi6MG39ZS44d1kKuzo95ZuEsfLt2j3LxCo0sDgCsi1AMA8AfNG3nohZGddHf3Jtq2L10Tpv+kjQnH2bQKQLVFqAcA4DIcHcy6q3sT/XtkZ/nXq62ZXyfqrS9/UUb2OaNLA4ByCPUAAFxBo/q19ezQ9hp6e0sdTM3V8zPj9e2WX1VSwqw9gOqDUA8AwFWYTSbd0j5AL4/uolZBXvpy7UG9PGerjqWfMbo0AJBEqAcA4Jp5u7vq7/e10V8HhCkzJ1+TPvlZi9Ynq+h8sdGlAajh2HwKAIAKMJlM6tyqgVo39taXaw/o681HtXVfhkbEhCgkyMvo8gDUUMzUAwBwHerUctKoO1vrHw+2U3FxiV77fIc+XZmks/lsWgWg6hHqAQC4AWGNvTV5VBfFdA7Shp2pmjDjJ23fn2F0WQBqGEI9AAA3yMXZQfff0lzPD+8odzdnvRuXoPcWJyj7TIHRpQGoIQj1AABUksZ+7np+eEfd27Opdh7M1ITp8dqwM5VNqwBYHaEeAIBK5Ohg1p3RjTV5VGcF+dbRJyuS9MYXO3Qi66zRpQGwY4R6AACsoIG3m54eHKkRfUJ19MQZTZy1RV9vPqLzxSVGlwbADrGkJQAAVmI2mdSjbUO1aVZPc1fv16L1h/RzYrpG9A1VYz93o8sDYEeYqQcAwMo867jo0Xsi9Og9Eco5W6jJn27V/LUHVVDEplUAKgcz9QAAVJEOIT5qFeypBd8na+WWX7Vtf7piY0IV1tjb6NIA2Dhm6gEAqEJurk4aHhOqZwZHymwy6c15v2jm13t15lyR0aUBsGGEegAADBAS5KVJozrrzuhg/bTnhJ6b/pO2JJ5g+UsA14VQDwCAQZwcHXRvz2Z6fnhHebu76oMlezR1UYKycvONLg2AjSHUAwBgsKAGdTUhtoMeuKW59h7N0nMz4rV2e4pKmLUHcI0I9QAAVAMOZrPu6BykyaO6qFlDd322ar9e/Wy7Uk/mGV0aABtgaKgvLCzUG2+8oe7du6tNmza6//77tXnz5qu+bunSpYqNjVW3bt0UHh6uW265RePHj9dvv/122esXLFigPn36KCIiQnfccYfmzp1b2W8FAIBK4eNZS0890E6j7myl45l5euHjLVr642E2rQJwRQ4vvPDCC0Y9/Omnn1ZcXJzuv/9+9e/fX/v27dPMmTMVHR0tf3//P33dkiVLZDKZdNtttykmJkaNGjXSihUr9OWXX2rAgAGqXbt26bXz5s3TxIkT1aVLFw0dOlQlJSX66KOPVLt2bUVGRla45nPnClXZ34bWru2is2cLK/emACQxvmCbTCaTghrUVfcIf2XmFmjNthRt35+h4AZ15e3uanR5pRhfgHWYTCa5uTlX7DUWg35mv2vXLg0aNEjjx4/XiBEjJEkFBQXq16+ffH19KzybvmfPHg0cOFD//Oc/NWrUKElSfn6+evbsqQ4dOmjatGml144bN05r167V+vXrVbdu3Qo9JzPzjEpKKvc/mY9PXWVknK7UewK4gPEFe7Dz4EnNWbVPp3IL1LtDgO7p0VS1XIzfaobxBViH2WxSvXp1KvYaK9VyVStXrpSTk5MGDRpUeszFxUX33Xeftm3bpvT09Ardr2HDhpKk3Nzc0mPx8fHKzs7W4MGDy1w7ZMgQ5eXlacOGDTfwDgAAqBptm9fX5FFddEv7AK3ZlqKJM+O1KznT6LIAVCOGhfrExEQ1adKkTKuMJLVp00YWi0WJiYlXvUd2drYyMzOVkJCg8ePHS5Kio6NLz+/du1eSFB4eXuZ1YWFhMpvNpecBAKjuark4asjtLTV+aAc5Ozno7QU79dHSPcql/QWAJMO+u8vIyFCDBg3KHffx8ZGka5qpv+OOO5SdnS1J8vT01MSJExUVFVXmGc7OzvL09CzzukvHKvptAAAARmse4KEXRnbWNz8d1fJNR7T7cJYe7N1c0WF+MplMRpcHwCCGhfr8/Hw5OTmVO+7i4iLpQn/91bz77rs6e/asDh8+rKVLlyovr+yyX3/2jEvPuZZn/FFF+5uulY9PxXr7AVw7xhfs0eh72uj26MaaOv8XzVieqG37T+rRQe3UwNutSutgfAHVg2Gh3tXVVUVFReWOXwral8L9lXTq1EmS1LNnT/Xu3Vv9+/eXm5ubhg4dWvqMwsLLfy1ZUFBwTc/4I34oC9gWxhfsWS0Hk8Y92E7rtv+mheuTNfb1NRrYo5lu7RAgs9n6s/aML8A6bOqHsj4+Ppdtf8nIyJAk+fr6Vuh+gYGBCgsL07Jly8o8o6ioqLRF55LCwkJlZ2dX+BkAAFQ3ZpNJvTsE6OXRXRQa5KV5aw7o5TlbdSz9jNGlAahChoX60NBQHT58uFzLzM6dO0vPV1R+fr5On/7fjEGrVq0kSbt37y5z3e7du1VSUlJ6HgAAW+ft7qrH72ujR+4K08mcfE365GfFbUhW0flio0sDUAUMC/UxMTEqKirSggULSo8VFhYqLi5O7du3L/0RbWpqqpKTk8u8Nisrq9z9du/eraSkJIWFhZUei4qKkqenpz7//PMy137xxRdyc3NTjx49KvMtAQBgKJPJpC6tG+jlMVGKat1Ayzcd1cRZP2vfr6eMLg2AlRnWU9+2bVvFxMRoypQpysjIUFBQkBYvXqzU1FS98sorpdc988wz2rJli/bt21d6rFevXurTp49atmwpNzc3HTx4UIsWLVLt2rU1duzY0utcXV3197//XZMmTdLjjz+u7t27a+vWrVq6dKnGjRsnd3f3Kn3PAABUhTq1nDSqX2tFhfnp05VJeu3zHbo5spHu69lMbq7Gb1oFoPIZtqOsdOHHqm+//baWLVumnJwchYSE6KmnnlLXrl1Lrxk2bFi5UP/aa69p8+bNSklJUX5+vnx8fBQVFaWxY8cqMDCw3HPmz5+vWbNmKSUlRf7+/ho2bJhiY2Ovq2Z+KAvYFsYXarqCwmJ99eMhrfr5mDxqO2vY7SGKbOlTKfdmfAHWcT0/lDU01NsiQj1gWxhfwAWHj+fq42+SlJJxRh1DfDTktpbyqFPxVeB+j/EFWIdNrX4DAACqThN/d00c0VH39myqXw5masL0eG3YmSrm9gD7QKgHAKCGcHQw687oxpo0qrMCfevokxVJeuOLHTpx6qzRpQG4QYR6AABqGD9vNz09OFLDY0J09MQZTZy5RSt+OqrikhKjSwNwnfgJPAAANZDZZFLPdo3Upll9zV29Xwu+T1Z84gmN7NNKwX51jS4PQAUxUw8AQA3mVddFjw2M0KP3hCvnTKEmf7pV89cdVEERm1YBtoSZegAAoA4hvmoV7KX565K1Mv5Xbd+XoeExIWrV2Nvo0gBcA2bqAQCAJMnN1Ukj+oTqnw9FymSS3pj3i2Z9k6gz54qMLg3AVRDqAQBAGaHBXnrx4c66MzpYmxLS9NyMeP2clM7yl0A1xuZTFcTmU4BtYXwBN+bXE6f18YokHU07rXbN62vo7S2171i24tYnKyu3QN7uLhrYs5miw/yMLhWwG+woWwUI9YBtYXwBN664pETfbU3R4g2HVGKxyGKRin/3WejsaNbwPqEEe6CSsKMsAACodA5ms+7oHKRJo7tIMpUJ9JJUeL5EceuTjSkOgCRCPQAAuEa+nrV0vvjyG1Rl5hZUcTUAfo9QDwAArlk9d5cKHQdQNQj1AADgmg3s2UzOjmXjg7OjWQN7NjOoIgASm08BAIAKuPRjWFa/AaoXQj0AAKiQ6DA/RYf5sboUUI3QfgMAAADYOEI9AAAAYOMI9QAAAICNI9QDAAAANo5QDwAAANg4Qj0AAABg4wj1AAAAgI0j1AMAAAA2jlAPAAAA2Dh2lK0gs9lkU/cFwPgCrInxBVS+6xlXJovFYrFCLQAAAACqCO03AAAAgI0j1AMAAAA2jlAPAAAA2DhCPQAAAGDjCPUAAACAjSPUAwAAADaOUA8AAADYOEI9AAAAYOMI9QAAAICNI9QDAAAANs7R6AJqqvT0dM2ePVs7d+7U7t27dfbsWc2ePVtdunQxujTApu3atUuLFy9WfHy8UlNT5enpqcjISD3xxBMKDg42ujzApiUkJOiDDz7Q3r17lZmZqbp16yo0NFSPPvqo2rdvb3R5gN2ZPn26pkyZotDQUC1ZsuSK1xLqDXL48GFNnz5dwcHBCgkJ0Y4dO4wuCbALM2bM0Pbt2xUTE6OQkBBlZGRo7ty5uvvuu7Vw4UI1a9bM6BIBm3Xs2DEVFxdr0KBB8vHx0enTp7Vs2TINHTpU06dPV7du3YwuEbAbGRkZev/99+Xm5nZN15ssFovFyjXhMs6cOaOioiJ5eXnpu+++06OPPspMPVAJtm/frvDwcDk7O5ceO3LkiPr3768777xTr776qoHVAfbn3LlzuvXWWxUeHq4PP/zQ6HIAu/Hss88qNTVVFotFubm5V52pp6feIHXq1JGXl5fRZQB2p3379mUCvSQ1btxYLVq0UHJyskFVAfarVq1a8vb2Vm5urtGlAHZj165dWrp0qcaPH3/NryHUA7B7FotFJ0+e5H+kgUpy5swZZWVl6dChQ3rrrbe0f/9+RUdHG10WYBcsFosmT56su+++W61atbrm19FTD8DuLV26VCdOnNCTTz5pdCmAXfjXv/6lb7/9VpLk5OSkBx98UH/9618NrgqwD1999ZUOHjyo9957r0KvI9QDsGvJycmaNGmSOnTooAEDBhhdDmAXHn30UT3wwANKS0vTkiVLVFhYqKKionKtbwAq5syZM3rzzTf1l7/8Rb6+vhV6Le03AOxWRkaGHnnkEXl4eOidd96R2cw/eUBlCAkJUbdu3XTvvfdq5syZ2rNnT4V6fwFc3vvvvy8nJyeNHDmywq/lEw6AXTp9+rTGjBmj06dPa8aMGfLx8TG6JMAuOTk5qXfv3lq1apXy8/ONLgewWenp6fr00081ePBgnTx5UikpKUpJSVFBQYGKioqUkpKinJycP3097TcA7E5BQYH++te/6siRI/rkk0/UtGlTo0sC7Fp+fr4sFovy8vLk6upqdDmATcrMzFRRUZGmTJmiKVOmlDvfu3dvjRkzRuPGjbvs6wn1AOxKcXGxnnjiCf3yyy+aNm2a2rVrZ3RJgN3IysqSt7d3mWNnzpzRt99+K39/f9WrV8+gygDbFxAQcNkfx7799ts6e/as/vWvf6lx48Z/+npCvYGmTZsmSaVrZy9ZskTbtm2Tu7u7hg4damRpgM169dVXtXbtWvXq1UvZ2dllNuuoXbu2br31VgOrA2zbE088IRcXF0VGRsrHx0fHjx9XXFyc0tLS9NZbbxldHmDT6tate9nPqE8//VQODg5X/fxiR1kDhYSEXPZ4o0aNtHbt2iquBrAPw4YN05YtWy57jrEF3JiFCxdqyZIlOnjwoHJzc1W3bl21a9dODz/8sDp37mx0eYBdGjZs2DXtKEuoBwAAAGwcq98AAAAANo5QDwAAANg4Qj0AAABg4wj1AAAAgI0j1AMAAAA2jlAPAAAA2DhCPQAAAGDjCPUAgGpv2LBhuuWWW4wuAwCqLUejCwAAGCM+Pl6xsbF/et7BwUF79+6twooAANeLUA8ANVy/fv3Uo0ePcsfNZr7MBQBbQagHgBqudevWGjBggNFlAABuANMwAIArSklJUUhIiKZOnarly5erf//+ioiI0M0336ypU6fq/Pnz5V6TlJSkRx99VF26dFFERIT69u2r6dOnq7i4uNy1GRkZeumll9S7d2+Fh4crOjpaI0eO1MaNG8tde+LECT311FPq1KmT2rZtq1GjRunw4cNWed8AYEuYqQeAGu7cuXPKysoqd9zZ2Vl16tQp/Xvt2rU6duyYhgwZovr162vt2rV69913lZqaqldeeaX0uoSEBA0bNkyOjo6l165bt05TpkxRUlKS3nzzzdJrU1JS9NBDDykzM1MDBgxQeHi4zp07p507d2rTpk3q1q1b6bVnz57V0KFD1bZtWz355JNKSUnR7NmzNXbsWC1fvlwODg5W+i8EANUfoR4AaripU6dq6tSp5Y7ffPPN+vDDD0v/TkpK0sKFCxUWFiZJGjp0qB577DHFxcXpgQceULt27SRJL7/8sgoLCzVv3jyFhoaWXvvEE09o+fLluu+++xQdHS1JevHFF5Wenq4ZM2bopptuKvP8kpKSMn+fOnVKo0aN0pgxY0qPeXt764033tCmTZvKvR4AahJCPQDUcA888IBiYmLKHff29i7zd9euXUsDvSSZTCaNHj1a3333nVavXq127dopMzNTO3bs0G233VYa6C9d+3//939auXKlVq9erejoaGVnZ+uHH37QTTfddNlA/scf6prN5nKr9URFRUmSjh49SqgHUKMR6gGghgsODlbXrl2vel2zZs3KHWvevLkk6dixY5IutNP8/vjvNW3aVGazufTaX3/9VRaLRa1bt76mOn19feXi4lLmmKenpyQpOzv7mu4BAPaKH8oCAGzClXrmLRZLFVYCANUPoR4AcE2Sk5PLHTt48KAkKTAwUJIUEBBQ5vjvHTp0SCUlJaXXBgUFyWQyKTEx0VolA0CNQagHAFyTTZs2ac+ePaV/WywWzZgxQ5J06623SpLq1aunyMhIrVu3Tvv37y9z7UcffSRJuu222yRdaJ3p0aOHNmzYoE2bNpV7HrPvAHDt6KkHgBpu7969WrJkyWXPXQrrkhQaGqrhw4dryJAh8vHx0Zo1a7Rp0yYNGDBAkZGRpddNmDBBw4YN05AhQzR48GD5+Pho3bp1+vHHH9WvX7/SlW8k6fnnn9fevXs1ZswY3X333QoLC1NBQYF27typRo0a6emnn7beGwcAO0KoB4Aabvny5Vq+fPllz61ataq0l/2WW25RkyZN9OGHH+rw4cOqV6+exo4dq7Fjx5Z5TUREhObNm6f//ve/+uKLL3T27FkFBgZq3Lhxevjhh8tcGxgYqEWLFum9997Thg0btGTJErm7uys0NFQPPPCAdd4wANghk4XvNwEAV5CSkqLevXvrscce09/+9jejywEAXAY99QAAAICNI9QDAAAANo5QDwAAANg4euoBAAAAG8dMPQAAAGDjCPUAAACAjSPUAwAAADaOUA8AAADYOEI9AAAAYOMI9QAAAICN+/9caqjw3xOYugAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 864x432 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"Qbh-533qOJ2M","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":105},"executionInfo":{"status":"ok","timestamp":1593633215939,"user_tz":180,"elapsed":333127,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"3006f973-8368-47a7-d911-be31529766d0"},"source":["import os\n","\n","# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n","\n","output_dir = '/content/drive/My Drive/Colab Notebooks/Torch/_FineTuningModels/SentenceClassification/model_save/bert_model_sentence_classification_tail_tuned_split_' + str(n_split) + '/'\n","\n","# Create output directory if needed\n","if not os.path.exists(output_dir):\n","    os.makedirs(output_dir)\n","\n","print(\"Saving model to %s\" % output_dir)\n","\n","# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n","# They can then be reloaded using `from_pretrained()`\n","model_to_save = bert_model.module if hasattr(bert_model, 'module') else bert_model  # Take care of distributed/parallel training\n","model_to_save.save_pretrained(output_dir)\n","bert_tokenizer.save_pretrained(output_dir)\n","\n","# Good practice: save your training arguments together with the trained model\n","# torch.save(args, os.path.join(output_dir, 'training_args.bin'))"],"execution_count":42,"outputs":[{"output_type":"stream","text":["Saving model to /content/drive/My Drive/Colab Notebooks/Torch/_FineTuningModels/SentenceClassification/model_save/bert_model_sentence_classification_tail_tuned_split_5/\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["('/content/drive/My Drive/Colab Notebooks/Torch/_FineTuningModels/SentenceClassification/model_save/bert_model_sentence_classification_tail_tuned_split_5/vocab.txt',\n"," '/content/drive/My Drive/Colab Notebooks/Torch/_FineTuningModels/SentenceClassification/model_save/bert_model_sentence_classification_tail_tuned_split_5/special_tokens_map.json',\n"," '/content/drive/My Drive/Colab Notebooks/Torch/_FineTuningModels/SentenceClassification/model_save/bert_model_sentence_classification_tail_tuned_split_5/added_tokens.json')"]},"metadata":{"tags":[]},"execution_count":42}]}]}