{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of Split4.ipynb","provenance":[{"file_id":"1ly17dl3w8rGXAPtd1owJFslx4RVJE78c","timestamp":1592607825372},{"file_id":"1VIBcIIFR_YFlSguO_JGlnJbFzyAcT6YH","timestamp":1592464333044},{"file_id":"1dZvMRgPPkRVGa_4BZ1Tvoom_U4pjwmRX","timestamp":1592435543596},{"file_id":"12Sf257YUAwzmSXOlE3llOhi0N1YVUbM7","timestamp":1583376883298}],"collapsed_sections":[],"authorship_tag":"ABX9TyPCYBSMf61YgTbVnbRkofjU"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"JQrQmaLj0UuZ","colab":{"base_uri":"https://localhost:8080/","height":122},"executionInfo":{"status":"ok","timestamp":1593324779813,"user_tz":180,"elapsed":25452,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"39ee1320-321d-4184-dd82-d8ddf2cf5cce"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JjEPtibx-EJD"},"source":["import numpy as np\n","import torch\n","\n","class EarlyStopping:\n","    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n","    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt'):\n","        \"\"\"\n","        Args:\n","            patience (int): How long to wait after last time validation loss improved.\n","                            Default: 7\n","            verbose (bool): If True, prints a message for each validation loss improvement. \n","                            Default: False\n","            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n","                            Default: 0\n","            path (str): Path for the checkpoint to be saved to.\n","                            Default: 'checkpoint.pt'\n","        \"\"\"\n","        self.patience = patience\n","        self.verbose = verbose\n","        self.counter = 0\n","        self.best_score = None\n","        self.early_stop = False\n","        self.val_loss_min = np.Inf\n","        self.delta = delta\n","        self.path = path\n","\n","    def __call__(self, val_loss, model):\n","\n","        score = -val_loss\n","\n","        if self.best_score is None:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model)\n","        elif score < self.best_score + self.delta:\n","            self.counter += 1\n","            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n","            if self.counter >= self.patience:\n","                self.early_stop = True\n","        else:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model)\n","            self.counter = 0\n","\n","    def save_checkpoint(self, val_loss, model):\n","        '''Saves model when validation loss decrease.'''\n","        if self.verbose:\n","            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n","        torch.save(model.state_dict(), self.path)\n","        self.val_loss_min = val_loss"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tjGPuXgoqulz"},"source":["def Accuracy(prediction, observation):\n","  prediction = prediction[:,1]\n","  prediction_class = (torch.reshape(prediction, observation.shape) > 0.5).float()\n","  correct = (prediction_class == observation).float().sum()\n","  accuracy = correct/prediction_class.shape[0]\n","  return float(accuracy.cpu())\n","\n","def Precision(prediction, observation):\n","  prediction = prediction[:,1]\n","  res = []\n","  prediction_class = (torch.reshape(prediction, observation.shape) > 0.5).float()\n","  for label in [0, 1]:\n","    correct = (prediction_class[prediction_class == label] == observation[prediction_class == label]).float().sum()\n","    precision = correct/prediction_class[prediction_class == label].shape[0]\n","    res.append(float(precision.cpu()))\n","  return res\n","\n","def Recall(prediction, observation):\n","  prediction = prediction[:,1]\n","  res = []\n","  prediction_class = (torch.reshape(prediction, observation.shape) > 0.5).float()\n","  for label in [0, 1]:\n","    correct = (prediction_class[observation == label] == observation[observation == label]).float().sum()\n","    recall = correct/prediction_class[observation == label].shape[0]\n","    res.append(float(recall.cpu()))\n","  return res"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sgz5Ea8a1wKr"},"source":["n_split = 4"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cutkFU0k1Pkv"},"source":["import pickle\n","import pandas as pd\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wSJO5A951VXh"},"source":["with open('/content/drive/My Drive/Data Master/X_train_final', 'rb') as file:\n","    X_train = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/Y_train_final', 'rb') as file:\n","    Y_train = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/X_test_final', 'rb') as file:\n","    X_test = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/Y_test_final', 'rb') as file:\n","    Y_test = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/word_index_final', 'rb') as file:\n","    word_index = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/train_index_final_split_' + str(n_split), 'rb') as file:\n","    train_index = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/valid_index_final_split_' + str(n_split), 'rb') as file:\n","    valid_index = pickle.load(file)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_v0BS5Cp_06s"},"source":["test_index = [i for i, _ in enumerate(X_test)]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NGqLg8IllrZE"},"source":["inv_word_index = {ix : w for w, ix in word_index.items()}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1-2YPzNN1x5T"},"source":["import itertools\n","features_index = {w:ix for ix, w in enumerate(np.unique(list(itertools.chain.from_iterable(np.array(X_train)[train_index]))))}\n","inv_features_index = {ix:w for ix, w in enumerate(np.unique(list(itertools.chain.from_iterable(np.array(X_train)[train_index]))))}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RxZWUTIv4K5T"},"source":["X_train_matrix = np.zeros((len(X_train), len(features_index)))\n","X_test_matrix = np.zeros((len(X_test), len(features_index)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"K6KzJuIy4dN8"},"source":["for i, x in enumerate(X_train):\n","  for w in x:\n","    if w in features_index:\n","      X_train_matrix[i,features_index[w]] += 1\n","\n","for i, x in enumerate(X_test):\n","  for w in x:\n","    if w in features_index:\n","      X_test_matrix[i,features_index[w]] += 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9d4attfQ0i-Q"},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"twcFT-Hl3fqP","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593324810646,"user_tz":180,"elapsed":56221,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"33eedbe9-93c6-4c65-f92f-530f9d6b07bd"},"source":["input_dim = X_train_matrix.shape[1]\n","input_dim"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["231280"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"9fbXl191nZhK"},"source":["class LogisticRegression (nn.Module):\n","\n","  def __init__(self):\n","    super(LogisticRegression, self).__init__()\n","\n","    self.fc1 = nn.Linear(input_dim, 2)\n","                                \n","    self.softmax = nn.Softmax(dim=1)\n","\n","  def forward(self, x):\n","    x = F.normalize(x)\n","    y = self.softmax(self.fc1(x))\n","\n","    return y"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Cgzf7IEqnyN4"},"source":["model = LogisticRegression()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0rnUcqchBE91"},"source":["X_train_tensor = torch.from_numpy(X_train_matrix[train_index]).float()\n","Y_train_tensor = torch.LongTensor(np.array(Y_train[train_index]))\n","\n","X_valid_tensor = torch.from_numpy(X_train_matrix[valid_index]).float()\n","Y_valid_tensor = torch.LongTensor(np.array(Y_train[valid_index]))\n","\n","X_test_tensor = torch.from_numpy(X_test_matrix).float()\n","Y_test_tensor = torch.LongTensor(np.array(Y_test))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GlP5dzFET5tF"},"source":["torch.manual_seed(0)\n","np.random.seed(0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SV0Da5qu98-C"},"source":["import torch.optim as optim\n","optimizer = optim.AdamW(model.parameters(), lr=0.01)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gHujp4Ww_ZuO"},"source":["from torch.optim.lr_scheduler import ReduceLROnPlateau\n","scheduler = ReduceLROnPlateau(optimizer, 'min')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qkfeoTBHRuOb","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593324812065,"user_tz":180,"elapsed":57606,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"4a4b4112-a024-4985-acb1-bb8d0eac999a"},"source":["weights = [sum(Y_train)/len(Y_train), 1-sum(Y_train)/len(Y_train)]\n","class_weights = torch.FloatTensor(weights)\n","class_weights"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0.1734, 0.8266])"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"8-F96WAE98zI"},"source":["criterion = nn.CrossEntropyLoss(weight=class_weights)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"E7KgiIq398rR","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1593324917753,"user_tz":180,"elapsed":163283,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"1a1cbebc-bda2-4eaa-c393-fefb6b6b1f80"},"source":["patience = 20\n","early_stopping = EarlyStopping(patience=patience, verbose=True)\n","\n","for i in range(100):\n","  model.train()\n","  optimizer.zero_grad()\n","  prediction = model(X_train_tensor)\n","  loss = criterion(prediction, Y_train_tensor)\n","  loss.backward()\n","  optimizer.step()\n","\n","  accuracy = Accuracy(prediction, Y_train_tensor)\n","\n","  model.eval()\n","\n","  val_prediction = model(X_valid_tensor)\n","  test_prediction = model(X_test_tensor)\n","  val_loss = criterion(val_prediction, Y_valid_tensor)\n","  test_loss = criterion(test_prediction, Y_test_tensor)\n","\n","  val_accuracy = Accuracy(val_prediction, Y_valid_tensor)\n","  test_accuracy = Accuracy(test_prediction, Y_test_tensor)\n","\n","  early_stopping(val_loss, model)\n","\n","  if early_stopping.early_stop:\n","    print(\"Early stopping\")\n","    break\n","\n","  print(i, float(loss.cpu()), accuracy, float(val_loss.cpu()), val_accuracy, float(test_loss.cpu()), test_accuracy)\n","\n","  scheduler.step(val_loss)\n","\n","model.load_state_dict(torch.load('checkpoint.pt'))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Validation loss decreased (inf --> 0.684838).  Saving model ...\n","0 0.6931551694869995 0.8267605900764465 0.6848384141921997 0.8932584524154663 0.6864914298057556 0.9002624750137329\n","Validation loss decreased (0.684838 --> 0.676672).  Saving model ...\n","1 0.6807587742805481 0.9619718194007874 0.6766719222068787 0.882022500038147 0.6799913644790649 0.8923884630203247\n","Validation loss decreased (0.676672 --> 0.668661).  Saving model ...\n","2 0.6685959696769714 0.9605633616447449 0.6686614155769348 0.882022500038147 0.6736319065093994 0.8897637724876404\n","Validation loss decreased (0.668661 --> 0.660820).  Saving model ...\n","3 0.6566922068595886 0.9619718194007874 0.6608203053474426 0.882022500038147 0.6674222350120544 0.8845144510269165\n","Validation loss decreased (0.660820 --> 0.653161).  Saving model ...\n","4 0.6450743079185486 0.9619718194007874 0.6531608700752258 0.882022500038147 0.6613755226135254 0.8845144510269165\n","Validation loss decreased (0.653161 --> 0.645695).  Saving model ...\n","5 0.633765459060669 0.9619718194007874 0.645695149898529 0.882022500038147 0.6555002331733704 0.8845144510269165\n","Validation loss decreased (0.645695 --> 0.638435).  Saving model ...\n","6 0.6227825880050659 0.9633802771568298 0.6384348273277283 0.882022500038147 0.6498019695281982 0.8845144510269165\n","Validation loss decreased (0.638435 --> 0.631391).  Saving model ...\n","7 0.6121432781219482 0.9633802771568298 0.6313908100128174 0.882022500038147 0.6442858576774597 0.8845144510269165\n","Validation loss decreased (0.631391 --> 0.624572).  Saving model ...\n","8 0.6018584966659546 0.9633802771568298 0.6245715022087097 0.882022500038147 0.6389546990394592 0.8845144510269165\n","Validation loss decreased (0.624572 --> 0.617984).  Saving model ...\n","9 0.5919370651245117 0.9633802771568298 0.6179835200309753 0.882022500038147 0.6338109374046326 0.8845144510269165\n","Validation loss decreased (0.617984 --> 0.611630).  Saving model ...\n","10 0.5823842287063599 0.9633802771568298 0.6116300821304321 0.882022500038147 0.6288563013076782 0.8845144510269165\n","Validation loss decreased (0.611630 --> 0.605514).  Saving model ...\n","11 0.5732024312019348 0.9633802771568298 0.6055141091346741 0.882022500038147 0.6240901350975037 0.8845144510269165\n","Validation loss decreased (0.605514 --> 0.599636).  Saving model ...\n","12 0.5643898248672485 0.9633802771568298 0.5996360182762146 0.882022500038147 0.619511604309082 0.8845144510269165\n","Validation loss decreased (0.599636 --> 0.593995).  Saving model ...\n","13 0.5559435486793518 0.9647887349128723 0.5939951539039612 0.882022500038147 0.6151175498962402 0.8845144510269165\n","Validation loss decreased (0.593995 --> 0.588590).  Saving model ...\n","14 0.5478575229644775 0.9661971926689148 0.5885897278785706 0.882022500038147 0.6109058856964111 0.8845144510269165\n","Validation loss decreased (0.588590 --> 0.583415).  Saving model ...\n","15 0.5401238799095154 0.9676056504249573 0.5834153294563293 0.882022500038147 0.6068727970123291 0.887139081954956\n","Validation loss decreased (0.583415 --> 0.578468).  Saving model ...\n","16 0.5327328443527222 0.9676056504249573 0.578467845916748 0.882022500038147 0.6030131578445435 0.887139081954956\n","Validation loss decreased (0.578468 --> 0.573741).  Saving model ...\n","17 0.5256739258766174 0.9676056504249573 0.5737410187721252 0.882022500038147 0.5993216633796692 0.887139081954956\n","Validation loss decreased (0.573741 --> 0.569228).  Saving model ...\n","18 0.5189360976219177 0.9676056504249573 0.5692282915115356 0.882022500038147 0.5957931876182556 0.887139081954956\n","Validation loss decreased (0.569228 --> 0.564923).  Saving model ...\n","19 0.5125052332878113 0.9690141081809998 0.5649229884147644 0.882022500038147 0.59242182970047 0.887139081954956\n","Validation loss decreased (0.564923 --> 0.560818).  Saving model ...\n","20 0.506369411945343 0.9690141081809998 0.560817539691925 0.882022500038147 0.5892016291618347 0.8897637724876404\n","Validation loss decreased (0.560818 --> 0.556904).  Saving model ...\n","21 0.5005158185958862 0.9690141081809998 0.5569040775299072 0.882022500038147 0.5861274600028992 0.8897637724876404\n","Validation loss decreased (0.556904 --> 0.553175).  Saving model ...\n","22 0.4949304163455963 0.9704225063323975 0.553174614906311 0.882022500038147 0.5831916332244873 0.887139081954956\n","Validation loss decreased (0.553175 --> 0.549621).  Saving model ...\n","23 0.4896005392074585 0.9718309640884399 0.5496206879615784 0.882022500038147 0.580388605594635 0.887139081954956\n","Validation loss decreased (0.549621 --> 0.546235).  Saving model ...\n","24 0.48451319336891174 0.9718309640884399 0.5462346076965332 0.8876404762268066 0.5777122378349304 0.887139081954956\n","Validation loss decreased (0.546235 --> 0.543009).  Saving model ...\n","25 0.4796561896800995 0.9718309640884399 0.5430087447166443 0.8876404762268066 0.5751567482948303 0.887139081954956\n","Validation loss decreased (0.543009 --> 0.539935).  Saving model ...\n","26 0.4750169515609741 0.9718309640884399 0.5399346351623535 0.8876404762268066 0.5727177858352661 0.8897637724876404\n","Validation loss decreased (0.539935 --> 0.537005).  Saving model ...\n","27 0.47058358788490295 0.9732394218444824 0.5370051860809326 0.8932584524154663 0.5703884363174438 0.8897637724876404\n","Validation loss decreased (0.537005 --> 0.534213).  Saving model ...\n","28 0.46634578704833984 0.9732394218444824 0.5342127680778503 0.8932584524154663 0.5681636333465576 0.8897637724876404\n","Validation loss decreased (0.534213 --> 0.531550).  Saving model ...\n","29 0.46229204535484314 0.9746478796005249 0.5315500497817993 0.8932584524154663 0.5660384297370911 0.8897637724876404\n","Validation loss decreased (0.531550 --> 0.529010).  Saving model ...\n","30 0.4584120512008667 0.9746478796005249 0.5290104150772095 0.8932584524154663 0.5640081167221069 0.8923884630203247\n","Validation loss decreased (0.529010 --> 0.526587).  Saving model ...\n","31 0.454696387052536 0.9746478796005249 0.5265874862670898 0.8932584524154663 0.5620683431625366 0.8950130939483643\n","Validation loss decreased (0.526587 --> 0.524275).  Saving model ...\n","32 0.4511364996433258 0.9746478796005249 0.5242749452590942 0.8932584524154663 0.5602145195007324 0.8976377844810486\n","Validation loss decreased (0.524275 --> 0.522066).  Saving model ...\n","33 0.44772276282310486 0.9746478796005249 0.5220663547515869 0.8932584524154663 0.5584425926208496 0.8976377844810486\n","Validation loss decreased (0.522066 --> 0.519956).  Saving model ...\n","34 0.4444476366043091 0.9746478796005249 0.5199561715126038 0.8932584524154663 0.5567477941513062 0.8976377844810486\n","Validation loss decreased (0.519956 --> 0.517939).  Saving model ...\n","35 0.4413035809993744 0.9746478796005249 0.5179390907287598 0.8932584524154663 0.555126965045929 0.8976377844810486\n","Validation loss decreased (0.517939 --> 0.516010).  Saving model ...\n","36 0.43828338384628296 0.9746478796005249 0.516010046005249 0.8932584524154663 0.5535762310028076 0.8976377844810486\n","Validation loss decreased (0.516010 --> 0.514164).  Saving model ...\n","37 0.4353798031806946 0.9746478796005249 0.5141642093658447 0.898876428604126 0.5520928502082825 0.9002624750137329\n","Validation loss decreased (0.514164 --> 0.512397).  Saving model ...\n","38 0.43258795142173767 0.9760563373565674 0.512397050857544 0.898876428604126 0.5506728887557983 0.8976377844810486\n","Validation loss decreased (0.512397 --> 0.510704).  Saving model ...\n","39 0.42990046739578247 0.9774647951126099 0.5107038617134094 0.898876428604126 0.5493130683898926 0.9002624750137329\n","Validation loss decreased (0.510704 --> 0.509081).  Saving model ...\n","40 0.42731207609176636 0.9774647951126099 0.5090806484222412 0.898876428604126 0.5480105876922607 0.9028871655464172\n","Validation loss decreased (0.509081 --> 0.507524).  Saving model ...\n","41 0.4248185157775879 0.9802817106246948 0.5075238347053528 0.898876428604126 0.5467628836631775 0.9055117964744568\n","Validation loss decreased (0.507524 --> 0.506030).  Saving model ...\n","42 0.4224146008491516 0.9816901683807373 0.5060296654701233 0.9044944047927856 0.5455670356750488 0.9055117964744568\n","Validation loss decreased (0.506030 --> 0.504595).  Saving model ...\n","43 0.42009520530700684 0.9816901683807373 0.5045948028564453 0.9044944047927856 0.5444210171699524 0.9055117964744568\n","Validation loss decreased (0.504595 --> 0.503216).  Saving model ...\n","44 0.4178566038608551 0.9816901683807373 0.5032159090042114 0.898876428604126 0.5433222055435181 0.9055117964744568\n","Validation loss decreased (0.503216 --> 0.501890).  Saving model ...\n","45 0.41569510102272034 0.983098566532135 0.5018895864486694 0.898876428604126 0.5422680974006653 0.9055117964744568\n","Validation loss decreased (0.501890 --> 0.500613).  Saving model ...\n","46 0.4136069715023041 0.9845070242881775 0.500613272190094 0.898876428604126 0.5412562489509583 0.9055117964744568\n","Validation loss decreased (0.500613 --> 0.499384).  Saving model ...\n","47 0.4115878641605377 0.9845070242881775 0.499384343624115 0.8932584524154663 0.5402855277061462 0.9055117964744568\n","Validation loss decreased (0.499384 --> 0.498200).  Saving model ...\n","48 0.40963566303253174 0.9845070242881775 0.4982002079486847 0.8932584524154663 0.5393530130386353 0.9055117964744568\n","Validation loss decreased (0.498200 --> 0.497058).  Saving model ...\n","49 0.40774717926979065 0.98591548204422 0.49705827236175537 0.8932584524154663 0.5384575724601746 0.9055117964744568\n","Validation loss decreased (0.497058 --> 0.495956).  Saving model ...\n","50 0.40591880679130554 0.9873239398002625 0.4959563910961151 0.8932584524154663 0.5375967025756836 0.9055117964744568\n","Validation loss decreased (0.495956 --> 0.494892).  Saving model ...\n","51 0.4041479825973511 0.9887323975563049 0.4948923587799072 0.8932584524154663 0.5367690324783325 0.9055117964744568\n","Validation loss decreased (0.494892 --> 0.493864).  Saving model ...\n","52 0.4024331271648407 0.9887323975563049 0.49386441707611084 0.8932584524154663 0.5359734296798706 0.9055117964744568\n","Validation loss decreased (0.493864 --> 0.492870).  Saving model ...\n","53 0.4007705748081207 0.9887323975563049 0.4928703308105469 0.8932584524154663 0.5352074503898621 0.9055117964744568\n","Validation loss decreased (0.492870 --> 0.491909).  Saving model ...\n","54 0.3991588056087494 0.9901408553123474 0.49190860986709595 0.898876428604126 0.5344703793525696 0.9055117964744568\n","Validation loss decreased (0.491909 --> 0.490977).  Saving model ...\n","55 0.39759561419487 0.9915493130683899 0.49097737669944763 0.898876428604126 0.5337604880332947 0.9055117964744568\n","Validation loss decreased (0.490977 --> 0.490075).  Saving model ...\n","56 0.39607927203178406 0.9915493130683899 0.4900752902030945 0.898876428604126 0.5330763459205627 0.9055117964744568\n","Validation loss decreased (0.490075 --> 0.489201).  Saving model ...\n","57 0.3946068286895752 0.9915493130683899 0.48920053243637085 0.898876428604126 0.5324168801307678 0.9055117964744568\n","Validation loss decreased (0.489201 --> 0.488352).  Saving model ...\n","58 0.3931776285171509 0.9943661689758301 0.48835206031799316 0.898876428604126 0.5317802429199219 0.9107611775398254\n","Validation loss decreased (0.488352 --> 0.487528).  Saving model ...\n","59 0.3917892873287201 0.9943661689758301 0.4875284433364868 0.898876428604126 0.5311658382415771 0.9107611775398254\n","Validation loss decreased (0.487528 --> 0.486728).  Saving model ...\n","60 0.39044034481048584 0.9943661689758301 0.48672837018966675 0.898876428604126 0.5305727124214172 0.913385808467865\n","Validation loss decreased (0.486728 --> 0.485951).  Saving model ...\n","61 0.3891289532184601 0.997183084487915 0.485950767993927 0.898876428604126 0.5299996733665466 0.913385808467865\n","Validation loss decreased (0.485951 --> 0.485195).  Saving model ...\n","62 0.3878546357154846 0.9985915422439575 0.48519471287727356 0.898876428604126 0.5294453501701355 0.913385808467865\n","Validation loss decreased (0.485195 --> 0.484459).  Saving model ...\n","63 0.3866146206855774 0.9985915422439575 0.4844589829444885 0.898876428604126 0.5289087891578674 0.913385808467865\n","Validation loss decreased (0.484459 --> 0.483742).  Saving model ...\n","64 0.3854082524776459 0.9985915422439575 0.4837423861026764 0.898876428604126 0.5283895134925842 0.9081364870071411\n","Validation loss decreased (0.483742 --> 0.483044).  Saving model ...\n","65 0.3842344284057617 1.0 0.48304447531700134 0.898876428604126 0.5278859734535217 0.9081364870071411\n","Validation loss decreased (0.483044 --> 0.482365).  Saving model ...\n","66 0.3830914795398712 1.0 0.48236459493637085 0.898876428604126 0.5273979306221008 0.9081364870071411\n","Validation loss decreased (0.482365 --> 0.481701).  Saving model ...\n","67 0.3819786608219147 1.0 0.48170140385627747 0.9044944047927856 0.5269247889518738 0.9081364870071411\n","Validation loss decreased (0.481701 --> 0.481054).  Saving model ...\n","68 0.3808947205543518 1.0 0.48105430603027344 0.9044944047927856 0.5264651775360107 0.9081364870071411\n","Validation loss decreased (0.481054 --> 0.480423).  Saving model ...\n","69 0.37983882427215576 1.0 0.48042264580726624 0.9044944047927856 0.5260182619094849 0.9107611775398254\n","Validation loss decreased (0.480423 --> 0.479806).  Saving model ...\n","70 0.37880972027778625 1.0 0.479806125164032 0.9044944047927856 0.5255842208862305 0.9107611775398254\n","Validation loss decreased (0.479806 --> 0.479204).  Saving model ...\n","71 0.3778064250946045 1.0 0.4792036712169647 0.9044944047927856 0.5251615643501282 0.9107611775398254\n","Validation loss decreased (0.479204 --> 0.478615).  Saving model ...\n","72 0.3768281638622284 1.0 0.47861507534980774 0.9044944047927856 0.5247507691383362 0.913385808467865\n","Validation loss decreased (0.478615 --> 0.478040).  Saving model ...\n","73 0.37587401270866394 1.0 0.47803953289985657 0.9044944047927856 0.5243499875068665 0.913385808467865\n","Validation loss decreased (0.478040 --> 0.477477).  Saving model ...\n","74 0.37494292855262756 1.0 0.47747665643692017 0.9044944047927856 0.5239591002464294 0.913385808467865\n","Validation loss decreased (0.477477 --> 0.476926).  Saving model ...\n","75 0.37403494119644165 1.0 0.4769257605075836 0.9044944047927856 0.5235781073570251 0.913385808467865\n","Validation loss decreased (0.476926 --> 0.476387).  Saving model ...\n","76 0.3731485903263092 1.0 0.4763867259025574 0.9044944047927856 0.523206353187561 0.913385808467865\n","Validation loss decreased (0.476387 --> 0.475859).  Saving model ...\n","77 0.37228327989578247 1.0 0.47585904598236084 0.9044944047927856 0.5228431820869446 0.913385808467865\n","Validation loss decreased (0.475859 --> 0.475342).  Saving model ...\n","78 0.3714378774166107 1.0 0.47534218430519104 0.9044944047927856 0.5224881768226624 0.913385808467865\n","Validation loss decreased (0.475342 --> 0.474836).  Saving model ...\n","79 0.3706119954586029 1.0 0.4748358130455017 0.9044944047927856 0.5221415162086487 0.913385808467865\n","Validation loss decreased (0.474836 --> 0.474340).  Saving model ...\n","80 0.36980557441711426 1.0 0.47433972358703613 0.9044944047927856 0.5218019485473633 0.913385808467865\n","Validation loss decreased (0.474340 --> 0.473853).  Saving model ...\n","81 0.36901775002479553 1.0 0.47385337948799133 0.9044944047927856 0.5214694738388062 0.913385808467865\n","Validation loss decreased (0.473853 --> 0.473377).  Saving model ...\n","82 0.36824744939804077 1.0 0.4733765721321106 0.9101123809814453 0.5211437940597534 0.913385808467865\n","Validation loss decreased (0.473377 --> 0.472909).  Saving model ...\n","83 0.3674948811531067 1.0 0.47290921211242676 0.9101123809814453 0.520825207233429 0.913385808467865\n","Validation loss decreased (0.472909 --> 0.472450).  Saving model ...\n","84 0.366758793592453 1.0 0.4724504053592682 0.9101123809814453 0.5205124616622925 0.913385808467865\n","Validation loss decreased (0.472450 --> 0.472001).  Saving model ...\n","85 0.3660390377044678 1.0 0.4720005989074707 0.9101123809814453 0.5202062129974365 0.913385808467865\n","Validation loss decreased (0.472001 --> 0.471559).  Saving model ...\n","86 0.3653348684310913 1.0 0.4715590178966522 0.9101123809814453 0.5199053883552551 0.913385808467865\n","Validation loss decreased (0.471559 --> 0.471125).  Saving model ...\n","87 0.36464646458625793 1.0 0.4711254835128784 0.9101123809814453 0.5196103453636169 0.913385808467865\n","Validation loss decreased (0.471125 --> 0.470700).  Saving model ...\n","88 0.3639722764492035 1.0 0.47070011496543884 0.9101123809814453 0.5193206071853638 0.913385808467865\n","Validation loss decreased (0.470700 --> 0.470282).  Saving model ...\n","89 0.3633127510547638 1.0 0.4702821969985962 0.9101123809814453 0.5190361142158508 0.913385808467865\n","Validation loss decreased (0.470282 --> 0.469872).  Saving model ...\n","90 0.3626672029495239 1.0 0.4698719084262848 0.9101123809814453 0.5187566876411438 0.913385808467865\n","Validation loss decreased (0.469872 --> 0.469469).  Saving model ...\n","91 0.36203533411026 1.0 0.469468891620636 0.9101123809814453 0.5184820294380188 0.913385808467865\n","Validation loss decreased (0.469469 --> 0.469073).  Saving model ...\n","92 0.36141660809516907 1.0 0.469073086977005 0.9101123809814453 0.5182122588157654 0.913385808467865\n","Validation loss decreased (0.469073 --> 0.468684).  Saving model ...\n","93 0.36081045866012573 1.0 0.46868404746055603 0.9101123809814453 0.5179464817047119 0.9160104990005493\n","Validation loss decreased (0.468684 --> 0.468302).  Saving model ...\n","94 0.36021676659584045 1.0 0.4683018922805786 0.9101123809814453 0.5176855325698853 0.9160104990005493\n","Validation loss decreased (0.468302 --> 0.467926).  Saving model ...\n","95 0.3596356511116028 1.0 0.4679258465766907 0.9101123809814453 0.5174285769462585 0.9160104990005493\n","Validation loss decreased (0.467926 --> 0.467556).  Saving model ...\n","96 0.3590656816959381 1.0 0.4675564765930176 0.9101123809814453 0.5171764492988586 0.9160104990005493\n","Validation loss decreased (0.467556 --> 0.467193).  Saving model ...\n","97 0.35850778222084045 1.0 0.46719321608543396 0.9101123809814453 0.5169277787208557 0.9160104990005493\n","Validation loss decreased (0.467193 --> 0.466836).  Saving model ...\n","98 0.35796046257019043 1.0 0.4668360650539398 0.9101123809814453 0.5166832804679871 0.9160104990005493\n","Validation loss decreased (0.466836 --> 0.466485).  Saving model ...\n","99 0.357424259185791 1.0 0.4664847254753113 0.915730357170105 0.516442596912384 0.9160104990005493\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"erpioWsYtaUa","colab":{"base_uri":"https://localhost:8080/","height":68},"executionInfo":{"status":"ok","timestamp":1593324917754,"user_tz":180,"elapsed":163279,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"e2831e33-9529-4656-c429-4dd58e356b53"},"source":["print(Precision(prediction, Y_train_tensor))\n","print(Precision(val_prediction, Y_valid_tensor))\n","print(Precision(test_prediction, Y_test_tensor))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[1.0, 1.0]\n","[0.9520547986030579, 0.75]\n","[0.9386503100395203, 0.7818182110786438]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Qu2e4Qh38lp4","colab":{"base_uri":"https://localhost:8080/","height":68},"executionInfo":{"status":"ok","timestamp":1593324917755,"user_tz":180,"elapsed":163274,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"03fd4492-5ffe-424d-9a44-9193fdd128d7"},"source":["print(Recall(prediction, Y_train_tensor))\n","print(Recall(val_prediction, Y_valid_tensor))\n","print(Recall(test_prediction, Y_test_tensor))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[1.0, 1.0]\n","[0.9455782175064087, 0.774193525314331]\n","[0.9622641801834106, 0.682539701461792]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5IoA1jJGBW2Q","colab":{"base_uri":"https://localhost:8080/","height":68},"executionInfo":{"status":"ok","timestamp":1593324917755,"user_tz":180,"elapsed":163268,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"dc41c19a-f25f-40be-9eb9-3e37727a95d7"},"source":["print(Accuracy(prediction, Y_train_tensor))\n","print(Accuracy(val_prediction, Y_valid_tensor))\n","print(Accuracy(test_prediction, Y_test_tensor))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1.0\n","0.915730357170105\n","0.9160104990005493\n"],"name":"stdout"}]}]}