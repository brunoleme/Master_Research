{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Split1.ipynb","provenance":[{"file_id":"1ly17dl3w8rGXAPtd1owJFslx4RVJE78c","timestamp":1592607825372},{"file_id":"1VIBcIIFR_YFlSguO_JGlnJbFzyAcT6YH","timestamp":1592464333044},{"file_id":"1dZvMRgPPkRVGa_4BZ1Tvoom_U4pjwmRX","timestamp":1592435543596},{"file_id":"12Sf257YUAwzmSXOlE3llOhi0N1YVUbM7","timestamp":1583376883298}],"collapsed_sections":[],"authorship_tag":"ABX9TyPXFoiuOPQVDSjWUMoT5zF1"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"JQrQmaLj0UuZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607485957065,"user_tz":180,"elapsed":21510,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"2863563e-d8e9-42f3-e051-866f9d0b67e2"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JjEPtibx-EJD","executionInfo":{"status":"ok","timestamp":1607485959709,"user_tz":180,"elapsed":24151,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["import numpy as np\n","import torch\n","\n","class EarlyStopping:\n","    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n","    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt'):\n","        \"\"\"\n","        Args:\n","            patience (int): How long to wait after last time validation loss improved.\n","                            Default: 7\n","            verbose (bool): If True, prints a message for each validation loss improvement. \n","                            Default: False\n","            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n","                            Default: 0\n","            path (str): Path for the checkpoint to be saved to.\n","                            Default: 'checkpoint.pt'\n","        \"\"\"\n","        self.patience = patience\n","        self.verbose = verbose\n","        self.counter = 0\n","        self.best_score = None\n","        self.early_stop = False\n","        self.val_loss_min = np.Inf\n","        self.delta = delta\n","        self.path = path\n","\n","    def __call__(self, val_loss, model):\n","\n","        score = -val_loss\n","\n","        if self.best_score is None:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model)\n","        elif score < self.best_score + self.delta:\n","            self.counter += 1\n","            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n","            if self.counter >= self.patience:\n","                self.early_stop = True\n","        else:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model)\n","            self.counter = 0\n","\n","    def save_checkpoint(self, val_loss, model):\n","        '''Saves model when validation loss decrease.'''\n","        if self.verbose:\n","            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n","        torch.save(model.state_dict(), self.path)\n","        self.val_loss_min = val_loss"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"tjGPuXgoqulz","executionInfo":{"status":"ok","timestamp":1607485959709,"user_tz":180,"elapsed":24149,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["def Accuracy(prediction, observation):\n","  prediction = prediction[:,1]\n","  prediction_class = (torch.reshape(prediction, observation.shape) > 0.5).float()\n","  correct = (prediction_class == observation).float().sum()\n","  accuracy = correct/prediction_class.shape[0]\n","  return float(accuracy.cpu())\n","\n","def Precision(prediction, observation):\n","  prediction = prediction[:,1]\n","  res = []\n","  prediction_class = (torch.reshape(prediction, observation.shape) > 0.5).float()\n","  for label in [0, 1]:\n","    correct = (prediction_class[prediction_class == label] == observation[prediction_class == label]).float().sum()\n","    precision = correct/prediction_class[prediction_class == label].shape[0]\n","    res.append(float(precision.cpu()))\n","  return res\n","\n","def Recall(prediction, observation):\n","  prediction = prediction[:,1]\n","  res = []\n","  prediction_class = (torch.reshape(prediction, observation.shape) > 0.5).float()\n","  for label in [0, 1]:\n","    correct = (prediction_class[observation == label] == observation[observation == label]).float().sum()\n","    recall = correct/prediction_class[observation == label].shape[0]\n","    res.append(float(recall.cpu()))\n","  return res"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"sgz5Ea8a1wKr","executionInfo":{"status":"ok","timestamp":1607485959710,"user_tz":180,"elapsed":24148,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["n_split = 1"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"cutkFU0k1Pkv","executionInfo":{"status":"ok","timestamp":1607485959711,"user_tz":180,"elapsed":24147,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["import pickle\n","import pandas as pd\n","import numpy as np"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"wSJO5A951VXh","executionInfo":{"status":"ok","timestamp":1607485964610,"user_tz":180,"elapsed":29044,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["with open('/content/drive/My Drive/Data Master/X_train_final', 'rb') as file:\n","    X_train = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/Y_train_final', 'rb') as file:\n","    Y_train = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/X_test_final', 'rb') as file:\n","    X_test = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/Y_test_final', 'rb') as file:\n","    Y_test = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/word_index_final', 'rb') as file:\n","    word_index = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/train_index_final_split_' + str(n_split), 'rb') as file:\n","    train_index = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/valid_index_final_split_' + str(n_split), 'rb') as file:\n","    valid_index = pickle.load(file)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"_v0BS5Cp_06s","executionInfo":{"status":"ok","timestamp":1607485964611,"user_tz":180,"elapsed":29043,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["test_index = [i for i, _ in enumerate(X_test)]"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"NGqLg8IllrZE","executionInfo":{"status":"ok","timestamp":1607485965640,"user_tz":180,"elapsed":30070,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["inv_word_index = {ix : w for w, ix in word_index.items()}"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"1-2YPzNN1x5T","executionInfo":{"status":"ok","timestamp":1607485969341,"user_tz":180,"elapsed":33769,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["import itertools\n","features_index = {w:ix for ix, w in enumerate(np.unique(list(itertools.chain.from_iterable(np.array(X_train)[train_index]))))}\n","inv_features_index = {ix:w for ix, w in enumerate(np.unique(list(itertools.chain.from_iterable(np.array(X_train)[train_index]))))}"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"RxZWUTIv4K5T","executionInfo":{"status":"ok","timestamp":1607485971173,"user_tz":180,"elapsed":35600,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["X_train_matrix = np.zeros((len(X_train), len(features_index)))\n","X_test_matrix = np.zeros((len(X_test), len(features_index)))"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"K6KzJuIy4dN8","executionInfo":{"status":"ok","timestamp":1607485988782,"user_tz":180,"elapsed":53207,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["for i, x in enumerate(X_train):\n","  for w in x:\n","    if w in features_index:\n","      X_train_matrix[i,features_index[w]] += 1\n","\n","for i, x in enumerate(X_test):\n","  for w in x:\n","    if w in features_index:\n","      X_test_matrix[i,features_index[w]] += 1"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"9d4attfQ0i-Q","executionInfo":{"status":"ok","timestamp":1607485988782,"user_tz":180,"elapsed":53204,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"twcFT-Hl3fqP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607485988783,"user_tz":180,"elapsed":53201,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"2084bcb7-45ab-4b49-a614-06ba687f2ffe"},"source":["input_dim = X_train_matrix.shape[1]\n","input_dim"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["246510"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"9fbXl191nZhK","executionInfo":{"status":"ok","timestamp":1607485988784,"user_tz":180,"elapsed":53200,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["class LogisticRegression (nn.Module):\n","\n","  def __init__(self):\n","    super(LogisticRegression, self).__init__()\n","\n","    self.fc1 = nn.Linear(input_dim, 2)\n","                                \n","    self.softmax = nn.Softmax(dim=1)\n","\n","  def forward(self, x):\n","    x = F.normalize(x)\n","    y = self.softmax(self.fc1(x))\n","\n","    return y"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"Cgzf7IEqnyN4","executionInfo":{"status":"ok","timestamp":1607485988784,"user_tz":180,"elapsed":53198,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["model = LogisticRegression()"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"0rnUcqchBE91","executionInfo":{"status":"ok","timestamp":1607485990782,"user_tz":180,"elapsed":55195,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["X_train_tensor = torch.from_numpy(X_train_matrix[train_index]).float()\n","Y_train_tensor = torch.LongTensor(np.array(Y_train[train_index]))\n","\n","X_valid_tensor = torch.from_numpy(X_train_matrix[valid_index]).float()\n","Y_valid_tensor = torch.LongTensor(np.array(Y_train[valid_index]))\n","\n","X_test_tensor = torch.from_numpy(X_test_matrix).float()\n","Y_test_tensor = torch.LongTensor(np.array(Y_test))"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"GlP5dzFET5tF","executionInfo":{"status":"ok","timestamp":1607485990784,"user_tz":180,"elapsed":55195,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["torch.manual_seed(0)\n","np.random.seed(0)"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"SV0Da5qu98-C","executionInfo":{"status":"ok","timestamp":1607485990785,"user_tz":180,"elapsed":55195,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["import torch.optim as optim\n","optimizer = optim.AdamW(model.parameters(), lr=0.01)"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"gHujp4Ww_ZuO","executionInfo":{"status":"ok","timestamp":1607485990785,"user_tz":180,"elapsed":55193,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["from torch.optim.lr_scheduler import ReduceLROnPlateau\n","scheduler = ReduceLROnPlateau(optimizer, 'min')"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"qkfeoTBHRuOb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607485990786,"user_tz":180,"elapsed":55190,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"5275c8ea-6d40-4d8c-dad5-7763a064d0b3"},"source":["weights = [sum(Y_train)/len(Y_train), 1-sum(Y_train)/len(Y_train)]\n","class_weights = torch.FloatTensor(weights)\n","class_weights"],"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0.1734, 0.8266])"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"8-F96WAE98zI","executionInfo":{"status":"ok","timestamp":1607485990786,"user_tz":180,"elapsed":55188,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["criterion = nn.CrossEntropyLoss(weight=class_weights)"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"E7KgiIq398rR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607486111490,"user_tz":180,"elapsed":175888,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"b5174390-ad82-4dd0-a6a6-4c6ffe7721d3"},"source":["patience = 20\n","early_stopping = EarlyStopping(patience=patience, verbose=True)\n","\n","for i in range(100):\n","  model.train()\n","  optimizer.zero_grad()\n","  prediction = model(X_train_tensor)\n","  loss = criterion(prediction, Y_train_tensor)\n","  loss.backward()\n","  optimizer.step()\n","\n","  accuracy = Accuracy(prediction, Y_train_tensor)\n","\n","  model.eval()\n","\n","  val_prediction = model(X_valid_tensor)\n","  test_prediction = model(X_test_tensor)\n","  val_loss = criterion(val_prediction, Y_valid_tensor)\n","  test_loss = criterion(test_prediction, Y_test_tensor)\n","\n","  val_accuracy = Accuracy(val_prediction, Y_valid_tensor)\n","  test_accuracy = Accuracy(test_prediction, Y_test_tensor)\n","\n","  early_stopping(val_loss, model)\n","\n","  if early_stopping.early_stop:\n","    print(\"Early stopping\")\n","    break\n","\n","  print(i, float(loss.cpu()), accuracy, float(val_loss.cpu()), val_accuracy, float(test_loss.cpu()), test_accuracy)\n","\n","  scheduler.step(val_loss)\n","\n","model.load_state_dict(torch.load('checkpoint.pt'))"],"execution_count":22,"outputs":[{"output_type":"stream","text":["Validation loss decreased (inf --> 0.685658).  Saving model ...\n","0 0.6931362152099609 0.202816903591156 0.6856582760810852 0.8651685118675232 0.6861729025840759 0.887139081954956\n","Validation loss decreased (0.685658 --> 0.678314).  Saving model ...\n","1 0.6805358529090881 0.9436619877815247 0.6783138513565063 0.9101123809814453 0.6796306371688843 0.9107611775398254\n","Validation loss decreased (0.678314 --> 0.671100).  Saving model ...\n","2 0.6681594848632812 0.9647887349128723 0.6711000800132751 0.9101123809814453 0.6732660531997681 0.9002624750137329\n","Validation loss decreased (0.671100 --> 0.664029).  Saving model ...\n","3 0.656043291091919 0.9676056504249573 0.6640288233757019 0.9101123809814453 0.6670638918876648 0.9002624750137329\n","Validation loss decreased (0.664029 --> 0.657115).  Saving model ...\n","4 0.6442183256149292 0.9661971926689148 0.6571149826049805 0.898876428604126 0.6610250473022461 0.9055117964744568\n","Validation loss decreased (0.657115 --> 0.650372).  Saving model ...\n","5 0.6327106952667236 0.9690141081809998 0.6503719091415405 0.898876428604126 0.6551517248153687 0.8976377844810486\n","Validation loss decreased (0.650372 --> 0.643814).  Saving model ...\n","6 0.621542751789093 0.9676056504249573 0.6438136100769043 0.898876428604126 0.6494491100311279 0.8923884630203247\n","Validation loss decreased (0.643814 --> 0.637455).  Saving model ...\n","7 0.6107323169708252 0.9676056504249573 0.6374554634094238 0.9044944047927856 0.6439236998558044 0.887139081954956\n","Validation loss decreased (0.637455 --> 0.631311).  Saving model ...\n","8 0.6002900004386902 0.9676056504249573 0.6313108205795288 0.9044944047927856 0.6385825872421265 0.887139081954956\n","Validation loss decreased (0.631311 --> 0.625390).  Saving model ...\n","9 0.5902227759361267 0.9676056504249573 0.6253901124000549 0.9101123809814453 0.6334338784217834 0.887139081954956\n","Validation loss decreased (0.625390 --> 0.619698).  Saving model ...\n","10 0.5805365443229675 0.9676056504249573 0.6196979880332947 0.9101123809814453 0.6284830570220947 0.887139081954956\n","Validation loss decreased (0.619698 --> 0.614233).  Saving model ...\n","11 0.571232259273529 0.9676056504249573 0.6142328381538391 0.9101123809814453 0.6237332820892334 0.887139081954956\n","Validation loss decreased (0.614233 --> 0.608986).  Saving model ...\n","12 0.5623092651367188 0.9676056504249573 0.608985960483551 0.9101123809814453 0.6191830039024353 0.8897637724876404\n","Validation loss decreased (0.608986 --> 0.603946).  Saving model ...\n","13 0.5537640452384949 0.9676056504249573 0.6039460301399231 0.9101123809814453 0.6148262619972229 0.8897637724876404\n","Validation loss decreased (0.603946 --> 0.599100).  Saving model ...\n","14 0.5455905199050903 0.9676056504249573 0.5990999937057495 0.9101123809814453 0.6106548309326172 0.8897637724876404\n","Validation loss decreased (0.599100 --> 0.594441).  Saving model ...\n","15 0.537777841091156 0.9676056504249573 0.5944405198097229 0.9101123809814453 0.6066622138023376 0.8923884630203247\n","Validation loss decreased (0.594441 --> 0.589962).  Saving model ...\n","16 0.5303175449371338 0.9676056504249573 0.5899617671966553 0.9101123809814453 0.6028414964675903 0.8923884630203247\n","Validation loss decreased (0.589962 --> 0.585664).  Saving model ...\n","17 0.5231971144676208 0.9690141081809998 0.5856642723083496 0.9101123809814453 0.5991883277893066 0.8923884630203247\n","Validation loss decreased (0.585664 --> 0.581550).  Saving model ...\n","18 0.5164046287536621 0.9704225063323975 0.5815496444702148 0.9101123809814453 0.5957000851631165 0.8923884630203247\n","Validation loss decreased (0.581550 --> 0.577620).  Saving model ...\n","19 0.50992751121521 0.9704225063323975 0.577620267868042 0.9101123809814453 0.5923736095428467 0.8923884630203247\n","Validation loss decreased (0.577620 --> 0.573878).  Saving model ...\n","20 0.5037522912025452 0.9718309640884399 0.5738783478736877 0.9101123809814453 0.5892064571380615 0.8950130939483643\n","Validation loss decreased (0.573878 --> 0.570320).  Saving model ...\n","21 0.4978640675544739 0.9718309640884399 0.5703201293945312 0.9101123809814453 0.586193323135376 0.8950130939483643\n","Validation loss decreased (0.570320 --> 0.566939).  Saving model ...\n","22 0.4922496974468231 0.9732394218444824 0.5669391751289368 0.9101123809814453 0.5833292007446289 0.8950130939483643\n","Validation loss decreased (0.566939 --> 0.563726).  Saving model ...\n","23 0.4868949353694916 0.9732394218444824 0.5637255311012268 0.9101123809814453 0.5806059837341309 0.8923884630203247\n","Validation loss decreased (0.563726 --> 0.560665).  Saving model ...\n","24 0.4817870557308197 0.9774647951126099 0.5606651306152344 0.9101123809814453 0.5780137181282043 0.8923884630203247\n","Validation loss decreased (0.560665 --> 0.557745).  Saving model ...\n","25 0.4769125282764435 0.9774647951126099 0.557745099067688 0.9101123809814453 0.5755438804626465 0.8923884630203247\n","Validation loss decreased (0.557745 --> 0.554954).  Saving model ...\n","26 0.4722588062286377 0.9788732528686523 0.5549536347389221 0.9101123809814453 0.5731872320175171 0.8950130939483643\n","Validation loss decreased (0.554954 --> 0.552281).  Saving model ...\n","27 0.4678144156932831 0.9788732528686523 0.5522811412811279 0.9101123809814453 0.5709364414215088 0.8976377844810486\n","Validation loss decreased (0.552281 --> 0.549723).  Saving model ...\n","28 0.4635668396949768 0.9788732528686523 0.5497226715087891 0.9101123809814453 0.5687856078147888 0.8976377844810486\n","Validation loss decreased (0.549723 --> 0.547275).  Saving model ...\n","29 0.4595048129558563 0.9788732528686523 0.547275185585022 0.9101123809814453 0.5667310953140259 0.8976377844810486\n","Validation loss decreased (0.547275 --> 0.544939).  Saving model ...\n","30 0.455619215965271 0.9802817106246948 0.5449385643005371 0.9101123809814453 0.5647702813148499 0.8976377844810486\n","Validation loss decreased (0.544939 --> 0.542712).  Saving model ...\n","31 0.45189931988716125 0.9816901683807373 0.5427121520042419 0.9101123809814453 0.562900960445404 0.8976377844810486\n","Validation loss decreased (0.542712 --> 0.540595).  Saving model ...\n","32 0.44833624362945557 0.9816901683807373 0.5405951738357544 0.9101123809814453 0.5611194968223572 0.8976377844810486\n","Validation loss decreased (0.540595 --> 0.538585).  Saving model ...\n","33 0.44492107629776 0.9816901683807373 0.5385845303535461 0.915730357170105 0.5594236850738525 0.8976377844810486\n","Validation loss decreased (0.538585 --> 0.536675).  Saving model ...\n","34 0.44164544343948364 0.9816901683807373 0.536674976348877 0.915730357170105 0.5578089356422424 0.8976377844810486\n","Validation loss decreased (0.536675 --> 0.534859).  Saving model ...\n","35 0.43850216269493103 0.983098566532135 0.5348591208457947 0.915730357170105 0.5562697649002075 0.8976377844810486\n","Validation loss decreased (0.534859 --> 0.533129).  Saving model ...\n","36 0.4354836046695709 0.983098566532135 0.5331292748451233 0.915730357170105 0.5548015236854553 0.8976377844810486\n","Validation loss decreased (0.533129 --> 0.531477).  Saving model ...\n","37 0.4325828552246094 0.983098566532135 0.5314769744873047 0.915730357170105 0.5533973574638367 0.8976377844810486\n","Validation loss decreased (0.531477 --> 0.529895).  Saving model ...\n","38 0.4297945201396942 0.9845070242881775 0.5298948884010315 0.915730357170105 0.5520532727241516 0.8976377844810486\n","Validation loss decreased (0.529895 --> 0.528377).  Saving model ...\n","39 0.42711153626441956 0.9845070242881775 0.52837735414505 0.915730357170105 0.5507644414901733 0.8976377844810486\n","Validation loss decreased (0.528377 --> 0.526921).  Saving model ...\n","40 0.4245293140411377 0.9845070242881775 0.5269209146499634 0.915730357170105 0.5495277643203735 0.8976377844810486\n","Validation loss decreased (0.526921 --> 0.525524).  Saving model ...\n","41 0.4220419228076935 0.9845070242881775 0.5255236625671387 0.915730357170105 0.5483419299125671 0.8976377844810486\n","Validation loss decreased (0.525524 --> 0.524185).  Saving model ...\n","42 0.41964566707611084 0.9845070242881775 0.5241850018501282 0.915730357170105 0.5472051501274109 0.8976377844810486\n","Validation loss decreased (0.524185 --> 0.522904).  Saving model ...\n","43 0.4173351228237152 0.9845070242881775 0.5229042768478394 0.9101123809814453 0.5461165904998779 0.8976377844810486\n","Validation loss decreased (0.522904 --> 0.521682).  Saving model ...\n","44 0.41510581970214844 0.98591548204422 0.5216816067695618 0.9101123809814453 0.5450743436813354 0.8976377844810486\n","Validation loss decreased (0.521682 --> 0.520515).  Saving model ...\n","45 0.41295453906059265 0.9873239398002625 0.5205148458480835 0.915730357170105 0.5440780520439148 0.9002624750137329\n","Validation loss decreased (0.520515 --> 0.519402).  Saving model ...\n","46 0.41087713837623596 0.9873239398002625 0.5194016695022583 0.915730357170105 0.5431246757507324 0.9002624750137329\n","Validation loss decreased (0.519402 --> 0.518338).  Saving model ...\n","47 0.4088701903820038 0.9873239398002625 0.5183383822441101 0.915730357170105 0.5422132015228271 0.9002624750137329\n","Validation loss decreased (0.518338 --> 0.517321).  Saving model ...\n","48 0.4069305658340454 0.9887323975563049 0.5173208713531494 0.915730357170105 0.5413390398025513 0.9002624750137329\n","Validation loss decreased (0.517321 --> 0.516344).  Saving model ...\n","49 0.4050541818141937 0.9887323975563049 0.5163442492485046 0.915730357170105 0.5404996871948242 0.9002624750137329\n","Validation loss decreased (0.516344 --> 0.515405).  Saving model ...\n","50 0.4032396674156189 0.9901408553123474 0.5154045820236206 0.915730357170105 0.5396925210952759 0.9002624750137329\n","Validation loss decreased (0.515405 --> 0.514499).  Saving model ...\n","51 0.40148329734802246 0.9901408553123474 0.5144985318183899 0.915730357170105 0.5389149785041809 0.9002624750137329\n","Validation loss decreased (0.514499 --> 0.513624).  Saving model ...\n","52 0.39978280663490295 0.9915493130683899 0.5136238932609558 0.915730357170105 0.5381651520729065 0.9002624750137329\n","Validation loss decreased (0.513624 --> 0.512780).  Saving model ...\n","53 0.3981359601020813 0.9915493130683899 0.5127795934677124 0.915730357170105 0.5374425053596497 0.9002624750137329\n","Validation loss decreased (0.512780 --> 0.511964).  Saving model ...\n","54 0.3965394198894501 0.9915493130683899 0.5119643807411194 0.915730357170105 0.536745548248291 0.9002624750137329\n","Validation loss decreased (0.511964 --> 0.511179).  Saving model ...\n","55 0.3949926495552063 0.9915493130683899 0.511178731918335 0.915730357170105 0.5360745191574097 0.9002624750137329\n","Validation loss decreased (0.511179 --> 0.510422).  Saving model ...\n","56 0.39349186420440674 0.9915493130683899 0.5104224681854248 0.9213483333587646 0.535427987575531 0.9002624750137329\n","Validation loss decreased (0.510422 --> 0.509695).  Saving model ...\n","57 0.39203664660453796 0.9943661689758301 0.5096948742866516 0.915730357170105 0.5348063707351685 0.9002624750137329\n","Validation loss decreased (0.509695 --> 0.508995).  Saving model ...\n","58 0.39062371850013733 0.9943661689758301 0.5089954733848572 0.915730357170105 0.534208357334137 0.9028871655464172\n","Validation loss decreased (0.508995 --> 0.508322).  Saving model ...\n","59 0.3892526626586914 0.9943661689758301 0.5083221197128296 0.915730357170105 0.5336328744888306 0.9081364870071411\n","Validation loss decreased (0.508322 --> 0.507673).  Saving model ...\n","60 0.38792115449905396 0.9957746267318726 0.507672905921936 0.915730357170105 0.5330780744552612 0.9081364870071411\n","Validation loss decreased (0.507673 --> 0.507046).  Saving model ...\n","61 0.3866272270679474 0.997183084487915 0.5070456266403198 0.915730357170105 0.5325425267219543 0.9107611775398254\n","Validation loss decreased (0.507046 --> 0.506438).  Saving model ...\n","62 0.3853701949119568 0.997183084487915 0.5064384341239929 0.915730357170105 0.5320250988006592 0.9107611775398254\n","Validation loss decreased (0.506438 --> 0.505849).  Saving model ...\n","63 0.38414785265922546 0.997183084487915 0.5058485865592957 0.915730357170105 0.5315238833427429 0.9107611775398254\n","Validation loss decreased (0.505849 --> 0.505275).  Saving model ...\n","64 0.38295993208885193 0.997183084487915 0.5052751898765564 0.915730357170105 0.5310379266738892 0.9107611775398254\n","Validation loss decreased (0.505275 --> 0.504717).  Saving model ...\n","65 0.3818039894104004 0.997183084487915 0.5047169327735901 0.915730357170105 0.5305659770965576 0.913385808467865\n","Validation loss decreased (0.504717 --> 0.504174).  Saving model ...\n","66 0.3806799352169037 0.997183084487915 0.5041740536689758 0.9213483333587646 0.5301083326339722 0.913385808467865\n","Validation loss decreased (0.504174 --> 0.503645).  Saving model ...\n","67 0.379584938287735 0.997183084487915 0.5036454796791077 0.9213483333587646 0.5296646952629089 0.913385808467865\n","Validation loss decreased (0.503645 --> 0.503132).  Saving model ...\n","68 0.3785196840763092 0.997183084487915 0.5031321048736572 0.9213483333587646 0.5292335152626038 0.913385808467865\n","Validation loss decreased (0.503132 --> 0.502633).  Saving model ...\n","69 0.377482146024704 0.997183084487915 0.502633273601532 0.9213483333587646 0.528816282749176 0.913385808467865\n","Validation loss decreased (0.502633 --> 0.502149).  Saving model ...\n","70 0.3764711320400238 0.997183084487915 0.5021491050720215 0.9213483333587646 0.5284116268157959 0.913385808467865\n","Validation loss decreased (0.502149 --> 0.501679).  Saving model ...\n","71 0.3754866123199463 0.997183084487915 0.5016794204711914 0.9213483333587646 0.5280196666717529 0.9107611775398254\n","Validation loss decreased (0.501679 --> 0.501223).  Saving model ...\n","72 0.3745272755622864 0.997183084487915 0.5012227892875671 0.9213483333587646 0.5276393890380859 0.9107611775398254\n","Validation loss decreased (0.501223 --> 0.500778).  Saving model ...\n","73 0.3735921084880829 0.997183084487915 0.5007783770561218 0.9213483333587646 0.5272700190544128 0.9107611775398254\n","Validation loss decreased (0.500778 --> 0.500345).  Saving model ...\n","74 0.37267935276031494 0.997183084487915 0.5003454685211182 0.9213483333587646 0.5269110202789307 0.9107611775398254\n","Validation loss decreased (0.500345 --> 0.499922).  Saving model ...\n","75 0.37178993225097656 0.997183084487915 0.49992242455482483 0.9213483333587646 0.5265613198280334 0.9107611775398254\n","Validation loss decreased (0.499922 --> 0.499509).  Saving model ...\n","76 0.37092217803001404 0.997183084487915 0.499508798122406 0.9213483333587646 0.5262200236320496 0.913385808467865\n","Validation loss decreased (0.499509 --> 0.499104).  Saving model ...\n","77 0.3700751066207886 0.997183084487915 0.4991036355495453 0.9213483333587646 0.5258873701095581 0.913385808467865\n","Validation loss decreased (0.499104 --> 0.498707).  Saving model ...\n","78 0.3692485988140106 0.997183084487915 0.4987069070339203 0.9213483333587646 0.5255621671676636 0.913385808467865\n","Validation loss decreased (0.498707 --> 0.498318).  Saving model ...\n","79 0.36844244599342346 0.997183084487915 0.4983178675174713 0.9213483333587646 0.5252444744110107 0.913385808467865\n","Validation loss decreased (0.498318 --> 0.497937).  Saving model ...\n","80 0.36765411496162415 0.997183084487915 0.49793654680252075 0.9213483333587646 0.5249338150024414 0.913385808467865\n","Validation loss decreased (0.497937 --> 0.497564).  Saving model ...\n","81 0.3668847978115082 0.997183084487915 0.4975639879703522 0.9213483333587646 0.5246309041976929 0.913385808467865\n","Validation loss decreased (0.497564 --> 0.497199).  Saving model ...\n","82 0.3661331832408905 0.997183084487915 0.49719899892807007 0.9213483333587646 0.5243346095085144 0.913385808467865\n","Validation loss decreased (0.497199 --> 0.496842).  Saving model ...\n","83 0.3653988242149353 0.997183084487915 0.49684229493141174 0.9213483333587646 0.524046003818512 0.913385808467865\n","Validation loss decreased (0.496842 --> 0.496493).  Saving model ...\n","84 0.36468130350112915 0.997183084487915 0.4964929223060608 0.9213483333587646 0.5237635970115662 0.913385808467865\n","Validation loss decreased (0.496493 --> 0.496152).  Saving model ...\n","85 0.3639797270298004 0.9985915422439575 0.4961518347263336 0.9213483333587646 0.5234878659248352 0.913385808467865\n","Validation loss decreased (0.496152 --> 0.495818).  Saving model ...\n","86 0.3632940649986267 0.9985915422439575 0.4958176612854004 0.9213483333587646 0.5232186913490295 0.913385808467865\n","Validation loss decreased (0.495818 --> 0.495490).  Saving model ...\n","87 0.36262357234954834 0.9985915422439575 0.4954897463321686 0.9213483333587646 0.5229547619819641 0.913385808467865\n","Validation loss decreased (0.495490 --> 0.495168).  Saving model ...\n","88 0.361967533826828 0.9985915422439575 0.49516817927360535 0.9213483333587646 0.5226964354515076 0.913385808467865\n","Validation loss decreased (0.495168 --> 0.494852).  Saving model ...\n","89 0.3613256812095642 0.9985915422439575 0.49485206604003906 0.9213483333587646 0.5224432349205017 0.913385808467865\n","Validation loss decreased (0.494852 --> 0.494541).  Saving model ...\n","90 0.360698401927948 0.9985915422439575 0.4945411682128906 0.9213483333587646 0.5221944451332092 0.913385808467865\n","Validation loss decreased (0.494541 --> 0.494235).  Saving model ...\n","91 0.36008375883102417 0.9985915422439575 0.4942352771759033 0.9213483333587646 0.5219501256942749 0.913385808467865\n","Validation loss decreased (0.494235 --> 0.493934).  Saving model ...\n","92 0.35948243737220764 0.9985915422439575 0.4939344525337219 0.9213483333587646 0.5217101573944092 0.913385808467865\n","Validation loss decreased (0.493934 --> 0.493638).  Saving model ...\n","93 0.35889360308647156 0.9985915422439575 0.49363845586776733 0.9213483333587646 0.5214746594429016 0.913385808467865\n","Validation loss decreased (0.493638 --> 0.493347).  Saving model ...\n","94 0.3583173453807831 0.9985915422439575 0.49334749579429626 0.9213483333587646 0.5212427377700806 0.913385808467865\n","Validation loss decreased (0.493347 --> 0.493061).  Saving model ...\n","95 0.35775279998779297 0.9985915422439575 0.49306121468544006 0.9213483333587646 0.5210156440734863 0.913385808467865\n","Validation loss decreased (0.493061 --> 0.492780).  Saving model ...\n","96 0.35719969868659973 0.9985915422439575 0.49278005957603455 0.9213483333587646 0.5207928419113159 0.913385808467865\n","Validation loss decreased (0.492780 --> 0.492504).  Saving model ...\n","97 0.356658011674881 0.9985915422439575 0.49250417947769165 0.9213483333587646 0.5205737948417664 0.913385808467865\n","Validation loss decreased (0.492504 --> 0.492233).  Saving model ...\n","98 0.35612761974334717 0.9985915422439575 0.4922327995300293 0.9213483333587646 0.5203588604927063 0.913385808467865\n","Validation loss decreased (0.492233 --> 0.491966).  Saving model ...\n","99 0.3556072413921356 0.9985915422439575 0.4919663071632385 0.9213483333587646 0.5201470255851746 0.913385808467865\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"erpioWsYtaUa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607486111490,"user_tz":180,"elapsed":175883,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"87e4ff54-3261-4a21-900c-63e57517c6a9"},"source":["print(Precision(prediction, Y_train_tensor))\n","print(Precision(val_prediction, Y_valid_tensor))\n","print(Precision(test_prediction, Y_test_tensor))"],"execution_count":23,"outputs":[{"output_type":"stream","text":["[1.0, 0.9919354915618896]\n","[0.9463087320327759, 0.7931034564971924]\n","[0.9357798099517822, 0.7777777910232544]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Qu2e4Qh38lp4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607486111491,"user_tz":180,"elapsed":175879,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"b4a7de76-9ff5-4be3-bad0-a2e3b20f5c89"},"source":["print(Recall(prediction, Y_train_tensor))\n","print(Recall(val_prediction, Y_valid_tensor))\n","print(Recall(test_prediction, Y_test_tensor))"],"execution_count":24,"outputs":[{"output_type":"stream","text":["[0.9982964396476746, 1.0]\n","[0.9591836929321289, 0.7419354915618896]\n","[0.9622641801834106, 0.6666666865348816]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5IoA1jJGBW2Q","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607486111491,"user_tz":180,"elapsed":175875,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"2da258f1-aa60-4eea-bcd7-1d170cdeef18"},"source":["print(Accuracy(prediction, Y_train_tensor))\n","print(Accuracy(val_prediction, Y_valid_tensor))\n","print(Accuracy(test_prediction, Y_test_tensor))"],"execution_count":25,"outputs":[{"output_type":"stream","text":["0.9985915422439575\n","0.9213483333587646\n","0.913385808467865\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zne61NvaqD6n","executionInfo":{"status":"ok","timestamp":1607486674166,"user_tz":180,"elapsed":739,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["with open('/content/drive/My Drive/Data Master/Prediction_BOW_RegressaoLogistica/test_prediction_split' + str(n_split), 'wb') as file:\n","    pickle.dump(test_prediction.detach().numpy(), file)"],"execution_count":33,"outputs":[]}]}