{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of Split1.ipynb","provenance":[{"file_id":"1ly17dl3w8rGXAPtd1owJFslx4RVJE78c","timestamp":1592607825372},{"file_id":"1VIBcIIFR_YFlSguO_JGlnJbFzyAcT6YH","timestamp":1592464333044},{"file_id":"1dZvMRgPPkRVGa_4BZ1Tvoom_U4pjwmRX","timestamp":1592435543596},{"file_id":"12Sf257YUAwzmSXOlE3llOhi0N1YVUbM7","timestamp":1583376883298}],"collapsed_sections":[],"authorship_tag":"ABX9TyMEbgDETABZed2ztiwdzZ0P"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"JQrQmaLj0UuZ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"executionInfo":{"status":"ok","timestamp":1593323917024,"user_tz":180,"elapsed":24052,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"cb120cb8-19eb-40d6-f600-da84108e4d97"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JjEPtibx-EJD","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593323918971,"user_tz":180,"elapsed":25989,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["import numpy as np\n","import torch\n","\n","class EarlyStopping:\n","    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n","    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt'):\n","        \"\"\"\n","        Args:\n","            patience (int): How long to wait after last time validation loss improved.\n","                            Default: 7\n","            verbose (bool): If True, prints a message for each validation loss improvement. \n","                            Default: False\n","            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n","                            Default: 0\n","            path (str): Path for the checkpoint to be saved to.\n","                            Default: 'checkpoint.pt'\n","        \"\"\"\n","        self.patience = patience\n","        self.verbose = verbose\n","        self.counter = 0\n","        self.best_score = None\n","        self.early_stop = False\n","        self.val_loss_min = np.Inf\n","        self.delta = delta\n","        self.path = path\n","\n","    def __call__(self, val_loss, model):\n","\n","        score = -val_loss\n","\n","        if self.best_score is None:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model)\n","        elif score < self.best_score + self.delta:\n","            self.counter += 1\n","            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n","            if self.counter >= self.patience:\n","                self.early_stop = True\n","        else:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model)\n","            self.counter = 0\n","\n","    def save_checkpoint(self, val_loss, model):\n","        '''Saves model when validation loss decrease.'''\n","        if self.verbose:\n","            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n","        torch.save(model.state_dict(), self.path)\n","        self.val_loss_min = val_loss"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"tjGPuXgoqulz","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593323918972,"user_tz":180,"elapsed":25985,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["def Accuracy(prediction, observation):\n","  prediction = prediction[:,1]\n","  prediction_class = (torch.reshape(prediction, observation.shape) > 0.5).float()\n","  correct = (prediction_class == observation).float().sum()\n","  accuracy = correct/prediction_class.shape[0]\n","  return float(accuracy.cpu())\n","\n","def Precision(prediction, observation):\n","  prediction = prediction[:,1]\n","  res = []\n","  prediction_class = (torch.reshape(prediction, observation.shape) > 0.5).float()\n","  for label in [0, 1]:\n","    correct = (prediction_class[prediction_class == label] == observation[prediction_class == label]).float().sum()\n","    precision = correct/prediction_class[prediction_class == label].shape[0]\n","    res.append(float(precision.cpu()))\n","  return res\n","\n","def Recall(prediction, observation):\n","  prediction = prediction[:,1]\n","  res = []\n","  prediction_class = (torch.reshape(prediction, observation.shape) > 0.5).float()\n","  for label in [0, 1]:\n","    correct = (prediction_class[observation == label] == observation[observation == label]).float().sum()\n","    recall = correct/prediction_class[observation == label].shape[0]\n","    res.append(float(recall.cpu()))\n","  return res"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"sgz5Ea8a1wKr","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593323918973,"user_tz":180,"elapsed":25981,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["n_split = 1"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"cutkFU0k1Pkv","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593323918975,"user_tz":180,"elapsed":25978,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["import pickle\n","import pandas as pd\n","import numpy as np"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"wSJO5A951VXh","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593323924098,"user_tz":180,"elapsed":31095,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["with open('/content/drive/My Drive/Data Master/X_train_final', 'rb') as file:\n","    X_train = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/Y_train_final', 'rb') as file:\n","    Y_train = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/X_test_final', 'rb') as file:\n","    X_test = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/Y_test_final', 'rb') as file:\n","    Y_test = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/word_index_final', 'rb') as file:\n","    word_index = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/train_index_final_split_' + str(n_split), 'rb') as file:\n","    train_index = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/valid_index_final_split_' + str(n_split), 'rb') as file:\n","    valid_index = pickle.load(file)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"_v0BS5Cp_06s","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593323924099,"user_tz":180,"elapsed":31091,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["test_index = [i for i, _ in enumerate(X_test)]"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"NGqLg8IllrZE","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593323924100,"user_tz":180,"elapsed":31087,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["inv_word_index = {ix : w for w, ix in word_index.items()}"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"1-2YPzNN1x5T","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593323929114,"user_tz":180,"elapsed":36096,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["import itertools\n","features_index = {w:ix for ix, w in enumerate(np.unique(list(itertools.chain.from_iterable(np.array(X_train)[train_index]))))}\n","inv_features_index = {ix:w for ix, w in enumerate(np.unique(list(itertools.chain.from_iterable(np.array(X_train)[train_index]))))}"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"RxZWUTIv4K5T","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593323930448,"user_tz":180,"elapsed":37426,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["X_train_matrix = np.zeros((len(X_train), len(features_index)))\n","X_test_matrix = np.zeros((len(X_test), len(features_index)))"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"K6KzJuIy4dN8","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593323948456,"user_tz":180,"elapsed":55429,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["for i, x in enumerate(X_train):\n","  for w in x:\n","    if w in features_index:\n","      X_train_matrix[i,features_index[w]] += 1\n","\n","for i, x in enumerate(X_test):\n","  for w in x:\n","    if w in features_index:\n","      X_test_matrix[i,features_index[w]] += 1"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"9d4attfQ0i-Q","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593323948456,"user_tz":180,"elapsed":55424,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"twcFT-Hl3fqP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593323948457,"user_tz":180,"elapsed":55420,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"e77b40c5-eef9-4390-8a7c-3b5e8750ca3c"},"source":["input_dim = X_train_matrix.shape[1]\n","input_dim"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["246510"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"9fbXl191nZhK","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593323948458,"user_tz":180,"elapsed":55413,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["class LogisticRegression (nn.Module):\n","\n","  def __init__(self):\n","    super(LogisticRegression, self).__init__()\n","\n","    self.fc1 = nn.Linear(input_dim, 2)\n","                                \n","    self.softmax = nn.Softmax(dim=1)\n","\n","  def forward(self, x):\n","    x = F.normalize(x)\n","    y = self.softmax(self.fc1(x))\n","\n","    return y"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"Cgzf7IEqnyN4","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593323948458,"user_tz":180,"elapsed":55408,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["model = LogisticRegression()"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"0rnUcqchBE91","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593323950547,"user_tz":180,"elapsed":57492,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["X_train_tensor = torch.from_numpy(X_train_matrix[train_index]).float()\n","Y_train_tensor = torch.LongTensor(np.array(Y_train[train_index]))\n","\n","X_valid_tensor = torch.from_numpy(X_train_matrix[valid_index]).float()\n","Y_valid_tensor = torch.LongTensor(np.array(Y_train[valid_index]))\n","\n","X_test_tensor = torch.from_numpy(X_test_matrix).float()\n","Y_test_tensor = torch.LongTensor(np.array(Y_test))"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"GlP5dzFET5tF","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593323950548,"user_tz":180,"elapsed":57488,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["torch.manual_seed(0)\n","np.random.seed(0)"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"SV0Da5qu98-C","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593323950549,"user_tz":180,"elapsed":57484,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["import torch.optim as optim\n","optimizer = optim.AdamW(model.parameters(), lr=0.01)"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"gHujp4Ww_ZuO","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593323950550,"user_tz":180,"elapsed":57480,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["from torch.optim.lr_scheduler import ReduceLROnPlateau\n","scheduler = ReduceLROnPlateau(optimizer, 'min')"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"qkfeoTBHRuOb","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593323950550,"user_tz":180,"elapsed":57475,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"3bc51363-1964-4204-b4f1-c247775687b1"},"source":["weights = [sum(Y_train)/len(Y_train), 1-sum(Y_train)/len(Y_train)]\n","class_weights = torch.FloatTensor(weights)\n","class_weights"],"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0.1734, 0.8266])"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"8-F96WAE98zI","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593323950551,"user_tz":180,"elapsed":57469,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["criterion = nn.CrossEntropyLoss(weight=class_weights)"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"E7KgiIq398rR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1593324076275,"user_tz":180,"elapsed":183188,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"b32082bf-3175-4ccd-ec81-3a2d34519b8a"},"source":["patience = 20\n","early_stopping = EarlyStopping(patience=patience, verbose=True)\n","\n","for i in range(100):\n","  model.train()\n","  optimizer.zero_grad()\n","  prediction = model(X_train_tensor)\n","  loss = criterion(prediction, Y_train_tensor)\n","  loss.backward()\n","  optimizer.step()\n","\n","  accuracy = Accuracy(prediction, Y_train_tensor)\n","\n","  model.eval()\n","\n","  val_prediction = model(X_valid_tensor)\n","  test_prediction = model(X_test_tensor)\n","  val_loss = criterion(val_prediction, Y_valid_tensor)\n","  test_loss = criterion(test_prediction, Y_test_tensor)\n","\n","  val_accuracy = Accuracy(val_prediction, Y_valid_tensor)\n","  test_accuracy = Accuracy(test_prediction, Y_test_tensor)\n","\n","  early_stopping(val_loss, model)\n","\n","  if early_stopping.early_stop:\n","    print(\"Early stopping\")\n","    break\n","\n","  print(i, float(loss.cpu()), accuracy, float(val_loss.cpu()), val_accuracy, float(test_loss.cpu()), test_accuracy)\n","\n","  scheduler.step(val_loss)\n","\n","model.load_state_dict(torch.load('checkpoint.pt'))"],"execution_count":22,"outputs":[{"output_type":"stream","text":["Validation loss decreased (inf --> 0.685711).  Saving model ...\n","0 0.6931824088096619 0.17183098196983337 0.6857109069824219 0.8707864880561829 0.6862044930458069 0.887139081954956\n","Validation loss decreased (0.685711 --> 0.678369).  Saving model ...\n","1 0.680579662322998 0.9436619877815247 0.6783691644668579 0.9101123809814453 0.6796597838401794 0.9107611775398254\n","Validation loss decreased (0.678369 --> 0.671157).  Saving model ...\n","2 0.6682050824165344 0.9633802771568298 0.6711574792861938 0.9101123809814453 0.673295795917511 0.9028871655464172\n","Validation loss decreased (0.671157 --> 0.664088).  Saving model ...\n","3 0.6560906171798706 0.9676056504249573 0.6640881896018982 0.9101123809814453 0.6670946478843689 0.9002624750137329\n","Validation loss decreased (0.664088 --> 0.657175).  Saving model ...\n","4 0.64426589012146 0.9661971926689148 0.6571747064590454 0.898876428604126 0.6610570549964905 0.9028871655464172\n","Validation loss decreased (0.657175 --> 0.650431).  Saving model ...\n","5 0.6327587962150574 0.9690141081809998 0.6504308581352234 0.898876428604126 0.6551852226257324 0.8976377844810486\n","Validation loss decreased (0.650431 --> 0.643872).  Saving model ...\n","6 0.6215906739234924 0.9676056504249573 0.6438718438148499 0.898876428604126 0.649483859539032 0.8923884630203247\n","Validation loss decreased (0.643872 --> 0.637512).  Saving model ...\n","7 0.6107786893844604 0.9676056504249573 0.6375117897987366 0.9044944047927856 0.6439593434333801 0.887139081954956\n","Validation loss decreased (0.637512 --> 0.631365).  Saving model ...\n","8 0.6003356575965881 0.9676056504249573 0.6313652396202087 0.9044944047927856 0.638619065284729 0.887139081954956\n","Validation loss decreased (0.631365 --> 0.625443).  Saving model ...\n","9 0.5902682542800903 0.9676056504249573 0.625442624092102 0.9044944047927856 0.6334704756736755 0.887139081954956\n","Validation loss decreased (0.625443 --> 0.619749).  Saving model ...\n","10 0.5805813074111938 0.9676056504249573 0.6197491884231567 0.9101123809814453 0.6285194158554077 0.887139081954956\n","Validation loss decreased (0.619749 --> 0.614283).  Saving model ...\n","11 0.571276068687439 0.9676056504249573 0.6142830848693848 0.9101123809814453 0.6237696409225464 0.887139081954956\n","Validation loss decreased (0.614283 --> 0.609037).  Saving model ...\n","12 0.5623526573181152 0.9676056504249573 0.6090368032455444 0.9101123809814453 0.6192189455032349 0.8897637724876404\n","Validation loss decreased (0.609037 --> 0.603998).  Saving model ...\n","13 0.5538064241409302 0.9676056504249573 0.603998064994812 0.9101123809814453 0.6148620843887329 0.8897637724876404\n","Validation loss decreased (0.603998 --> 0.599155).  Saving model ...\n","14 0.5456312298774719 0.9676056504249573 0.5991547703742981 0.9101123809814453 0.6106914281845093 0.8897637724876404\n","Validation loss decreased (0.599155 --> 0.594497).  Saving model ...\n","15 0.5378184914588928 0.9676056504249573 0.5944967865943909 0.9101123809814453 0.6066998243331909 0.8897637724876404\n","Validation loss decreased (0.594497 --> 0.590019).  Saving model ...\n","16 0.5303568243980408 0.9676056504249573 0.5900192260742188 0.9101123809814453 0.602878987789154 0.8923884630203247\n","Validation loss decreased (0.590019 --> 0.585721).  Saving model ...\n","17 0.5232350826263428 0.9690141081809998 0.585721492767334 0.9101123809814453 0.5992263555526733 0.8923884630203247\n","Validation loss decreased (0.585721 --> 0.581606).  Saving model ...\n","18 0.5164417624473572 0.9704225063323975 0.5816056728363037 0.9101123809814453 0.5957374572753906 0.8923884630203247\n","Validation loss decreased (0.581606 --> 0.577674).  Saving model ...\n","19 0.5099632740020752 0.9704225063323975 0.5776744484901428 0.9101123809814453 0.5924100875854492 0.8923884630203247\n","Validation loss decreased (0.577674 --> 0.573929).  Saving model ...\n","20 0.503786563873291 0.9718309640884399 0.5739293694496155 0.9101123809814453 0.589241623878479 0.8950130939483643\n","Validation loss decreased (0.573929 --> 0.570368).  Saving model ...\n","21 0.4978979527950287 0.9718309640884399 0.5703681111335754 0.9101123809814453 0.5862274765968323 0.8950130939483643\n","Validation loss decreased (0.570368 --> 0.566985).  Saving model ...\n","22 0.4922823905944824 0.9732394218444824 0.5669849514961243 0.9101123809814453 0.5833621621131897 0.8950130939483643\n","Validation loss decreased (0.566985 --> 0.563770).  Saving model ...\n","23 0.4869268238544464 0.9732394218444824 0.5637698769569397 0.9101123809814453 0.5806375741958618 0.8923884630203247\n","Validation loss decreased (0.563770 --> 0.560710).  Saving model ...\n","24 0.48181766271591187 0.9774647951126099 0.5607098340988159 0.9101123809814453 0.578045666217804 0.8923884630203247\n","Validation loss decreased (0.560710 --> 0.557791).  Saving model ...\n","25 0.47694262862205505 0.9774647951126099 0.5577908158302307 0.9101123809814453 0.5755759477615356 0.8923884630203247\n","Validation loss decreased (0.557791 --> 0.555001).  Saving model ...\n","26 0.4722883701324463 0.9788732528686523 0.5550006031990051 0.9101123809814453 0.5732200145721436 0.8950130939483643\n","Validation loss decreased (0.555001 --> 0.552330).  Saving model ...\n","27 0.467842698097229 0.9788732528686523 0.5523297786712646 0.9101123809814453 0.5709695816040039 0.8950130939483643\n","Validation loss decreased (0.552330 --> 0.549772).  Saving model ...\n","28 0.46359387040138245 0.9788732528686523 0.5497722625732422 0.9101123809814453 0.5688191652297974 0.8976377844810486\n","Validation loss decreased (0.549772 --> 0.547325).  Saving model ...\n","29 0.45953184366226196 0.9788732528686523 0.5473250150680542 0.9101123809814453 0.5667650103569031 0.8976377844810486\n","Validation loss decreased (0.547325 --> 0.544988).  Saving model ...\n","30 0.4556451737880707 0.9802817106246948 0.544987678527832 0.9101123809814453 0.5648034811019897 0.8976377844810486\n","Validation loss decreased (0.544988 --> 0.542759).  Saving model ...\n","31 0.45192471146583557 0.9816901683807373 0.5427594780921936 0.9101123809814453 0.5629328489303589 0.8976377844810486\n","Validation loss decreased (0.542759 --> 0.540640).  Saving model ...\n","32 0.4483610689640045 0.9816901683807373 0.5406401753425598 0.9101123809814453 0.5611506700515747 0.8976377844810486\n","Validation loss decreased (0.540640 --> 0.538627).  Saving model ...\n","33 0.4449446499347687 0.9816901683807373 0.5386268496513367 0.915730357170105 0.5594529509544373 0.8976377844810486\n","Validation loss decreased (0.538627 --> 0.536715).  Saving model ...\n","34 0.4416691064834595 0.9816901683807373 0.5367154479026794 0.915730357170105 0.5578373670578003 0.8976377844810486\n","Validation loss decreased (0.536715 --> 0.534898).  Saving model ...\n","35 0.43852469325065613 0.983098566532135 0.5348983407020569 0.915730357170105 0.5562973022460938 0.8976377844810486\n","Validation loss decreased (0.534898 --> 0.533168).  Saving model ...\n","36 0.43550553917884827 0.983098566532135 0.5331681966781616 0.915730357170105 0.5548282265663147 0.8976377844810486\n","Validation loss decreased (0.533168 --> 0.531516).  Saving model ...\n","37 0.4326046407222748 0.983098566532135 0.5315161943435669 0.915730357170105 0.5534245371818542 0.8976377844810486\n","Validation loss decreased (0.531516 --> 0.529935).  Saving model ...\n","38 0.4298151731491089 0.9845070242881775 0.5299350023269653 0.915730357170105 0.5520808100700378 0.8976377844810486\n","Validation loss decreased (0.529935 --> 0.528419).  Saving model ...\n","39 0.42713215947151184 0.9845070242881775 0.5284188985824585 0.915730357170105 0.5507920980453491 0.8976377844810486\n","Validation loss decreased (0.528419 --> 0.526963).  Saving model ...\n","40 0.4245496094226837 0.9845070242881775 0.526963472366333 0.915730357170105 0.5495561957359314 0.8976377844810486\n","Validation loss decreased (0.526963 --> 0.525566).  Saving model ...\n","41 0.42206186056137085 0.9845070242881775 0.5255663990974426 0.915730357170105 0.5483704805374146 0.8976377844810486\n","Validation loss decreased (0.525566 --> 0.524227).  Saving model ...\n","42 0.41966477036476135 0.9845070242881775 0.5242270827293396 0.915730357170105 0.5472331643104553 0.8976377844810486\n","Validation loss decreased (0.524227 --> 0.522946).  Saving model ...\n","43 0.41735363006591797 0.9845070242881775 0.5229457020759583 0.9101123809814453 0.5461438298225403 0.8976377844810486\n","Validation loss decreased (0.522946 --> 0.521721).  Saving model ...\n","44 0.415123850107193 0.98591548204422 0.5217212438583374 0.9101123809814453 0.5451009273529053 0.8976377844810486\n","Validation loss decreased (0.521721 --> 0.520553).  Saving model ...\n","45 0.41297227144241333 0.9873239398002625 0.5205526947975159 0.915730357170105 0.5441035628318787 0.8976377844810486\n","Validation loss decreased (0.520553 --> 0.519438).  Saving model ...\n","46 0.41089439392089844 0.9873239398002625 0.5194379687309265 0.915730357170105 0.543150007724762 0.9002624750137329\n","Validation loss decreased (0.519438 --> 0.518374).  Saving model ...\n","47 0.40888673067092896 0.9873239398002625 0.5183737277984619 0.915730357170105 0.5422371625900269 0.9002624750137329\n","Validation loss decreased (0.518374 --> 0.517355).  Saving model ...\n","48 0.4069466292858124 0.9887323975563049 0.5173553228378296 0.915730357170105 0.5413622260093689 0.9002624750137329\n","Validation loss decreased (0.517355 --> 0.516379).  Saving model ...\n","49 0.4050707519054413 0.9887323975563049 0.5163788199424744 0.915730357170105 0.540523111820221 0.9002624750137329\n","Validation loss decreased (0.516379 --> 0.515440).  Saving model ...\n","50 0.4032554030418396 0.9901408553123474 0.5154399275779724 0.915730357170105 0.5397161841392517 0.9002624750137329\n","Validation loss decreased (0.515440 --> 0.514535).  Saving model ...\n","51 0.4014989733695984 0.9901408553123474 0.5145347714424133 0.915730357170105 0.5389392375946045 0.9002624750137329\n","Validation loss decreased (0.514535 --> 0.513661).  Saving model ...\n","52 0.39979827404022217 0.9915493130683899 0.5136609077453613 0.915730357170105 0.5381895899772644 0.9002624750137329\n","Validation loss decreased (0.513661 --> 0.512817).  Saving model ...\n","53 0.39815056324005127 0.9915493130683899 0.5128169059753418 0.915730357170105 0.537466824054718 0.9002624750137329\n","Validation loss decreased (0.512817 --> 0.512002).  Saving model ...\n","54 0.3965543806552887 0.9915493130683899 0.5120017528533936 0.915730357170105 0.5367701053619385 0.9002624750137329\n","Validation loss decreased (0.512002 --> 0.511216).  Saving model ...\n","55 0.3950064480304718 0.9915493130683899 0.5112156867980957 0.915730357170105 0.5360987782478333 0.9002624750137329\n","Validation loss decreased (0.511216 --> 0.510459).  Saving model ...\n","56 0.3935060203075409 0.9915493130683899 0.5104587078094482 0.9213483333587646 0.5354518890380859 0.9002624750137329\n","Validation loss decreased (0.510459 --> 0.509730).  Saving model ...\n","57 0.3920498192310333 0.9943661689758301 0.5097299814224243 0.915730357170105 0.5348291397094727 0.9002624750137329\n","Validation loss decreased (0.509730 --> 0.509029).  Saving model ...\n","58 0.3906373381614685 0.9943661689758301 0.5090293884277344 0.915730357170105 0.5342307090759277 0.9028871655464172\n","Validation loss decreased (0.509029 --> 0.508355).  Saving model ...\n","59 0.38926592469215393 0.9943661689758301 0.5083549618721008 0.915730357170105 0.5336543321609497 0.9081364870071411\n","Validation loss decreased (0.508355 --> 0.507705).  Saving model ...\n","60 0.38793328404426575 0.9957746267318726 0.5077052712440491 0.915730357170105 0.533099353313446 0.9081364870071411\n","Validation loss decreased (0.507705 --> 0.507078).  Saving model ...\n","61 0.38663962483406067 0.997183084487915 0.5070778727531433 0.915730357170105 0.5325638651847839 0.9081364870071411\n","Validation loss decreased (0.507078 --> 0.506471).  Saving model ...\n","62 0.3853822946548462 0.997183084487915 0.5064705610275269 0.915730357170105 0.5320462584495544 0.9107611775398254\n","Validation loss decreased (0.506471 --> 0.505882).  Saving model ...\n","63 0.38416004180908203 0.997183084487915 0.5058816075325012 0.915730357170105 0.531545102596283 0.9107611775398254\n","Validation loss decreased (0.505882 --> 0.505309).  Saving model ...\n","64 0.38297131657600403 0.997183084487915 0.5053085684776306 0.915730357170105 0.5310596823692322 0.9107611775398254\n","Validation loss decreased (0.505309 --> 0.504751).  Saving model ...\n","65 0.38181573152542114 0.997183084487915 0.5047509670257568 0.915730357170105 0.530587911605835 0.913385808467865\n","Validation loss decreased (0.504751 --> 0.504208).  Saving model ...\n","66 0.3806907832622528 0.997183084487915 0.5042080879211426 0.9213483333587646 0.5301304459571838 0.913385808467865\n","Validation loss decreased (0.504208 --> 0.503680).  Saving model ...\n","67 0.37959641218185425 0.997183084487915 0.503679633140564 0.9213483333587646 0.5296866297721863 0.913385808467865\n","Validation loss decreased (0.503680 --> 0.503166).  Saving model ...\n","68 0.378530353307724 0.997183084487915 0.5031656622886658 0.9213483333587646 0.5292555093765259 0.913385808467865\n","Validation loss decreased (0.503166 --> 0.502667).  Saving model ...\n","69 0.377492755651474 0.997183084487915 0.5026665329933167 0.9213483333587646 0.5288378000259399 0.913385808467865\n","Validation loss decreased (0.502667 --> 0.502182).  Saving model ...\n","70 0.37648192048072815 0.997183084487915 0.5021817088127136 0.9213483333587646 0.5284331440925598 0.913385808467865\n","Validation loss decreased (0.502182 --> 0.501711).  Saving model ...\n","71 0.3754969835281372 0.997183084487915 0.5017112493515015 0.9213483333587646 0.5280402898788452 0.9107611775398254\n","Validation loss decreased (0.501711 --> 0.501254).  Saving model ...\n","72 0.37453731894493103 0.997183084487915 0.5012537837028503 0.9213483333587646 0.5276597738265991 0.9107611775398254\n","Validation loss decreased (0.501254 --> 0.500809).  Saving model ...\n","73 0.3736017942428589 0.997183084487915 0.5008094906806946 0.9213483333587646 0.5272901654243469 0.9107611775398254\n","Validation loss decreased (0.500809 --> 0.500376).  Saving model ...\n","74 0.3726893663406372 0.997183084487915 0.500376284122467 0.9213483333587646 0.5269310474395752 0.9107611775398254\n","Validation loss decreased (0.500376 --> 0.499954).  Saving model ...\n","75 0.3717995285987854 0.997183084487915 0.49995362758636475 0.9213483333587646 0.526581346988678 0.9107611775398254\n","Validation loss decreased (0.499954 --> 0.499540).  Saving model ...\n","76 0.3709316551685333 0.997183084487915 0.49954017996788025 0.9213483333587646 0.526240348815918 0.913385808467865\n","Validation loss decreased (0.499540 --> 0.499135).  Saving model ...\n","77 0.3700849413871765 0.997183084487915 0.4991353154182434 0.9213483333587646 0.525907576084137 0.913385808467865\n","Validation loss decreased (0.499135 --> 0.498739).  Saving model ...\n","78 0.36925792694091797 0.997183084487915 0.4987388551235199 0.9213483333587646 0.5255826711654663 0.913385808467865\n","Validation loss decreased (0.498739 --> 0.498350).  Saving model ...\n","79 0.36845099925994873 0.997183084487915 0.4983501136302948 0.9213483333587646 0.5252649188041687 0.913385808467865\n","Validation loss decreased (0.498350 --> 0.497969).  Saving model ...\n","80 0.3676632344722748 0.997183084487915 0.4979691207408905 0.9213483333587646 0.5249544382095337 0.913385808467865\n","Validation loss decreased (0.497969 --> 0.497596).  Saving model ...\n","81 0.3668935000896454 0.997183084487915 0.4975959062576294 0.9213483333587646 0.5246513485908508 0.913385808467865\n","Validation loss decreased (0.497596 --> 0.497231).  Saving model ...\n","82 0.36614182591438293 0.997183084487915 0.4972309172153473 0.9213483333587646 0.524355411529541 0.913385808467865\n","Validation loss decreased (0.497231 --> 0.496874).  Saving model ...\n","83 0.3654073178768158 0.997183084487915 0.4968735873699188 0.9213483333587646 0.5240659713745117 0.913385808467865\n","Validation loss decreased (0.496874 --> 0.496524).  Saving model ...\n","84 0.3646896183490753 0.997183084487915 0.4965241849422455 0.9213483333587646 0.5237835645675659 0.913385808467865\n","Validation loss decreased (0.496524 --> 0.496182).  Saving model ...\n","85 0.3639880418777466 0.9985915422439575 0.49618247151374817 0.9213483333587646 0.5235076546669006 0.913385808467865\n","Validation loss decreased (0.496182 --> 0.495848).  Saving model ...\n","86 0.3633021116256714 0.9985915422439575 0.49584800004959106 0.9213483333587646 0.5232381224632263 0.913385808467865\n","Validation loss decreased (0.495848 --> 0.495520).  Saving model ...\n","87 0.3626311123371124 0.9985915422439575 0.49552005529403687 0.9213483333587646 0.5229742527008057 0.913385808467865\n","Validation loss decreased (0.495520 --> 0.495198).  Saving model ...\n","88 0.3619750440120697 0.9985915422439575 0.49519822001457214 0.9213483333587646 0.52271568775177 0.913385808467865\n","Validation loss decreased (0.495198 --> 0.494882).  Saving model ...\n","89 0.3613334894180298 0.9985915422439575 0.4948822855949402 0.9213483333587646 0.5224625468254089 0.913385808467865\n","Validation loss decreased (0.494882 --> 0.494572).  Saving model ...\n","90 0.3607056736946106 0.9985915422439575 0.49457189440727234 0.9213483333587646 0.5222140550613403 0.913385808467865\n","Validation loss decreased (0.494572 --> 0.494266).  Saving model ...\n","91 0.36009103059768677 0.9985915422439575 0.4942663311958313 0.9213483333587646 0.5219699144363403 0.913385808467865\n","Validation loss decreased (0.494266 --> 0.493966).  Saving model ...\n","92 0.3594895601272583 0.9985915422439575 0.49396559596061707 0.9213483333587646 0.5217299461364746 0.913385808467865\n","Validation loss decreased (0.493966 --> 0.493669).  Saving model ...\n","93 0.3589008152484894 0.9985915422439575 0.493669331073761 0.9213483333587646 0.5214942097663879 0.913385808467865\n","Validation loss decreased (0.493669 --> 0.493378).  Saving model ...\n","94 0.3583242893218994 0.9985915422439575 0.4933784604072571 0.9213483333587646 0.5212627053260803 0.913385808467865\n","Validation loss decreased (0.493378 --> 0.493092).  Saving model ...\n","95 0.3577597439289093 0.9985915422439575 0.49309226870536804 0.9213483333587646 0.5210353136062622 0.913385808467865\n","Validation loss decreased (0.493092 --> 0.492811).  Saving model ...\n","96 0.3572067618370056 0.9985915422439575 0.49281081557273865 0.9213483333587646 0.5208123326301575 0.913385808467865\n","Validation loss decreased (0.492811 --> 0.492534).  Saving model ...\n","97 0.35666516423225403 0.9985915422439575 0.4925343990325928 0.9213483333587646 0.520592987537384 0.913385808467865\n","Validation loss decreased (0.492534 --> 0.492263).  Saving model ...\n","98 0.3561340272426605 0.9985915422439575 0.49226319789886475 0.9213483333587646 0.5203777551651001 0.913385808467865\n","Validation loss decreased (0.492263 --> 0.491996).  Saving model ...\n","99 0.3556142747402191 0.9985915422439575 0.49199628829956055 0.9213483333587646 0.5201663374900818 0.913385808467865\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"erpioWsYtaUa","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"executionInfo":{"status":"ok","timestamp":1593324076276,"user_tz":180,"elapsed":183183,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"810a5c12-5ef3-40f5-b9de-76fd1b79bb61"},"source":["print(Precision(prediction, Y_train_tensor))\n","print(Precision(val_prediction, Y_valid_tensor))\n","print(Precision(test_prediction, Y_test_tensor))"],"execution_count":23,"outputs":[{"output_type":"stream","text":["[1.0, 0.9919354915618896]\n","[0.9463087320327759, 0.7931034564971924]\n","[0.9357798099517822, 0.7777777910232544]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Qu2e4Qh38lp4","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"executionInfo":{"status":"ok","timestamp":1593324076277,"user_tz":180,"elapsed":183177,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"eaba708f-3d7e-462d-c2ab-a28e35122ed0"},"source":["print(Recall(prediction, Y_train_tensor))\n","print(Recall(val_prediction, Y_valid_tensor))\n","print(Recall(test_prediction, Y_test_tensor))"],"execution_count":24,"outputs":[{"output_type":"stream","text":["[0.9982964396476746, 1.0]\n","[0.9591836929321289, 0.7419354915618896]\n","[0.9622641801834106, 0.6666666865348816]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5IoA1jJGBW2Q","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"executionInfo":{"status":"ok","timestamp":1593324076278,"user_tz":180,"elapsed":183172,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"bb8252b2-c8a6-40cf-9a0d-0d790254c33c"},"source":["print(Accuracy(prediction, Y_train_tensor))\n","print(Accuracy(val_prediction, Y_valid_tensor))\n","print(Accuracy(test_prediction, Y_test_tensor))"],"execution_count":25,"outputs":[{"output_type":"stream","text":["0.9985915422439575\n","0.9213483333587646\n","0.913385808467865\n"],"name":"stdout"}]}]}