{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Split4.ipynb","provenance":[{"file_id":"1ly17dl3w8rGXAPtd1owJFslx4RVJE78c","timestamp":1592607825372},{"file_id":"1VIBcIIFR_YFlSguO_JGlnJbFzyAcT6YH","timestamp":1592464333044},{"file_id":"1dZvMRgPPkRVGa_4BZ1Tvoom_U4pjwmRX","timestamp":1592435543596},{"file_id":"12Sf257YUAwzmSXOlE3llOhi0N1YVUbM7","timestamp":1583376883298}],"collapsed_sections":[],"authorship_tag":"ABX9TyPX+cjnN4k5kUMKZ+fCaInC"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"JQrQmaLj0UuZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607487565800,"user_tz":180,"elapsed":20340,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"8eb17f20-c71d-4993-d6a1-38291f569296"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JjEPtibx-EJD","executionInfo":{"status":"ok","timestamp":1607487568553,"user_tz":180,"elapsed":23090,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["import numpy as np\n","import torch\n","\n","class EarlyStopping:\n","    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n","    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt'):\n","        \"\"\"\n","        Args:\n","            patience (int): How long to wait after last time validation loss improved.\n","                            Default: 7\n","            verbose (bool): If True, prints a message for each validation loss improvement. \n","                            Default: False\n","            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n","                            Default: 0\n","            path (str): Path for the checkpoint to be saved to.\n","                            Default: 'checkpoint.pt'\n","        \"\"\"\n","        self.patience = patience\n","        self.verbose = verbose\n","        self.counter = 0\n","        self.best_score = None\n","        self.early_stop = False\n","        self.val_loss_min = np.Inf\n","        self.delta = delta\n","        self.path = path\n","\n","    def __call__(self, val_loss, model):\n","\n","        score = -val_loss\n","\n","        if self.best_score is None:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model)\n","        elif score < self.best_score + self.delta:\n","            self.counter += 1\n","            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n","            if self.counter >= self.patience:\n","                self.early_stop = True\n","        else:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model)\n","            self.counter = 0\n","\n","    def save_checkpoint(self, val_loss, model):\n","        '''Saves model when validation loss decrease.'''\n","        if self.verbose:\n","            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n","        torch.save(model.state_dict(), self.path)\n","        self.val_loss_min = val_loss"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"tjGPuXgoqulz","executionInfo":{"status":"ok","timestamp":1607487568554,"user_tz":180,"elapsed":23088,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["def Accuracy(prediction, observation):\n","  prediction = prediction[:,1]\n","  prediction_class = (torch.reshape(prediction, observation.shape) > 0.5).float()\n","  correct = (prediction_class == observation).float().sum()\n","  accuracy = correct/prediction_class.shape[0]\n","  return float(accuracy.cpu())\n","\n","def Precision(prediction, observation):\n","  prediction = prediction[:,1]\n","  res = []\n","  prediction_class = (torch.reshape(prediction, observation.shape) > 0.5).float()\n","  for label in [0, 1]:\n","    correct = (prediction_class[prediction_class == label] == observation[prediction_class == label]).float().sum()\n","    precision = correct/prediction_class[prediction_class == label].shape[0]\n","    res.append(float(precision.cpu()))\n","  return res\n","\n","def Recall(prediction, observation):\n","  prediction = prediction[:,1]\n","  res = []\n","  prediction_class = (torch.reshape(prediction, observation.shape) > 0.5).float()\n","  for label in [0, 1]:\n","    correct = (prediction_class[observation == label] == observation[observation == label]).float().sum()\n","    recall = correct/prediction_class[observation == label].shape[0]\n","    res.append(float(recall.cpu()))\n","  return res"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"sgz5Ea8a1wKr","executionInfo":{"status":"ok","timestamp":1607487568554,"user_tz":180,"elapsed":23086,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["n_split = 4"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"cutkFU0k1Pkv","executionInfo":{"status":"ok","timestamp":1607487568555,"user_tz":180,"elapsed":23085,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["import pickle\n","import pandas as pd\n","import numpy as np"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"wSJO5A951VXh","executionInfo":{"status":"ok","timestamp":1607487571200,"user_tz":180,"elapsed":25729,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["with open('/content/drive/My Drive/Data Master/X_train_final', 'rb') as file:\n","    X_train = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/Y_train_final', 'rb') as file:\n","    Y_train = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/X_test_final', 'rb') as file:\n","    X_test = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/Y_test_final', 'rb') as file:\n","    Y_test = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/word_index_final', 'rb') as file:\n","    word_index = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/train_index_final_split_' + str(n_split), 'rb') as file:\n","    train_index = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/valid_index_final_split_' + str(n_split), 'rb') as file:\n","    valid_index = pickle.load(file)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"_v0BS5Cp_06s","executionInfo":{"status":"ok","timestamp":1607487571201,"user_tz":180,"elapsed":25728,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["test_index = [i for i, _ in enumerate(X_test)]"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"NGqLg8IllrZE","executionInfo":{"status":"ok","timestamp":1607487571202,"user_tz":180,"elapsed":25727,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["inv_word_index = {ix : w for w, ix in word_index.items()}"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"1-2YPzNN1x5T","executionInfo":{"status":"ok","timestamp":1607487576130,"user_tz":180,"elapsed":30653,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["import itertools\n","features_index = {w:ix for ix, w in enumerate(np.unique(list(itertools.chain.from_iterable(np.array(X_train)[train_index]))))}\n","inv_features_index = {ix:w for ix, w in enumerate(np.unique(list(itertools.chain.from_iterable(np.array(X_train)[train_index]))))}"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"RxZWUTIv4K5T","executionInfo":{"status":"ok","timestamp":1607487577578,"user_tz":180,"elapsed":32099,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["X_train_matrix = np.zeros((len(X_train), len(features_index)))\n","X_test_matrix = np.zeros((len(X_test), len(features_index)))"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"K6KzJuIy4dN8","executionInfo":{"status":"ok","timestamp":1607487595745,"user_tz":180,"elapsed":50264,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["for i, x in enumerate(X_train):\n","  for w in x:\n","    if w in features_index:\n","      X_train_matrix[i,features_index[w]] += 1\n","\n","for i, x in enumerate(X_test):\n","  for w in x:\n","    if w in features_index:\n","      X_test_matrix[i,features_index[w]] += 1"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"9d4attfQ0i-Q","executionInfo":{"status":"ok","timestamp":1607487595747,"user_tz":180,"elapsed":50265,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"twcFT-Hl3fqP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607487595747,"user_tz":180,"elapsed":50259,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"e421ad9e-3fb4-47db-bb27-383cd5552167"},"source":["input_dim = X_train_matrix.shape[1]\n","input_dim"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["231280"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"9fbXl191nZhK","executionInfo":{"status":"ok","timestamp":1607487595748,"user_tz":180,"elapsed":50258,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["class LogisticRegression (nn.Module):\n","\n","  def __init__(self):\n","    super(LogisticRegression, self).__init__()\n","\n","    self.fc1 = nn.Linear(input_dim, 2)\n","                                \n","    self.softmax = nn.Softmax(dim=1)\n","\n","  def forward(self, x):\n","    x = F.normalize(x)\n","    y = self.softmax(self.fc1(x))\n","\n","    return y"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"Cgzf7IEqnyN4","executionInfo":{"status":"ok","timestamp":1607487595748,"user_tz":180,"elapsed":50256,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["model = LogisticRegression()"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"0rnUcqchBE91","executionInfo":{"status":"ok","timestamp":1607487597610,"user_tz":180,"elapsed":52117,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["X_train_tensor = torch.from_numpy(X_train_matrix[train_index]).float()\n","Y_train_tensor = torch.LongTensor(np.array(Y_train[train_index]))\n","\n","X_valid_tensor = torch.from_numpy(X_train_matrix[valid_index]).float()\n","Y_valid_tensor = torch.LongTensor(np.array(Y_train[valid_index]))\n","\n","X_test_tensor = torch.from_numpy(X_test_matrix).float()\n","Y_test_tensor = torch.LongTensor(np.array(Y_test))"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"GlP5dzFET5tF","executionInfo":{"status":"ok","timestamp":1607487597612,"user_tz":180,"elapsed":52117,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["torch.manual_seed(0)\n","np.random.seed(0)"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"SV0Da5qu98-C","executionInfo":{"status":"ok","timestamp":1607487597613,"user_tz":180,"elapsed":52116,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["import torch.optim as optim\n","optimizer = optim.AdamW(model.parameters(), lr=0.01)"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"gHujp4Ww_ZuO","executionInfo":{"status":"ok","timestamp":1607487597613,"user_tz":180,"elapsed":52115,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["from torch.optim.lr_scheduler import ReduceLROnPlateau\n","scheduler = ReduceLROnPlateau(optimizer, 'min')"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"qkfeoTBHRuOb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607487597614,"user_tz":180,"elapsed":52111,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"15d1a2d2-aa70-4953-fc23-151946e90159"},"source":["weights = [sum(Y_train)/len(Y_train), 1-sum(Y_train)/len(Y_train)]\n","class_weights = torch.FloatTensor(weights)\n","class_weights"],"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0.1734, 0.8266])"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"8-F96WAE98zI","executionInfo":{"status":"ok","timestamp":1607487597614,"user_tz":180,"elapsed":52110,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["criterion = nn.CrossEntropyLoss(weight=class_weights)"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"E7KgiIq398rR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607487709068,"user_tz":180,"elapsed":163560,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"9ecfffbf-28ac-4baf-a665-1d33ab26a5c0"},"source":["patience = 20\n","early_stopping = EarlyStopping(patience=patience, verbose=True)\n","\n","for i in range(100):\n","  model.train()\n","  optimizer.zero_grad()\n","  prediction = model(X_train_tensor)\n","  loss = criterion(prediction, Y_train_tensor)\n","  loss.backward()\n","  optimizer.step()\n","\n","  accuracy = Accuracy(prediction, Y_train_tensor)\n","\n","  model.eval()\n","\n","  val_prediction = model(X_valid_tensor)\n","  test_prediction = model(X_test_tensor)\n","  val_loss = criterion(val_prediction, Y_valid_tensor)\n","  test_loss = criterion(test_prediction, Y_test_tensor)\n","\n","  val_accuracy = Accuracy(val_prediction, Y_valid_tensor)\n","  test_accuracy = Accuracy(test_prediction, Y_test_tensor)\n","\n","  early_stopping(val_loss, model)\n","\n","  if early_stopping.early_stop:\n","    print(\"Early stopping\")\n","    break\n","\n","  print(i, float(loss.cpu()), accuracy, float(val_loss.cpu()), val_accuracy, float(test_loss.cpu()), test_accuracy)\n","\n","  scheduler.step(val_loss)\n","\n","model.load_state_dict(torch.load('checkpoint.pt'))"],"execution_count":22,"outputs":[{"output_type":"stream","text":["Validation loss decreased (inf --> 0.684960).  Saving model ...\n","0 0.6931716799736023 0.7985915541648865 0.6849604249000549 0.898876428604126 0.6863391995429993 0.8818897604942322\n","Validation loss decreased (0.684960 --> 0.676829).  Saving model ...\n","1 0.6808243989944458 0.9478873014450073 0.6768291592597961 0.9269663095474243 0.679888129234314 0.9160104990005493\n","Validation loss decreased (0.676829 --> 0.668844).  Saving model ...\n","2 0.6686843037605286 0.9718309640884399 0.6688441634178162 0.9213483333587646 0.6735982894897461 0.913385808467865\n","Validation loss decreased (0.668844 --> 0.661024).  Saving model ...\n","3 0.6567928791046143 0.9661971926689148 0.6610238552093506 0.898876428604126 0.6674606800079346 0.9107611775398254\n","Validation loss decreased (0.661024 --> 0.653385).  Saving model ...\n","4 0.645180881023407 0.9633802771568298 0.6533854007720947 0.8932584524154663 0.6614757180213928 0.9002624750137329\n","Validation loss decreased (0.653385 --> 0.645943).  Saving model ...\n","5 0.633875846862793 0.9619718194007874 0.6459426879882812 0.8876404762268066 0.6556490659713745 0.9002624750137329\n","Validation loss decreased (0.645943 --> 0.638707).  Saving model ...\n","6 0.6228975653648376 0.9619718194007874 0.6387068033218384 0.8876404762268066 0.6499841809272766 0.887139081954956\n","Validation loss decreased (0.638707 --> 0.631686).  Saving model ...\n","7 0.6122626066207886 0.9647887349128723 0.6316856741905212 0.8764045238494873 0.6444884538650513 0.887139081954956\n","Validation loss decreased (0.631686 --> 0.624888).  Saving model ...\n","8 0.6019818782806396 0.9647887349128723 0.6248877644538879 0.8764045238494873 0.6391696333885193 0.887139081954956\n","Validation loss decreased (0.624888 --> 0.618319).  Saving model ...\n","9 0.5920621752738953 0.9647887349128723 0.6183189749717712 0.882022500038147 0.6340370178222656 0.887139081954956\n","Validation loss decreased (0.618319 --> 0.611984).  Saving model ...\n","10 0.5825099945068359 0.9647887349128723 0.6119839549064636 0.882022500038147 0.629097044467926 0.887139081954956\n","Validation loss decreased (0.611984 --> 0.605884).  Saving model ...\n","11 0.5733284950256348 0.9647887349128723 0.6058844327926636 0.8876404762268066 0.6243495345115662 0.887139081954956\n","Validation loss decreased (0.605884 --> 0.600019).  Saving model ...\n","12 0.5645166635513306 0.9647887349128723 0.6000185012817383 0.8876404762268066 0.6197918653488159 0.8897637724876404\n","Validation loss decreased (0.600019 --> 0.594384).  Saving model ...\n","13 0.5560705661773682 0.9647887349128723 0.5943843126296997 0.8876404762268066 0.61541748046875 0.8923884630203247\n","Validation loss decreased (0.594384 --> 0.588978).  Saving model ...\n","14 0.5479841828346252 0.9647887349128723 0.5889781713485718 0.8876404762268066 0.611221432685852 0.8923884630203247\n","Validation loss decreased (0.588978 --> 0.583798).  Saving model ...\n","15 0.5402495265007019 0.9647887349128723 0.5837979912757874 0.8876404762268066 0.6071977019309998 0.8897637724876404\n","Validation loss decreased (0.583798 --> 0.578840).  Saving model ...\n","16 0.5328571200370789 0.9647887349128723 0.5788403153419495 0.882022500038147 0.6033439040184021 0.8897637724876404\n","Validation loss decreased (0.578840 --> 0.574101).  Saving model ...\n","17 0.5257961750030518 0.9676056504249573 0.5741010904312134 0.882022500038147 0.5996576547622681 0.8845144510269165\n","Validation loss decreased (0.574101 --> 0.569576).  Saving model ...\n","18 0.5190566778182983 0.9690141081809998 0.5695756077766418 0.882022500038147 0.5961356163024902 0.8845144510269165\n","Validation loss decreased (0.569576 --> 0.565257).  Saving model ...\n","19 0.5126248598098755 0.9690141081809998 0.5652569532394409 0.882022500038147 0.5927750468254089 0.8845144510269165\n","Validation loss decreased (0.565257 --> 0.561139).  Saving model ...\n","20 0.5064885020256042 0.9690141081809998 0.5611385703086853 0.8876404762268066 0.5895712971687317 0.887139081954956\n","Validation loss decreased (0.561139 --> 0.557213).  Saving model ...\n","21 0.5006340742111206 0.9690141081809998 0.557212769985199 0.8876404762268066 0.5865169763565063 0.887139081954956\n","Validation loss decreased (0.557213 --> 0.553472).  Saving model ...\n","22 0.49504804611206055 0.9690141081809998 0.5534716248512268 0.8876404762268066 0.583604633808136 0.887139081954956\n","Validation loss decreased (0.553472 --> 0.549905).  Saving model ...\n","23 0.4897186756134033 0.9690141081809998 0.5499051809310913 0.8876404762268066 0.5808244943618774 0.8897637724876404\n","Validation loss decreased (0.549905 --> 0.546506).  Saving model ...\n","24 0.4846327006816864 0.9704225063323975 0.5465055704116821 0.8876404762268066 0.5781678557395935 0.8897637724876404\n","Validation loss decreased (0.546506 --> 0.543263).  Saving model ...\n","25 0.47977638244628906 0.9704225063323975 0.5432634949684143 0.8876404762268066 0.5756272673606873 0.8923884630203247\n","Validation loss decreased (0.543263 --> 0.540172).  Saving model ...\n","26 0.4751383662223816 0.9718309640884399 0.5401724576950073 0.8876404762268066 0.5731974840164185 0.8923884630203247\n","Validation loss decreased (0.540172 --> 0.537225).  Saving model ...\n","27 0.4707067906856537 0.9718309640884399 0.5372248291969299 0.8876404762268066 0.5708746910095215 0.8923884630203247\n","Validation loss decreased (0.537225 --> 0.534415).  Saving model ...\n","28 0.46647006273269653 0.9732394218444824 0.5344145894050598 0.8876404762268066 0.5686565041542053 0.8950130939483643\n","Validation loss decreased (0.534415 --> 0.531735).  Saving model ...\n","29 0.4624179005622864 0.9746478796005249 0.5317351818084717 0.8932584524154663 0.566540539264679 0.8950130939483643\n","Validation loss decreased (0.531735 --> 0.529181).  Saving model ...\n","30 0.4585399031639099 0.9746478796005249 0.529180645942688 0.8932584524154663 0.5645231008529663 0.8950130939483643\n","Validation loss decreased (0.529181 --> 0.526744).  Saving model ...\n","31 0.4548260569572449 0.9746478796005249 0.5267438888549805 0.8932584524154663 0.5626007914543152 0.8950130939483643\n","Validation loss decreased (0.526744 --> 0.524419).  Saving model ...\n","32 0.45126840472221375 0.9746478796005249 0.5244189500808716 0.8932584524154663 0.560767650604248 0.8950130939483643\n","Validation loss decreased (0.524419 --> 0.522199).  Saving model ...\n","33 0.44785580039024353 0.9746478796005249 0.5221992135047913 0.8932584524154663 0.5590174198150635 0.8950130939483643\n","Validation loss decreased (0.522199 --> 0.520078).  Saving model ...\n","34 0.44458216428756714 0.9746478796005249 0.5200780630111694 0.8932584524154663 0.5573442578315735 0.9002624750137329\n","Validation loss decreased (0.520078 --> 0.518050).  Saving model ...\n","35 0.4414396584033966 0.9760563373565674 0.5180495977401733 0.8932584524154663 0.5557421445846558 0.9002624750137329\n","Validation loss decreased (0.518050 --> 0.516108).  Saving model ...\n","36 0.4384205639362335 0.9760563373565674 0.5161079168319702 0.8932584524154663 0.5542053580284119 0.8976377844810486\n","Validation loss decreased (0.516108 --> 0.514248).  Saving model ...\n","37 0.43551790714263916 0.9760563373565674 0.514248251914978 0.8932584524154663 0.5527312755584717 0.8976377844810486\n","Validation loss decreased (0.514248 --> 0.512466).  Saving model ...\n","38 0.4327267110347748 0.9774647951126099 0.5124664306640625 0.898876428604126 0.551317572593689 0.8976377844810486\n","Validation loss decreased (0.512466 --> 0.510759).  Saving model ...\n","39 0.4300391674041748 0.9774647951126099 0.5107589364051819 0.9044944047927856 0.5499626398086548 0.9002624750137329\n","Validation loss decreased (0.510759 --> 0.509122).  Saving model ...\n","40 0.4274512529373169 0.9802817106246948 0.5091220736503601 0.9044944047927856 0.5486655235290527 0.9002624750137329\n","Validation loss decreased (0.509122 --> 0.507552).  Saving model ...\n","41 0.4249575138092041 0.9802817106246948 0.5075522661209106 0.9044944047927856 0.5474249124526978 0.9002624750137329\n","Validation loss decreased (0.507552 --> 0.506047).  Saving model ...\n","42 0.42255309224128723 0.9816901683807373 0.5060468316078186 0.9044944047927856 0.5462390184402466 0.9002624750137329\n","Validation loss decreased (0.506047 --> 0.504601).  Saving model ...\n","43 0.4202331602573395 0.983098566532135 0.5046014189720154 0.9044944047927856 0.5451043248176575 0.9002624750137329\n","Validation loss decreased (0.504601 --> 0.503213).  Saving model ...\n","44 0.4179939031600952 0.983098566532135 0.5032132863998413 0.9044944047927856 0.5440178513526917 0.9002624750137329\n","Validation loss decreased (0.503213 --> 0.501878).  Saving model ...\n","45 0.4158315062522888 0.983098566532135 0.501878023147583 0.9044944047927856 0.5429756045341492 0.9002624750137329\n","Validation loss decreased (0.501878 --> 0.500593).  Saving model ...\n","46 0.4137418866157532 0.983098566532135 0.5005930066108704 0.9044944047927856 0.5419741868972778 0.9002624750137329\n","Validation loss decreased (0.500593 --> 0.499354).  Saving model ...\n","47 0.41172128915786743 0.983098566532135 0.49935439229011536 0.9044944047927856 0.5410100817680359 0.9028871655464172\n","Validation loss decreased (0.499354 --> 0.498160).  Saving model ...\n","48 0.4097675085067749 0.9845070242881775 0.4981599450111389 0.9101123809814453 0.5400815606117249 0.9028871655464172\n","Validation loss decreased (0.498160 --> 0.497007).  Saving model ...\n","49 0.40787726640701294 0.9845070242881775 0.49700722098350525 0.9101123809814453 0.5391871333122253 0.9028871655464172\n","Validation loss decreased (0.497007 --> 0.495894).  Saving model ...\n","50 0.40604689717292786 0.9887323975563049 0.4958942234516144 0.9101123809814453 0.5383254885673523 0.9028871655464172\n","Validation loss decreased (0.495894 --> 0.494820).  Saving model ...\n","51 0.4042741656303406 0.9887323975563049 0.4948198199272156 0.9044944047927856 0.5374968647956848 0.9028871655464172\n","Validation loss decreased (0.494820 --> 0.493782).  Saving model ...\n","52 0.4025571644306183 0.9887323975563049 0.49378180503845215 0.9101123809814453 0.5367007255554199 0.9028871655464172\n","Validation loss decreased (0.493782 --> 0.492779).  Saving model ...\n","53 0.4008922874927521 0.9901408553123474 0.492779016494751 0.9101123809814453 0.535935640335083 0.9055117964744568\n","Validation loss decreased (0.492779 --> 0.491810).  Saving model ...\n","54 0.39927855134010315 0.9901408553123474 0.49180999398231506 0.9044944047927856 0.535200834274292 0.9055117964744568\n","Validation loss decreased (0.491810 --> 0.490872).  Saving model ...\n","55 0.3977128267288208 0.9901408553123474 0.49087223410606384 0.9044944047927856 0.5344945192337036 0.9055117964744568\n","Validation loss decreased (0.490872 --> 0.489964).  Saving model ...\n","56 0.3961939811706543 0.9915493130683899 0.48996415734291077 0.9044944047927856 0.5338141322135925 0.9055117964744568\n","Validation loss decreased (0.489964 --> 0.489084).  Saving model ...\n","57 0.39471960067749023 0.9929577708244324 0.4890839159488678 0.9044944047927856 0.5331575274467468 0.9081364870071411\n","Validation loss decreased (0.489084 --> 0.488230).  Saving model ...\n","58 0.3932874798774719 0.9943661689758301 0.48823001980781555 0.9044944047927856 0.5325232744216919 0.9081364870071411\n","Validation loss decreased (0.488230 --> 0.487401).  Saving model ...\n","59 0.39189666509628296 0.9943661689758301 0.4874005615711212 0.9044944047927856 0.5319088697433472 0.9081364870071411\n","Validation loss decreased (0.487401 --> 0.486594).  Saving model ...\n","60 0.3905450701713562 0.9943661689758301 0.4865940809249878 0.9044944047927856 0.5313135981559753 0.9028871655464172\n","Validation loss decreased (0.486594 --> 0.485810).  Saving model ...\n","61 0.3892313241958618 0.997183084487915 0.485809862613678 0.9044944047927856 0.5307373404502869 0.9028871655464172\n","Validation loss decreased (0.485810 --> 0.485047).  Saving model ...\n","62 0.38795432448387146 0.9985915422439575 0.4850473701953888 0.9044944047927856 0.5301786065101624 0.9055117964744568\n","Validation loss decreased (0.485047 --> 0.484306).  Saving model ...\n","63 0.3867117762565613 0.9985915422439575 0.4843057692050934 0.9044944047927856 0.529638409614563 0.9055117964744568\n","Validation loss decreased (0.484306 --> 0.483584).  Saving model ...\n","64 0.38550353050231934 1.0 0.48358383774757385 0.9044944047927856 0.5291157960891724 0.9081364870071411\n","Validation loss decreased (0.483584 --> 0.482882).  Saving model ...\n","65 0.38432732224464417 1.0 0.4828818142414093 0.9044944047927856 0.5286102890968323 0.9107611775398254\n","Validation loss decreased (0.482882 --> 0.482198).  Saving model ...\n","66 0.38318198919296265 1.0 0.4821978807449341 0.9044944047927856 0.5281214714050293 0.913385808467865\n","Validation loss decreased (0.482198 --> 0.481532).  Saving model ...\n","67 0.3820672035217285 1.0 0.4815319776535034 0.9044944047927856 0.5276476144790649 0.913385808467865\n","Validation loss decreased (0.481532 --> 0.480882).  Saving model ...\n","68 0.3809812068939209 1.0 0.480882465839386 0.9044944047927856 0.5271881222724915 0.913385808467865\n","Validation loss decreased (0.480882 --> 0.480249).  Saving model ...\n","69 0.3799229562282562 1.0 0.48024874925613403 0.9044944047927856 0.5267410278320312 0.913385808467865\n","Validation loss decreased (0.480249 --> 0.479630).  Saving model ...\n","70 0.3788917362689972 1.0 0.4796298146247864 0.9044944047927856 0.5263059735298157 0.9107611775398254\n","Validation loss decreased (0.479630 --> 0.479025).  Saving model ...\n","71 0.37788623571395874 1.0 0.47902482748031616 0.9044944047927856 0.5258815288543701 0.9107611775398254\n","Validation loss decreased (0.479025 --> 0.478433).  Saving model ...\n","72 0.37690621614456177 1.0 0.4784332811832428 0.9044944047927856 0.5254672169685364 0.9107611775398254\n","Validation loss decreased (0.478433 --> 0.477855).  Saving model ...\n","73 0.3759496510028839 1.0 0.47785472869873047 0.9044944047927856 0.5250629782676697 0.9107611775398254\n","Validation loss decreased (0.477855 --> 0.477289).  Saving model ...\n","74 0.37501704692840576 1.0 0.4772888123989105 0.9044944047927856 0.5246685147285461 0.9107611775398254\n","Validation loss decreased (0.477289 --> 0.476735).  Saving model ...\n","75 0.3741069734096527 1.0 0.47673532366752625 0.9044944047927856 0.5242839455604553 0.9107611775398254\n","Validation loss decreased (0.476735 --> 0.476194).  Saving model ...\n","76 0.37321874499320984 1.0 0.4761940538883209 0.9044944047927856 0.523909330368042 0.9107611775398254\n","Validation loss decreased (0.476194 --> 0.475665).  Saving model ...\n","77 0.37235140800476074 1.0 0.4756646454334259 0.9044944047927856 0.5235435366630554 0.9107611775398254\n","Validation loss decreased (0.475665 --> 0.475147).  Saving model ...\n","78 0.3715047240257263 1.0 0.47514668107032776 0.9044944047927856 0.5231868624687195 0.9107611775398254\n","Validation loss decreased (0.475147 --> 0.474639).  Saving model ...\n","79 0.3706771433353424 1.0 0.4746394753456116 0.9044944047927856 0.5228387117385864 0.9107611775398254\n","Validation loss decreased (0.474639 --> 0.474143).  Saving model ...\n","80 0.36986908316612244 1.0 0.47414258122444153 0.9101123809814453 0.5224986672401428 0.9107611775398254\n","Validation loss decreased (0.474143 --> 0.473656).  Saving model ...\n","81 0.3690798580646515 1.0 0.47365567088127136 0.9101123809814453 0.5221652984619141 0.9107611775398254\n","Validation loss decreased (0.473656 --> 0.473178).  Saving model ...\n","82 0.3683077096939087 1.0 0.47317835688591003 0.9101123809814453 0.5218389630317688 0.9107611775398254\n","Validation loss decreased (0.473178 --> 0.472710).  Saving model ...\n","83 0.3675536513328552 1.0 0.4727097451686859 0.9101123809814453 0.5215181708335876 0.9107611775398254\n","Validation loss decreased (0.472710 --> 0.472250).  Saving model ...\n","84 0.3668161928653717 1.0 0.47225019335746765 0.9101123809814453 0.5212035775184631 0.9107611775398254\n","Validation loss decreased (0.472250 --> 0.471799).  Saving model ...\n","85 0.3660948574542999 1.0 0.4717988967895508 0.9101123809814453 0.5208946466445923 0.9107611775398254\n","Validation loss decreased (0.471799 --> 0.471356).  Saving model ...\n","86 0.3653896152973175 1.0 0.47135600447654724 0.9101123809814453 0.5205913782119751 0.9107611775398254\n","Validation loss decreased (0.471356 --> 0.470921).  Saving model ...\n","87 0.36469969153404236 1.0 0.4709213078022003 0.9101123809814453 0.5202935934066772 0.9107611775398254\n","Validation loss decreased (0.470921 --> 0.470495).  Saving model ...\n","88 0.36402446031570435 1.0 0.47049495577812195 0.9101123809814453 0.5200015306472778 0.9107611775398254\n","Validation loss decreased (0.470495 --> 0.470076).  Saving model ...\n","89 0.363363653421402 1.0 0.47007641196250916 0.9101123809814453 0.5197151899337769 0.9107611775398254\n","Validation loss decreased (0.470076 --> 0.469665).  Saving model ...\n","90 0.36271703243255615 1.0 0.46966540813446045 0.9101123809814453 0.5194340944290161 0.9107611775398254\n","Validation loss decreased (0.469665 --> 0.469262).  Saving model ...\n","91 0.3620838522911072 1.0 0.46926209330558777 0.9101123809814453 0.5191583633422852 0.9107611775398254\n","Validation loss decreased (0.469262 --> 0.468866).  Saving model ...\n","92 0.3614639937877655 1.0 0.46886584162712097 0.9101123809814453 0.5188876986503601 0.9107611775398254\n","Validation loss decreased (0.468866 --> 0.468477).  Saving model ...\n","93 0.36085668206214905 1.0 0.46847689151763916 0.9101123809814453 0.5186214447021484 0.9107611775398254\n","Validation loss decreased (0.468477 --> 0.468094).  Saving model ...\n","94 0.36026203632354736 1.0 0.46809422969818115 0.9101123809814453 0.5183599591255188 0.9107611775398254\n","Validation loss decreased (0.468094 --> 0.467718).  Saving model ...\n","95 0.35967984795570374 1.0 0.4677182137966156 0.9101123809814453 0.5181017518043518 0.9107611775398254\n","Validation loss decreased (0.467718 --> 0.467348).  Saving model ...\n","96 0.3591092526912689 1.0 0.46734818816185 0.9101123809814453 0.5178478360176086 0.9107611775398254\n","Validation loss decreased (0.467348 --> 0.466984).  Saving model ...\n","97 0.35854992270469666 1.0 0.46698427200317383 0.9101123809814453 0.517597496509552 0.9107611775398254\n","Validation loss decreased (0.466984 --> 0.466626).  Saving model ...\n","98 0.3580017387866974 1.0 0.46662622690200806 0.9101123809814453 0.5173513293266296 0.9107611775398254\n","Validation loss decreased (0.466626 --> 0.466274).  Saving model ...\n","99 0.35746443271636963 1.0 0.466274231672287 0.9101123809814453 0.5171087384223938 0.9107611775398254\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"erpioWsYtaUa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607487709069,"user_tz":180,"elapsed":163556,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"4db8ec8d-0f40-4233-a4be-a2b31ca94ee6"},"source":["print(Precision(prediction, Y_train_tensor))\n","print(Precision(val_prediction, Y_valid_tensor))\n","print(Precision(test_prediction, Y_test_tensor))"],"execution_count":23,"outputs":[{"output_type":"stream","text":["[1.0, 1.0]\n","[0.951724112033844, 0.7272727489471436]\n","[0.9382715821266174, 0.7543859481811523]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Qu2e4Qh38lp4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607487709070,"user_tz":180,"elapsed":163553,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"d10861ae-78ba-410b-adbb-266a00d816ca"},"source":["print(Recall(prediction, Y_train_tensor))\n","print(Recall(val_prediction, Y_valid_tensor))\n","print(Recall(test_prediction, Y_test_tensor))"],"execution_count":24,"outputs":[{"output_type":"stream","text":["[1.0, 1.0]\n","[0.9387755393981934, 0.774193525314331]\n","[0.955974817276001, 0.682539701461792]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5IoA1jJGBW2Q","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607487709071,"user_tz":180,"elapsed":163549,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"4b0b7418-e5e7-45dc-88f6-bb763f39dd9b"},"source":["print(Accuracy(prediction, Y_train_tensor))\n","print(Accuracy(val_prediction, Y_valid_tensor))\n","print(Accuracy(test_prediction, Y_test_tensor))"],"execution_count":25,"outputs":[{"output_type":"stream","text":["1.0\n","0.9101123809814453\n","0.9107611775398254\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aq6D8MnVuSzC","executionInfo":{"status":"ok","timestamp":1607487709071,"user_tz":180,"elapsed":163547,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["with open('/content/drive/My Drive/Data Master/Prediction_BOW_RegressaoLogistica/test_prediction_split' + str(n_split), 'wb') as file:\n","    pickle.dump(test_prediction.detach().numpy(), file)"],"execution_count":26,"outputs":[]}]}