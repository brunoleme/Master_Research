{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of Split2.ipynb","provenance":[{"file_id":"1ly17dl3w8rGXAPtd1owJFslx4RVJE78c","timestamp":1592607825372},{"file_id":"1VIBcIIFR_YFlSguO_JGlnJbFzyAcT6YH","timestamp":1592464333044},{"file_id":"1dZvMRgPPkRVGa_4BZ1Tvoom_U4pjwmRX","timestamp":1592435543596},{"file_id":"12Sf257YUAwzmSXOlE3llOhi0N1YVUbM7","timestamp":1583376883298}],"collapsed_sections":[],"authorship_tag":"ABX9TyPTUn6/oLXKURAfczd7gcNe"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"JQrQmaLj0UuZ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593324161167,"user_tz":180,"elapsed":1205,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"da779318-04e4-41bf-b579-173950665949"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JjEPtibx-EJD","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593324161569,"user_tz":180,"elapsed":1599,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["import numpy as np\n","import torch\n","\n","class EarlyStopping:\n","    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n","    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt'):\n","        \"\"\"\n","        Args:\n","            patience (int): How long to wait after last time validation loss improved.\n","                            Default: 7\n","            verbose (bool): If True, prints a message for each validation loss improvement. \n","                            Default: False\n","            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n","                            Default: 0\n","            path (str): Path for the checkpoint to be saved to.\n","                            Default: 'checkpoint.pt'\n","        \"\"\"\n","        self.patience = patience\n","        self.verbose = verbose\n","        self.counter = 0\n","        self.best_score = None\n","        self.early_stop = False\n","        self.val_loss_min = np.Inf\n","        self.delta = delta\n","        self.path = path\n","\n","    def __call__(self, val_loss, model):\n","\n","        score = -val_loss\n","\n","        if self.best_score is None:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model)\n","        elif score < self.best_score + self.delta:\n","            self.counter += 1\n","            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n","            if self.counter >= self.patience:\n","                self.early_stop = True\n","        else:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model)\n","            self.counter = 0\n","\n","    def save_checkpoint(self, val_loss, model):\n","        '''Saves model when validation loss decrease.'''\n","        if self.verbose:\n","            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n","        torch.save(model.state_dict(), self.path)\n","        self.val_loss_min = val_loss"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"tjGPuXgoqulz","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593324161569,"user_tz":180,"elapsed":1593,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["def Accuracy(prediction, observation):\n","  prediction = prediction[:,1]\n","  prediction_class = (torch.reshape(prediction, observation.shape) > 0.5).float()\n","  correct = (prediction_class == observation).float().sum()\n","  accuracy = correct/prediction_class.shape[0]\n","  return float(accuracy.cpu())\n","\n","def Precision(prediction, observation):\n","  prediction = prediction[:,1]\n","  res = []\n","  prediction_class = (torch.reshape(prediction, observation.shape) > 0.5).float()\n","  for label in [0, 1]:\n","    correct = (prediction_class[prediction_class == label] == observation[prediction_class == label]).float().sum()\n","    precision = correct/prediction_class[prediction_class == label].shape[0]\n","    res.append(float(precision.cpu()))\n","  return res\n","\n","def Recall(prediction, observation):\n","  prediction = prediction[:,1]\n","  res = []\n","  prediction_class = (torch.reshape(prediction, observation.shape) > 0.5).float()\n","  for label in [0, 1]:\n","    correct = (prediction_class[observation == label] == observation[observation == label]).float().sum()\n","    recall = correct/prediction_class[observation == label].shape[0]\n","    res.append(float(recall.cpu()))\n","  return res"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"sgz5Ea8a1wKr","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593324161959,"user_tz":180,"elapsed":1978,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["n_split = 2"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"cutkFU0k1Pkv","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593324161960,"user_tz":180,"elapsed":1974,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["import pickle\n","import pandas as pd\n","import numpy as np"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"wSJO5A951VXh","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593324163405,"user_tz":180,"elapsed":3414,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["with open('/content/drive/My Drive/Data Master/X_train_final', 'rb') as file:\n","    X_train = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/Y_train_final', 'rb') as file:\n","    Y_train = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/X_test_final', 'rb') as file:\n","    X_test = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/Y_test_final', 'rb') as file:\n","    Y_test = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/word_index_final', 'rb') as file:\n","    word_index = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/train_index_final_split_' + str(n_split), 'rb') as file:\n","    train_index = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/valid_index_final_split_' + str(n_split), 'rb') as file:\n","    valid_index = pickle.load(file)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"_v0BS5Cp_06s","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593324163406,"user_tz":180,"elapsed":3408,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["test_index = [i for i, _ in enumerate(X_test)]"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"NGqLg8IllrZE","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593324163407,"user_tz":180,"elapsed":3404,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["inv_word_index = {ix : w for w, ix in word_index.items()}"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"1-2YPzNN1x5T","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593324168004,"user_tz":180,"elapsed":7996,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["import itertools\n","features_index = {w:ix for ix, w in enumerate(np.unique(list(itertools.chain.from_iterable(np.array(X_train)[train_index]))))}\n","inv_features_index = {ix:w for ix, w in enumerate(np.unique(list(itertools.chain.from_iterable(np.array(X_train)[train_index]))))}"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"RxZWUTIv4K5T","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593324169926,"user_tz":180,"elapsed":9912,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["X_train_matrix = np.zeros((len(X_train), len(features_index)))\n","X_test_matrix = np.zeros((len(X_test), len(features_index)))"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"K6KzJuIy4dN8","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593324193197,"user_tz":180,"elapsed":33178,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["for i, x in enumerate(X_train):\n","  for w in x:\n","    if w in features_index:\n","      X_train_matrix[i,features_index[w]] += 1\n","\n","for i, x in enumerate(X_test):\n","  for w in x:\n","    if w in features_index:\n","      X_test_matrix[i,features_index[w]] += 1"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"9d4attfQ0i-Q","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593324193197,"user_tz":180,"elapsed":33174,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"twcFT-Hl3fqP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593324193198,"user_tz":180,"elapsed":33169,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"d1f90579-0ffc-4e92-9dbc-fa55eb51188d"},"source":["input_dim = X_train_matrix.shape[1]\n","input_dim"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["248563"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"9fbXl191nZhK","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593324193199,"user_tz":180,"elapsed":33164,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["class LogisticRegression (nn.Module):\n","\n","  def __init__(self):\n","    super(LogisticRegression, self).__init__()\n","\n","    self.fc1 = nn.Linear(input_dim, 2)\n","                                \n","    self.softmax = nn.Softmax(dim=1)\n","\n","  def forward(self, x):\n","    x = F.normalize(x)\n","    y = self.softmax(self.fc1(x))\n","\n","    return y"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"Cgzf7IEqnyN4","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593324193199,"user_tz":180,"elapsed":33159,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["model = LogisticRegression()"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"0rnUcqchBE91","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593324195147,"user_tz":180,"elapsed":35102,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["X_train_tensor = torch.from_numpy(X_train_matrix[train_index]).float()\n","Y_train_tensor = torch.LongTensor(np.array(Y_train[train_index]))\n","\n","X_valid_tensor = torch.from_numpy(X_train_matrix[valid_index]).float()\n","Y_valid_tensor = torch.LongTensor(np.array(Y_train[valid_index]))\n","\n","X_test_tensor = torch.from_numpy(X_test_matrix).float()\n","Y_test_tensor = torch.LongTensor(np.array(Y_test))"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"GlP5dzFET5tF","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593324195148,"user_tz":180,"elapsed":35099,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["torch.manual_seed(0)\n","np.random.seed(0)"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"SV0Da5qu98-C","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593324195149,"user_tz":180,"elapsed":35095,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["import torch.optim as optim\n","optimizer = optim.AdamW(model.parameters(), lr=0.01)"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"gHujp4Ww_ZuO","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593324195149,"user_tz":180,"elapsed":35089,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["from torch.optim.lr_scheduler import ReduceLROnPlateau\n","scheduler = ReduceLROnPlateau(optimizer, 'min')"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"qkfeoTBHRuOb","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593324195150,"user_tz":180,"elapsed":35085,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"0cf5bece-8fca-4a67-9d6f-6e7f03731403"},"source":["weights = [sum(Y_train)/len(Y_train), 1-sum(Y_train)/len(Y_train)]\n","class_weights = torch.FloatTensor(weights)\n","class_weights"],"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0.1734, 0.8266])"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"8-F96WAE98zI","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593324195151,"user_tz":180,"elapsed":35080,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["criterion = nn.CrossEntropyLoss(weight=class_weights)"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"E7KgiIq398rR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1593324325034,"user_tz":180,"elapsed":164958,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"7b8a54ce-5728-4da6-9953-9b5cc8326e33"},"source":["patience = 20\n","early_stopping = EarlyStopping(patience=patience, verbose=True)\n","\n","for i in range(100):\n","  model.train()\n","  optimizer.zero_grad()\n","  prediction = model(X_train_tensor)\n","  loss = criterion(prediction, Y_train_tensor)\n","  loss.backward()\n","  optimizer.step()\n","\n","  accuracy = Accuracy(prediction, Y_train_tensor)\n","\n","  model.eval()\n","\n","  val_prediction = model(X_valid_tensor)\n","  test_prediction = model(X_test_tensor)\n","  val_loss = criterion(val_prediction, Y_valid_tensor)\n","  test_loss = criterion(test_prediction, Y_test_tensor)\n","\n","  val_accuracy = Accuracy(val_prediction, Y_valid_tensor)\n","  test_accuracy = Accuracy(test_prediction, Y_test_tensor)\n","\n","  early_stopping(val_loss, model)\n","\n","  if early_stopping.early_stop:\n","    print(\"Early stopping\")\n","    break\n","\n","  print(i, float(loss.cpu()), accuracy, float(val_loss.cpu()), val_accuracy, float(test_loss.cpu()), test_accuracy)\n","\n","  scheduler.step(val_loss)\n","\n","model.load_state_dict(torch.load('checkpoint.pt'))"],"execution_count":22,"outputs":[{"output_type":"stream","text":["Validation loss decreased (inf --> 0.684774).  Saving model ...\n","0 0.6931463479995728 0.8267605900764465 0.6847744584083557 0.915730357170105 0.6864333152770996 0.9028871655464172\n","Validation loss decreased (0.684774 --> 0.676549).  Saving model ...\n","1 0.6807453632354736 0.9647887349128723 0.6765491366386414 0.9101123809814453 0.6799028515815735 0.8976377844810486\n","Validation loss decreased (0.676549 --> 0.668484).  Saving model ...\n","2 0.6685779094696045 0.9633802771568298 0.6684841513633728 0.915730357170105 0.6735154986381531 0.8923884630203247\n","Validation loss decreased (0.668484 --> 0.660593).  Saving model ...\n","3 0.6566711664199829 0.9647887349128723 0.6605931520462036 0.915730357170105 0.6672776341438293 0.8897637724876404\n","Validation loss decreased (0.660593 --> 0.652889).  Saving model ...\n","4 0.6450502872467041 0.9647887349128723 0.6528887152671814 0.915730357170105 0.6611995697021484 0.8897637724876404\n","Validation loss decreased (0.652889 --> 0.645381).  Saving model ...\n","5 0.6337361335754395 0.9647887349128723 0.6453810334205627 0.915730357170105 0.6552926301956177 0.8897637724876404\n","Validation loss decreased (0.645381 --> 0.638079).  Saving model ...\n","6 0.6227492094039917 0.9647887349128723 0.638079047203064 0.915730357170105 0.6495636105537415 0.8897637724876404\n","Validation loss decreased (0.638079 --> 0.630992).  Saving model ...\n","7 0.612102210521698 0.9647887349128723 0.6309919357299805 0.915730357170105 0.6440173983573914 0.8897637724876404\n","Validation loss decreased (0.630992 --> 0.624126).  Saving model ...\n","8 0.6018090844154358 0.9661971926689148 0.6241263151168823 0.915730357170105 0.6386566758155823 0.8897637724876404\n","Validation loss decreased (0.624126 --> 0.617488).  Saving model ...\n","9 0.5918766260147095 0.9661971926689148 0.6174879670143127 0.915730357170105 0.6334826350212097 0.8897637724876404\n","Validation loss decreased (0.617488 --> 0.611084).  Saving model ...\n","10 0.5823105573654175 0.9661971926689148 0.6110837459564209 0.915730357170105 0.6284947991371155 0.8897637724876404\n","Validation loss decreased (0.611084 --> 0.604917).  Saving model ...\n","11 0.5731125473976135 0.9661971926689148 0.6049171090126038 0.915730357170105 0.623692512512207 0.8897637724876404\n","Validation loss decreased (0.604917 --> 0.598988).  Saving model ...\n","12 0.5642818212509155 0.9661971926689148 0.5989883542060852 0.915730357170105 0.6190722584724426 0.8897637724876404\n","Validation loss decreased (0.598988 --> 0.593297).  Saving model ...\n","13 0.5558152198791504 0.9661971926689148 0.5932971239089966 0.915730357170105 0.6146320700645447 0.8897637724876404\n","Validation loss decreased (0.593297 --> 0.587844).  Saving model ...\n","14 0.5477070212364197 0.9676056504249573 0.587843656539917 0.915730357170105 0.6103681325912476 0.8923884630203247\n","Validation loss decreased (0.587844 --> 0.582624).  Saving model ...\n","15 0.5399492979049683 0.9676056504249573 0.5826237797737122 0.915730357170105 0.606277585029602 0.8923884630203247\n","Validation loss decreased (0.582624 --> 0.577633).  Saving model ...\n","16 0.5325339436531067 0.9676056504249573 0.5776334404945374 0.915730357170105 0.602354884147644 0.8923884630203247\n","Validation loss decreased (0.577633 --> 0.572867).  Saving model ...\n","17 0.5254490375518799 0.9676056504249573 0.5728669166564941 0.915730357170105 0.5985952019691467 0.8923884630203247\n","Validation loss decreased (0.572867 --> 0.568320).  Saving model ...\n","18 0.5186843276023865 0.9676056504249573 0.5683200359344482 0.915730357170105 0.5949949026107788 0.8923884630203247\n","Validation loss decreased (0.568320 --> 0.563986).  Saving model ...\n","19 0.5122270584106445 0.9676056504249573 0.5639856457710266 0.915730357170105 0.5915488600730896 0.8923884630203247\n","Validation loss decreased (0.563986 --> 0.559856).  Saving model ...\n","20 0.5060653686523438 0.9676056504249573 0.5598562359809875 0.915730357170105 0.5882500410079956 0.8923884630203247\n","Validation loss decreased (0.559856 --> 0.555925).  Saving model ...\n","21 0.5001857876777649 0.9676056504249573 0.5559250116348267 0.915730357170105 0.5850949287414551 0.8897637724876404\n","Validation loss decreased (0.555925 --> 0.552185).  Saving model ...\n","22 0.494576096534729 0.9690141081809998 0.5521847605705261 0.915730357170105 0.5820775628089905 0.8897637724876404\n","Validation loss decreased (0.552185 --> 0.548627).  Saving model ...\n","23 0.4892226755619049 0.9704225063323975 0.548627495765686 0.915730357170105 0.5791927576065063 0.8897637724876404\n","Validation loss decreased (0.548627 --> 0.545245).  Saving model ...\n","24 0.48411324620246887 0.9718309640884399 0.5452446937561035 0.915730357170105 0.576433539390564 0.8897637724876404\n","Validation loss decreased (0.545245 --> 0.542029).  Saving model ...\n","25 0.4792349934577942 0.9732394218444824 0.5420291423797607 0.915730357170105 0.5737957954406738 0.8897637724876404\n","Validation loss decreased (0.542029 --> 0.538973).  Saving model ...\n","26 0.474576473236084 0.9732394218444824 0.5389730930328369 0.915730357170105 0.5712738633155823 0.8897637724876404\n","Validation loss decreased (0.538973 --> 0.536069).  Saving model ...\n","27 0.4701255261898041 0.9732394218444824 0.5360686779022217 0.915730357170105 0.5688639879226685 0.8923884630203247\n","Validation loss decreased (0.536069 --> 0.533308).  Saving model ...\n","28 0.4658719003200531 0.9732394218444824 0.533308207988739 0.915730357170105 0.566558837890625 0.8923884630203247\n","Validation loss decreased (0.533308 --> 0.530685).  Saving model ...\n","29 0.4618038237094879 0.9746478796005249 0.5306847095489502 0.915730357170105 0.5643545389175415 0.8923884630203247\n","Validation loss decreased (0.530685 --> 0.528191).  Saving model ...\n","30 0.45791181921958923 0.9746478796005249 0.528191089630127 0.915730357170105 0.5622465014457703 0.8923884630203247\n","Validation loss decreased (0.528191 --> 0.525820).  Saving model ...\n","31 0.4541863799095154 0.9760563373565674 0.5258203744888306 0.915730357170105 0.5602304339408875 0.8923884630203247\n","Validation loss decreased (0.525820 --> 0.523566).  Saving model ...\n","32 0.45061758160591125 0.9760563373565674 0.5235655307769775 0.915730357170105 0.5583009123802185 0.8923884630203247\n","Validation loss decreased (0.523566 --> 0.521421).  Saving model ...\n","33 0.4471977651119232 0.9760563373565674 0.5214207172393799 0.915730357170105 0.5564542412757874 0.8923884630203247\n","Validation loss decreased (0.521421 --> 0.519380).  Saving model ...\n","34 0.4439179599285126 0.9774647951126099 0.5193801522254944 0.915730357170105 0.5546871423721313 0.8923884630203247\n","Validation loss decreased (0.519380 --> 0.517438).  Saving model ...\n","35 0.44077175855636597 0.9788732528686523 0.5174380540847778 0.9269663095474243 0.5529953241348267 0.8923884630203247\n","Validation loss decreased (0.517438 --> 0.515588).  Saving model ...\n","36 0.43775057792663574 0.9788732528686523 0.5155883431434631 0.9269663095474243 0.5513746738433838 0.8923884630203247\n","Validation loss decreased (0.515588 --> 0.513826).  Saving model ...\n","37 0.4348488450050354 0.9788732528686523 0.5138258934020996 0.9269663095474243 0.5498223900794983 0.8923884630203247\n","Validation loss decreased (0.513826 --> 0.512147).  Saving model ...\n","38 0.43205952644348145 0.9802817106246948 0.5121467113494873 0.9269663095474243 0.5483346581459045 0.8923884630203247\n","Validation loss decreased (0.512147 --> 0.510545).  Saving model ...\n","39 0.4293771982192993 0.9802817106246948 0.5105451941490173 0.9269663095474243 0.546908974647522 0.8950130939483643\n","Validation loss decreased (0.510545 --> 0.509017).  Saving model ...\n","40 0.42679548263549805 0.9816901683807373 0.5090168714523315 0.9269663095474243 0.545541524887085 0.8950130939483643\n","Validation loss decreased (0.509017 --> 0.507558).  Saving model ...\n","41 0.42431002855300903 0.9816901683807373 0.5075578093528748 0.9269663095474243 0.5442298650741577 0.8950130939483643\n","Validation loss decreased (0.507558 --> 0.506164).  Saving model ...\n","42 0.42191556096076965 0.983098566532135 0.5061642527580261 0.9269663095474243 0.5429713726043701 0.8976377844810486\n","Validation loss decreased (0.506164 --> 0.504832).  Saving model ...\n","43 0.4196075201034546 0.9845070242881775 0.5048319101333618 0.9269663095474243 0.5417634844779968 0.8976377844810486\n","Validation loss decreased (0.504832 --> 0.503557).  Saving model ...\n","44 0.4173816442489624 0.9845070242881775 0.5035572052001953 0.9269663095474243 0.5406031608581543 0.8976377844810486\n","Validation loss decreased (0.503557 --> 0.502337).  Saving model ...\n","45 0.4152340888977051 0.9845070242881775 0.5023368000984192 0.9269663095474243 0.539488673210144 0.9002624750137329\n","Validation loss decreased (0.502337 --> 0.501168).  Saving model ...\n","46 0.4131607115268707 0.98591548204422 0.5011679530143738 0.9269663095474243 0.538418173789978 0.9002624750137329\n","Validation loss decreased (0.501168 --> 0.500047).  Saving model ...\n","47 0.4111577868461609 0.98591548204422 0.5000473260879517 0.9269663095474243 0.5373885035514832 0.9055117964744568\n","Validation loss decreased (0.500047 --> 0.498972).  Saving model ...\n","48 0.40922242403030396 0.98591548204422 0.49897176027297974 0.9269663095474243 0.5363982915878296 0.9055117964744568\n","Validation loss decreased (0.498972 --> 0.497939).  Saving model ...\n","49 0.4073512554168701 0.98591548204422 0.49793893098831177 0.9269663095474243 0.5354456305503845 0.9081364870071411\n","Validation loss decreased (0.497939 --> 0.496946).  Saving model ...\n","50 0.405541330575943 0.98591548204422 0.4969463050365448 0.9269663095474243 0.534528374671936 0.9081364870071411\n","Validation loss decreased (0.496946 --> 0.495991).  Saving model ...\n","51 0.40378978848457336 0.98591548204422 0.4959914982318878 0.9269663095474243 0.5336451530456543 0.9081364870071411\n","Validation loss decreased (0.495991 --> 0.495072).  Saving model ...\n","52 0.40209370851516724 0.9873239398002625 0.4950718879699707 0.9269663095474243 0.5327939987182617 0.9107611775398254\n","Validation loss decreased (0.495072 --> 0.494186).  Saving model ...\n","53 0.40045079588890076 0.9873239398002625 0.49418607354164124 0.9269663095474243 0.5319736003875732 0.9107611775398254\n","Validation loss decreased (0.494186 --> 0.493332).  Saving model ...\n","54 0.3988591134548187 0.9873239398002625 0.4933316707611084 0.9269663095474243 0.5311825275421143 0.9107611775398254\n","Validation loss decreased (0.493332 --> 0.492507).  Saving model ...\n","55 0.3973156809806824 0.9873239398002625 0.4925069808959961 0.9269663095474243 0.5304193496704102 0.9107611775398254\n","Validation loss decreased (0.492507 --> 0.491710).  Saving model ...\n","56 0.3958185017108917 0.98591548204422 0.4917100965976715 0.9269663095474243 0.5296821594238281 0.913385808467865\n","Validation loss decreased (0.491710 --> 0.490940).  Saving model ...\n","57 0.3943665325641632 0.98591548204422 0.49093982577323914 0.9269663095474243 0.5289704203605652 0.9160104990005493\n","Validation loss decreased (0.490940 --> 0.490194).  Saving model ...\n","58 0.392956405878067 0.9873239398002625 0.49019408226013184 0.9269663095474243 0.5282829999923706 0.9160104990005493\n","Validation loss decreased (0.490194 --> 0.489472).  Saving model ...\n","59 0.39158695936203003 0.9887323975563049 0.48947224020957947 0.9269663095474243 0.5276181101799011 0.9160104990005493\n","Validation loss decreased (0.489472 --> 0.488772).  Saving model ...\n","60 0.3902570903301239 0.9887323975563049 0.48877227306365967 0.9269663095474243 0.5269754528999329 0.9160104990005493\n","Validation loss decreased (0.488772 --> 0.488094).  Saving model ...\n","61 0.3889642357826233 0.9901408553123474 0.4880935847759247 0.9269663095474243 0.5263534784317017 0.9160104990005493\n","Validation loss decreased (0.488094 --> 0.487435).  Saving model ...\n","62 0.38770726323127747 0.9915493130683899 0.4874347746372223 0.9269663095474243 0.5257513523101807 0.9160104990005493\n","Validation loss decreased (0.487435 --> 0.486795).  Saving model ...\n","63 0.3864850699901581 0.9915493130683899 0.4867945611476898 0.9269663095474243 0.5251681208610535 0.9160104990005493\n","Validation loss decreased (0.486795 --> 0.486172).  Saving model ...\n","64 0.3852955102920532 0.9915493130683899 0.48617246747016907 0.9269663095474243 0.5246031880378723 0.9160104990005493\n","Validation loss decreased (0.486172 --> 0.485567).  Saving model ...\n","65 0.3841383457183838 0.9915493130683899 0.4855671226978302 0.9269663095474243 0.5240557193756104 0.9186351895332336\n","Validation loss decreased (0.485567 --> 0.484978).  Saving model ...\n","66 0.3830110728740692 0.9915493130683899 0.484978049993515 0.9269663095474243 0.5235245823860168 0.9186351895332336\n","Validation loss decreased (0.484978 --> 0.484404).  Saving model ...\n","67 0.3819136619567871 0.9915493130683899 0.4844043254852295 0.9269663095474243 0.5230094790458679 0.9186351895332336\n","Validation loss decreased (0.484404 --> 0.483845).  Saving model ...\n","68 0.3808443248271942 0.9929577708244324 0.48384514451026917 0.9269663095474243 0.5225086808204651 0.9186351895332336\n","Validation loss decreased (0.483845 --> 0.483300).  Saving model ...\n","69 0.37980207800865173 0.9929577708244324 0.48329994082450867 0.9269663095474243 0.5220226049423218 0.9186351895332336\n","Validation loss decreased (0.483300 --> 0.482768).  Saving model ...\n","70 0.3787863850593567 0.9929577708244324 0.48276808857917786 0.9269663095474243 0.5215509533882141 0.9186351895332336\n","Validation loss decreased (0.482768 --> 0.482249).  Saving model ...\n","71 0.3777962028980255 0.9929577708244324 0.48224887251853943 0.9269663095474243 0.5210918188095093 0.9186351895332336\n","Validation loss decreased (0.482249 --> 0.481742).  Saving model ...\n","72 0.37682995200157166 0.9929577708244324 0.481741726398468 0.9269663095474243 0.5206454396247864 0.9186351895332336\n","Validation loss decreased (0.481742 --> 0.481246).  Saving model ...\n","73 0.375887393951416 0.9929577708244324 0.4812464118003845 0.9269663095474243 0.5202112197875977 0.9186351895332336\n","Validation loss decreased (0.481246 --> 0.480762).  Saving model ...\n","74 0.37496745586395264 0.9929577708244324 0.48076221346855164 0.9269663095474243 0.5197889804840088 0.9212598204612732\n","Validation loss decreased (0.480762 --> 0.480289).  Saving model ...\n","75 0.3740696310997009 0.9943661689758301 0.48028889298439026 0.9269663095474243 0.5193772912025452 0.9212598204612732\n","Validation loss decreased (0.480289 --> 0.479826).  Saving model ...\n","76 0.3731929659843445 0.9943661689758301 0.4798256456851959 0.9269663095474243 0.5189765691757202 0.9212598204612732\n","Validation loss decreased (0.479826 --> 0.479373).  Saving model ...\n","77 0.3723369538784027 0.9957746267318726 0.47937268018722534 0.9269663095474243 0.5185854434967041 0.9212598204612732\n","Validation loss decreased (0.479373 --> 0.478929).  Saving model ...\n","78 0.3715004324913025 0.9957746267318726 0.4789290726184845 0.9269663095474243 0.5182046294212341 0.9212598204612732\n","Validation loss decreased (0.478929 --> 0.478495).  Saving model ...\n","79 0.3706831932067871 0.9957746267318726 0.478494793176651 0.9269663095474243 0.5178328156471252 0.9212598204612732\n","Validation loss decreased (0.478495 --> 0.478070).  Saving model ...\n","80 0.36988475918769836 0.9957746267318726 0.4780695140361786 0.9269663095474243 0.5174700021743774 0.9212598204612732\n","Validation loss decreased (0.478070 --> 0.477653).  Saving model ...\n","81 0.36910438537597656 0.9957746267318726 0.4776528775691986 0.9269663095474243 0.5171158313751221 0.9212598204612732\n","Validation loss decreased (0.477653 --> 0.477245).  Saving model ...\n","82 0.3683408200740814 0.9957746267318726 0.4772445261478424 0.9269663095474243 0.5167699456214905 0.9212598204612732\n","Validation loss decreased (0.477245 --> 0.476844).  Saving model ...\n","83 0.3675945997238159 0.9957746267318726 0.47684434056282043 0.9269663095474243 0.5164315700531006 0.9212598204612732\n","Validation loss decreased (0.476844 --> 0.476452).  Saving model ...\n","84 0.36686423420906067 0.9957746267318726 0.4764523208141327 0.9269663095474243 0.5161011219024658 0.9212598204612732\n","Validation loss decreased (0.476452 --> 0.476068).  Saving model ...\n","85 0.36615025997161865 0.997183084487915 0.47606751322746277 0.9269663095474243 0.5157778263092041 0.9212598204612732\n","Validation loss decreased (0.476068 --> 0.475690).  Saving model ...\n","86 0.3654515743255615 0.997183084487915 0.475690096616745 0.9269663095474243 0.515461802482605 0.9212598204612732\n","Validation loss decreased (0.475690 --> 0.475320).  Saving model ...\n","87 0.3647676706314087 0.997183084487915 0.4753202199935913 0.9269663095474243 0.515152096748352 0.9212598204612732\n","Validation loss decreased (0.475320 --> 0.474957).  Saving model ...\n","88 0.3640982508659363 0.997183084487915 0.47495734691619873 0.9269663095474243 0.5148488879203796 0.9212598204612732\n","Validation loss decreased (0.474957 --> 0.474601).  Saving model ...\n","89 0.3634432554244995 0.997183084487915 0.47460097074508667 0.9269663095474243 0.5145518779754639 0.9212598204612732\n","Validation loss decreased (0.474601 --> 0.474251).  Saving model ...\n","90 0.36280184984207153 0.997183084487915 0.4742513597011566 0.9269663095474243 0.5142608284950256 0.9212598204612732\n","Validation loss decreased (0.474251 --> 0.473908).  Saving model ...\n","91 0.3621734082698822 0.997183084487915 0.47390830516815186 0.9269663095474243 0.5139755606651306 0.9212598204612732\n","Validation loss decreased (0.473908 --> 0.473572).  Saving model ...\n","92 0.361558198928833 0.997183084487915 0.4735715687274933 0.9269663095474243 0.5136955380439758 0.9212598204612732\n","Validation loss decreased (0.473572 --> 0.473241).  Saving model ...\n","93 0.36095523834228516 0.997183084487915 0.47324085235595703 0.9269663095474243 0.5134211778640747 0.9212598204612732\n","Validation loss decreased (0.473241 --> 0.472917).  Saving model ...\n","94 0.36036473512649536 0.997183084487915 0.4729165732860565 0.9269663095474243 0.5131515264511108 0.9212598204612732\n","Validation loss decreased (0.472917 --> 0.472597).  Saving model ...\n","95 0.35978594422340393 0.997183084487915 0.4725974202156067 0.9269663095474243 0.5128871202468872 0.9238845109939575\n","Validation loss decreased (0.472597 --> 0.472285).  Saving model ...\n","96 0.35921865701675415 0.997183084487915 0.4722845256328583 0.9269663095474243 0.512627124786377 0.9238845109939575\n","Validation loss decreased (0.472285 --> 0.471977).  Saving model ...\n","97 0.3586631119251251 0.997183084487915 0.47197675704956055 0.9269663095474243 0.5123714804649353 0.9238845109939575\n","Validation loss decreased (0.471977 --> 0.471675).  Saving model ...\n","98 0.3581179082393646 0.997183084487915 0.4716746211051941 0.9269663095474243 0.5121203660964966 0.9238845109939575\n","Validation loss decreased (0.471675 --> 0.471378).  Saving model ...\n","99 0.357583612203598 0.997183084487915 0.4713781774044037 0.9269663095474243 0.5118737816810608 0.9238845109939575\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"erpioWsYtaUa","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"executionInfo":{"status":"ok","timestamp":1593324325035,"user_tz":180,"elapsed":164953,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"30bf46e3-1ab7-423a-fbde-4e561f1fadee"},"source":["print(Precision(prediction, Y_train_tensor))\n","print(Precision(val_prediction, Y_valid_tensor))\n","print(Precision(test_prediction, Y_test_tensor))"],"execution_count":23,"outputs":[{"output_type":"stream","text":["[1.0, 0.984000027179718]\n","[0.9589040875434875, 0.78125]\n","[0.9418960213661194, 0.8148148059844971]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Qu2e4Qh38lp4","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"executionInfo":{"status":"ok","timestamp":1593324325036,"user_tz":180,"elapsed":164949,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"cf1d75e2-393b-4719-c6b1-6d29b299ae69"},"source":["print(Recall(prediction, Y_train_tensor))\n","print(Recall(val_prediction, Y_valid_tensor))\n","print(Recall(test_prediction, Y_test_tensor))"],"execution_count":24,"outputs":[{"output_type":"stream","text":["[0.9965928196907043, 1.0]\n","[0.9523809552192688, 0.8064516186714172]\n","[0.9685534834861755, 0.6984127163887024]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5IoA1jJGBW2Q","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"executionInfo":{"status":"ok","timestamp":1593324325036,"user_tz":180,"elapsed":164943,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"a4578b8a-ee37-4506-c652-9c0a00dfbfb1"},"source":["print(Accuracy(prediction, Y_train_tensor))\n","print(Accuracy(val_prediction, Y_valid_tensor))\n","print(Accuracy(test_prediction, Y_test_tensor))"],"execution_count":25,"outputs":[{"output_type":"stream","text":["0.997183084487915\n","0.9269663095474243\n","0.9238845109939575\n"],"name":"stdout"}]}]}