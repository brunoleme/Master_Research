{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Split3.ipynb","provenance":[{"file_id":"1ly17dl3w8rGXAPtd1owJFslx4RVJE78c","timestamp":1592607825372},{"file_id":"1VIBcIIFR_YFlSguO_JGlnJbFzyAcT6YH","timestamp":1592464333044},{"file_id":"1dZvMRgPPkRVGa_4BZ1Tvoom_U4pjwmRX","timestamp":1592435543596},{"file_id":"12Sf257YUAwzmSXOlE3llOhi0N1YVUbM7","timestamp":1583376883298}],"collapsed_sections":[],"authorship_tag":"ABX9TyMgFncSMj1SDiRQ5ry9jFjb"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"JQrQmaLj0UuZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607487112000,"user_tz":180,"elapsed":22314,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"cecce494-6f44-4631-f628-cbc46c5faf9d"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JjEPtibx-EJD","executionInfo":{"status":"ok","timestamp":1607487114649,"user_tz":180,"elapsed":24959,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["import numpy as np\n","import torch\n","\n","class EarlyStopping:\n","    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n","    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt'):\n","        \"\"\"\n","        Args:\n","            patience (int): How long to wait after last time validation loss improved.\n","                            Default: 7\n","            verbose (bool): If True, prints a message for each validation loss improvement. \n","                            Default: False\n","            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n","                            Default: 0\n","            path (str): Path for the checkpoint to be saved to.\n","                            Default: 'checkpoint.pt'\n","        \"\"\"\n","        self.patience = patience\n","        self.verbose = verbose\n","        self.counter = 0\n","        self.best_score = None\n","        self.early_stop = False\n","        self.val_loss_min = np.Inf\n","        self.delta = delta\n","        self.path = path\n","\n","    def __call__(self, val_loss, model):\n","\n","        score = -val_loss\n","\n","        if self.best_score is None:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model)\n","        elif score < self.best_score + self.delta:\n","            self.counter += 1\n","            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n","            if self.counter >= self.patience:\n","                self.early_stop = True\n","        else:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model)\n","            self.counter = 0\n","\n","    def save_checkpoint(self, val_loss, model):\n","        '''Saves model when validation loss decrease.'''\n","        if self.verbose:\n","            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n","        torch.save(model.state_dict(), self.path)\n","        self.val_loss_min = val_loss"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"tjGPuXgoqulz","executionInfo":{"status":"ok","timestamp":1607487114650,"user_tz":180,"elapsed":24958,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["def Accuracy(prediction, observation):\n","  prediction = prediction[:,1]\n","  prediction_class = (torch.reshape(prediction, observation.shape) > 0.5).float()\n","  correct = (prediction_class == observation).float().sum()\n","  accuracy = correct/prediction_class.shape[0]\n","  return float(accuracy.cpu())\n","\n","def Precision(prediction, observation):\n","  prediction = prediction[:,1]\n","  res = []\n","  prediction_class = (torch.reshape(prediction, observation.shape) > 0.5).float()\n","  for label in [0, 1]:\n","    correct = (prediction_class[prediction_class == label] == observation[prediction_class == label]).float().sum()\n","    precision = correct/prediction_class[prediction_class == label].shape[0]\n","    res.append(float(precision.cpu()))\n","  return res\n","\n","def Recall(prediction, observation):\n","  prediction = prediction[:,1]\n","  res = []\n","  prediction_class = (torch.reshape(prediction, observation.shape) > 0.5).float()\n","  for label in [0, 1]:\n","    correct = (prediction_class[observation == label] == observation[observation == label]).float().sum()\n","    recall = correct/prediction_class[observation == label].shape[0]\n","    res.append(float(recall.cpu()))\n","  return res"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"sgz5Ea8a1wKr","executionInfo":{"status":"ok","timestamp":1607487114650,"user_tz":180,"elapsed":24957,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["n_split = 3"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"cutkFU0k1Pkv","executionInfo":{"status":"ok","timestamp":1607487114651,"user_tz":180,"elapsed":24955,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["import pickle\n","import pandas as pd\n","import numpy as np"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"wSJO5A951VXh","executionInfo":{"status":"ok","timestamp":1607487118036,"user_tz":180,"elapsed":28338,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["with open('/content/drive/My Drive/Data Master/X_train_final', 'rb') as file:\n","    X_train = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/Y_train_final', 'rb') as file:\n","    Y_train = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/X_test_final', 'rb') as file:\n","    X_test = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/Y_test_final', 'rb') as file:\n","    Y_test = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/word_index_final', 'rb') as file:\n","    word_index = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/train_index_final_split_' + str(n_split), 'rb') as file:\n","    train_index = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/valid_index_final_split_' + str(n_split), 'rb') as file:\n","    valid_index = pickle.load(file)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"_v0BS5Cp_06s","executionInfo":{"status":"ok","timestamp":1607487118037,"user_tz":180,"elapsed":28337,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["test_index = [i for i, _ in enumerate(X_test)]"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"NGqLg8IllrZE","executionInfo":{"status":"ok","timestamp":1607487118037,"user_tz":180,"elapsed":28335,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["inv_word_index = {ix : w for w, ix in word_index.items()}"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"1-2YPzNN1x5T","executionInfo":{"status":"ok","timestamp":1607487122856,"user_tz":180,"elapsed":33153,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["import itertools\n","features_index = {w:ix for ix, w in enumerate(np.unique(list(itertools.chain.from_iterable(np.array(X_train)[train_index]))))}\n","inv_features_index = {ix:w for ix, w in enumerate(np.unique(list(itertools.chain.from_iterable(np.array(X_train)[train_index]))))}"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"RxZWUTIv4K5T","executionInfo":{"status":"ok","timestamp":1607487124441,"user_tz":180,"elapsed":34736,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["X_train_matrix = np.zeros((len(X_train), len(features_index)))\n","X_test_matrix = np.zeros((len(X_test), len(features_index)))"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"K6KzJuIy4dN8","executionInfo":{"status":"ok","timestamp":1607487142642,"user_tz":180,"elapsed":52935,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["for i, x in enumerate(X_train):\n","  for w in x:\n","    if w in features_index:\n","      X_train_matrix[i,features_index[w]] += 1\n","\n","for i, x in enumerate(X_test):\n","  for w in x:\n","    if w in features_index:\n","      X_test_matrix[i,features_index[w]] += 1"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"9d4attfQ0i-Q","executionInfo":{"status":"ok","timestamp":1607487142643,"user_tz":180,"elapsed":52935,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"twcFT-Hl3fqP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607487142643,"user_tz":180,"elapsed":52930,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"89469430-0f24-486e-afbf-a4cae2cde6db"},"source":["input_dim = X_train_matrix.shape[1]\n","input_dim"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["245166"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"9fbXl191nZhK","executionInfo":{"status":"ok","timestamp":1607487142644,"user_tz":180,"elapsed":52930,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["class LogisticRegression (nn.Module):\n","\n","  def __init__(self):\n","    super(LogisticRegression, self).__init__()\n","\n","    self.fc1 = nn.Linear(input_dim, 2)\n","                                \n","    self.softmax = nn.Softmax(dim=1)\n","\n","  def forward(self, x):\n","    x = F.normalize(x)\n","    y = self.softmax(self.fc1(x))\n","\n","    return y"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"Cgzf7IEqnyN4","executionInfo":{"status":"ok","timestamp":1607487142644,"user_tz":180,"elapsed":52928,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["model = LogisticRegression()"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"0rnUcqchBE91","executionInfo":{"status":"ok","timestamp":1607487144454,"user_tz":180,"elapsed":54736,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["X_train_tensor = torch.from_numpy(X_train_matrix[train_index]).float()\n","Y_train_tensor = torch.LongTensor(np.array(Y_train[train_index]))\n","\n","X_valid_tensor = torch.from_numpy(X_train_matrix[valid_index]).float()\n","Y_valid_tensor = torch.LongTensor(np.array(Y_train[valid_index]))\n","\n","X_test_tensor = torch.from_numpy(X_test_matrix).float()\n","Y_test_tensor = torch.LongTensor(np.array(Y_test))"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"GlP5dzFET5tF","executionInfo":{"status":"ok","timestamp":1607487144457,"user_tz":180,"elapsed":54737,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["torch.manual_seed(0)\n","np.random.seed(0)"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"SV0Da5qu98-C","executionInfo":{"status":"ok","timestamp":1607487144457,"user_tz":180,"elapsed":54735,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["import torch.optim as optim\n","optimizer = optim.AdamW(model.parameters(), lr=0.01)"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"gHujp4Ww_ZuO","executionInfo":{"status":"ok","timestamp":1607487144458,"user_tz":180,"elapsed":54734,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["from torch.optim.lr_scheduler import ReduceLROnPlateau\n","scheduler = ReduceLROnPlateau(optimizer, 'min')"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"qkfeoTBHRuOb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607487144458,"user_tz":180,"elapsed":54730,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"8f72373e-7724-45df-ff40-fdf9efc7462d"},"source":["weights = [sum(Y_train)/len(Y_train), 1-sum(Y_train)/len(Y_train)]\n","class_weights = torch.FloatTensor(weights)\n","class_weights"],"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0.1734, 0.8266])"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"8-F96WAE98zI","executionInfo":{"status":"ok","timestamp":1607487144459,"user_tz":180,"elapsed":54729,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["criterion = nn.CrossEntropyLoss(weight=class_weights)"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"E7KgiIq398rR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607487265620,"user_tz":180,"elapsed":175886,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"8bab7969-c563-4d26-8e7c-00913af0fabf"},"source":["patience = 20\n","early_stopping = EarlyStopping(patience=patience, verbose=True)\n","\n","for i in range(100):\n","  model.train()\n","  optimizer.zero_grad()\n","  prediction = model(X_train_tensor)\n","  loss = criterion(prediction, Y_train_tensor)\n","  loss.backward()\n","  optimizer.step()\n","\n","  accuracy = Accuracy(prediction, Y_train_tensor)\n","\n","  model.eval()\n","\n","  val_prediction = model(X_valid_tensor)\n","  test_prediction = model(X_test_tensor)\n","  val_loss = criterion(val_prediction, Y_valid_tensor)\n","  test_loss = criterion(test_prediction, Y_test_tensor)\n","\n","  val_accuracy = Accuracy(val_prediction, Y_valid_tensor)\n","  test_accuracy = Accuracy(test_prediction, Y_test_tensor)\n","\n","  early_stopping(val_loss, model)\n","\n","  if early_stopping.early_stop:\n","    print(\"Early stopping\")\n","    break\n","\n","  print(i, float(loss.cpu()), accuracy, float(val_loss.cpu()), val_accuracy, float(test_loss.cpu()), test_accuracy)\n","\n","  scheduler.step(val_loss)\n","\n","model.load_state_dict(torch.load('checkpoint.pt'))"],"execution_count":22,"outputs":[{"output_type":"stream","text":["Validation loss decreased (inf --> 0.685824).  Saving model ...\n","0 0.6931819915771484 0.8267605900764465 0.6858238577842712 0.915730357170105 0.6864386200904846 0.887139081954956\n","Validation loss decreased (0.685824 --> 0.678688).  Saving model ...\n","1 0.6805492043495178 0.9605633616447449 0.6786878108978271 0.9213483333587646 0.6797327399253845 0.913385808467865\n","Validation loss decreased (0.678688 --> 0.671679).  Saving model ...\n","2 0.6681944131851196 0.9704225063323975 0.6716789603233337 0.9101123809814453 0.6733528971672058 0.9081364870071411\n","Validation loss decreased (0.671679 --> 0.664808).  Saving model ...\n","3 0.6561005711555481 0.9661971926689148 0.6648080945014954 0.9044944047927856 0.6671581268310547 0.9028871655464172\n","Validation loss decreased (0.664808 --> 0.658083).  Saving model ...\n","4 0.644300103187561 0.9647887349128723 0.6580830216407776 0.9101123809814453 0.6611389517784119 0.8976377844810486\n","Validation loss decreased (0.658083 --> 0.651517).  Saving model ...\n","5 0.632817804813385 0.9647887349128723 0.6515166759490967 0.9213483333587646 0.6552920341491699 0.8950130939483643\n","Validation loss decreased (0.651517 --> 0.645126).  Saving model ...\n","6 0.6216763854026794 0.9647887349128723 0.6451258063316345 0.9213483333587646 0.6496209502220154 0.8950130939483643\n","Validation loss decreased (0.645126 --> 0.638928).  Saving model ...\n","7 0.610892653465271 0.9661971926689148 0.6389281153678894 0.9213483333587646 0.64412921667099 0.8897637724876404\n","Validation loss decreased (0.638928 --> 0.632940).  Saving model ...\n","8 0.6004799604415894 0.9647887349128723 0.6329396367073059 0.915730357170105 0.6388229131698608 0.887139081954956\n","Validation loss decreased (0.632940 --> 0.627173).  Saving model ...\n","9 0.5904451608657837 0.9647887349128723 0.6271725296974182 0.915730357170105 0.6337089538574219 0.887139081954956\n","Validation loss decreased (0.627173 --> 0.621633).  Saving model ...\n","10 0.5807914137840271 0.9647887349128723 0.6216331124305725 0.9213483333587646 0.6287936568260193 0.887139081954956\n","Validation loss decreased (0.621633 --> 0.616320).  Saving model ...\n","11 0.5715199112892151 0.9647887349128723 0.6163197159767151 0.9213483333587646 0.6240795850753784 0.8897637724876404\n","Validation loss decreased (0.616320 --> 0.611222).  Saving model ...\n","12 0.5626299977302551 0.9647887349128723 0.6112218499183655 0.9213483333587646 0.6195637583732605 0.8923884630203247\n","Validation loss decreased (0.611222 --> 0.606325).  Saving model ...\n","13 0.5541173219680786 0.9661971926689148 0.6063247323036194 0.9213483333587646 0.6152394413948059 0.8923884630203247\n","Validation loss decreased (0.606325 --> 0.601613).  Saving model ...\n","14 0.5459766983985901 0.9661971926689148 0.6016134023666382 0.9213483333587646 0.6110952496528625 0.8923884630203247\n","Validation loss decreased (0.601613 --> 0.597077).  Saving model ...\n","15 0.5381965637207031 0.9661971926689148 0.5970765948295593 0.9213483333587646 0.6071223020553589 0.8923884630203247\n","Validation loss decreased (0.597077 --> 0.592710).  Saving model ...\n","16 0.5307677984237671 0.9676056504249573 0.5927103757858276 0.9213483333587646 0.6033130288124084 0.8923884630203247\n","Validation loss decreased (0.592710 --> 0.588516).  Saving model ...\n","17 0.5236778855323792 0.9676056504249573 0.588516116142273 0.9213483333587646 0.5996642112731934 0.8897637724876404\n","Validation loss decreased (0.588516 --> 0.584500).  Saving model ...\n","18 0.5169148445129395 0.9676056504249573 0.5844996571540833 0.9213483333587646 0.5961739420890808 0.8923884630203247\n","Validation loss decreased (0.584500 --> 0.580667).  Saving model ...\n","19 0.5104662775993347 0.9690141081809998 0.5806667804718018 0.9213483333587646 0.5928421020507812 0.8923884630203247\n","Validation loss decreased (0.580667 --> 0.577021).  Saving model ...\n","20 0.5043182969093323 0.9704225063323975 0.5770211815834045 0.9213483333587646 0.589667022228241 0.8923884630203247\n","Validation loss decreased (0.577021 --> 0.573561).  Saving model ...\n","21 0.4984564781188965 0.9718309640884399 0.5735610723495483 0.9213483333587646 0.5866444110870361 0.8950130939483643\n","Validation loss decreased (0.573561 --> 0.570278).  Saving model ...\n","22 0.49286743998527527 0.9732394218444824 0.570277988910675 0.9213483333587646 0.5837684869766235 0.8950130939483643\n","Validation loss decreased (0.570278 --> 0.567158).  Saving model ...\n","23 0.4875369369983673 0.9746478796005249 0.5671582818031311 0.9213483333587646 0.5810282230377197 0.9002624750137329\n","Validation loss decreased (0.567158 --> 0.564186).  Saving model ...\n","24 0.4824526906013489 0.9760563373565674 0.564185619354248 0.9213483333587646 0.5784123539924622 0.9002624750137329\n","Validation loss decreased (0.564186 --> 0.561344).  Saving model ...\n","25 0.4776010811328888 0.9760563373565674 0.5613436102867126 0.9213483333587646 0.5759091973304749 0.9002624750137329\n","Validation loss decreased (0.561344 --> 0.558621).  Saving model ...\n","26 0.4729698896408081 0.9760563373565674 0.5586209297180176 0.9213483333587646 0.5735095143318176 0.9002624750137329\n","Validation loss decreased (0.558621 --> 0.556010).  Saving model ...\n","27 0.4685465097427368 0.9760563373565674 0.556009829044342 0.9213483333587646 0.5712067484855652 0.9028871655464172\n","Validation loss decreased (0.556010 --> 0.553510).  Saving model ...\n","28 0.46431973576545715 0.9774647951126099 0.553509533405304 0.9213483333587646 0.568996787071228 0.9028871655464172\n","Validation loss decreased (0.553510 --> 0.551121).  Saving model ...\n","29 0.4602785110473633 0.9788732528686523 0.5511208772659302 0.9213483333587646 0.5668799877166748 0.9055117964744568\n","Validation loss decreased (0.551121 --> 0.548847).  Saving model ...\n","30 0.45641231536865234 0.9788732528686523 0.5488473176956177 0.9213483333587646 0.5648552179336548 0.9055117964744568\n","Validation loss decreased (0.548847 --> 0.546691).  Saving model ...\n","31 0.45271167159080505 0.9788732528686523 0.5466905832290649 0.9213483333587646 0.5629225373268127 0.9055117964744568\n","Validation loss decreased (0.546691 --> 0.544649).  Saving model ...\n","32 0.44916772842407227 0.9788732528686523 0.5446491241455078 0.9213483333587646 0.5610790848731995 0.9055117964744568\n","Validation loss decreased (0.544649 --> 0.542717).  Saving model ...\n","33 0.4457698464393616 0.9802817106246948 0.5427168607711792 0.9213483333587646 0.5593209862709045 0.9055117964744568\n","Validation loss decreased (0.542717 --> 0.540885).  Saving model ...\n","34 0.4425120949745178 0.9802817106246948 0.540885329246521 0.9269663095474243 0.5576411485671997 0.9055117964744568\n","Validation loss decreased (0.540885 --> 0.539144).  Saving model ...\n","35 0.43938517570495605 0.983098566532135 0.5391436815261841 0.9269663095474243 0.5560336709022522 0.9055117964744568\n","Validation loss decreased (0.539144 --> 0.537481).  Saving model ...\n","36 0.4363827705383301 0.983098566532135 0.5374810695648193 0.9269663095474243 0.5544899702072144 0.9081364870071411\n","Validation loss decreased (0.537481 --> 0.535889).  Saving model ...\n","37 0.43349772691726685 0.983098566532135 0.5358889698982239 0.9269663095474243 0.5530038475990295 0.9081364870071411\n","Validation loss decreased (0.535889 --> 0.534362).  Saving model ...\n","38 0.4307234287261963 0.983098566532135 0.5343618988990784 0.9269663095474243 0.5515720844268799 0.9081364870071411\n","Validation loss decreased (0.534362 --> 0.532898).  Saving model ...\n","39 0.4280546009540558 0.9845070242881775 0.5328975319862366 0.9269663095474243 0.5501917600631714 0.9081364870071411\n","Validation loss decreased (0.532898 --> 0.531497).  Saving model ...\n","40 0.42548540234565735 0.9845070242881775 0.5314969420433044 0.9269663095474243 0.5488626956939697 0.9081364870071411\n","Validation loss decreased (0.531497 --> 0.530161).  Saving model ...\n","41 0.4230102002620697 0.9845070242881775 0.5301612019538879 0.9269663095474243 0.547585666179657 0.9081364870071411\n","Validation loss decreased (0.530161 --> 0.528892).  Saving model ...\n","42 0.420624703168869 0.9845070242881775 0.528891921043396 0.9269663095474243 0.5463610291481018 0.9081364870071411\n","Validation loss decreased (0.528892 --> 0.527689).  Saving model ...\n","43 0.41832444071769714 0.9845070242881775 0.5276890397071838 0.9269663095474243 0.5451878905296326 0.9081364870071411\n","Validation loss decreased (0.527689 --> 0.526551).  Saving model ...\n","44 0.41610461473464966 0.9845070242881775 0.5265508890151978 0.9269663095474243 0.544064998626709 0.9081364870071411\n","Validation loss decreased (0.526551 --> 0.525472).  Saving model ...\n","45 0.4139620065689087 0.9845070242881775 0.5254723429679871 0.9269663095474243 0.5429890751838684 0.9107611775398254\n","Validation loss decreased (0.525472 --> 0.524448).  Saving model ...\n","46 0.4118921160697937 0.9887323975563049 0.5244479775428772 0.9269663095474243 0.54195636510849 0.9107611775398254\n","Validation loss decreased (0.524448 --> 0.523472).  Saving model ...\n","47 0.40989235043525696 0.9887323975563049 0.5234715938568115 0.9269663095474243 0.5409627556800842 0.913385808467865\n","Validation loss decreased (0.523472 --> 0.522537).  Saving model ...\n","48 0.4079591631889343 0.9873239398002625 0.52253657579422 0.9269663095474243 0.5400044322013855 0.913385808467865\n","Validation loss decreased (0.522537 --> 0.521640).  Saving model ...\n","49 0.4060887396335602 0.9873239398002625 0.5216397047042847 0.9269663095474243 0.5390775799751282 0.913385808467865\n","Validation loss decreased (0.521640 --> 0.520778).  Saving model ...\n","50 0.40427953004837036 0.9887323975563049 0.520777702331543 0.9269663095474243 0.5381811857223511 0.913385808467865\n","Validation loss decreased (0.520778 --> 0.519951).  Saving model ...\n","51 0.4025276303291321 0.9887323975563049 0.5199506878852844 0.9269663095474243 0.5373149514198303 0.9160104990005493\n","Validation loss decreased (0.519951 --> 0.519159).  Saving model ...\n","52 0.40083107352256775 0.9887323975563049 0.519159197807312 0.9269663095474243 0.5364786386489868 0.9160104990005493\n","Validation loss decreased (0.519159 --> 0.518404).  Saving model ...\n","53 0.39918774366378784 0.9901408553123474 0.5184041261672974 0.9269663095474243 0.5356729030609131 0.9160104990005493\n","Validation loss decreased (0.518404 --> 0.517686).  Saving model ...\n","54 0.39759498834609985 0.9901408553123474 0.5176861882209778 0.9269663095474243 0.534898579120636 0.9160104990005493\n","Validation loss decreased (0.517686 --> 0.517005).  Saving model ...\n","55 0.3960506319999695 0.9915493130683899 0.5170050859451294 0.9269663095474243 0.534153938293457 0.9160104990005493\n","Validation loss decreased (0.517005 --> 0.516359).  Saving model ...\n","56 0.3945530951023102 0.9929577708244324 0.5163589119911194 0.9269663095474243 0.5334388613700867 0.9186351895332336\n","Validation loss decreased (0.516359 --> 0.515745).  Saving model ...\n","57 0.39310014247894287 0.9929577708244324 0.5157446265220642 0.9269663095474243 0.5327518582344055 0.9186351895332336\n","Validation loss decreased (0.515745 --> 0.515159).  Saving model ...\n","58 0.3916900157928467 0.9943661689758301 0.5151594281196594 0.9269663095474243 0.532089352607727 0.9186351895332336\n","Validation loss decreased (0.515159 --> 0.514599).  Saving model ...\n","59 0.3903208076953888 0.9943661689758301 0.5145989060401917 0.9269663095474243 0.5314493775367737 0.9186351895332336\n","Validation loss decreased (0.514599 --> 0.514060).  Saving model ...\n","60 0.38899102807044983 0.9943661689758301 0.5140600204467773 0.9269663095474243 0.5308300256729126 0.9186351895332336\n","Validation loss decreased (0.514060 --> 0.513541).  Saving model ...\n","61 0.3876991868019104 0.9943661689758301 0.5135408639907837 0.9269663095474243 0.530229389667511 0.9186351895332336\n","Validation loss decreased (0.513541 --> 0.513040).  Saving model ...\n","62 0.3864443302154541 0.9957746267318726 0.5130403637886047 0.9269663095474243 0.5296469330787659 0.9186351895332336\n","Validation loss decreased (0.513040 --> 0.512558).  Saving model ...\n","63 0.385223925113678 0.9957746267318726 0.5125579237937927 0.9269663095474243 0.5290823578834534 0.9186351895332336\n","Validation loss decreased (0.512558 --> 0.512094).  Saving model ...\n","64 0.3840373456478119 0.9957746267318726 0.5120941996574402 0.9269663095474243 0.5285353660583496 0.9186351895332336\n","Validation loss decreased (0.512094 --> 0.511650).  Saving model ...\n","65 0.38288363814353943 0.9957746267318726 0.5116497874259949 0.9269663095474243 0.5280068516731262 0.9212598204612732\n","Validation loss decreased (0.511650 --> 0.511225).  Saving model ...\n","66 0.3817605674266815 0.9957746267318726 0.5112247467041016 0.9269663095474243 0.5274966359138489 0.9212598204612732\n","Validation loss decreased (0.511225 --> 0.510819).  Saving model ...\n","67 0.38066786527633667 0.9957746267318726 0.5108189582824707 0.9269663095474243 0.5270045399665833 0.9212598204612732\n","Validation loss decreased (0.510819 --> 0.510431).  Saving model ...\n","68 0.37960371375083923 0.9957746267318726 0.5104314684867859 0.932584285736084 0.526529848575592 0.9212598204612732\n","Validation loss decreased (0.510431 --> 0.510061).  Saving model ...\n","69 0.37856757640838623 0.997183084487915 0.5100605487823486 0.932584285736084 0.5260711908340454 0.9212598204612732\n","Validation loss decreased (0.510061 --> 0.509704).  Saving model ...\n","70 0.3775585889816284 0.997183084487915 0.5097042322158813 0.9382022619247437 0.5256274938583374 0.9238845109939575\n","Validation loss decreased (0.509704 --> 0.509360).  Saving model ...\n","71 0.37657520174980164 0.997183084487915 0.509360134601593 0.9382022619247437 0.5251967906951904 0.9238845109939575\n","Validation loss decreased (0.509360 --> 0.509027).  Saving model ...\n","72 0.37561681866645813 0.997183084487915 0.5090273022651672 0.9382022619247437 0.5247784852981567 0.9238845109939575\n","Validation loss decreased (0.509027 --> 0.508704).  Saving model ...\n","73 0.37468215823173523 0.997183084487915 0.5087039470672607 0.9382022619247437 0.5243709683418274 0.9238845109939575\n","Validation loss decreased (0.508704 --> 0.508390).  Saving model ...\n","74 0.373771071434021 0.997183084487915 0.5083897113800049 0.9382022619247437 0.5239742398262024 0.9238845109939575\n","Validation loss decreased (0.508390 --> 0.508084).  Saving model ...\n","75 0.3728826344013214 0.997183084487915 0.5080844759941101 0.9382022619247437 0.5235878229141235 0.9238845109939575\n","Validation loss decreased (0.508084 --> 0.507788).  Saving model ...\n","76 0.37201517820358276 0.997183084487915 0.5077882409095764 0.9382022619247437 0.5232115983963013 0.9265092015266418\n","Validation loss decreased (0.507788 --> 0.507502).  Saving model ...\n","77 0.37116947770118713 0.997183084487915 0.5075017213821411 0.9382022619247437 0.5228465795516968 0.9265092015266418\n","Validation loss decreased (0.507502 --> 0.507225).  Saving model ...\n","78 0.37034356594085693 0.997183084487915 0.5072245597839355 0.9382022619247437 0.5224912762641907 0.9238845109939575\n","Validation loss decreased (0.507225 --> 0.506957).  Saving model ...\n","79 0.369536817073822 0.997183084487915 0.5069569945335388 0.9382022619247437 0.522146999835968 0.9238845109939575\n","Validation loss decreased (0.506957 --> 0.506699).  Saving model ...\n","80 0.36874920129776 0.997183084487915 0.506698727607727 0.9438202381134033 0.5218125581741333 0.9238845109939575\n","Validation loss decreased (0.506699 --> 0.506449).  Saving model ...\n","81 0.3679801821708679 0.997183084487915 0.5064486861228943 0.9438202381134033 0.5214874744415283 0.9238845109939575\n","Validation loss decreased (0.506449 --> 0.506206).  Saving model ...\n","82 0.36722850799560547 0.997183084487915 0.5062060356140137 0.9438202381134033 0.5211707949638367 0.9238845109939575\n","Validation loss decreased (0.506206 --> 0.505970).  Saving model ...\n","83 0.3664937913417816 0.997183084487915 0.505969762802124 0.9438202381134033 0.5208622217178345 0.9238845109939575\n","Validation loss decreased (0.505970 --> 0.505739).  Saving model ...\n","84 0.36577585339546204 0.997183084487915 0.5057389736175537 0.9438202381134033 0.5205603837966919 0.9238845109939575\n","Validation loss decreased (0.505739 --> 0.505513).  Saving model ...\n","85 0.3650743365287781 0.997183084487915 0.5055128335952759 0.9438202381134033 0.5202649235725403 0.9238845109939575\n","Validation loss decreased (0.505513 --> 0.505291).  Saving model ...\n","86 0.36438778042793274 0.997183084487915 0.5052910447120667 0.9438202381134033 0.5199756622314453 0.9238845109939575\n","Validation loss decreased (0.505291 --> 0.505073).  Saving model ...\n","87 0.3637164533138275 0.997183084487915 0.5050733089447021 0.9438202381134033 0.5196923613548279 0.9238845109939575\n","Validation loss decreased (0.505073 --> 0.504860).  Saving model ...\n","88 0.3630596995353699 0.997183084487915 0.5048599243164062 0.9438202381134033 0.5194146037101746 0.9238845109939575\n","Validation loss decreased (0.504860 --> 0.504651).  Saving model ...\n","89 0.36241722106933594 0.997183084487915 0.5046508312225342 0.9438202381134033 0.519142746925354 0.9238845109939575\n","Validation loss decreased (0.504651 --> 0.504447).  Saving model ...\n","90 0.3617885410785675 0.997183084487915 0.5044468641281128 0.9438202381134033 0.518876850605011 0.9238845109939575\n","Validation loss decreased (0.504447 --> 0.504247).  Saving model ...\n","91 0.3611728549003601 0.997183084487915 0.5042473673820496 0.9438202381134033 0.5186169743537903 0.9238845109939575\n","Validation loss decreased (0.504247 --> 0.504052).  Saving model ...\n","92 0.36057043075561523 0.997183084487915 0.504052460193634 0.9438202381134033 0.5183627009391785 0.9238845109939575\n","Validation loss decreased (0.504052 --> 0.503862).  Saving model ...\n","93 0.3599804937839508 0.997183084487915 0.5038617253303528 0.9438202381134033 0.5181136131286621 0.9238845109939575\n","Validation loss decreased (0.503862 --> 0.503675).  Saving model ...\n","94 0.35940277576446533 0.997183084487915 0.5036752223968506 0.9438202381134033 0.5178696513175964 0.9238845109939575\n","Validation loss decreased (0.503675 --> 0.503492).  Saving model ...\n","95 0.3588368594646454 0.997183084487915 0.5034918785095215 0.9438202381134033 0.5176303386688232 0.9238845109939575\n","Validation loss decreased (0.503492 --> 0.503311).  Saving model ...\n","96 0.3582823574542999 0.997183084487915 0.5033113956451416 0.9438202381134033 0.5173951387405396 0.9238845109939575\n","Validation loss decreased (0.503311 --> 0.503134).  Saving model ...\n","97 0.35773909091949463 0.997183084487915 0.5031335949897766 0.9438202381134033 0.5171638131141663 0.9238845109939575\n","Validation loss decreased (0.503134 --> 0.502958).  Saving model ...\n","98 0.35720694065093994 0.997183084487915 0.5029580593109131 0.9438202381134033 0.5169361233711243 0.9238845109939575\n","Validation loss decreased (0.502958 --> 0.502785).  Saving model ...\n","99 0.3566848039627075 0.997183084487915 0.5027849078178406 0.9438202381134033 0.516711413860321 0.9238845109939575\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"erpioWsYtaUa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607487265621,"user_tz":180,"elapsed":175883,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"78ec4419-2057-49ea-ded8-867e3181e822"},"source":["print(Precision(prediction, Y_train_tensor))\n","print(Precision(val_prediction, Y_valid_tensor))\n","print(Precision(test_prediction, Y_test_tensor))"],"execution_count":23,"outputs":[{"output_type":"stream","text":["[1.0, 0.984000027179718]\n","[0.9477124214172363, 0.9200000166893005]\n","[0.9365558624267578, 0.8399999737739563]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Qu2e4Qh38lp4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607487265621,"user_tz":180,"elapsed":175879,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"ff7ef85f-145f-4b32-dd9c-7324eb67cdff"},"source":["print(Recall(prediction, Y_train_tensor))\n","print(Recall(val_prediction, Y_valid_tensor))\n","print(Recall(test_prediction, Y_test_tensor))"],"execution_count":24,"outputs":[{"output_type":"stream","text":["[0.9965928196907043, 1.0]\n","[0.9863945841789246, 0.7419354915618896]\n","[0.9748427867889404, 0.6666666865348816]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5IoA1jJGBW2Q","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607487265622,"user_tz":180,"elapsed":175876,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"b1c1f931-f913-42b0-ed4b-2aa958b683cc"},"source":["print(Accuracy(prediction, Y_train_tensor))\n","print(Accuracy(val_prediction, Y_valid_tensor))\n","print(Accuracy(test_prediction, Y_test_tensor))"],"execution_count":25,"outputs":[{"output_type":"stream","text":["0.997183084487915\n","0.9438202381134033\n","0.9238845109939575\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Da7g_anAsjrX","executionInfo":{"status":"ok","timestamp":1607487265622,"user_tz":180,"elapsed":175874,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["with open('/content/drive/My Drive/Data Master/Prediction_BOW_RegressaoLogistica/test_prediction_split' + str(n_split), 'wb') as file:\n","    pickle.dump(test_prediction.detach().numpy(), file)"],"execution_count":26,"outputs":[]}]}