{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Split5.ipynb","provenance":[{"file_id":"1ly17dl3w8rGXAPtd1owJFslx4RVJE78c","timestamp":1592607825372},{"file_id":"1VIBcIIFR_YFlSguO_JGlnJbFzyAcT6YH","timestamp":1592464333044},{"file_id":"1dZvMRgPPkRVGa_4BZ1Tvoom_U4pjwmRX","timestamp":1592435543596},{"file_id":"12Sf257YUAwzmSXOlE3llOhi0N1YVUbM7","timestamp":1583376883298}],"collapsed_sections":[],"authorship_tag":"ABX9TyMziJXj3obVgyrcFkOIYBq7"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"JQrQmaLj0UuZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607487774050,"user_tz":180,"elapsed":23901,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"c0f98811-e674-4c28-9124-b47bf71cf39a"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JjEPtibx-EJD","executionInfo":{"status":"ok","timestamp":1607487776777,"user_tz":180,"elapsed":26622,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["import numpy as np\n","import torch\n","\n","class EarlyStopping:\n","    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n","    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt'):\n","        \"\"\"\n","        Args:\n","            patience (int): How long to wait after last time validation loss improved.\n","                            Default: 7\n","            verbose (bool): If True, prints a message for each validation loss improvement. \n","                            Default: False\n","            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n","                            Default: 0\n","            path (str): Path for the checkpoint to be saved to.\n","                            Default: 'checkpoint.pt'\n","        \"\"\"\n","        self.patience = patience\n","        self.verbose = verbose\n","        self.counter = 0\n","        self.best_score = None\n","        self.early_stop = False\n","        self.val_loss_min = np.Inf\n","        self.delta = delta\n","        self.path = path\n","\n","    def __call__(self, val_loss, model):\n","\n","        score = -val_loss\n","\n","        if self.best_score is None:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model)\n","        elif score < self.best_score + self.delta:\n","            self.counter += 1\n","            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n","            if self.counter >= self.patience:\n","                self.early_stop = True\n","        else:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model)\n","            self.counter = 0\n","\n","    def save_checkpoint(self, val_loss, model):\n","        '''Saves model when validation loss decrease.'''\n","        if self.verbose:\n","            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n","        torch.save(model.state_dict(), self.path)\n","        self.val_loss_min = val_loss"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"tjGPuXgoqulz","executionInfo":{"status":"ok","timestamp":1607487776779,"user_tz":180,"elapsed":26622,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["def Accuracy(prediction, observation):\n","  prediction = prediction[:,1]\n","  prediction_class = (torch.reshape(prediction, observation.shape) > 0.5).float()\n","  correct = (prediction_class == observation).float().sum()\n","  accuracy = correct/prediction_class.shape[0]\n","  return float(accuracy.cpu())\n","\n","def Precision(prediction, observation):\n","  prediction = prediction[:,1]\n","  res = []\n","  prediction_class = (torch.reshape(prediction, observation.shape) > 0.5).float()\n","  for label in [0, 1]:\n","    correct = (prediction_class[prediction_class == label] == observation[prediction_class == label]).float().sum()\n","    precision = correct/prediction_class[prediction_class == label].shape[0]\n","    res.append(float(precision.cpu()))\n","  return res\n","\n","def Recall(prediction, observation):\n","  prediction = prediction[:,1]\n","  res = []\n","  prediction_class = (torch.reshape(prediction, observation.shape) > 0.5).float()\n","  for label in [0, 1]:\n","    correct = (prediction_class[observation == label] == observation[observation == label]).float().sum()\n","    recall = correct/prediction_class[observation == label].shape[0]\n","    res.append(float(recall.cpu()))\n","  return res"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"sgz5Ea8a1wKr","executionInfo":{"status":"ok","timestamp":1607487776779,"user_tz":180,"elapsed":26620,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["n_split = 5"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"cutkFU0k1Pkv","executionInfo":{"status":"ok","timestamp":1607487776780,"user_tz":180,"elapsed":26619,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["import pickle\n","import pandas as pd\n","import numpy as np"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"wSJO5A951VXh","executionInfo":{"status":"ok","timestamp":1607487780161,"user_tz":180,"elapsed":29998,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["with open('/content/drive/My Drive/Data Master/X_train_final', 'rb') as file:\n","    X_train = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/Y_train_final', 'rb') as file:\n","    Y_train = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/X_test_final', 'rb') as file:\n","    X_test = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/Y_test_final', 'rb') as file:\n","    Y_test = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/word_index_final', 'rb') as file:\n","    word_index = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/train_index_final_split_' + str(n_split), 'rb') as file:\n","    train_index = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/valid_index_final_split_' + str(n_split), 'rb') as file:\n","    valid_index = pickle.load(file)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"_v0BS5Cp_06s","executionInfo":{"status":"ok","timestamp":1607487780161,"user_tz":180,"elapsed":29996,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["test_index = [i for i, _ in enumerate(X_test)]"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"NGqLg8IllrZE","executionInfo":{"status":"ok","timestamp":1607487780162,"user_tz":180,"elapsed":29995,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["inv_word_index = {ix : w for w, ix in word_index.items()}"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"1-2YPzNN1x5T","executionInfo":{"status":"ok","timestamp":1607487785131,"user_tz":180,"elapsed":34963,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["import itertools\n","features_index = {w:ix for ix, w in enumerate(np.unique(list(itertools.chain.from_iterable(np.array(X_train)[train_index]))))}\n","inv_features_index = {ix:w for ix, w in enumerate(np.unique(list(itertools.chain.from_iterable(np.array(X_train)[train_index]))))}"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"RxZWUTIv4K5T","executionInfo":{"status":"ok","timestamp":1607487786769,"user_tz":180,"elapsed":36599,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["X_train_matrix = np.zeros((len(X_train), len(features_index)))\n","X_test_matrix = np.zeros((len(X_test), len(features_index)))"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"K6KzJuIy4dN8","executionInfo":{"status":"ok","timestamp":1607487806144,"user_tz":180,"elapsed":55972,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["for i, x in enumerate(X_train):\n","  for w in x:\n","    if w in features_index:\n","      X_train_matrix[i,features_index[w]] += 1\n","\n","for i, x in enumerate(X_test):\n","  for w in x:\n","    if w in features_index:\n","      X_test_matrix[i,features_index[w]] += 1"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"9d4attfQ0i-Q","executionInfo":{"status":"ok","timestamp":1607487806146,"user_tz":180,"elapsed":55972,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"twcFT-Hl3fqP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607487806146,"user_tz":180,"elapsed":55967,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"7d489a69-4dac-4a46-d14f-4ac443087626"},"source":["input_dim = X_train_matrix.shape[1]\n","input_dim"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["239262"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"9fbXl191nZhK","executionInfo":{"status":"ok","timestamp":1607487806147,"user_tz":180,"elapsed":55967,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["class LogisticRegression (nn.Module):\n","\n","  def __init__(self):\n","    super(LogisticRegression, self).__init__()\n","\n","    self.fc1 = nn.Linear(input_dim, 2)\n","                                \n","    self.softmax = nn.Softmax(dim=1)\n","\n","  def forward(self, x):\n","    x = F.normalize(x)\n","    y = self.softmax(self.fc1(x))\n","\n","    return y"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"Cgzf7IEqnyN4","executionInfo":{"status":"ok","timestamp":1607487806147,"user_tz":180,"elapsed":55964,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["model = LogisticRegression()"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"0rnUcqchBE91","executionInfo":{"status":"ok","timestamp":1607487807390,"user_tz":180,"elapsed":57205,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["X_train_tensor = torch.from_numpy(X_train_matrix[train_index]).float()\n","Y_train_tensor = torch.LongTensor(np.array(Y_train[train_index]))\n","\n","X_valid_tensor = torch.from_numpy(X_train_matrix[valid_index]).float()\n","Y_valid_tensor = torch.LongTensor(np.array(Y_train[valid_index]))\n","\n","X_test_tensor = torch.from_numpy(X_test_matrix).float()\n","Y_test_tensor = torch.LongTensor(np.array(Y_test))"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"GlP5dzFET5tF","executionInfo":{"status":"ok","timestamp":1607487807392,"user_tz":180,"elapsed":57205,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["torch.manual_seed(0)\n","np.random.seed(0)"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"SV0Da5qu98-C","executionInfo":{"status":"ok","timestamp":1607487807392,"user_tz":180,"elapsed":57204,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["import torch.optim as optim\n","optimizer = optim.AdamW(model.parameters(), lr=0.01)"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"gHujp4Ww_ZuO","executionInfo":{"status":"ok","timestamp":1607487807393,"user_tz":180,"elapsed":57203,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["from torch.optim.lr_scheduler import ReduceLROnPlateau\n","scheduler = ReduceLROnPlateau(optimizer, 'min')"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"qkfeoTBHRuOb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607487807393,"user_tz":180,"elapsed":57198,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"cca6507b-48cf-42ac-b8b9-5636073a38ae"},"source":["weights = [sum(Y_train)/len(Y_train), 1-sum(Y_train)/len(Y_train)]\n","class_weights = torch.FloatTensor(weights)\n","class_weights"],"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0.1734, 0.8266])"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"8-F96WAE98zI","executionInfo":{"status":"ok","timestamp":1607487807394,"user_tz":180,"elapsed":57198,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["criterion = nn.CrossEntropyLoss(weight=class_weights)"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"E7KgiIq398rR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607487938424,"user_tz":180,"elapsed":188223,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"affcda7c-f0b4-4788-cadc-f7d6dd98074b"},"source":["patience = 20\n","early_stopping = EarlyStopping(patience=patience, verbose=True)\n","\n","for i in range(100):\n","  model.train()\n","  optimizer.zero_grad()\n","  prediction = model(X_train_tensor)\n","  loss = criterion(prediction, Y_train_tensor)\n","  loss.backward()\n","  optimizer.step()\n","\n","  accuracy = Accuracy(prediction, Y_train_tensor)\n","\n","  model.eval()\n","\n","  val_prediction = model(X_valid_tensor)\n","  test_prediction = model(X_test_tensor)\n","  val_loss = criterion(val_prediction, Y_valid_tensor)\n","  test_loss = criterion(test_prediction, Y_test_tensor)\n","\n","  val_accuracy = Accuracy(val_prediction, Y_valid_tensor)\n","  test_accuracy = Accuracy(test_prediction, Y_test_tensor)\n","\n","  early_stopping(val_loss, model)\n","\n","  if early_stopping.early_stop:\n","    print(\"Early stopping\")\n","    break\n","\n","  print(i, float(loss.cpu()), accuracy, float(val_loss.cpu()), val_accuracy, float(test_loss.cpu()), test_accuracy)\n","\n","  scheduler.step(val_loss)\n","\n","model.load_state_dict(torch.load('checkpoint.pt'))"],"execution_count":22,"outputs":[{"output_type":"stream","text":["Validation loss decreased (inf --> 0.684617).  Saving model ...\n","0 0.6931641101837158 0.7542135119438171 0.6846165657043457 0.9147727489471436 0.6863439679145813 0.8792650699615479\n","Validation loss decreased (0.684617 --> 0.676210).  Saving model ...\n","1 0.6808705925941467 0.9578651785850525 0.6762101650238037 0.9147727489471436 0.6796659827232361 0.8792650699615479\n","Validation loss decreased (0.676210 --> 0.667952).  Saving model ...\n","2 0.6688099503517151 0.9578651785850525 0.6679520010948181 0.9147727489471436 0.6731255650520325 0.8792650699615479\n","Validation loss decreased (0.667952 --> 0.659856).  Saving model ...\n","3 0.6570106148719788 0.9578651785850525 0.6598563194274902 0.9147727489471436 0.6667340993881226 0.8792650699615479\n","Validation loss decreased (0.659856 --> 0.651937).  Saving model ...\n","4 0.6454964280128479 0.9578651785850525 0.6519372463226318 0.9147727489471436 0.6605029106140137 0.8792650699615479\n","Validation loss decreased (0.651937 --> 0.644209).  Saving model ...\n","5 0.6342886090278625 0.959269642829895 0.6442094445228577 0.9147727489471436 0.65444415807724 0.8792650699615479\n","Validation loss decreased (0.644209 --> 0.636686).  Saving model ...\n","6 0.6234074234962463 0.959269642829895 0.6366862654685974 0.9147727489471436 0.6485679745674133 0.8792650699615479\n","Validation loss decreased (0.636686 --> 0.629379).  Saving model ...\n","7 0.6128667593002319 0.959269642829895 0.6293785572052002 0.9147727489471436 0.6428812742233276 0.8792650699615479\n","Validation loss decreased (0.629379 --> 0.622294).  Saving model ...\n","8 0.6026778221130371 0.959269642829895 0.6222937107086182 0.9147727489471436 0.6373853087425232 0.8818897604942322\n","Validation loss decreased (0.622294 --> 0.615437).  Saving model ...\n","9 0.5928478240966797 0.959269642829895 0.615437388420105 0.9147727489471436 0.6320812106132507 0.8818897604942322\n","Validation loss decreased (0.615437 --> 0.608814).  Saving model ...\n","10 0.5833821296691895 0.959269642829895 0.6088141202926636 0.9204545617103577 0.6269702911376953 0.8818897604942322\n","Validation loss decreased (0.608814 --> 0.602426).  Saving model ...\n","11 0.5742809772491455 0.959269642829895 0.6024260520935059 0.9204545617103577 0.622052013874054 0.8818897604942322\n","Validation loss decreased (0.602426 --> 0.596277).  Saving model ...\n","12 0.5655436515808105 0.959269642829895 0.5962771773338318 0.9204545617103577 0.6173259019851685 0.8818897604942322\n","Validation loss decreased (0.596277 --> 0.590366).  Saving model ...\n","13 0.5571668148040771 0.9620786309242249 0.5903663635253906 0.9204545617103577 0.6127881407737732 0.8818897604942322\n","Validation loss decreased (0.590366 --> 0.584693).  Saving model ...\n","14 0.5491445064544678 0.9620786309242249 0.584692656993866 0.9204545617103577 0.6084345579147339 0.8818897604942322\n","Validation loss decreased (0.584693 --> 0.579253).  Saving model ...\n","15 0.54146808385849 0.9648876190185547 0.5792525410652161 0.9204545617103577 0.6042611598968506 0.8818897604942322\n","Validation loss decreased (0.579253 --> 0.574043).  Saving model ...\n","16 0.5341295599937439 0.9648876190185547 0.5740430355072021 0.9204545617103577 0.6002646684646606 0.8818897604942322\n","Validation loss decreased (0.574043 --> 0.569059).  Saving model ...\n","17 0.5271188616752625 0.9648876190185547 0.569058895111084 0.9204545617103577 0.5964410901069641 0.8818897604942322\n","Validation loss decreased (0.569059 --> 0.564296).  Saving model ...\n","18 0.5204241275787354 0.966292142868042 0.5642955899238586 0.9204545617103577 0.5927855372428894 0.8818897604942322\n","Validation loss decreased (0.564296 --> 0.559746).  Saving model ...\n","19 0.5140329599380493 0.9676966071128845 0.5597463846206665 0.9204545617103577 0.5892918109893799 0.8818897604942322\n","Validation loss decreased (0.559746 --> 0.555405).  Saving model ...\n","20 0.507933497428894 0.9676966071128845 0.5554052591323853 0.9204545617103577 0.5859518647193909 0.887139081954956\n","Validation loss decreased (0.555405 --> 0.551264).  Saving model ...\n","21 0.5021123886108398 0.9691011309623718 0.5512642860412598 0.9204545617103577 0.5827606916427612 0.887139081954956\n","Validation loss decreased (0.551264 --> 0.547317).  Saving model ...\n","22 0.4965572655200958 0.9691011309623718 0.54731684923172 0.9204545617103577 0.5797122120857239 0.887139081954956\n","Validation loss decreased (0.547317 --> 0.543555).  Saving model ...\n","23 0.49125441908836365 0.9691011309623718 0.5435553789138794 0.9204545617103577 0.5768023729324341 0.8897637724876404\n","Validation loss decreased (0.543555 --> 0.539973).  Saving model ...\n","24 0.4861922860145569 0.9719101190567017 0.5399727821350098 0.9204545617103577 0.5740256309509277 0.8897637724876404\n","Validation loss decreased (0.539973 --> 0.536561).  Saving model ...\n","25 0.48135748505592346 0.9719101190567017 0.5365614295005798 0.9204545617103577 0.5713756680488586 0.8897637724876404\n","Validation loss decreased (0.536561 --> 0.533313).  Saving model ...\n","26 0.4767387807369232 0.9719101190567017 0.5333133935928345 0.9204545617103577 0.5688457489013672 0.8897637724876404\n","Validation loss decreased (0.533313 --> 0.530221).  Saving model ...\n","27 0.47232529520988464 0.9719101190567017 0.5302205085754395 0.9204545617103577 0.5664283633232117 0.8897637724876404\n","Validation loss decreased (0.530221 --> 0.527276).  Saving model ...\n","28 0.4681033492088318 0.9719101190567017 0.527275800704956 0.9261363744735718 0.5641195178031921 0.8923884630203247\n","Validation loss decreased (0.527276 --> 0.524472).  Saving model ...\n","29 0.4640650749206543 0.9733145833015442 0.5244723558425903 0.9261363744735718 0.5619139671325684 0.8923884630203247\n","Validation loss decreased (0.524472 --> 0.521803).  Saving model ...\n","30 0.46019884943962097 0.9747191071510315 0.5218033194541931 0.9204545617103577 0.5598078966140747 0.8923884630203247\n","Validation loss decreased (0.521803 --> 0.519262).  Saving model ...\n","31 0.4564953148365021 0.9747191071510315 0.519262433052063 0.9204545617103577 0.557797372341156 0.8950130939483643\n","Validation loss decreased (0.519262 --> 0.516843).  Saving model ...\n","32 0.45294591784477234 0.9747191071510315 0.5168429017066956 0.9204545617103577 0.5558759570121765 0.8950130939483643\n","Validation loss decreased (0.516843 --> 0.514537).  Saving model ...\n","33 0.4495418667793274 0.9747191071510315 0.5145372152328491 0.9261363744735718 0.5540386438369751 0.8950130939483643\n","Validation loss decreased (0.514537 --> 0.512340).  Saving model ...\n","34 0.44627511501312256 0.9747191071510315 0.5123403072357178 0.9261363744735718 0.552280604839325 0.8950130939483643\n","Validation loss decreased (0.512340 --> 0.510246).  Saving model ...\n","35 0.44313856959342957 0.9747191071510315 0.510245680809021 0.9261363744735718 0.55059814453125 0.8950130939483643\n","Validation loss decreased (0.510246 --> 0.508248).  Saving model ...\n","36 0.4401247203350067 0.9747191071510315 0.5082484483718872 0.9261363744735718 0.5489882230758667 0.8950130939483643\n","Validation loss decreased (0.508248 --> 0.506344).  Saving model ...\n","37 0.437226265668869 0.976123571395874 0.5063436627388 0.9261363744735718 0.5474488735198975 0.8950130939483643\n","Validation loss decreased (0.506344 --> 0.504526).  Saving model ...\n","38 0.43443819880485535 0.976123571395874 0.5045264363288879 0.9261363744735718 0.5459752082824707 0.8976377844810486\n","Validation loss decreased (0.504526 --> 0.502791).  Saving model ...\n","39 0.4317546486854553 0.976123571395874 0.5027912259101868 0.9261363744735718 0.5445640087127686 0.8976377844810486\n","Validation loss decreased (0.502791 --> 0.501134).  Saving model ...\n","40 0.42916953563690186 0.9789325594902039 0.5011336207389832 0.9261363744735718 0.5432116985321045 0.9002624750137329\n","Validation loss decreased (0.501134 --> 0.499549).  Saving model ...\n","41 0.4266783595085144 0.9789325594902039 0.4995485842227936 0.9261363744735718 0.5419138073921204 0.9002624750137329\n","Validation loss decreased (0.499549 --> 0.498033).  Saving model ...\n","42 0.42427581548690796 0.9789325594902039 0.4980330169200897 0.9261363744735718 0.5406696796417236 0.9002624750137329\n","Validation loss decreased (0.498033 --> 0.496583).  Saving model ...\n","43 0.421957790851593 0.9789325594902039 0.49658268690109253 0.9261363744735718 0.5394765734672546 0.9002624750137329\n","Validation loss decreased (0.496583 --> 0.495195).  Saving model ...\n","44 0.41971999406814575 0.9803370833396912 0.4951946437358856 0.9318181872367859 0.5383328795433044 0.9002624750137329\n","Validation loss decreased (0.495195 --> 0.493865).  Saving model ...\n","45 0.417558491230011 0.9817415475845337 0.49386507272720337 0.9318181872367859 0.5372353792190552 0.9002624750137329\n","Validation loss decreased (0.493865 --> 0.492590).  Saving model ...\n","46 0.41547006368637085 0.9817415475845337 0.4925899803638458 0.9318181872367859 0.5361811518669128 0.9002624750137329\n","Validation loss decreased (0.492590 --> 0.491367).  Saving model ...\n","47 0.41345101594924927 0.9817415475845337 0.4913666248321533 0.9318181872367859 0.5351678729057312 0.9002624750137329\n","Validation loss decreased (0.491367 --> 0.490192).  Saving model ...\n","48 0.4114977717399597 0.9817415475845337 0.4901915490627289 0.9318181872367859 0.5341939926147461 0.9028871655464172\n","Validation loss decreased (0.490192 --> 0.489063).  Saving model ...\n","49 0.4096072316169739 0.983146071434021 0.4890625774860382 0.9318181872367859 0.533257007598877 0.9028871655464172\n","Validation loss decreased (0.489063 --> 0.487977).  Saving model ...\n","50 0.4077775180339813 0.983146071434021 0.48797714710235596 0.9318181872367859 0.532356321811676 0.9028871655464172\n","Validation loss decreased (0.487977 --> 0.486933).  Saving model ...\n","51 0.4060048758983612 0.983146071434021 0.486933171749115 0.9318181872367859 0.531489908695221 0.9028871655464172\n","Validation loss decreased (0.486933 --> 0.485928).  Saving model ...\n","52 0.404287189245224 0.983146071434021 0.48592785000801086 0.9318181872367859 0.5306567549705505 0.9028871655464172\n","Validation loss decreased (0.485928 --> 0.484959).  Saving model ...\n","53 0.4026225209236145 0.9887640476226807 0.48495912551879883 0.9318181872367859 0.5298538208007812 0.9028871655464172\n","Validation loss decreased (0.484959 --> 0.484024).  Saving model ...\n","54 0.401007741689682 0.9915730357170105 0.48402437567710876 0.9318181872367859 0.5290796160697937 0.9028871655464172\n","Validation loss decreased (0.484024 --> 0.483122).  Saving model ...\n","55 0.399441123008728 0.992977499961853 0.483121782541275 0.9375 0.5283328890800476 0.9028871655464172\n","Validation loss decreased (0.483122 --> 0.482250).  Saving model ...\n","56 0.397921085357666 0.992977499961853 0.4822499454021454 0.9375 0.5276123881340027 0.9028871655464172\n","Validation loss decreased (0.482250 --> 0.481407).  Saving model ...\n","57 0.3964448571205139 0.992977499961853 0.48140716552734375 0.9375 0.5269174575805664 0.9028871655464172\n","Validation loss decreased (0.481407 --> 0.480592).  Saving model ...\n","58 0.39501091837882996 0.992977499961853 0.48059195280075073 0.9375 0.5262467265129089 0.9028871655464172\n","Validation loss decreased (0.480592 --> 0.479803).  Saving model ...\n","59 0.3936181962490082 0.992977499961853 0.4798029065132141 0.9375 0.5255991816520691 0.9028871655464172\n","Validation loss decreased (0.479803 --> 0.479038).  Saving model ...\n","60 0.39226415753364563 0.992977499961853 0.47903814911842346 0.9375 0.5249729156494141 0.9055117964744568\n","Validation loss decreased (0.479038 --> 0.478296).  Saving model ...\n","61 0.39094778895378113 0.9943820238113403 0.478296160697937 0.9375 0.5243667960166931 0.9055117964744568\n","Validation loss decreased (0.478296 --> 0.477576).  Saving model ...\n","62 0.3896677494049072 0.9957864880561829 0.4775763154029846 0.9375 0.5237802267074585 0.9055117964744568\n","Validation loss decreased (0.477576 --> 0.476876).  Saving model ...\n","63 0.38842228055000305 0.9957864880561829 0.4768764078617096 0.9375 0.523212194442749 0.9055117964744568\n","Validation loss decreased (0.476876 --> 0.476197).  Saving model ...\n","64 0.38720962405204773 0.9957864880561829 0.47619694471359253 0.9375 0.5226621627807617 0.9055117964744568\n","Validation loss decreased (0.476197 --> 0.475536).  Saving model ...\n","65 0.38602977991104126 0.9957864880561829 0.4755364954471588 0.9375 0.522129476070404 0.9055117964744568\n","Validation loss decreased (0.475536 --> 0.474894).  Saving model ...\n","66 0.3848808705806732 0.9957864880561829 0.4748936593532562 0.9375 0.5216124653816223 0.9081364870071411\n","Validation loss decreased (0.474894 --> 0.474268).  Saving model ...\n","67 0.38376131653785706 0.9957864880561829 0.47426751255989075 0.9375 0.5211108922958374 0.9081364870071411\n","Validation loss decreased (0.474268 --> 0.473657).  Saving model ...\n","68 0.38267067074775696 0.9957864880561829 0.4736573398113251 0.9375 0.5206239819526672 0.9081364870071411\n","Validation loss decreased (0.473657 --> 0.473062).  Saving model ...\n","69 0.38160786032676697 0.9957864880561829 0.4730623960494995 0.9375 0.5201499462127686 0.9081364870071411\n","Validation loss decreased (0.473062 --> 0.472482).  Saving model ...\n","70 0.3805714547634125 0.9957864880561829 0.4724816679954529 0.9375 0.5196893811225891 0.9081364870071411\n","Validation loss decreased (0.472482 --> 0.471915).  Saving model ...\n","71 0.3795607388019562 0.9943820238113403 0.47191527485847473 0.9375 0.5192421078681946 0.9081364870071411\n","Validation loss decreased (0.471915 --> 0.471362).  Saving model ...\n","72 0.3785751461982727 0.9943820238113403 0.47136226296424866 0.9375 0.5188063383102417 0.9081364870071411\n","Validation loss decreased (0.471362 --> 0.470822).  Saving model ...\n","73 0.3776134252548218 0.9943820238113403 0.4708217978477478 0.9375 0.5183823704719543 0.913385808467865\n","Validation loss decreased (0.470822 --> 0.470294).  Saving model ...\n","74 0.37667497992515564 0.9943820238113403 0.4702936112880707 0.9375 0.5179689526557922 0.913385808467865\n","Validation loss decreased (0.470294 --> 0.469777).  Saving model ...\n","75 0.37575867772102356 0.9957864880561829 0.46977704763412476 0.9375 0.5175658464431763 0.913385808467865\n","Validation loss decreased (0.469777 --> 0.469271).  Saving model ...\n","76 0.3748641014099121 0.9957864880561829 0.469271183013916 0.9375 0.5171729922294617 0.9160104990005493\n","Validation loss decreased (0.469271 --> 0.468776).  Saving model ...\n","77 0.3739909827709198 0.9957864880561829 0.46877631545066833 0.9375 0.5167887806892395 0.9160104990005493\n","Validation loss decreased (0.468776 --> 0.468292).  Saving model ...\n","78 0.373137503862381 0.9957864880561829 0.46829167008399963 0.9375 0.5164141654968262 0.9160104990005493\n","Validation loss decreased (0.468292 --> 0.467817).  Saving model ...\n","79 0.3723040223121643 0.9957864880561829 0.4678169786930084 0.9375 0.5160484313964844 0.9160104990005493\n","Validation loss decreased (0.467817 --> 0.467352).  Saving model ...\n","80 0.3714892864227295 0.9957864880561829 0.4673517644405365 0.9375 0.5156910419464111 0.9160104990005493\n","Validation loss decreased (0.467352 --> 0.466896).  Saving model ...\n","81 0.37069305777549744 0.9957864880561829 0.4668959379196167 0.9375 0.5153411030769348 0.9160104990005493\n","Validation loss decreased (0.466896 --> 0.466449).  Saving model ...\n","82 0.3699145019054413 0.9957864880561829 0.46644869446754456 0.9375 0.5149988532066345 0.9160104990005493\n","Validation loss decreased (0.466449 --> 0.466010).  Saving model ...\n","83 0.3691537380218506 0.9957864880561829 0.4660097062587738 0.9375 0.5146638751029968 0.9160104990005493\n","Validation loss decreased (0.466010 --> 0.465579).  Saving model ...\n","84 0.3684089779853821 0.9957864880561829 0.46557915210723877 0.9375 0.5143358707427979 0.9160104990005493\n","Validation loss decreased (0.465579 --> 0.465156).  Saving model ...\n","85 0.36768102645874023 0.9957864880561829 0.4651564955711365 0.9375 0.5140142440795898 0.9160104990005493\n","Validation loss decreased (0.465156 --> 0.464742).  Saving model ...\n","86 0.36696869134902954 0.9957864880561829 0.46474164724349976 0.9375 0.5136995911598206 0.9160104990005493\n","Validation loss decreased (0.464742 --> 0.464334).  Saving model ...\n","87 0.36627137660980225 0.9971910119056702 0.4643343985080719 0.9375 0.5133909583091736 0.9186351895332336\n","Validation loss decreased (0.464334 --> 0.463934).  Saving model ...\n","88 0.3655887842178345 0.9971910119056702 0.46393418312072754 0.9375 0.5130881071090698 0.9186351895332336\n","Validation loss decreased (0.463934 --> 0.463541).  Saving model ...\n","89 0.36492082476615906 0.9971910119056702 0.4635408818721771 0.9375 0.5127907991409302 0.9186351895332336\n","Validation loss decreased (0.463541 --> 0.463154).  Saving model ...\n","90 0.364266961812973 0.9971910119056702 0.4631543457508087 0.9375 0.5124988555908203 0.9186351895332336\n","Validation loss decreased (0.463154 --> 0.462774).  Saving model ...\n","91 0.3636264204978943 0.9971910119056702 0.46277424693107605 0.9375 0.512212872505188 0.9186351895332336\n","Validation loss decreased (0.462774 --> 0.462401).  Saving model ...\n","92 0.3629992604255676 0.9971910119056702 0.4624006748199463 0.9375 0.5119313597679138 0.9186351895332336\n","Validation loss decreased (0.462401 --> 0.462033).  Saving model ...\n","93 0.362385094165802 0.9971910119056702 0.4620332717895508 0.9375 0.5116549730300903 0.9212598204612732\n","Validation loss decreased (0.462033 --> 0.461672).  Saving model ...\n","94 0.3617830276489258 0.9971910119056702 0.4616717994213104 0.9375 0.5113833546638489 0.9212598204612732\n","Validation loss decreased (0.461672 --> 0.461316).  Saving model ...\n","95 0.3611927628517151 0.9971910119056702 0.4613163471221924 0.9375 0.5111166834831238 0.9212598204612732\n","Validation loss decreased (0.461316 --> 0.460967).  Saving model ...\n","96 0.36061471700668335 0.9971910119056702 0.46096673607826233 0.9375 0.5108540654182434 0.9212598204612732\n","Validation loss decreased (0.460967 --> 0.460622).  Saving model ...\n","97 0.36004820466041565 0.9971910119056702 0.4606221318244934 0.9375 0.5105956792831421 0.9212598204612732\n","Validation loss decreased (0.460622 --> 0.460283).  Saving model ...\n","98 0.3594927191734314 0.9971910119056702 0.4602830410003662 0.9375 0.5103417038917542 0.9212598204612732\n","Validation loss decreased (0.460283 --> 0.459950).  Saving model ...\n","99 0.3589477837085724 0.9971910119056702 0.4599495232105255 0.9375 0.5100914835929871 0.9212598204612732\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"erpioWsYtaUa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607487938425,"user_tz":180,"elapsed":188219,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"3d342cb9-8186-41ae-b8ac-f522217678fc"},"source":["print(Precision(prediction, Y_train_tensor))\n","print(Precision(val_prediction, Y_valid_tensor))\n","print(Precision(test_prediction, Y_test_tensor))"],"execution_count":23,"outputs":[{"output_type":"stream","text":["[1.0, 0.9841269850730896]\n","[0.9655172228813171, 0.8064516186714172]\n","[0.941717803478241, 0.800000011920929]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Qu2e4Qh38lp4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607487938426,"user_tz":180,"elapsed":188216,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"6395c76b-7634-4641-b064-10f0b5385af0"},"source":["print(Recall(prediction, Y_train_tensor))\n","print(Recall(val_prediction, Y_valid_tensor))\n","print(Recall(test_prediction, Y_test_tensor))"],"execution_count":24,"outputs":[{"output_type":"stream","text":["[0.9965986609458923, 1.0]\n","[0.9589040875434875, 0.8333333134651184]\n","[0.9654088020324707, 0.6984127163887024]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5IoA1jJGBW2Q","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607487938427,"user_tz":180,"elapsed":188212,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"baf335f0-6cb9-4335-fa83-f816c8c5c7c2"},"source":["print(Accuracy(prediction, Y_train_tensor))\n","print(Accuracy(val_prediction, Y_valid_tensor))\n","print(Accuracy(test_prediction, Y_test_tensor))"],"execution_count":25,"outputs":[{"output_type":"stream","text":["0.9971910119056702\n","0.9375\n","0.9212598204612732\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gxc6TbGyufYQ","executionInfo":{"status":"ok","timestamp":1607487938747,"user_tz":180,"elapsed":188531,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["with open('/content/drive/My Drive/Data Master/Prediction_BOW_RegressaoLogistica/test_prediction_split' + str(n_split), 'wb') as file:\n","    pickle.dump(test_prediction.detach().numpy(), file)"],"execution_count":26,"outputs":[]}]}