{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of Split5.ipynb","provenance":[{"file_id":"1ly17dl3w8rGXAPtd1owJFslx4RVJE78c","timestamp":1592607825372},{"file_id":"1VIBcIIFR_YFlSguO_JGlnJbFzyAcT6YH","timestamp":1592464333044},{"file_id":"1dZvMRgPPkRVGa_4BZ1Tvoom_U4pjwmRX","timestamp":1592435543596},{"file_id":"12Sf257YUAwzmSXOlE3llOhi0N1YVUbM7","timestamp":1583376883298}],"collapsed_sections":[],"authorship_tag":"ABX9TyN18y3rRNyfm+wgp7Z4N1qJ"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"JQrQmaLj0UuZ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"executionInfo":{"status":"ok","timestamp":1593324979513,"user_tz":180,"elapsed":22475,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"f6855229-39ed-4b34-af18-1398ad0572f8"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JjEPtibx-EJD","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593324981684,"user_tz":180,"elapsed":24637,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["import numpy as np\n","import torch\n","\n","class EarlyStopping:\n","    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n","    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt'):\n","        \"\"\"\n","        Args:\n","            patience (int): How long to wait after last time validation loss improved.\n","                            Default: 7\n","            verbose (bool): If True, prints a message for each validation loss improvement. \n","                            Default: False\n","            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n","                            Default: 0\n","            path (str): Path for the checkpoint to be saved to.\n","                            Default: 'checkpoint.pt'\n","        \"\"\"\n","        self.patience = patience\n","        self.verbose = verbose\n","        self.counter = 0\n","        self.best_score = None\n","        self.early_stop = False\n","        self.val_loss_min = np.Inf\n","        self.delta = delta\n","        self.path = path\n","\n","    def __call__(self, val_loss, model):\n","\n","        score = -val_loss\n","\n","        if self.best_score is None:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model)\n","        elif score < self.best_score + self.delta:\n","            self.counter += 1\n","            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n","            if self.counter >= self.patience:\n","                self.early_stop = True\n","        else:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model)\n","            self.counter = 0\n","\n","    def save_checkpoint(self, val_loss, model):\n","        '''Saves model when validation loss decrease.'''\n","        if self.verbose:\n","            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n","        torch.save(model.state_dict(), self.path)\n","        self.val_loss_min = val_loss"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"tjGPuXgoqulz","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593324981685,"user_tz":180,"elapsed":24633,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["def Accuracy(prediction, observation):\n","  prediction = prediction[:,1]\n","  prediction_class = (torch.reshape(prediction, observation.shape) > 0.5).float()\n","  correct = (prediction_class == observation).float().sum()\n","  accuracy = correct/prediction_class.shape[0]\n","  return float(accuracy.cpu())\n","\n","def Precision(prediction, observation):\n","  prediction = prediction[:,1]\n","  res = []\n","  prediction_class = (torch.reshape(prediction, observation.shape) > 0.5).float()\n","  for label in [0, 1]:\n","    correct = (prediction_class[prediction_class == label] == observation[prediction_class == label]).float().sum()\n","    precision = correct/prediction_class[prediction_class == label].shape[0]\n","    res.append(float(precision.cpu()))\n","  return res\n","\n","def Recall(prediction, observation):\n","  prediction = prediction[:,1]\n","  res = []\n","  prediction_class = (torch.reshape(prediction, observation.shape) > 0.5).float()\n","  for label in [0, 1]:\n","    correct = (prediction_class[observation == label] == observation[observation == label]).float().sum()\n","    recall = correct/prediction_class[observation == label].shape[0]\n","    res.append(float(recall.cpu()))\n","  return res"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"sgz5Ea8a1wKr","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593324981686,"user_tz":180,"elapsed":24630,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["n_split = 5"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"cutkFU0k1Pkv","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593324981686,"user_tz":180,"elapsed":24625,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["import pickle\n","import pandas as pd\n","import numpy as np"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"wSJO5A951VXh","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593324986940,"user_tz":180,"elapsed":29874,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["with open('/content/drive/My Drive/Data Master/X_train_final', 'rb') as file:\n","    X_train = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/Y_train_final', 'rb') as file:\n","    Y_train = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/X_test_final', 'rb') as file:\n","    X_test = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/Y_test_final', 'rb') as file:\n","    Y_test = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/word_index_final', 'rb') as file:\n","    word_index = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/train_index_final_split_' + str(n_split), 'rb') as file:\n","    train_index = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/valid_index_final_split_' + str(n_split), 'rb') as file:\n","    valid_index = pickle.load(file)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"_v0BS5Cp_06s","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593324986941,"user_tz":180,"elapsed":29870,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["test_index = [i for i, _ in enumerate(X_test)]"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"NGqLg8IllrZE","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593324986942,"user_tz":180,"elapsed":29866,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["inv_word_index = {ix : w for w, ix in word_index.items()}"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"1-2YPzNN1x5T","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593324991517,"user_tz":180,"elapsed":34436,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["import itertools\n","features_index = {w:ix for ix, w in enumerate(np.unique(list(itertools.chain.from_iterable(np.array(X_train)[train_index]))))}\n","inv_features_index = {ix:w for ix, w in enumerate(np.unique(list(itertools.chain.from_iterable(np.array(X_train)[train_index]))))}"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"RxZWUTIv4K5T","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593324993039,"user_tz":180,"elapsed":35953,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["X_train_matrix = np.zeros((len(X_train), len(features_index)))\n","X_test_matrix = np.zeros((len(X_test), len(features_index)))"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"K6KzJuIy4dN8","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593325010567,"user_tz":180,"elapsed":53477,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["for i, x in enumerate(X_train):\n","  for w in x:\n","    if w in features_index:\n","      X_train_matrix[i,features_index[w]] += 1\n","\n","for i, x in enumerate(X_test):\n","  for w in x:\n","    if w in features_index:\n","      X_test_matrix[i,features_index[w]] += 1"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"9d4attfQ0i-Q","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593325010567,"user_tz":180,"elapsed":53472,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"twcFT-Hl3fqP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593325010568,"user_tz":180,"elapsed":53468,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"c96ee074-df3d-4992-bf90-7e99ee28c339"},"source":["input_dim = X_train_matrix.shape[1]\n","input_dim"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["239262"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"9fbXl191nZhK","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593325010569,"user_tz":180,"elapsed":53463,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["class LogisticRegression (nn.Module):\n","\n","  def __init__(self):\n","    super(LogisticRegression, self).__init__()\n","\n","    self.fc1 = nn.Linear(input_dim, 2)\n","                                \n","    self.softmax = nn.Softmax(dim=1)\n","\n","  def forward(self, x):\n","    x = F.normalize(x)\n","    y = self.softmax(self.fc1(x))\n","\n","    return y"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"Cgzf7IEqnyN4","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593325010569,"user_tz":180,"elapsed":53459,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["model = LogisticRegression()"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"0rnUcqchBE91","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593325012057,"user_tz":180,"elapsed":54942,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["X_train_tensor = torch.from_numpy(X_train_matrix[train_index]).float()\n","Y_train_tensor = torch.LongTensor(np.array(Y_train[train_index]))\n","\n","X_valid_tensor = torch.from_numpy(X_train_matrix[valid_index]).float()\n","Y_valid_tensor = torch.LongTensor(np.array(Y_train[valid_index]))\n","\n","X_test_tensor = torch.from_numpy(X_test_matrix).float()\n","Y_test_tensor = torch.LongTensor(np.array(Y_test))"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"GlP5dzFET5tF","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593325012058,"user_tz":180,"elapsed":54938,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["torch.manual_seed(0)\n","np.random.seed(0)"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"SV0Da5qu98-C","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593325012058,"user_tz":180,"elapsed":54933,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["import torch.optim as optim\n","optimizer = optim.AdamW(model.parameters(), lr=0.01)"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"gHujp4Ww_ZuO","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593325012059,"user_tz":180,"elapsed":54929,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["from torch.optim.lr_scheduler import ReduceLROnPlateau\n","scheduler = ReduceLROnPlateau(optimizer, 'min')"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"qkfeoTBHRuOb","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593325012060,"user_tz":180,"elapsed":54926,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"2df0b416-fcd9-4edb-9ca4-e39dc9891c82"},"source":["weights = [sum(Y_train)/len(Y_train), 1-sum(Y_train)/len(Y_train)]\n","class_weights = torch.FloatTensor(weights)\n","class_weights"],"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0.1734, 0.8266])"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"8-F96WAE98zI","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593325012060,"user_tz":180,"elapsed":54920,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["criterion = nn.CrossEntropyLoss(weight=class_weights)"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"E7KgiIq398rR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1593325129304,"user_tz":180,"elapsed":172159,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"9f970376-64f1-4fca-c7fa-ea72f2d9d0e8"},"source":["patience = 20\n","early_stopping = EarlyStopping(patience=patience, verbose=True)\n","\n","for i in range(100):\n","  model.train()\n","  optimizer.zero_grad()\n","  prediction = model(X_train_tensor)\n","  loss = criterion(prediction, Y_train_tensor)\n","  loss.backward()\n","  optimizer.step()\n","\n","  accuracy = Accuracy(prediction, Y_train_tensor)\n","\n","  model.eval()\n","\n","  val_prediction = model(X_valid_tensor)\n","  test_prediction = model(X_test_tensor)\n","  val_loss = criterion(val_prediction, Y_valid_tensor)\n","  test_loss = criterion(test_prediction, Y_test_tensor)\n","\n","  val_accuracy = Accuracy(val_prediction, Y_valid_tensor)\n","  test_accuracy = Accuracy(test_prediction, Y_test_tensor)\n","\n","  early_stopping(val_loss, model)\n","\n","  if early_stopping.early_stop:\n","    print(\"Early stopping\")\n","    break\n","\n","  print(i, float(loss.cpu()), accuracy, float(val_loss.cpu()), val_accuracy, float(test_loss.cpu()), test_accuracy)\n","\n","  scheduler.step(val_loss)\n","\n","model.load_state_dict(torch.load('checkpoint.pt'))"],"execution_count":22,"outputs":[{"output_type":"stream","text":["Validation loss decreased (inf --> 0.684562).  Saving model ...\n","0 0.6931253671646118 0.1825842708349228 0.6845621466636658 0.9090909361839294 0.6863304376602173 0.8818897604942322\n","Validation loss decreased (0.684562 --> 0.676155).  Saving model ...\n","1 0.6808327436447144 0.9550561904907227 0.6761547923088074 0.9034090638160706 0.6796486377716064 0.8818897604942322\n","Validation loss decreased (0.676155 --> 0.667890).  Saving model ...\n","2 0.6687724590301514 0.9578651785850525 0.6678902506828308 0.9147727489471436 0.6731002926826477 0.8818897604942322\n","Validation loss decreased (0.667890 --> 0.659786).  Saving model ...\n","3 0.6569738984107971 0.959269642829895 0.6597859263420105 0.9147727489471436 0.6667011380195618 0.8792650699615479\n","Validation loss decreased (0.659786 --> 0.651862).  Saving model ...\n","4 0.6454607844352722 0.9578651785850525 0.6518622636795044 0.9147727489471436 0.6604675054550171 0.8792650699615479\n","Validation loss decreased (0.651862 --> 0.644133).  Saving model ...\n","5 0.6342541575431824 0.959269642829895 0.6441327929496765 0.9147727489471436 0.6544095873832703 0.8792650699615479\n","Validation loss decreased (0.644133 --> 0.636609).  Saving model ...\n","6 0.6233737468719482 0.959269642829895 0.6366093754768372 0.9147727489471436 0.6485349535942078 0.8792650699615479\n","Validation loss decreased (0.636609 --> 0.629301).  Saving model ...\n","7 0.6128344535827637 0.959269642829895 0.6293006539344788 0.9147727489471436 0.6428473591804504 0.8792650699615479\n","Validation loss decreased (0.629301 --> 0.622214).  Saving model ...\n","8 0.6026462912559509 0.959269642829895 0.6222137212753296 0.9147727489471436 0.6373502612113953 0.8792650699615479\n","Validation loss decreased (0.622214 --> 0.615355).  Saving model ...\n","9 0.5928177833557129 0.959269642829895 0.6153548359870911 0.9147727489471436 0.6320447325706482 0.8818897604942322\n","Validation loss decreased (0.615355 --> 0.608730).  Saving model ...\n","10 0.5833529829978943 0.959269642829895 0.6087296009063721 0.9147727489471436 0.6269339323043823 0.8818897604942322\n","Validation loss decreased (0.608730 --> 0.602342).  Saving model ...\n","11 0.574253261089325 0.959269642829895 0.6023420691490173 0.9204545617103577 0.6220167875289917 0.8818897604942322\n","Validation loss decreased (0.602342 --> 0.596194).  Saving model ...\n","12 0.565517008304596 0.959269642829895 0.5961941480636597 0.9204545617103577 0.6172907948493958 0.8818897604942322\n","Validation loss decreased (0.596194 --> 0.590285).  Saving model ...\n","13 0.5571412444114685 0.9606741666793823 0.590285062789917 0.9204545617103577 0.6127533912658691 0.8818897604942322\n","Validation loss decreased (0.590285 --> 0.584613).  Saving model ...\n","14 0.5491201281547546 0.9620786309242249 0.5846132636070251 0.9204545617103577 0.6084004044532776 0.8818897604942322\n","Validation loss decreased (0.584613 --> 0.579175).  Saving model ...\n","15 0.541445255279541 0.9648876190185547 0.5791749358177185 0.9204545617103577 0.6042296290397644 0.8818897604942322\n","Validation loss decreased (0.579175 --> 0.573968).  Saving model ...\n","16 0.5341082215309143 0.9648876190185547 0.5739675760269165 0.9204545617103577 0.6002362966537476 0.8818897604942322\n","Validation loss decreased (0.573968 --> 0.568986).  Saving model ...\n","17 0.5270982980728149 0.9648876190185547 0.5689860582351685 0.9204545617103577 0.5964152216911316 0.8818897604942322\n","Validation loss decreased (0.568986 --> 0.564225).  Saving model ...\n","18 0.5204041600227356 0.966292142868042 0.5642249584197998 0.9204545617103577 0.5927600264549255 0.8818897604942322\n","Validation loss decreased (0.564225 --> 0.559678).  Saving model ...\n","19 0.5140146613121033 0.966292142868042 0.5596778988838196 0.9204545617103577 0.5892645716667175 0.8845144510269165\n","Validation loss decreased (0.559678 --> 0.555339).  Saving model ...\n","20 0.5079157948493958 0.9691011309623718 0.5553387999534607 0.9204545617103577 0.5859246850013733 0.887139081954956\n","Validation loss decreased (0.555339 --> 0.551201).  Saving model ...\n","21 0.5020956993103027 0.9691011309623718 0.5512005090713501 0.9204545617103577 0.5827344059944153 0.887139081954956\n","Validation loss decreased (0.551201 --> 0.547256).  Saving model ...\n","22 0.4965415298938751 0.9691011309623718 0.5472555160522461 0.9204545617103577 0.5796887278556824 0.887139081954956\n","Validation loss decreased (0.547256 --> 0.543497).  Saving model ...\n","23 0.49123990535736084 0.9691011309623718 0.5434967875480652 0.9204545617103577 0.5767807364463806 0.8897637724876404\n","Validation loss decreased (0.543497 --> 0.539916).  Saving model ...\n","24 0.4861781597137451 0.9719101190567017 0.5399162769317627 0.9204545617103577 0.5740039348602295 0.8897637724876404\n","Validation loss decreased (0.539916 --> 0.536506).  Saving model ...\n","25 0.48134493827819824 0.9719101190567017 0.536506175994873 0.9204545617103577 0.5713518261909485 0.8897637724876404\n","Validation loss decreased (0.536506 --> 0.533259).  Saving model ...\n","26 0.47672656178474426 0.9719101190567017 0.5332587957382202 0.9204545617103577 0.5688190460205078 0.8897637724876404\n","Validation loss decreased (0.533259 --> 0.530167).  Saving model ...\n","27 0.47231325507164 0.9719101190567017 0.5301673412322998 0.9204545617103577 0.5664018392562866 0.8897637724876404\n","Validation loss decreased (0.530167 --> 0.527224).  Saving model ...\n","28 0.46809232234954834 0.9719101190567017 0.5272244215011597 0.9261363744735718 0.5640941858291626 0.8923884630203247\n","Validation loss decreased (0.527224 --> 0.524422).  Saving model ...\n","29 0.4640539288520813 0.9733145833015442 0.524422287940979 0.9261363744735718 0.5618904829025269 0.8923884630203247\n","Validation loss decreased (0.524422 --> 0.521754).  Saving model ...\n","30 0.460188090801239 0.9747191071510315 0.5217543840408325 0.9204545617103577 0.559784471988678 0.8923884630203247\n","Validation loss decreased (0.521754 --> 0.519213).  Saving model ...\n","31 0.4564855396747589 0.9747191071510315 0.5192133784294128 0.9204545617103577 0.5577716827392578 0.8950130939483643\n","Validation loss decreased (0.519213 --> 0.516793).  Saving model ...\n","32 0.4529360830783844 0.9747191071510315 0.5167933702468872 0.9261363744735718 0.5558475852012634 0.8950130939483643\n","Validation loss decreased (0.516793 --> 0.514488).  Saving model ...\n","33 0.4495329260826111 0.9747191071510315 0.5144876837730408 0.9261363744735718 0.5540087223052979 0.8950130939483643\n","Validation loss decreased (0.514488 --> 0.512291).  Saving model ...\n","34 0.44626671075820923 0.9747191071510315 0.5122911334037781 0.9261363744735718 0.5522511601448059 0.8950130939483643\n","Validation loss decreased (0.512291 --> 0.510197).  Saving model ...\n","35 0.4431298077106476 0.9747191071510315 0.5101971626281738 0.9261363744735718 0.5505704879760742 0.8950130939483643\n","Validation loss decreased (0.510197 --> 0.508200).  Saving model ...\n","36 0.44011643528938293 0.9747191071510315 0.5082002878189087 0.9261363744735718 0.5489615201950073 0.8950130939483643\n","Validation loss decreased (0.508200 --> 0.506295).  Saving model ...\n","37 0.437218576669693 0.976123571395874 0.5062950253486633 0.9261363744735718 0.5474202036857605 0.8976377844810486\n","Validation loss decreased (0.506295 --> 0.504477).  Saving model ...\n","38 0.43443089723587036 0.976123571395874 0.5044770240783691 0.9261363744735718 0.5459454655647278 0.8976377844810486\n","Validation loss decreased (0.504477 --> 0.502741).  Saving model ...\n","39 0.43174755573272705 0.976123571395874 0.5027410387992859 0.9261363744735718 0.5445325374603271 0.9002624750137329\n","Validation loss decreased (0.502741 --> 0.501083).  Saving model ...\n","40 0.4291626811027527 0.9789325594902039 0.5010830163955688 0.9261363744735718 0.5431802272796631 0.9002624750137329\n","Validation loss decreased (0.501083 --> 0.499499).  Saving model ...\n","41 0.4266716241836548 0.9789325594902039 0.4994986355304718 0.9261363744735718 0.5418835878372192 0.9002624750137329\n","Validation loss decreased (0.499499 --> 0.497983).  Saving model ...\n","42 0.4242697060108185 0.9789325594902039 0.49798303842544556 0.9261363744735718 0.540640652179718 0.9002624750137329\n","Validation loss decreased (0.497983 --> 0.496533).  Saving model ...\n","43 0.4219517409801483 0.9789325594902039 0.4965328276157379 0.9261363744735718 0.5394481420516968 0.9002624750137329\n","Validation loss decreased (0.496533 --> 0.495144).  Saving model ...\n","44 0.4197145402431488 0.9803370833396912 0.4951438307762146 0.9261363744735718 0.5383031368255615 0.9002624750137329\n","Validation loss decreased (0.495144 --> 0.493813).  Saving model ...\n","45 0.417553186416626 0.9817415475845337 0.4938133656978607 0.9318181872367859 0.5372046232223511 0.9002624750137329\n","Validation loss decreased (0.493813 --> 0.492538).  Saving model ...\n","46 0.41546472907066345 0.9817415475845337 0.49253812432289124 0.9318181872367859 0.5361504554748535 0.9002624750137329\n","Validation loss decreased (0.492538 --> 0.491315).  Saving model ...\n","47 0.4134458005428314 0.9817415475845337 0.4913148283958435 0.9318181872367859 0.5351383090019226 0.9002624750137329\n","Validation loss decreased (0.491315 --> 0.490140).  Saving model ...\n","48 0.41149264574050903 0.9817415475845337 0.49014025926589966 0.9318181872367859 0.5341653227806091 0.9028871655464172\n","Validation loss decreased (0.490140 --> 0.489012).  Saving model ...\n","49 0.4096027910709381 0.983146071434021 0.4890115559101105 0.9318181872367859 0.5332295298576355 0.9028871655464172\n","Validation loss decreased (0.489012 --> 0.487926).  Saving model ...\n","50 0.40777283906936646 0.983146071434021 0.487926185131073 0.9318181872367859 0.5323291420936584 0.9028871655464172\n","Validation loss decreased (0.487926 --> 0.486882).  Saving model ...\n","51 0.4060005843639374 0.983146071434021 0.4868820607662201 0.9318181872367859 0.5314626097679138 0.9028871655464172\n","Validation loss decreased (0.486882 --> 0.485877).  Saving model ...\n","52 0.4042830169200897 0.983146071434021 0.4858768582344055 0.9318181872367859 0.5306295156478882 0.9028871655464172\n","Validation loss decreased (0.485877 --> 0.484908).  Saving model ...\n","53 0.40261808037757874 0.9887640476226807 0.48490801453590393 0.9318181872367859 0.5298267006874084 0.9028871655464172\n","Validation loss decreased (0.484908 --> 0.483974).  Saving model ...\n","54 0.4010036587715149 0.9915730357170105 0.48397359251976013 0.9318181872367859 0.5290539264678955 0.9028871655464172\n","Validation loss decreased (0.483974 --> 0.483072).  Saving model ...\n","55 0.3994371294975281 0.992977499961853 0.48307177424430847 0.9375 0.5283082723617554 0.9028871655464172\n","Validation loss decreased (0.483072 --> 0.482200).  Saving model ...\n","56 0.3979167938232422 0.992977499961853 0.4822002649307251 0.9375 0.527588427066803 0.9028871655464172\n","Validation loss decreased (0.482200 --> 0.481358).  Saving model ...\n","57 0.39644110202789307 0.992977499961853 0.4813578426837921 0.9375 0.5268939733505249 0.9028871655464172\n","Validation loss decreased (0.481358 --> 0.480543).  Saving model ...\n","58 0.395007461309433 0.992977499961853 0.4805431067943573 0.9375 0.52622389793396 0.9028871655464172\n","Validation loss decreased (0.480543 --> 0.479754).  Saving model ...\n","59 0.39361459016799927 0.992977499961853 0.47975414991378784 0.9375 0.5255768299102783 0.9028871655464172\n","Validation loss decreased (0.479754 --> 0.478990).  Saving model ...\n","60 0.3922605812549591 0.9943820238113403 0.4789901077747345 0.9375 0.5249515175819397 0.9055117964744568\n","Validation loss decreased (0.478990 --> 0.478248).  Saving model ...\n","61 0.39094430208206177 0.9943820238113403 0.4782484471797943 0.9375 0.5243462920188904 0.9055117964744568\n","Validation loss decreased (0.478248 --> 0.477529).  Saving model ...\n","62 0.3896643817424774 0.9957864880561829 0.4775293171405792 0.9375 0.5237604379653931 0.9055117964744568\n","Validation loss decreased (0.477529 --> 0.476831).  Saving model ...\n","63 0.38841870427131653 0.9957864880561829 0.4768306314945221 0.9375 0.5231930613517761 0.9055117964744568\n","Validation loss decreased (0.476831 --> 0.476152).  Saving model ...\n","64 0.38720643520355225 0.9957864880561829 0.47615188360214233 0.9375 0.5226439833641052 0.9055117964744568\n","Validation loss decreased (0.476152 --> 0.475492).  Saving model ...\n","65 0.3860268294811249 0.9957864880561829 0.4754917621612549 0.9375 0.5221116542816162 0.9055117964744568\n","Validation loss decreased (0.475492 --> 0.474850).  Saving model ...\n","66 0.38487738370895386 0.9957864880561829 0.47484973073005676 0.9375 0.5215957164764404 0.9081364870071411\n","Validation loss decreased (0.474850 --> 0.474224).  Saving model ...\n","67 0.383758544921875 0.9957864880561829 0.4742244780063629 0.9375 0.5210947394371033 0.9081364870071411\n","Validation loss decreased (0.474224 --> 0.473615).  Saving model ...\n","68 0.38266754150390625 0.9957864880561829 0.4736148715019226 0.9375 0.5206081867218018 0.9081364870071411\n","Validation loss decreased (0.473615 --> 0.473021).  Saving model ...\n","69 0.38160446286201477 0.9957864880561829 0.4730205237865448 0.9375 0.5201350450515747 0.9081364870071411\n","Validation loss decreased (0.473021 --> 0.472441).  Saving model ...\n","70 0.38056838512420654 0.9943820238113403 0.4724409282207489 0.9375 0.5196754336357117 0.9081364870071411\n","Validation loss decreased (0.472441 --> 0.471876).  Saving model ...\n","71 0.37955808639526367 0.9943820238113403 0.4718756377696991 0.9375 0.5192282795906067 0.9081364870071411\n","Validation loss decreased (0.471876 --> 0.471323).  Saving model ...\n","72 0.3785722851753235 0.9943820238113403 0.4713233709335327 0.9375 0.5187938213348389 0.9081364870071411\n","Validation loss decreased (0.471323 --> 0.470784).  Saving model ...\n","73 0.3776107132434845 0.9943820238113403 0.4707838296890259 0.9375 0.5183703899383545 0.913385808467865\n","Validation loss decreased (0.470784 --> 0.470256).  Saving model ...\n","74 0.37667202949523926 0.9943820238113403 0.47025611996650696 0.9375 0.5179575085639954 0.913385808467865\n","Validation loss decreased (0.470256 --> 0.469740).  Saving model ...\n","75 0.3757558763027191 0.9957864880561829 0.46974027156829834 0.9375 0.5175549983978271 0.913385808467865\n","Validation loss decreased (0.469740 --> 0.469235).  Saving model ...\n","76 0.37486180663108826 0.9957864880561829 0.46923530101776123 0.9375 0.5171623229980469 0.9160104990005493\n","Validation loss decreased (0.469235 --> 0.468741).  Saving model ...\n","77 0.37398800253868103 0.9957864880561829 0.46874120831489563 0.9375 0.5167790651321411 0.9160104990005493\n","Validation loss decreased (0.468741 --> 0.468257).  Saving model ...\n","78 0.3731352388858795 0.9957864880561829 0.46825745701789856 0.9375 0.516404926776886 0.9160104990005493\n","Validation loss decreased (0.468257 --> 0.467784).  Saving model ...\n","79 0.37230172753334045 0.9957864880561829 0.46778371930122375 0.9375 0.5160400867462158 0.9160104990005493\n","Validation loss decreased (0.467784 --> 0.467319).  Saving model ...\n","80 0.3714870512485504 0.9957864880561829 0.4673190116882324 0.9375 0.5156826972961426 0.9160104990005493\n","Validation loss decreased (0.467319 --> 0.466864).  Saving model ...\n","81 0.3706907033920288 0.9957864880561829 0.4668637812137604 0.9375 0.5153330564498901 0.9160104990005493\n","Validation loss decreased (0.466864 --> 0.466417).  Saving model ...\n","82 0.3699120879173279 0.9957864880561829 0.4664170444011688 0.9375 0.5149915814399719 0.9160104990005493\n","Validation loss decreased (0.466417 --> 0.465979).  Saving model ...\n","83 0.3691512644290924 0.9957864880561829 0.4659789204597473 0.9375 0.5146567821502686 0.9160104990005493\n","Validation loss decreased (0.465979 --> 0.465549).  Saving model ...\n","84 0.3684066832065582 0.9957864880561829 0.4655490219593048 0.9375 0.5143291354179382 0.9160104990005493\n","Validation loss decreased (0.465549 --> 0.465127).  Saving model ...\n","85 0.36767876148223877 0.9957864880561829 0.4651273190975189 0.9375 0.5140085220336914 0.9160104990005493\n","Validation loss decreased (0.465127 --> 0.464713).  Saving model ...\n","86 0.3669660985469818 0.9957864880561829 0.4647130072116852 0.9375 0.513694167137146 0.9160104990005493\n","Validation loss decreased (0.464713 --> 0.464306).  Saving model ...\n","87 0.3662691116333008 0.9971910119056702 0.46430614590644836 0.9375 0.5133857727050781 0.9186351895332336\n","Validation loss decreased (0.464306 --> 0.463906).  Saving model ...\n","88 0.3655867874622345 0.9971910119056702 0.46390634775161743 0.9375 0.5130829215049744 0.9186351895332336\n","Validation loss decreased (0.463906 --> 0.463514).  Saving model ...\n","89 0.36491894721984863 0.9971910119056702 0.4635135233402252 0.9375 0.5127865076065063 0.9186351895332336\n","Validation loss decreased (0.463514 --> 0.463128).  Saving model ...\n","90 0.36426517367362976 0.9971910119056702 0.46312758326530457 0.9375 0.5124949216842651 0.9186351895332336\n","Validation loss decreased (0.463128 --> 0.462748).  Saving model ...\n","91 0.36362460255622864 0.9971910119056702 0.46274808049201965 0.9375 0.5122090578079224 0.9186351895332336\n","Validation loss decreased (0.462748 --> 0.462375).  Saving model ...\n","92 0.36299726366996765 0.9971910119056702 0.46237483620643616 0.9375 0.5119278430938721 0.9212598204612732\n","Validation loss decreased (0.462375 --> 0.462008).  Saving model ...\n","93 0.3623828887939453 0.9971910119056702 0.46200791001319885 0.9375 0.5116521120071411 0.9212598204612732\n","Validation loss decreased (0.462008 --> 0.461647).  Saving model ...\n","94 0.3617807626724243 0.9971910119056702 0.46164706349372864 0.9375 0.511380672454834 0.9212598204612732\n","Validation loss decreased (0.461647 --> 0.461292).  Saving model ...\n","95 0.3611910045146942 0.9971910119056702 0.46129176020622253 0.9375 0.5111138820648193 0.9212598204612732\n","Validation loss decreased (0.461292 --> 0.460942).  Saving model ...\n","96 0.36061280965805054 0.9971910119056702 0.46094202995300293 0.9375 0.5108515620231628 0.9212598204612732\n","Validation loss decreased (0.460942 --> 0.460598).  Saving model ...\n","97 0.36004626750946045 0.9971910119056702 0.46059828996658325 0.9375 0.5105934143066406 0.9212598204612732\n","Validation loss decreased (0.460598 --> 0.460260).  Saving model ...\n","98 0.3594908118247986 0.9971910119056702 0.46025964617729187 0.9375 0.5103402137756348 0.9212598204612732\n","Validation loss decreased (0.460260 --> 0.459926).  Saving model ...\n","99 0.3589461147785187 0.9971910119056702 0.4599263072013855 0.9375 0.5100904107093811 0.9212598204612732\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"erpioWsYtaUa","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"executionInfo":{"status":"ok","timestamp":1593325129306,"user_tz":180,"elapsed":172155,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"91629bd7-0539-4728-d23d-f156aff12d0c"},"source":["print(Precision(prediction, Y_train_tensor))\n","print(Precision(val_prediction, Y_valid_tensor))\n","print(Precision(test_prediction, Y_test_tensor))"],"execution_count":23,"outputs":[{"output_type":"stream","text":["[1.0, 0.9841269850730896]\n","[0.9655172228813171, 0.8064516186714172]\n","[0.941717803478241, 0.800000011920929]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Qu2e4Qh38lp4","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"executionInfo":{"status":"ok","timestamp":1593325129306,"user_tz":180,"elapsed":172149,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"010c1433-dee8-498c-ef0d-9b744a12c0c2"},"source":["print(Recall(prediction, Y_train_tensor))\n","print(Recall(val_prediction, Y_valid_tensor))\n","print(Recall(test_prediction, Y_test_tensor))"],"execution_count":24,"outputs":[{"output_type":"stream","text":["[0.9965986609458923, 1.0]\n","[0.9589040875434875, 0.8333333134651184]\n","[0.9654088020324707, 0.6984127163887024]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5IoA1jJGBW2Q","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"executionInfo":{"status":"ok","timestamp":1593325129307,"user_tz":180,"elapsed":172144,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"7818c3e0-da40-4003-d863-13f026e321c2"},"source":["print(Accuracy(prediction, Y_train_tensor))\n","print(Accuracy(val_prediction, Y_valid_tensor))\n","print(Accuracy(test_prediction, Y_test_tensor))"],"execution_count":25,"outputs":[{"output_type":"stream","text":["0.9971910119056702\n","0.9375\n","0.9212598204612732\n"],"name":"stdout"}]}]}