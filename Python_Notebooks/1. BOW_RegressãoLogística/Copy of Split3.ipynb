{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of Split3.ipynb","provenance":[{"file_id":"1ly17dl3w8rGXAPtd1owJFslx4RVJE78c","timestamp":1592607825372},{"file_id":"1VIBcIIFR_YFlSguO_JGlnJbFzyAcT6YH","timestamp":1592464333044},{"file_id":"1dZvMRgPPkRVGa_4BZ1Tvoom_U4pjwmRX","timestamp":1592435543596},{"file_id":"12Sf257YUAwzmSXOlE3llOhi0N1YVUbM7","timestamp":1583376883298}],"collapsed_sections":[],"authorship_tag":"ABX9TyM0tByNSMjiQhFwckomWa/1"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"JQrQmaLj0UuZ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"executionInfo":{"status":"ok","timestamp":1593324368517,"user_tz":180,"elapsed":21255,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"a8d41ef9-772e-4db4-87d3-8eb71238d3ef"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JjEPtibx-EJD","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593324371395,"user_tz":180,"elapsed":24124,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["import numpy as np\n","import torch\n","\n","class EarlyStopping:\n","    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n","    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt'):\n","        \"\"\"\n","        Args:\n","            patience (int): How long to wait after last time validation loss improved.\n","                            Default: 7\n","            verbose (bool): If True, prints a message for each validation loss improvement. \n","                            Default: False\n","            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n","                            Default: 0\n","            path (str): Path for the checkpoint to be saved to.\n","                            Default: 'checkpoint.pt'\n","        \"\"\"\n","        self.patience = patience\n","        self.verbose = verbose\n","        self.counter = 0\n","        self.best_score = None\n","        self.early_stop = False\n","        self.val_loss_min = np.Inf\n","        self.delta = delta\n","        self.path = path\n","\n","    def __call__(self, val_loss, model):\n","\n","        score = -val_loss\n","\n","        if self.best_score is None:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model)\n","        elif score < self.best_score + self.delta:\n","            self.counter += 1\n","            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n","            if self.counter >= self.patience:\n","                self.early_stop = True\n","        else:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model)\n","            self.counter = 0\n","\n","    def save_checkpoint(self, val_loss, model):\n","        '''Saves model when validation loss decrease.'''\n","        if self.verbose:\n","            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n","        torch.save(model.state_dict(), self.path)\n","        self.val_loss_min = val_loss"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"tjGPuXgoqulz","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593324371395,"user_tz":180,"elapsed":24120,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["def Accuracy(prediction, observation):\n","  prediction = prediction[:,1]\n","  prediction_class = (torch.reshape(prediction, observation.shape) > 0.5).float()\n","  correct = (prediction_class == observation).float().sum()\n","  accuracy = correct/prediction_class.shape[0]\n","  return float(accuracy.cpu())\n","\n","def Precision(prediction, observation):\n","  prediction = prediction[:,1]\n","  res = []\n","  prediction_class = (torch.reshape(prediction, observation.shape) > 0.5).float()\n","  for label in [0, 1]:\n","    correct = (prediction_class[prediction_class == label] == observation[prediction_class == label]).float().sum()\n","    precision = correct/prediction_class[prediction_class == label].shape[0]\n","    res.append(float(precision.cpu()))\n","  return res\n","\n","def Recall(prediction, observation):\n","  prediction = prediction[:,1]\n","  res = []\n","  prediction_class = (torch.reshape(prediction, observation.shape) > 0.5).float()\n","  for label in [0, 1]:\n","    correct = (prediction_class[observation == label] == observation[observation == label]).float().sum()\n","    recall = correct/prediction_class[observation == label].shape[0]\n","    res.append(float(recall.cpu()))\n","  return res"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"sgz5Ea8a1wKr","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593324372265,"user_tz":180,"elapsed":24984,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["n_split = 3"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"cutkFU0k1Pkv","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593324372266,"user_tz":180,"elapsed":24980,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["import pickle\n","import pandas as pd\n","import numpy as np"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"wSJO5A951VXh","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593324373604,"user_tz":180,"elapsed":26311,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["with open('/content/drive/My Drive/Data Master/X_train_final', 'rb') as file:\n","    X_train = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/Y_train_final', 'rb') as file:\n","    Y_train = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/X_test_final', 'rb') as file:\n","    X_test = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/Y_test_final', 'rb') as file:\n","    Y_test = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/word_index_final', 'rb') as file:\n","    word_index = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/train_index_final_split_' + str(n_split), 'rb') as file:\n","    train_index = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/valid_index_final_split_' + str(n_split), 'rb') as file:\n","    valid_index = pickle.load(file)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"_v0BS5Cp_06s","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593324373605,"user_tz":180,"elapsed":26307,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["test_index = [i for i, _ in enumerate(X_test)]"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"NGqLg8IllrZE","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593324373605,"user_tz":180,"elapsed":26303,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["inv_word_index = {ix : w for w, ix in word_index.items()}"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"1-2YPzNN1x5T","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593324378805,"user_tz":180,"elapsed":31497,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["import itertools\n","features_index = {w:ix for ix, w in enumerate(np.unique(list(itertools.chain.from_iterable(np.array(X_train)[train_index]))))}\n","inv_features_index = {ix:w for ix, w in enumerate(np.unique(list(itertools.chain.from_iterable(np.array(X_train)[train_index]))))}"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"RxZWUTIv4K5T","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593324380182,"user_tz":180,"elapsed":32870,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["X_train_matrix = np.zeros((len(X_train), len(features_index)))\n","X_test_matrix = np.zeros((len(X_test), len(features_index)))"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"K6KzJuIy4dN8","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593324398101,"user_tz":180,"elapsed":50784,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["for i, x in enumerate(X_train):\n","  for w in x:\n","    if w in features_index:\n","      X_train_matrix[i,features_index[w]] += 1\n","\n","for i, x in enumerate(X_test):\n","  for w in x:\n","    if w in features_index:\n","      X_test_matrix[i,features_index[w]] += 1"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"9d4attfQ0i-Q","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593324398102,"user_tz":180,"elapsed":50781,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"twcFT-Hl3fqP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593324398104,"user_tz":180,"elapsed":50777,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"4c3cbf5a-e39e-4bd2-acd5-e4678aae127d"},"source":["input_dim = X_train_matrix.shape[1]\n","input_dim"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["245166"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"9fbXl191nZhK","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593324398105,"user_tz":180,"elapsed":50772,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["class LogisticRegression (nn.Module):\n","\n","  def __init__(self):\n","    super(LogisticRegression, self).__init__()\n","\n","    self.fc1 = nn.Linear(input_dim, 2)\n","                                \n","    self.softmax = nn.Softmax(dim=1)\n","\n","  def forward(self, x):\n","    x = F.normalize(x)\n","    y = self.softmax(self.fc1(x))\n","\n","    return y"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"Cgzf7IEqnyN4","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593324398105,"user_tz":180,"elapsed":50767,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["model = LogisticRegression()"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"0rnUcqchBE91","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593324399952,"user_tz":180,"elapsed":52610,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["X_train_tensor = torch.from_numpy(X_train_matrix[train_index]).float()\n","Y_train_tensor = torch.LongTensor(np.array(Y_train[train_index]))\n","\n","X_valid_tensor = torch.from_numpy(X_train_matrix[valid_index]).float()\n","Y_valid_tensor = torch.LongTensor(np.array(Y_train[valid_index]))\n","\n","X_test_tensor = torch.from_numpy(X_test_matrix).float()\n","Y_test_tensor = torch.LongTensor(np.array(Y_test))"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"GlP5dzFET5tF","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593324399953,"user_tz":180,"elapsed":52606,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["torch.manual_seed(0)\n","np.random.seed(0)"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"SV0Da5qu98-C","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593324399954,"user_tz":180,"elapsed":52603,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["import torch.optim as optim\n","optimizer = optim.AdamW(model.parameters(), lr=0.01)"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"gHujp4Ww_ZuO","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593324399954,"user_tz":180,"elapsed":52598,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["from torch.optim.lr_scheduler import ReduceLROnPlateau\n","scheduler = ReduceLROnPlateau(optimizer, 'min')"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"qkfeoTBHRuOb","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593324399955,"user_tz":180,"elapsed":52595,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"50f63d8a-9a89-48d0-a340-2c63b0ee8383"},"source":["weights = [sum(Y_train)/len(Y_train), 1-sum(Y_train)/len(Y_train)]\n","class_weights = torch.FloatTensor(weights)\n","class_weights"],"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0.1734, 0.8266])"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"8-F96WAE98zI","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593324399955,"user_tz":180,"elapsed":52589,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["criterion = nn.CrossEntropyLoss(weight=class_weights)"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"E7KgiIq398rR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1593324530315,"user_tz":180,"elapsed":182944,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"1a2d2e40-e82e-4da6-debe-a6dc951f160a"},"source":["patience = 20\n","early_stopping = EarlyStopping(patience=patience, verbose=True)\n","\n","for i in range(100):\n","  model.train()\n","  optimizer.zero_grad()\n","  prediction = model(X_train_tensor)\n","  loss = criterion(prediction, Y_train_tensor)\n","  loss.backward()\n","  optimizer.step()\n","\n","  accuracy = Accuracy(prediction, Y_train_tensor)\n","\n","  model.eval()\n","\n","  val_prediction = model(X_valid_tensor)\n","  test_prediction = model(X_test_tensor)\n","  val_loss = criterion(val_prediction, Y_valid_tensor)\n","  test_loss = criterion(test_prediction, Y_test_tensor)\n","\n","  val_accuracy = Accuracy(val_prediction, Y_valid_tensor)\n","  test_accuracy = Accuracy(test_prediction, Y_test_tensor)\n","\n","  early_stopping(val_loss, model)\n","\n","  if early_stopping.early_stop:\n","    print(\"Early stopping\")\n","    break\n","\n","  print(i, float(loss.cpu()), accuracy, float(val_loss.cpu()), val_accuracy, float(test_loss.cpu()), test_accuracy)\n","\n","  scheduler.step(val_loss)\n","\n","model.load_state_dict(torch.load('checkpoint.pt'))"],"execution_count":22,"outputs":[{"output_type":"stream","text":["Validation loss decreased (inf --> 0.685889).  Saving model ...\n","0 0.6931992769241333 0.17323943972587585 0.685889482498169 0.8707864880561829 0.6862495541572571 0.8897637724876404\n","Validation loss decreased (0.685889 --> 0.678743).  Saving model ...\n","1 0.6806076169013977 0.9549295902252197 0.6787430644035339 0.932584285736084 0.6797298192977905 0.9081364870071411\n","Validation loss decreased (0.678743 --> 0.671719).  Saving model ...\n","2 0.6682475209236145 0.9647887349128723 0.6717190742492676 0.9213483333587646 0.6733886003494263 0.9055117964744568\n","Validation loss decreased (0.671719 --> 0.664831).  Saving model ...\n","3 0.6561485528945923 0.9690141081809998 0.6648309826850891 0.9101123809814453 0.6672104001045227 0.9028871655464172\n","Validation loss decreased (0.664831 --> 0.658093).  Saving model ...\n","4 0.6443424224853516 0.9647887349128723 0.6580925583839417 0.9101123809814453 0.6611943244934082 0.8976377844810486\n","Validation loss decreased (0.658093 --> 0.651520).  Saving model ...\n","5 0.6328562498092651 0.9661971926689148 0.6515201926231384 0.9213483333587646 0.6553446054458618 0.8976377844810486\n","Validation loss decreased (0.651520 --> 0.645130).  Saving model ...\n","6 0.6217127442359924 0.9661971926689148 0.645130455493927 0.9213483333587646 0.6496676802635193 0.8923884630203247\n","Validation loss decreased (0.645130 --> 0.638941).  Saving model ...\n","7 0.6109273433685303 0.9647887349128723 0.6389408111572266 0.9213483333587646 0.6441709399223328 0.8897637724876404\n","Validation loss decreased (0.638941 --> 0.632964).  Saving model ...\n","8 0.600511908531189 0.9647887349128723 0.6329643130302429 0.9213483333587646 0.6388620734214783 0.8897637724876404\n","Validation loss decreased (0.632964 --> 0.627210).  Saving model ...\n","9 0.5904732346534729 0.9647887349128723 0.6272097229957581 0.9213483333587646 0.6337487101554871 0.8897637724876404\n","Validation loss decreased (0.627210 --> 0.621678).  Saving model ...\n","10 0.5808159112930298 0.9647887349128723 0.6216781735420227 0.9213483333587646 0.6288354992866516 0.8897637724876404\n","Validation loss decreased (0.621678 --> 0.616365).  Saving model ...\n","11 0.5715416669845581 0.9647887349128723 0.6163648962974548 0.9213483333587646 0.6241228580474854 0.8897637724876404\n","Validation loss decreased (0.616365 --> 0.611258).  Saving model ...\n","12 0.5626503229141235 0.9661971926689148 0.6112584471702576 0.9213483333587646 0.6196058988571167 0.8923884630203247\n","Validation loss decreased (0.611258 --> 0.606347).  Saving model ...\n","13 0.5541362762451172 0.9661971926689148 0.6063466668128967 0.9213483333587646 0.6152766942977905 0.8923884630203247\n","Validation loss decreased (0.606347 --> 0.601619).  Saving model ...\n","14 0.5459935665130615 0.9661971926689148 0.6016188263893127 0.9213483333587646 0.6111257672309875 0.8923884630203247\n","Validation loss decreased (0.601619 --> 0.597069).  Saving model ...\n","15 0.5382117033004761 0.9661971926689148 0.5970689654350281 0.9213483333587646 0.6071469187736511 0.8923884630203247\n","Validation loss decreased (0.597069 --> 0.592696).  Saving model ...\n","16 0.5307800769805908 0.9676056504249573 0.5926957726478577 0.9213483333587646 0.6033342480659485 0.8923884630203247\n","Validation loss decreased (0.592696 --> 0.588502).  Saving model ...\n","17 0.5236883759498596 0.9676056504249573 0.5885016918182373 0.9213483333587646 0.5996853113174438 0.8923884630203247\n","Validation loss decreased (0.588502 --> 0.584492).  Saving model ...\n","18 0.5169238448143005 0.9676056504249573 0.5844916105270386 0.9213483333587646 0.5961976647377014 0.8923884630203247\n","Validation loss decreased (0.584492 --> 0.580669).  Saving model ...\n","19 0.5104739665985107 0.9704225063323975 0.5806688070297241 0.9213483333587646 0.5928704738616943 0.8923884630203247\n","Validation loss decreased (0.580669 --> 0.577033).  Saving model ...\n","20 0.5043237805366516 0.9704225063323975 0.5770331025123596 0.9213483333587646 0.589699923992157 0.8923884630203247\n","Validation loss decreased (0.577033 --> 0.573580).  Saving model ...\n","21 0.498460590839386 0.9718309640884399 0.5735798478126526 0.9213483333587646 0.5866807699203491 0.8950130939483643\n","Validation loss decreased (0.573580 --> 0.570298).  Saving model ...\n","22 0.49287018179893494 0.9732394218444824 0.5702980160713196 0.9213483333587646 0.5838053822517395 0.8976377844810486\n","Validation loss decreased (0.570298 --> 0.567174).  Saving model ...\n","23 0.48753827810287476 0.9746478796005249 0.5671743750572205 0.9213483333587646 0.5810627341270447 0.9002624750137329\n","Validation loss decreased (0.567174 --> 0.564194).  Saving model ...\n","24 0.4824525713920593 0.9760563373565674 0.5641942024230957 0.9213483333587646 0.5784425735473633 0.9002624750137329\n","Validation loss decreased (0.564194 --> 0.561344).  Saving model ...\n","25 0.47760000824928284 0.9760563373565674 0.5613440275192261 0.9213483333587646 0.5759340524673462 0.9002624750137329\n","Validation loss decreased (0.561344 --> 0.558615).  Saving model ...\n","26 0.4729677140712738 0.9760563373565674 0.5586145520210266 0.9213483333587646 0.5735299587249756 0.9002624750137329\n","Validation loss decreased (0.558615 --> 0.556000).  Saving model ...\n","27 0.46854323148727417 0.9774647951126099 0.5560002326965332 0.9213483333587646 0.5712243914604187 0.9028871655464172\n","Validation loss decreased (0.556000 --> 0.553500).  Saving model ...\n","28 0.46431514620780945 0.9788732528686523 0.5535004138946533 0.9213483333587646 0.5690146684646606 0.9028871655464172\n","Validation loss decreased (0.553500 --> 0.551116).  Saving model ...\n","29 0.46027296781539917 0.9788732528686523 0.5511158108711243 0.9213483333587646 0.5668989419937134 0.9055117964744568\n","Validation loss decreased (0.551116 --> 0.548848).  Saving model ...\n","30 0.4564061164855957 0.9788732528686523 0.5488476157188416 0.9213483333587646 0.5648767352104187 0.9055117964744568\n","Validation loss decreased (0.548848 --> 0.546695).  Saving model ...\n","31 0.45270484685897827 0.9788732528686523 0.546695351600647 0.9213483333587646 0.562945544719696 0.9028871655464172\n","Validation loss decreased (0.546695 --> 0.544656).  Saving model ...\n","32 0.4491594731807709 0.9788732528686523 0.5446564555168152 0.9213483333587646 0.561103105545044 0.9055117964744568\n","Validation loss decreased (0.544656 --> 0.542725).  Saving model ...\n","33 0.44576165080070496 0.9802817106246948 0.5427246689796448 0.9213483333587646 0.559344470500946 0.9055117964744568\n","Validation loss decreased (0.542725 --> 0.540891).  Saving model ...\n","34 0.44250285625457764 0.9816901683807373 0.5408908724784851 0.9269663095474243 0.5576630234718323 0.9055117964744568\n","Validation loss decreased (0.540891 --> 0.539146).  Saving model ...\n","35 0.4393754005432129 0.983098566532135 0.5391455292701721 0.9269663095474243 0.5560518503189087 0.9081364870071411\n","Validation loss decreased (0.539146 --> 0.537480).  Saving model ...\n","36 0.43637245893478394 0.983098566532135 0.5374798774719238 0.9269663095474243 0.5545053482055664 0.9081364870071411\n","Validation loss decreased (0.537480 --> 0.535885).  Saving model ...\n","37 0.43348702788352966 0.983098566532135 0.5358853936195374 0.9269663095474243 0.5530176758766174 0.9081364870071411\n","Validation loss decreased (0.535885 --> 0.534358).  Saving model ...\n","38 0.43071210384368896 0.9845070242881775 0.5343579649925232 0.9269663095474243 0.5515848398208618 0.9081364870071411\n","Validation loss decreased (0.534358 --> 0.532895).  Saving model ...\n","39 0.4280429780483246 0.9845070242881775 0.5328950881958008 0.9269663095474243 0.5502046942710876 0.9081364870071411\n","Validation loss decreased (0.532895 --> 0.531497).  Saving model ...\n","40 0.42547282576560974 0.9845070242881775 0.531496524810791 0.9269663095474243 0.5488767623901367 0.9081364870071411\n","Validation loss decreased (0.531497 --> 0.530164).  Saving model ...\n","41 0.4229980707168579 0.9845070242881775 0.5301635265350342 0.9269663095474243 0.5476004481315613 0.9081364870071411\n","Validation loss decreased (0.530164 --> 0.528896).  Saving model ...\n","42 0.42061176896095276 0.9845070242881775 0.5288958549499512 0.9269663095474243 0.5463759899139404 0.9081364870071411\n","Validation loss decreased (0.528896 --> 0.527694).  Saving model ...\n","43 0.41831183433532715 0.9845070242881775 0.5276938080787659 0.9269663095474243 0.5452030301094055 0.9081364870071411\n","Validation loss decreased (0.527694 --> 0.526555).  Saving model ...\n","44 0.4160919785499573 0.9845070242881775 0.5265548229217529 0.9269663095474243 0.5440794229507446 0.9081364870071411\n","Validation loss decreased (0.526555 --> 0.525474).  Saving model ...\n","45 0.4139488935470581 0.9845070242881775 0.525474488735199 0.9269663095474243 0.5430013537406921 0.9107611775398254\n","Validation loss decreased (0.525474 --> 0.524448).  Saving model ...\n","46 0.4118795394897461 0.9887323975563049 0.5244483947753906 0.9269663095474243 0.5419673323631287 0.9107611775398254\n","Validation loss decreased (0.524448 --> 0.523470).  Saving model ...\n","47 0.40987926721572876 0.9887323975563049 0.5234700441360474 0.9269663095474243 0.5409724712371826 0.913385808467865\n","Validation loss decreased (0.523470 --> 0.522534).  Saving model ...\n","48 0.40794622898101807 0.9873239398002625 0.5225343704223633 0.9269663095474243 0.5400125980377197 0.913385808467865\n","Validation loss decreased (0.522534 --> 0.521638).  Saving model ...\n","49 0.40607595443725586 0.9873239398002625 0.521638035774231 0.9269663095474243 0.5390865206718445 0.913385808467865\n","Validation loss decreased (0.521638 --> 0.520778).  Saving model ...\n","50 0.4042662978172302 0.9887323975563049 0.5207775831222534 0.9269663095474243 0.5381905436515808 0.9160104990005493\n","Validation loss decreased (0.520778 --> 0.519953).  Saving model ...\n","51 0.40251481533050537 0.9887323975563049 0.519952654838562 0.9269663095474243 0.5373254418373108 0.9160104990005493\n","Validation loss decreased (0.519953 --> 0.519163).  Saving model ...\n","52 0.400818407535553 0.9887323975563049 0.5191627740859985 0.9269663095474243 0.5364903807640076 0.9160104990005493\n","Validation loss decreased (0.519163 --> 0.518409).  Saving model ...\n","53 0.39917513728141785 0.9901408553123474 0.5184088349342346 0.9269663095474243 0.5356845855712891 0.9160104990005493\n","Validation loss decreased (0.518409 --> 0.517691).  Saving model ...\n","54 0.39758241176605225 0.9901408553123474 0.5176910758018494 0.9269663095474243 0.5349098443984985 0.9160104990005493\n","Validation loss decreased (0.517691 --> 0.517009).  Saving model ...\n","55 0.3960385024547577 0.9915493130683899 0.5170087218284607 0.9269663095474243 0.5341647863388062 0.9160104990005493\n","Validation loss decreased (0.517009 --> 0.516361).  Saving model ...\n","56 0.39454102516174316 0.9929577708244324 0.5163606405258179 0.9269663095474243 0.5334489345550537 0.9186351895332336\n","Validation loss decreased (0.516361 --> 0.515745).  Saving model ...\n","57 0.39308780431747437 0.9929577708244324 0.5157446265220642 0.9269663095474243 0.5327597260475159 0.9186351895332336\n","Validation loss decreased (0.515745 --> 0.515158).  Saving model ...\n","58 0.3916780948638916 0.9943661689758301 0.5151575207710266 0.9269663095474243 0.5320963859558105 0.9186351895332336\n","Validation loss decreased (0.515158 --> 0.514596).  Saving model ...\n","59 0.3903089165687561 0.9943661689758301 0.5145964026451111 0.9269663095474243 0.5314563512802124 0.9186351895332336\n","Validation loss decreased (0.514596 --> 0.514058).  Saving model ...\n","60 0.3889797329902649 0.9943661689758301 0.514057993888855 0.9269663095474243 0.5308366417884827 0.9186351895332336\n","Validation loss decreased (0.514058 --> 0.513540).  Saving model ...\n","61 0.3876880705356598 0.9943661689758301 0.5135399699211121 0.9269663095474243 0.5302370190620422 0.9186351895332336\n","Validation loss decreased (0.513540 --> 0.513041).  Saving model ...\n","62 0.3864332139492035 0.9957746267318726 0.5130409002304077 0.9269663095474243 0.5296554565429688 0.9186351895332336\n","Validation loss decreased (0.513041 --> 0.512560).  Saving model ...\n","63 0.38521289825439453 0.9957746267318726 0.5125601887702942 0.9269663095474243 0.5290920734405518 0.9186351895332336\n","Validation loss decreased (0.512560 --> 0.512098).  Saving model ...\n","64 0.3840266764163971 0.9957746267318726 0.5120975375175476 0.9269663095474243 0.5285458564758301 0.9212598204612732\n","Validation loss decreased (0.512098 --> 0.511653).  Saving model ...\n","65 0.38287264108657837 0.9957746267318726 0.511653482913971 0.9269663095474243 0.5280175805091858 0.9212598204612732\n","Validation loss decreased (0.511653 --> 0.511228).  Saving model ...\n","66 0.381750226020813 0.9957746267318726 0.5112279057502747 0.9269663095474243 0.5275067090988159 0.9212598204612732\n","Validation loss decreased (0.511228 --> 0.510821).  Saving model ...\n","67 0.38065752387046814 0.9957746267318726 0.5108208060264587 0.932584285736084 0.5270140767097473 0.9212598204612732\n","Validation loss decreased (0.510821 --> 0.510432).  Saving model ...\n","68 0.37959349155426025 0.9957746267318726 0.5104315876960754 0.932584285736084 0.5265382528305054 0.9212598204612732\n","Validation loss decreased (0.510432 --> 0.510059).  Saving model ...\n","69 0.37855780124664307 0.997183084487915 0.5100588798522949 0.9382022619247437 0.5260785818099976 0.9212598204612732\n","Validation loss decreased (0.510059 --> 0.509701).  Saving model ...\n","70 0.37754854559898376 0.997183084487915 0.509701132774353 0.9382022619247437 0.5256338715553284 0.9238845109939575\n","Validation loss decreased (0.509701 --> 0.509357).  Saving model ...\n","71 0.3765656650066376 0.997183084487915 0.5093570351600647 0.9382022619247437 0.5252029895782471 0.9238845109939575\n","Validation loss decreased (0.509357 --> 0.509025).  Saving model ...\n","72 0.37560734152793884 0.997183084487915 0.5090245604515076 0.9382022619247437 0.5247848033905029 0.9238845109939575\n","Validation loss decreased (0.509025 --> 0.508702).  Saving model ...\n","73 0.3746730089187622 0.997183084487915 0.5087022185325623 0.9382022619247437 0.5243784189224243 0.9238845109939575\n","Validation loss decreased (0.508702 --> 0.508389).  Saving model ...\n","74 0.37376222014427185 0.997183084487915 0.5083889365196228 0.9382022619247437 0.523982584476471 0.9238845109939575\n","Validation loss decreased (0.508389 --> 0.508085).  Saving model ...\n","75 0.37287360429763794 0.997183084487915 0.5080852508544922 0.9382022619247437 0.5235971808433533 0.9238845109939575\n","Validation loss decreased (0.508085 --> 0.507790).  Saving model ...\n","76 0.37200644612312317 0.997183084487915 0.5077900290489197 0.9382022619247437 0.5232212543487549 0.9265092015266418\n","Validation loss decreased (0.507790 --> 0.507503).  Saving model ...\n","77 0.371160626411438 0.997183084487915 0.5075033903121948 0.9382022619247437 0.5228563547134399 0.9265092015266418\n","Validation loss decreased (0.507503 --> 0.507226).  Saving model ...\n","78 0.37033477425575256 0.997183084487915 0.5072259902954102 0.9382022619247437 0.5225012898445129 0.9238845109939575\n","Validation loss decreased (0.507226 --> 0.506958).  Saving model ...\n","79 0.369528591632843 0.997183084487915 0.5069575905799866 0.9382022619247437 0.5221559405326843 0.9238845109939575\n","Validation loss decreased (0.506958 --> 0.506698).  Saving model ...\n","80 0.36874106526374817 0.997183084487915 0.5066978931427002 0.9438202381134033 0.521820604801178 0.9238845109939575\n","Validation loss decreased (0.506698 --> 0.506447).  Saving model ...\n","81 0.36797186732292175 0.997183084487915 0.5064465999603271 0.9438202381134033 0.5214946269989014 0.9238845109939575\n","Validation loss decreased (0.506447 --> 0.506203).  Saving model ...\n","82 0.3672204315662384 0.997183084487915 0.5062032341957092 0.9438202381134033 0.5211771726608276 0.9238845109939575\n","Validation loss decreased (0.506203 --> 0.505966).  Saving model ...\n","83 0.3664858937263489 0.997183084487915 0.5059663653373718 0.9438202381134033 0.5208680629730225 0.9238845109939575\n","Validation loss decreased (0.505966 --> 0.505736).  Saving model ...\n","84 0.365768164396286 0.997183084487915 0.5057356953620911 0.9438202381134033 0.5205667018890381 0.9238845109939575\n","Validation loss decreased (0.505736 --> 0.505510).  Saving model ...\n","85 0.36506620049476624 0.997183084487915 0.505510151386261 0.9438202381134033 0.5202719569206238 0.9238845109939575\n","Validation loss decreased (0.505510 --> 0.505289).  Saving model ...\n","86 0.3643799126148224 0.997183084487915 0.5052893757820129 0.9438202381134033 0.519983172416687 0.9238845109939575\n","Validation loss decreased (0.505289 --> 0.505073).  Saving model ...\n","87 0.3637087643146515 0.997183084487915 0.5050726532936096 0.9438202381134033 0.5197002291679382 0.9238845109939575\n","Validation loss decreased (0.505073 --> 0.504860).  Saving model ...\n","88 0.36305221915245056 0.997183084487915 0.5048600435256958 0.9438202381134033 0.5194233059883118 0.9238845109939575\n","Validation loss decreased (0.504860 --> 0.504652).  Saving model ...\n","89 0.3624098002910614 0.997183084487915 0.5046517252922058 0.9438202381134033 0.5191518664360046 0.9238845109939575\n","Validation loss decreased (0.504652 --> 0.504447).  Saving model ...\n","90 0.3617808222770691 0.997183084487915 0.504447340965271 0.9438202381134033 0.518885612487793 0.9238845109939575\n","Validation loss decreased (0.504447 --> 0.504247).  Saving model ...\n","91 0.36116576194763184 0.997183084487915 0.5042473673820496 0.9438202381134033 0.5186254382133484 0.9238845109939575\n","Validation loss decreased (0.504247 --> 0.504052).  Saving model ...\n","92 0.36056333780288696 0.997183084487915 0.504051685333252 0.9438202381134033 0.5183705687522888 0.9238845109939575\n","Validation loss decreased (0.504052 --> 0.503860).  Saving model ...\n","93 0.3599731922149658 0.997183084487915 0.503860354423523 0.9438202381134033 0.518121063709259 0.9238845109939575\n","Validation loss decreased (0.503860 --> 0.503673).  Saving model ...\n","94 0.3593956530094147 0.997183084487915 0.5036727786064148 0.9438202381134033 0.517876386642456 0.9238845109939575\n","Validation loss decreased (0.503673 --> 0.503489).  Saving model ...\n","95 0.35883012413978577 0.997183084487915 0.5034888982772827 0.9438202381134033 0.5176371932029724 0.9238845109939575\n","Validation loss decreased (0.503489 --> 0.503308).  Saving model ...\n","96 0.35827526450157166 0.997183084487915 0.5033084750175476 0.9438202381134033 0.5174015164375305 0.9238845109939575\n","Validation loss decreased (0.503308 --> 0.503131).  Saving model ...\n","97 0.35773250460624695 0.997183084487915 0.503131091594696 0.9438202381134033 0.5171704292297363 0.9238845109939575\n","Validation loss decreased (0.503131 --> 0.502956).  Saving model ...\n","98 0.35719966888427734 0.997183084487915 0.5029560923576355 0.9438202381134033 0.5169432759284973 0.9238845109939575\n","Validation loss decreased (0.502956 --> 0.502783).  Saving model ...\n","99 0.3566785454750061 0.997183084487915 0.5027832388877869 0.9438202381134033 0.5167192816734314 0.9238845109939575\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"erpioWsYtaUa","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"executionInfo":{"status":"ok","timestamp":1593324530316,"user_tz":180,"elapsed":182940,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"64eedeb6-87a2-4600-e264-3f1cea836c6a"},"source":["print(Precision(prediction, Y_train_tensor))\n","print(Precision(val_prediction, Y_valid_tensor))\n","print(Precision(test_prediction, Y_test_tensor))"],"execution_count":23,"outputs":[{"output_type":"stream","text":["[1.0, 0.984000027179718]\n","[0.9477124214172363, 0.9200000166893005]\n","[0.9365558624267578, 0.8399999737739563]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Qu2e4Qh38lp4","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"executionInfo":{"status":"ok","timestamp":1593324530316,"user_tz":180,"elapsed":182934,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"160c6b22-85d5-4ed9-900c-bea0f35cef0c"},"source":["print(Recall(prediction, Y_train_tensor))\n","print(Recall(val_prediction, Y_valid_tensor))\n","print(Recall(test_prediction, Y_test_tensor))"],"execution_count":24,"outputs":[{"output_type":"stream","text":["[0.9965928196907043, 1.0]\n","[0.9863945841789246, 0.7419354915618896]\n","[0.9748427867889404, 0.6666666865348816]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5IoA1jJGBW2Q","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"executionInfo":{"status":"ok","timestamp":1593324530317,"user_tz":180,"elapsed":182929,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"cc5ecb3b-9e5d-4959-ab19-2ea26849e45c"},"source":["print(Accuracy(prediction, Y_train_tensor))\n","print(Accuracy(val_prediction, Y_valid_tensor))\n","print(Accuracy(test_prediction, Y_test_tensor))"],"execution_count":25,"outputs":[{"output_type":"stream","text":["0.997183084487915\n","0.9438202381134033\n","0.9238845109939575\n"],"name":"stdout"}]}]}