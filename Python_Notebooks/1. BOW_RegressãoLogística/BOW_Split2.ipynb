{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Split2.ipynb","provenance":[{"file_id":"1ly17dl3w8rGXAPtd1owJFslx4RVJE78c","timestamp":1592607825372},{"file_id":"1VIBcIIFR_YFlSguO_JGlnJbFzyAcT6YH","timestamp":1592464333044},{"file_id":"1dZvMRgPPkRVGa_4BZ1Tvoom_U4pjwmRX","timestamp":1592435543596},{"file_id":"12Sf257YUAwzmSXOlE3llOhi0N1YVUbM7","timestamp":1583376883298}],"collapsed_sections":[],"authorship_tag":"ABX9TyM2P8R8HTs6q+kn+WGuDZpg"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"JQrQmaLj0UuZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607486763619,"user_tz":180,"elapsed":29637,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"b2f559d9-7e2d-45f1-d847-625ea9b66b47"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JjEPtibx-EJD","executionInfo":{"status":"ok","timestamp":1607486766238,"user_tz":180,"elapsed":32252,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["import numpy as np\n","import torch\n","\n","class EarlyStopping:\n","    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n","    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt'):\n","        \"\"\"\n","        Args:\n","            patience (int): How long to wait after last time validation loss improved.\n","                            Default: 7\n","            verbose (bool): If True, prints a message for each validation loss improvement. \n","                            Default: False\n","            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n","                            Default: 0\n","            path (str): Path for the checkpoint to be saved to.\n","                            Default: 'checkpoint.pt'\n","        \"\"\"\n","        self.patience = patience\n","        self.verbose = verbose\n","        self.counter = 0\n","        self.best_score = None\n","        self.early_stop = False\n","        self.val_loss_min = np.Inf\n","        self.delta = delta\n","        self.path = path\n","\n","    def __call__(self, val_loss, model):\n","\n","        score = -val_loss\n","\n","        if self.best_score is None:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model)\n","        elif score < self.best_score + self.delta:\n","            self.counter += 1\n","            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n","            if self.counter >= self.patience:\n","                self.early_stop = True\n","        else:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model)\n","            self.counter = 0\n","\n","    def save_checkpoint(self, val_loss, model):\n","        '''Saves model when validation loss decrease.'''\n","        if self.verbose:\n","            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n","        torch.save(model.state_dict(), self.path)\n","        self.val_loss_min = val_loss"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"tjGPuXgoqulz","executionInfo":{"status":"ok","timestamp":1607486766239,"user_tz":180,"elapsed":32251,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["def Accuracy(prediction, observation):\n","  prediction = prediction[:,1]\n","  prediction_class = (torch.reshape(prediction, observation.shape) > 0.5).float()\n","  correct = (prediction_class == observation).float().sum()\n","  accuracy = correct/prediction_class.shape[0]\n","  return float(accuracy.cpu())\n","\n","def Precision(prediction, observation):\n","  prediction = prediction[:,1]\n","  res = []\n","  prediction_class = (torch.reshape(prediction, observation.shape) > 0.5).float()\n","  for label in [0, 1]:\n","    correct = (prediction_class[prediction_class == label] == observation[prediction_class == label]).float().sum()\n","    precision = correct/prediction_class[prediction_class == label].shape[0]\n","    res.append(float(precision.cpu()))\n","  return res\n","\n","def Recall(prediction, observation):\n","  prediction = prediction[:,1]\n","  res = []\n","  prediction_class = (torch.reshape(prediction, observation.shape) > 0.5).float()\n","  for label in [0, 1]:\n","    correct = (prediction_class[observation == label] == observation[observation == label]).float().sum()\n","    recall = correct/prediction_class[observation == label].shape[0]\n","    res.append(float(recall.cpu()))\n","  return res"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"sgz5Ea8a1wKr","executionInfo":{"status":"ok","timestamp":1607486766240,"user_tz":180,"elapsed":32250,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["n_split = 2"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"cutkFU0k1Pkv","executionInfo":{"status":"ok","timestamp":1607486766241,"user_tz":180,"elapsed":32248,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["import pickle\n","import pandas as pd\n","import numpy as np"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"wSJO5A951VXh","executionInfo":{"status":"ok","timestamp":1607486772005,"user_tz":180,"elapsed":38010,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["with open('/content/drive/My Drive/Data Master/X_train_final', 'rb') as file:\n","    X_train = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/Y_train_final', 'rb') as file:\n","    Y_train = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/X_test_final', 'rb') as file:\n","    X_test = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/Y_test_final', 'rb') as file:\n","    Y_test = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/word_index_final', 'rb') as file:\n","    word_index = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/train_index_final_split_' + str(n_split), 'rb') as file:\n","    train_index = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/valid_index_final_split_' + str(n_split), 'rb') as file:\n","    valid_index = pickle.load(file)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"_v0BS5Cp_06s","executionInfo":{"status":"ok","timestamp":1607486772007,"user_tz":180,"elapsed":38010,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["test_index = [i for i, _ in enumerate(X_test)]"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"NGqLg8IllrZE","executionInfo":{"status":"ok","timestamp":1607486772007,"user_tz":180,"elapsed":38008,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["inv_word_index = {ix : w for w, ix in word_index.items()}"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"1-2YPzNN1x5T","executionInfo":{"status":"ok","timestamp":1607486776612,"user_tz":180,"elapsed":42612,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["import itertools\n","features_index = {w:ix for ix, w in enumerate(np.unique(list(itertools.chain.from_iterable(np.array(X_train)[train_index]))))}\n","inv_features_index = {ix:w for ix, w in enumerate(np.unique(list(itertools.chain.from_iterable(np.array(X_train)[train_index]))))}"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"RxZWUTIv4K5T","executionInfo":{"status":"ok","timestamp":1607486778294,"user_tz":180,"elapsed":44292,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["X_train_matrix = np.zeros((len(X_train), len(features_index)))\n","X_test_matrix = np.zeros((len(X_test), len(features_index)))"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"K6KzJuIy4dN8","executionInfo":{"status":"ok","timestamp":1607486796994,"user_tz":180,"elapsed":62990,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["for i, x in enumerate(X_train):\n","  for w in x:\n","    if w in features_index:\n","      X_train_matrix[i,features_index[w]] += 1\n","\n","for i, x in enumerate(X_test):\n","  for w in x:\n","    if w in features_index:\n","      X_test_matrix[i,features_index[w]] += 1"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"9d4attfQ0i-Q","executionInfo":{"status":"ok","timestamp":1607486796997,"user_tz":180,"elapsed":62991,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"twcFT-Hl3fqP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607486796998,"user_tz":180,"elapsed":62988,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"f0ecd90d-e493-4579-ea90-6e5fce7a0462"},"source":["input_dim = X_train_matrix.shape[1]\n","input_dim"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["248563"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"9fbXl191nZhK","executionInfo":{"status":"ok","timestamp":1607486796998,"user_tz":180,"elapsed":62986,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["class LogisticRegression (nn.Module):\n","\n","  def __init__(self):\n","    super(LogisticRegression, self).__init__()\n","\n","    self.fc1 = nn.Linear(input_dim, 2)\n","                                \n","    self.softmax = nn.Softmax(dim=1)\n","\n","  def forward(self, x):\n","    x = F.normalize(x)\n","    y = self.softmax(self.fc1(x))\n","\n","    return y"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"Cgzf7IEqnyN4","executionInfo":{"status":"ok","timestamp":1607486796999,"user_tz":180,"elapsed":62985,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["model = LogisticRegression()"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"0rnUcqchBE91","executionInfo":{"status":"ok","timestamp":1607486798461,"user_tz":180,"elapsed":64445,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["X_train_tensor = torch.from_numpy(X_train_matrix[train_index]).float()\n","Y_train_tensor = torch.LongTensor(np.array(Y_train[train_index]))\n","\n","X_valid_tensor = torch.from_numpy(X_train_matrix[valid_index]).float()\n","Y_valid_tensor = torch.LongTensor(np.array(Y_train[valid_index]))\n","\n","X_test_tensor = torch.from_numpy(X_test_matrix).float()\n","Y_test_tensor = torch.LongTensor(np.array(Y_test))"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"GlP5dzFET5tF","executionInfo":{"status":"ok","timestamp":1607486798465,"user_tz":180,"elapsed":64447,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["torch.manual_seed(0)\n","np.random.seed(0)"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"SV0Da5qu98-C","executionInfo":{"status":"ok","timestamp":1607486798465,"user_tz":180,"elapsed":64445,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["import torch.optim as optim\n","optimizer = optim.AdamW(model.parameters(), lr=0.01)"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"gHujp4Ww_ZuO","executionInfo":{"status":"ok","timestamp":1607486798466,"user_tz":180,"elapsed":64444,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["from torch.optim.lr_scheduler import ReduceLROnPlateau\n","scheduler = ReduceLROnPlateau(optimizer, 'min')"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"qkfeoTBHRuOb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607486798466,"user_tz":180,"elapsed":64440,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"f8fb660e-95a0-4a84-aa8a-885128f5c8eb"},"source":["weights = [sum(Y_train)/len(Y_train), 1-sum(Y_train)/len(Y_train)]\n","class_weights = torch.FloatTensor(weights)\n","class_weights"],"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0.1734, 0.8266])"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"8-F96WAE98zI","executionInfo":{"status":"ok","timestamp":1607486798467,"user_tz":180,"elapsed":64439,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["criterion = nn.CrossEntropyLoss(weight=class_weights)"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"E7KgiIq398rR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607486923623,"user_tz":180,"elapsed":189590,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"439430d9-1ebb-403b-b0bc-b86be88af206"},"source":["patience = 20\n","early_stopping = EarlyStopping(patience=patience, verbose=True)\n","\n","for i in range(100):\n","  model.train()\n","  optimizer.zero_grad()\n","  prediction = model(X_train_tensor)\n","  loss = criterion(prediction, Y_train_tensor)\n","  loss.backward()\n","  optimizer.step()\n","\n","  accuracy = Accuracy(prediction, Y_train_tensor)\n","\n","  model.eval()\n","\n","  val_prediction = model(X_valid_tensor)\n","  test_prediction = model(X_test_tensor)\n","  val_loss = criterion(val_prediction, Y_valid_tensor)\n","  test_loss = criterion(test_prediction, Y_test_tensor)\n","\n","  val_accuracy = Accuracy(val_prediction, Y_valid_tensor)\n","  test_accuracy = Accuracy(test_prediction, Y_test_tensor)\n","\n","  early_stopping(val_loss, model)\n","\n","  if early_stopping.early_stop:\n","    print(\"Early stopping\")\n","    break\n","\n","  print(i, float(loss.cpu()), accuracy, float(val_loss.cpu()), val_accuracy, float(test_loss.cpu()), test_accuracy)\n","\n","  scheduler.step(val_loss)\n","\n","model.load_state_dict(torch.load('checkpoint.pt'))"],"execution_count":22,"outputs":[{"output_type":"stream","text":["Validation loss decreased (inf --> 0.684869).  Saving model ...\n","0 0.6931418180465698 0.26760563254356384 0.6848694086074829 0.8932584524154663 0.6862788796424866 0.8792650699615479\n","Validation loss decreased (0.684869 --> 0.676664).  Saving model ...\n","1 0.680787980556488 0.9507042169570923 0.6766639351844788 0.9438202381134033 0.6798176169395447 0.9081364870071411\n","Validation loss decreased (0.676664 --> 0.668593).  Saving model ...\n","2 0.6686474084854126 0.9661971926689148 0.6685926914215088 0.932584285736084 0.6735280156135559 0.9186351895332336\n","Validation loss decreased (0.668593 --> 0.660681).  Saving model ...\n","3 0.6567561030387878 0.9718309640884399 0.6606810688972473 0.9269663095474243 0.6673928499221802 0.9107611775398254\n","Validation loss decreased (0.660681 --> 0.652949).  Saving model ...\n","4 0.645143449306488 0.9732394218444824 0.6529485583305359 0.9213483333587646 0.6614104509353638 0.9081364870071411\n","Validation loss decreased (0.652949 --> 0.645413).  Saving model ...\n","5 0.633833646774292 0.9690141081809998 0.6454131603240967 0.9101123809814453 0.655583918094635 0.9002624750137329\n","Validation loss decreased (0.645413 --> 0.638090).  Saving model ...\n","6 0.6228482723236084 0.9647887349128723 0.6380898356437683 0.9101123809814453 0.649917483329773 0.9002624750137329\n","Validation loss decreased (0.638090 --> 0.630990).  Saving model ...\n","7 0.6122035980224609 0.9633802771568298 0.6309895515441895 0.9101123809814453 0.6444138288497925 0.9002624750137329\n","Validation loss decreased (0.630990 --> 0.624122).  Saving model ...\n","8 0.6019106507301331 0.9647887349128723 0.6241219639778137 0.9101123809814453 0.6390821933746338 0.8976377844810486\n","Validation loss decreased (0.624122 --> 0.617494).  Saving model ...\n","9 0.5919778943061829 0.9661971926689148 0.617493748664856 0.9101123809814453 0.6339269876480103 0.8950130939483643\n","Validation loss decreased (0.617494 --> 0.611110).  Saving model ...\n","10 0.5824103355407715 0.9661971926689148 0.6111103892326355 0.9101123809814453 0.6289553046226501 0.8950130939483643\n","Validation loss decreased (0.611110 --> 0.604973).  Saving model ...\n","11 0.5732098817825317 0.9661971926689148 0.604973316192627 0.9101123809814453 0.6241700649261475 0.8950130939483643\n","Validation loss decreased (0.604973 --> 0.599081).  Saving model ...\n","12 0.5643767714500427 0.9661971926689148 0.5990809798240662 0.9101123809814453 0.6195699572563171 0.8950130939483643\n","Validation loss decreased (0.599081 --> 0.593428).  Saving model ...\n","13 0.5559083223342896 0.9661971926689148 0.5934277772903442 0.9101123809814453 0.6151506304740906 0.8950130939483643\n","Validation loss decreased (0.593428 --> 0.588009).  Saving model ...\n","14 0.547798752784729 0.9661971926689148 0.5880086421966553 0.9101123809814453 0.6109063625335693 0.8950130939483643\n","Validation loss decreased (0.588009 --> 0.582818).  Saving model ...\n","15 0.540040135383606 0.9661971926689148 0.582817554473877 0.9101123809814453 0.6068294048309326 0.8950130939483643\n","Validation loss decreased (0.582818 --> 0.577850).  Saving model ...\n","16 0.5326229929924011 0.9661971926689148 0.5778495073318481 0.9101123809814453 0.6029147505760193 0.8950130939483643\n","Validation loss decreased (0.577850 --> 0.573101).  Saving model ...\n","17 0.525536835193634 0.9676056504249573 0.5731011629104614 0.915730357170105 0.5991589426994324 0.8950130939483643\n","Validation loss decreased (0.573101 --> 0.568569).  Saving model ...\n","18 0.5187708735466003 0.9690141081809998 0.5685691833496094 0.915730357170105 0.5955585837364197 0.8950130939483643\n","Validation loss decreased (0.568569 --> 0.564250).  Saving model ...\n","19 0.5123133659362793 0.9704225063323975 0.5642502903938293 0.915730357170105 0.5921120047569275 0.8923884630203247\n","Validation loss decreased (0.564250 --> 0.560140).  Saving model ...\n","20 0.5061514973640442 0.9704225063323975 0.5601404309272766 0.915730357170105 0.5888171792030334 0.8923884630203247\n","Validation loss decreased (0.560140 --> 0.556233).  Saving model ...\n","21 0.5002719759941101 0.9704225063323975 0.5562334656715393 0.915730357170105 0.5856693983078003 0.8923884630203247\n","Validation loss decreased (0.556233 --> 0.552522).  Saving model ...\n","22 0.4946620762348175 0.9704225063323975 0.5525215864181519 0.915730357170105 0.582665205001831 0.8923884630203247\n","Validation loss decreased (0.552522 --> 0.548996).  Saving model ...\n","23 0.4893089532852173 0.9704225063323975 0.5489957332611084 0.915730357170105 0.5797971487045288 0.8897637724876404\n","Validation loss decreased (0.548996 --> 0.545645).  Saving model ...\n","24 0.48419949412345886 0.9718309640884399 0.5456445813179016 0.915730357170105 0.5770567059516907 0.8897637724876404\n","Validation loss decreased (0.545645 --> 0.542457).  Saving model ...\n","25 0.47932183742523193 0.9732394218444824 0.5424572825431824 0.915730357170105 0.574435830116272 0.8897637724876404\n","Validation loss decreased (0.542457 --> 0.539424).  Saving model ...\n","26 0.474663645029068 0.9746478796005249 0.5394235849380493 0.915730357170105 0.5719263553619385 0.8923884630203247\n","Validation loss decreased (0.539424 --> 0.536534).  Saving model ...\n","27 0.470213383436203 0.9746478796005249 0.5365344285964966 0.915730357170105 0.5695220232009888 0.8923884630203247\n","Validation loss decreased (0.536534 --> 0.533783).  Saving model ...\n","28 0.46595919132232666 0.9746478796005249 0.5337827205657959 0.915730357170105 0.5672176480293274 0.8923884630203247\n","Validation loss decreased (0.533783 --> 0.531163).  Saving model ...\n","29 0.4618915319442749 0.9746478796005249 0.5311627388000488 0.915730357170105 0.5650094747543335 0.8923884630203247\n","Validation loss decreased (0.531163 --> 0.528670).  Saving model ...\n","30 0.45799967646598816 0.9746478796005249 0.528670072555542 0.915730357170105 0.5628960728645325 0.8923884630203247\n","Validation loss decreased (0.528670 --> 0.526300).  Saving model ...\n","31 0.45427387952804565 0.9760563373565674 0.526300311088562 0.915730357170105 0.5608753561973572 0.8923884630203247\n","Validation loss decreased (0.526300 --> 0.524049).  Saving model ...\n","32 0.45070528984069824 0.9760563373565674 0.5240490436553955 0.915730357170105 0.5589441657066345 0.8923884630203247\n","Validation loss decreased (0.524049 --> 0.521911).  Saving model ...\n","33 0.44728484749794006 0.9774647951126099 0.5219108462333679 0.9213483333587646 0.5570998787879944 0.8923884630203247\n","Validation loss decreased (0.521911 --> 0.519880).  Saving model ...\n","34 0.4440050423145294 0.9788732528686523 0.5198795795440674 0.9269663095474243 0.5553385615348816 0.8923884630203247\n","Validation loss decreased (0.519880 --> 0.517948).  Saving model ...\n","35 0.44085732102394104 0.9788732528686523 0.5179482698440552 0.9269663095474243 0.5536544322967529 0.8923884630203247\n","Validation loss decreased (0.517948 --> 0.516110).  Saving model ...\n","36 0.4378359913825989 0.9788732528686523 0.5161096453666687 0.9269663095474243 0.5520427823066711 0.8923884630203247\n","Validation loss decreased (0.516110 --> 0.514357).  Saving model ...\n","37 0.43493324518203735 0.9802817106246948 0.5143566727638245 0.9269663095474243 0.5504973530769348 0.8950130939483643\n","Validation loss decreased (0.514357 --> 0.512683).  Saving model ...\n","38 0.43214213848114014 0.9802817106246948 0.5126827955245972 0.9269663095474243 0.5490134954452515 0.8976377844810486\n","Validation loss decreased (0.512683 --> 0.511083).  Saving model ...\n","39 0.42945852875709534 0.9802817106246948 0.5110829472541809 0.9269663095474243 0.5475873947143555 0.8976377844810486\n","Validation loss decreased (0.511083 --> 0.509553).  Saving model ...\n","40 0.4268759787082672 0.9816901683807373 0.5095528364181519 0.9269663095474243 0.5462163686752319 0.8976377844810486\n","Validation loss decreased (0.509553 --> 0.508089).  Saving model ...\n","41 0.4243885278701782 0.9845070242881775 0.5080893635749817 0.9269663095474243 0.544898509979248 0.8976377844810486\n","Validation loss decreased (0.508089 --> 0.506690).  Saving model ...\n","42 0.42199239134788513 0.9845070242881775 0.5066898465156555 0.9269663095474243 0.543632984161377 0.8976377844810486\n","Validation loss decreased (0.506690 --> 0.505353).  Saving model ...\n","43 0.4196828007698059 0.9845070242881775 0.5053526759147644 0.9269663095474243 0.5424185395240784 0.8976377844810486\n","Validation loss decreased (0.505353 --> 0.504075).  Saving model ...\n","44 0.4174549877643585 0.9845070242881775 0.5040746927261353 0.9269663095474243 0.5412543416023254 0.8976377844810486\n","Validation loss decreased (0.504075 --> 0.502854).  Saving model ...\n","45 0.41530537605285645 0.9845070242881775 0.5028541088104248 0.9269663095474243 0.5401381850242615 0.9028871655464172\n","Validation loss decreased (0.502854 --> 0.501687).  Saving model ...\n","46 0.4132293462753296 0.9845070242881775 0.5016866326332092 0.9269663095474243 0.5390675067901611 0.9055117964744568\n","Validation loss decreased (0.501687 --> 0.500569).  Saving model ...\n","47 0.41122445464134216 0.9845070242881775 0.5005688071250916 0.9269663095474243 0.5380397439002991 0.9055117964744568\n","Validation loss decreased (0.500569 --> 0.499497).  Saving model ...\n","48 0.4092872738838196 0.98591548204422 0.49949681758880615 0.9269663095474243 0.5370518565177917 0.9055117964744568\n","Validation loss decreased (0.499497 --> 0.498467).  Saving model ...\n","49 0.40741339325904846 0.98591548204422 0.4984666109085083 0.9269663095474243 0.5361003875732422 0.9055117964744568\n","Validation loss decreased (0.498467 --> 0.497475).  Saving model ...\n","50 0.40560078620910645 0.98591548204422 0.4974745512008667 0.9269663095474243 0.5351820588111877 0.9055117964744568\n","Validation loss decreased (0.497475 --> 0.496518).  Saving model ...\n","51 0.40384694933891296 0.98591548204422 0.4965183734893799 0.9269663095474243 0.5342958569526672 0.9081364870071411\n","Validation loss decreased (0.496518 --> 0.495595).  Saving model ...\n","52 0.4021487534046173 0.98591548204422 0.495595246553421 0.9269663095474243 0.5334393382072449 0.913385808467865\n","Validation loss decreased (0.495595 --> 0.494704).  Saving model ...\n","53 0.4005030393600464 0.98591548204422 0.49470439553260803 0.9269663095474243 0.532611608505249 0.913385808467865\n","Validation loss decreased (0.494704 --> 0.493844).  Saving model ...\n","54 0.3989093005657196 0.9873239398002625 0.49384433031082153 0.9269663095474243 0.5318126678466797 0.913385808467865\n","Validation loss decreased (0.493844 --> 0.493014).  Saving model ...\n","55 0.39736345410346985 0.98591548204422 0.49301400780677795 0.9269663095474243 0.5310415625572205 0.913385808467865\n","Validation loss decreased (0.493014 --> 0.492213).  Saving model ...\n","56 0.3958636522293091 0.98591548204422 0.49221301078796387 0.9269663095474243 0.530298113822937 0.913385808467865\n","Validation loss decreased (0.492213 --> 0.491440).  Saving model ...\n","57 0.39440852403640747 0.9873239398002625 0.4914399981498718 0.9269663095474243 0.5295811295509338 0.9160104990005493\n","Validation loss decreased (0.491440 --> 0.490693).  Saving model ...\n","58 0.3929968774318695 0.9873239398002625 0.4906933903694153 0.9269663095474243 0.5288898348808289 0.9160104990005493\n","Validation loss decreased (0.490693 --> 0.489971).  Saving model ...\n","59 0.39162522554397583 0.9873239398002625 0.48997101187705994 0.9269663095474243 0.5282219648361206 0.9160104990005493\n","Validation loss decreased (0.489971 --> 0.489271).  Saving model ...\n","60 0.3902930021286011 0.9887323975563049 0.48927146196365356 0.9269663095474243 0.5275769829750061 0.9160104990005493\n","Validation loss decreased (0.489271 --> 0.488593).  Saving model ...\n","61 0.3889976441860199 0.9915493130683899 0.4885927736759186 0.9269663095474243 0.5269521474838257 0.9186351895332336\n","Validation loss decreased (0.488593 --> 0.487933).  Saving model ...\n","62 0.38773882389068604 0.9915493130683899 0.4879330098628998 0.9269663095474243 0.5263461470603943 0.9186351895332336\n","Validation loss decreased (0.487933 --> 0.487291).  Saving model ...\n","63 0.3865143656730652 0.9915493130683899 0.48729071021080017 0.9269663095474243 0.5257582068443298 0.9186351895332336\n","Validation loss decreased (0.487291 --> 0.486665).  Saving model ...\n","64 0.38532301783561707 0.9915493130683899 0.48666512966156006 0.9269663095474243 0.5251866579055786 0.9186351895332336\n","Validation loss decreased (0.486665 --> 0.486056).  Saving model ...\n","65 0.3841632604598999 0.9915493130683899 0.4860555827617645 0.9269663095474243 0.5246313810348511 0.9186351895332336\n","Validation loss decreased (0.486056 --> 0.485461).  Saving model ...\n","66 0.38303473591804504 0.9915493130683899 0.48546144366264343 0.9269663095474243 0.5240921378135681 0.9186351895332336\n","Validation loss decreased (0.485461 --> 0.484882).  Saving model ...\n","67 0.3819349706172943 0.9915493130683899 0.4848824739456177 0.9269663095474243 0.5235684514045715 0.9212598204612732\n","Validation loss decreased (0.484882 --> 0.484319).  Saving model ...\n","68 0.3808639347553253 0.9915493130683899 0.48431891202926636 0.9269663095474243 0.5230602622032166 0.9212598204612732\n","Validation loss decreased (0.484319 --> 0.483770).  Saving model ...\n","69 0.3798202574253082 0.9929577708244324 0.4837697744369507 0.9269663095474243 0.522567629814148 0.9212598204612732\n","Validation loss decreased (0.483770 --> 0.483235).  Saving model ...\n","70 0.37880244851112366 0.9929577708244324 0.4832347631454468 0.9269663095474243 0.5220893025398254 0.9212598204612732\n","Validation loss decreased (0.483235 --> 0.482713).  Saving model ...\n","71 0.3778105676174164 0.9929577708244324 0.48271334171295166 0.9269663095474243 0.5216251611709595 0.9212598204612732\n","Validation loss decreased (0.482713 --> 0.482205).  Saving model ...\n","72 0.37684333324432373 0.9929577708244324 0.48220470547676086 0.9269663095474243 0.521173894405365 0.9212598204612732\n","Validation loss decreased (0.482205 --> 0.481708).  Saving model ...\n","73 0.37589868903160095 0.9929577708244324 0.4817076623439789 0.9269663095474243 0.5207356810569763 0.9212598204612732\n","Validation loss decreased (0.481708 --> 0.481221).  Saving model ...\n","74 0.37497755885124207 0.9943661689758301 0.481221467256546 0.9269663095474243 0.5203079581260681 0.9212598204612732\n","Validation loss decreased (0.481221 --> 0.480745).  Saving model ...\n","75 0.3740781545639038 0.9943661689758301 0.480745404958725 0.9269663095474243 0.5198912024497986 0.9212598204612732\n","Validation loss decreased (0.480745 --> 0.480279).  Saving model ...\n","76 0.373200386762619 0.9943661689758301 0.48027896881103516 0.9269663095474243 0.5194839239120483 0.9212598204612732\n","Validation loss decreased (0.480279 --> 0.479822).  Saving model ...\n","77 0.37234270572662354 0.9957746267318726 0.4798218309879303 0.9269663095474243 0.5190863609313965 0.9212598204612732\n","Validation loss decreased (0.479822 --> 0.479374).  Saving model ...\n","78 0.3715052306652069 0.9957746267318726 0.4793737828731537 0.9269663095474243 0.5186978578567505 0.9212598204612732\n","Validation loss decreased (0.479374 --> 0.478934).  Saving model ...\n","79 0.37068676948547363 0.9957746267318726 0.47893428802490234 0.9269663095474243 0.5183190107345581 0.9212598204612732\n","Validation loss decreased (0.478934 --> 0.478504).  Saving model ...\n","80 0.36988693475723267 0.9957746267318726 0.4785044193267822 0.9269663095474243 0.5179488658905029 0.9212598204612732\n","Validation loss decreased (0.478504 --> 0.478083).  Saving model ...\n","81 0.36910516023635864 0.9957746267318726 0.47808319330215454 0.9269663095474243 0.5175876617431641 0.9212598204612732\n","Validation loss decreased (0.478083 --> 0.477671).  Saving model ...\n","82 0.3683408796787262 0.9957746267318726 0.4776705503463745 0.9269663095474243 0.5172353982925415 0.9212598204612732\n","Validation loss decreased (0.477671 --> 0.477267).  Saving model ...\n","83 0.3675936758518219 0.9957746267318726 0.4772668182849884 0.9269663095474243 0.516891360282898 0.9212598204612732\n","Validation loss decreased (0.477267 --> 0.476871).  Saving model ...\n","84 0.36686277389526367 0.9957746267318726 0.476871132850647 0.9269663095474243 0.516555905342102 0.9212598204612732\n","Validation loss decreased (0.476871 --> 0.476483).  Saving model ...\n","85 0.3661476671695709 0.9957746267318726 0.47648337483406067 0.9269663095474243 0.5162276029586792 0.9212598204612732\n","Validation loss decreased (0.476483 --> 0.476103).  Saving model ...\n","86 0.3654482364654541 0.997183084487915 0.4761030673980713 0.9269663095474243 0.5159064531326294 0.9212598204612732\n","Validation loss decreased (0.476103 --> 0.475730).  Saving model ...\n","87 0.36476340889930725 0.997183084487915 0.4757298231124878 0.9269663095474243 0.5155919194221497 0.9212598204612732\n","Validation loss decreased (0.475730 --> 0.475363).  Saving model ...\n","88 0.36409351229667664 0.997183084487915 0.475363165140152 0.9269663095474243 0.5152837634086609 0.9212598204612732\n","Validation loss decreased (0.475363 --> 0.475003).  Saving model ...\n","89 0.3634374737739563 0.997183084487915 0.4750029742717743 0.9269663095474243 0.5149810910224915 0.9212598204612732\n","Validation loss decreased (0.475003 --> 0.474649).  Saving model ...\n","90 0.362795352935791 0.997183084487915 0.47464898228645325 0.932584285736084 0.5146846175193787 0.9212598204612732\n","Validation loss decreased (0.474649 --> 0.474301).  Saving model ...\n","91 0.3621664047241211 0.997183084487915 0.47430121898651123 0.932584285736084 0.5143930912017822 0.9212598204612732\n","Validation loss decreased (0.474301 --> 0.473960).  Saving model ...\n","92 0.36155039072036743 0.997183084487915 0.4739598333835602 0.932584285736084 0.5141074061393738 0.9212598204612732\n","Validation loss decreased (0.473960 --> 0.473624).  Saving model ...\n","93 0.3609466254711151 0.997183084487915 0.47362416982650757 0.932584285736084 0.5138270258903503 0.9212598204612732\n","Validation loss decreased (0.473624 --> 0.473295).  Saving model ...\n","94 0.3603556454181671 0.997183084487915 0.4732949435710907 0.932584285736084 0.513551652431488 0.9238845109939575\n","Validation loss decreased (0.473295 --> 0.472972).  Saving model ...\n","95 0.3597765862941742 0.997183084487915 0.472971647977829 0.932584285736084 0.513282060623169 0.9238845109939575\n","Validation loss decreased (0.472972 --> 0.472654).  Saving model ...\n","96 0.3592089116573334 0.997183084487915 0.4726543128490448 0.932584285736084 0.5130171179771423 0.9238845109939575\n","Validation loss decreased (0.472654 --> 0.472343).  Saving model ...\n","97 0.35865259170532227 0.997183084487915 0.47234269976615906 0.932584285736084 0.5127570629119873 0.9238845109939575\n","Validation loss decreased (0.472343 --> 0.472037).  Saving model ...\n","98 0.3581071197986603 0.997183084487915 0.4720366299152374 0.932584285736084 0.5125018358230591 0.9238845109939575\n","Validation loss decreased (0.472037 --> 0.471736).  Saving model ...\n","99 0.3575723469257355 0.997183084487915 0.47173622250556946 0.932584285736084 0.5122507214546204 0.9238845109939575\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"erpioWsYtaUa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607486923624,"user_tz":180,"elapsed":189587,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"3b07c55b-004b-45fd-9ce2-41bcdd54fbe8"},"source":["print(Precision(prediction, Y_train_tensor))\n","print(Precision(val_prediction, Y_valid_tensor))\n","print(Precision(test_prediction, Y_test_tensor))"],"execution_count":23,"outputs":[{"output_type":"stream","text":["[1.0, 0.984000027179718]\n","[0.9591836929321289, 0.8064516186714172]\n","[0.9418960213661194, 0.8148148059844971]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Qu2e4Qh38lp4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607486923624,"user_tz":180,"elapsed":189583,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"fe6e24e3-59b1-4def-fe29-6feef30b5582"},"source":["print(Recall(prediction, Y_train_tensor))\n","print(Recall(val_prediction, Y_valid_tensor))\n","print(Recall(test_prediction, Y_test_tensor))"],"execution_count":24,"outputs":[{"output_type":"stream","text":["[0.9965928196907043, 1.0]\n","[0.9591836929321289, 0.8064516186714172]\n","[0.9685534834861755, 0.6984127163887024]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5IoA1jJGBW2Q","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607486923625,"user_tz":180,"elapsed":189578,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"fd5e37d0-0ae7-4833-820f-c0ed5ceda7c8"},"source":["print(Accuracy(prediction, Y_train_tensor))\n","print(Accuracy(val_prediction, Y_valid_tensor))\n","print(Accuracy(test_prediction, Y_test_tensor))"],"execution_count":25,"outputs":[{"output_type":"stream","text":["0.997183084487915\n","0.932584285736084\n","0.9238845109939575\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"z6-Ut1YrrM43","executionInfo":{"status":"ok","timestamp":1607486923626,"user_tz":180,"elapsed":189578,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["with open('/content/drive/My Drive/Data Master/Prediction_BOW_RegressaoLogistica/test_prediction_split' + str(n_split), 'wb') as file:\n","    pickle.dump(test_prediction.detach().numpy(), file)"],"execution_count":26,"outputs":[]}]}