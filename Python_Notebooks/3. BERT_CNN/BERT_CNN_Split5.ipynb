{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of FineTuned_Split5.ipynb","provenance":[{"file_id":"1iEtoUyt4l6WoYZKnFY4vMwGIaInqm1Z7","timestamp":1592589760254},{"file_id":"1jM_MQeWnqB4LrmlAc_rZ00W9zJK7Hw_d","timestamp":1590464112416}],"collapsed_sections":[],"authorship_tag":"ABX9TyMfRp/2J2IfZUPYHrDtz8nc"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"KWy32B6i5zUX","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593670219844,"user_tz":180,"elapsed":1096,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"d1c2b1a0-bd39-45a9-8ffc-15b031572dc5"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IUvtjwnKQx0R","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593670220568,"user_tz":180,"elapsed":1817,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["import numpy as np\n","import torch\n","\n","class EarlyStopping:\n","    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n","    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt'):\n","        \"\"\"\n","        Args:\n","            patience (int): How long to wait after last time validation loss improved.\n","                            Default: 7\n","            verbose (bool): If True, prints a message for each validation loss improvement. \n","                            Default: False\n","            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n","                            Default: 0\n","            path (str): Path for the checkpoint to be saved to.\n","                            Default: 'checkpoint.pt'\n","        \"\"\"\n","        self.patience = patience\n","        self.verbose = verbose\n","        self.counter = 0\n","        self.best_score = None\n","        self.early_stop = False\n","        self.val_loss_min = np.Inf\n","        self.delta = delta\n","        self.path = path\n","\n","    def __call__(self, val_loss, model):\n","\n","        score = -val_loss\n","\n","        if self.best_score is None:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model)\n","        elif score < self.best_score + self.delta:\n","            self.counter += 1\n","            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n","            if self.counter >= self.patience:\n","                self.early_stop = True\n","        else:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model)\n","            self.counter = 0\n","\n","    def save_checkpoint(self, val_loss, model):\n","        '''Saves model when validation loss decrease.'''\n","        if self.verbose:\n","            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n","        torch.save(model.state_dict(), self.path)\n","        self.val_loss_min = val_loss"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"WtPr52JNXzXL","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593670220569,"user_tz":180,"elapsed":1815,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["def Accuracy(prediction, observation):\n","  prediction = prediction[:,1]\n","  prediction_class = (torch.reshape(prediction, observation.shape) > 0.5).float()\n","  correct = (prediction_class == observation).float().sum()\n","  accuracy = correct/prediction_class.shape[0]\n","  return float(accuracy.cpu())\n","\n","def Precision(prediction, observation):\n","  prediction = prediction[:,1]\n","  res = []\n","  prediction_class = (torch.reshape(prediction, observation.shape) > 0.5).float()\n","  for label in [0, 1]:\n","    correct = (prediction_class[prediction_class == label] == observation[prediction_class == label]).float().sum()\n","    precision = correct/prediction_class[prediction_class == label].shape[0]\n","    res.append(float(precision.cpu()))\n","  return res\n","\n","def Recall(prediction, observation):\n","  prediction = prediction[:,1]\n","  res = []\n","  prediction_class = (torch.reshape(prediction, observation.shape) > 0.5).float()\n","  for label in [0, 1]:\n","    correct = (prediction_class[observation == label] == observation[observation == label]).float().sum()\n","    recall = correct/prediction_class[observation == label].shape[0]\n","    res.append(float(recall.cpu()))\n","  return res"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"tLrptDIu6E6A","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593670220570,"user_tz":180,"elapsed":1814,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["n_split = 5"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"uCC2fopD6JTj","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593670220570,"user_tz":180,"elapsed":1811,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["import pickle\n","import numpy as np"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"LXHTiUtW6MJX","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593670225367,"user_tz":180,"elapsed":6606,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["with open('/content/drive/My Drive/Data Master/X_train_final', 'rb') as file:\n","    X_train = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/Y_train_final', 'rb') as file:\n","    Y_train = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/X_test_final', 'rb') as file:\n","    X_test = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/Y_test_final', 'rb') as file:\n","    Y_test = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/word_index_final', 'rb') as file:\n","    word_index = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/train_last_layer_embeddings_tail_fine_tuned_split' + str(n_split) + '.pkl', 'rb') as file:\n","    train_last_layer_embeddings = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/train_all_layers_embeddings_tail_fine_tuned_split' + str(n_split) + '.pkl', 'rb') as file:\n","    train_all_layers_embeddings = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/train_cls_token_embeddings_tail_fine_tuned_split' + str(n_split) + '.pkl', 'rb') as file:\n","    train_cls_token_embeddings = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/test_last_layer_embeddings_tail_fine_tuned_split' + str(n_split) + '.pkl', 'rb') as file:\n","    test_last_layer_embeddings = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/test_all_layers_embeddings_tail_fine_tuned_split' + str(n_split) + '.pkl', 'rb') as file:\n","    test_all_layers_embeddings = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/test_cls_token_embeddings_tail_fine_tuned_split' + str(n_split) + '.pkl', 'rb') as file:\n","    test_cls_token_embeddings = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/train_index_final_split_' + str(n_split), 'rb') as file:\n","    train_index = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/valid_index_final_split_' + str(n_split), 'rb') as file:\n","    valid_index = pickle.load(file)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"3f7F7ELTH7Kc","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593670225367,"user_tz":180,"elapsed":6604,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["test_index = [i for i, _ in enumerate(X_test)]"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"7cw3aVs0tNYu","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593670225368,"user_tz":180,"elapsed":6602,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["inv_word_index = {ix : w for w, ix in word_index.items()}"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"-imDG-lFcsym","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593670229872,"user_tz":180,"elapsed":11104,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["import itertools\n","features_index = {w:ix for ix, w in enumerate(np.unique(list(itertools.chain.from_iterable(np.array(X_train)[train_index]))))}\n","inv_features_index = {ix:w for ix, w in enumerate(np.unique(list(itertools.chain.from_iterable(np.array(X_train)[train_index]))))}"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"8cMPG0UDc2LV","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593670231021,"user_tz":180,"elapsed":12249,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["X_train_matrix = np.zeros((len(X_train), len(features_index)))\n","X_test_matrix = np.zeros((len(X_test), len(features_index)))"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"weNsqkv4c5ih","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593670248290,"user_tz":180,"elapsed":29516,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["for i, x in enumerate(X_train):\n","  for w in x:\n","    if w in features_index:\n","      X_train_matrix[i,features_index[w]] += 1\n","\n","for i, x in enumerate(X_test):\n","  for w in x:\n","    if w in features_index:\n","      X_test_matrix[i,features_index[w]] += 1"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"UA9bR-8qsdkz","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593670248291,"user_tz":180,"elapsed":29515,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["data_train_doc_ids = [(i, d) for i, d in enumerate(X_train)]\n","data_test_doc_ids = [(i, d) for i, d in enumerate(X_test)]"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"fslOxq7L_dkN","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593670248292,"user_tz":180,"elapsed":29513,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["target_train_doc_ids = [(i, y) for i, y in enumerate(Y_train)]\n","target_test_doc_ids = [(i, y) for i, y in enumerate(Y_test)]"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"gBUtPIZ56-qI","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593670248293,"user_tz":180,"elapsed":29512,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["doc_train_ids = np.array([i for i, _ in data_train_doc_ids])\n","doc_test_ids = np.array([i for i, _ in data_test_doc_ids])\n","doc_train_dict = {k:v for k, v in [(i, d) for i, d in data_train_doc_ids]}\n","doc_test_dict = {k:v for k, v in [(i, d) for i, d in data_test_doc_ids]}\n","target_train_dict = {k:v for k, v in [(i, y) for i, y in target_train_doc_ids]}\n","target_test_dict = {k:v for k, v in [(i, y) for i, y in target_test_doc_ids]}"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"SNrkQqCt7wTE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":952},"executionInfo":{"status":"ok","timestamp":1593670248293,"user_tz":180,"elapsed":29504,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"f3d3d826-5383-4681-a85b-47a2f8d320bd"},"source":["doc_train_ids[train_index]"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([  0,   1,   2,   3,   4,   5,   7,   8,   9,  10,  12,  13,  14,\n","        15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  27,  28,\n","        29,  30,  31,  32,  34,  35,  38,  42,  43,  45,  46,  47,  48,\n","        49,  50,  52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,\n","        63,  64,  65,  66,  69,  70,  71,  73,  75,  76,  77,  78,  79,\n","        80,  82,  83,  84,  85,  87,  88,  89,  90,  94,  95,  97,  99,\n","       100, 101, 103, 104, 105, 106, 109, 111, 113, 114, 115, 116, 117,\n","       118, 119, 120, 121, 122, 124, 126, 127, 129, 130, 131, 132, 133,\n","       134, 135, 137, 140, 141, 143, 144, 147, 149, 150, 152, 153, 154,\n","       155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 168,\n","       169, 170, 171, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184,\n","       185, 186, 187, 188, 189, 190, 191, 192, 193, 196, 197, 198, 199,\n","       201, 202, 203, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214,\n","       216, 217, 218, 219, 220, 221, 222, 223, 225, 226, 227, 228, 229,\n","       230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 241, 242, 243,\n","       245, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258,\n","       264, 266, 267, 268, 271, 272, 274, 275, 277, 278, 279, 280, 281,\n","       282, 283, 284, 287, 288, 290, 291, 292, 293, 294, 295, 296, 297,\n","       299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 310, 311, 313,\n","       316, 318, 319, 321, 322, 324, 325, 326, 327, 328, 329, 330, 331,\n","       332, 333, 334, 336, 337, 338, 339, 340, 342, 343, 345, 348, 349,\n","       350, 351, 354, 355, 356, 358, 359, 360, 363, 364, 366, 367, 369,\n","       371, 372, 373, 374, 375, 376, 378, 379, 382, 383, 385, 386, 387,\n","       388, 389, 390, 391, 392, 393, 394, 395, 397, 398, 399, 401, 402,\n","       403, 405, 406, 407, 408, 410, 411, 412, 413, 414, 415, 416, 417,\n","       418, 419, 420, 422, 423, 424, 426, 427, 428, 429, 430, 431, 432,\n","       433, 434, 435, 436, 437, 438, 439, 441, 442, 444, 445, 446, 447,\n","       449, 450, 452, 453, 454, 455, 456, 457, 458, 460, 461, 462, 463,\n","       464, 466, 467, 469, 470, 473, 474, 475, 477, 478, 480, 481, 482,\n","       484, 485, 486, 488, 489, 490, 491, 494, 495, 496, 497, 498, 499,\n","       500, 501, 502, 503, 504, 505, 506, 509, 511, 512, 513, 514, 517,\n","       518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530,\n","       531, 532, 533, 534, 535, 537, 538, 540, 541, 542, 543, 544, 545,\n","       547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 558, 559, 560,\n","       561, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574,\n","       575, 576, 577, 578, 579, 580, 582, 583, 584, 585, 586, 587, 588,\n","       590, 591, 592, 594, 595, 596, 598, 599, 600, 601, 602, 603, 605,\n","       606, 607, 608, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619,\n","       620, 621, 622, 623, 625, 626, 627, 629, 630, 631, 632, 634, 635,\n","       636, 637, 639, 640, 642, 643, 644, 645, 646, 647, 648, 649, 651,\n","       652, 653, 654, 655, 656, 660, 661, 662, 664, 665, 666, 667, 669,\n","       670, 671, 672, 673, 674, 675, 676, 678, 679, 680, 681, 682, 683,\n","       684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 697, 698,\n","       701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 712, 713, 714,\n","       715, 718, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730,\n","       731, 732, 733, 734, 735, 736, 737, 738, 740, 742, 743, 744, 745,\n","       747, 748, 749, 750, 752, 753, 754, 755, 756, 757, 758, 759, 760,\n","       761, 764, 765, 766, 767, 768, 769, 770, 771, 773, 774, 776, 777,\n","       779, 780, 781, 782, 784, 785, 786, 788, 789, 790, 791, 793, 794,\n","       795, 796, 797, 798, 799, 800, 802, 803, 806, 807, 808, 809, 810,\n","       811, 813, 814, 815, 816, 818, 821, 824, 826, 827, 829, 830, 831,\n","       832, 834, 835, 837, 838, 839, 840, 841, 842, 843, 844, 845, 847,\n","       848, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861,\n","       863, 864, 865, 866, 867, 868, 869, 870, 872, 873, 874, 875, 876,\n","       877, 878, 879, 880, 881, 882, 883, 884, 885, 887])"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"npzysPqN8-Pi","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":255},"executionInfo":{"status":"ok","timestamp":1593670248294,"user_tz":180,"elapsed":29498,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"6de22886-8aa5-4d5e-8116-26580b54f3a2"},"source":["doc_train_ids[valid_index]"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([  6,  11,  26,  33,  36,  37,  39,  40,  41,  44,  51,  67,  68,\n","        72,  74,  81,  86,  91,  92,  93,  96,  98, 102, 107, 108, 110,\n","       112, 123, 125, 128, 136, 138, 139, 142, 145, 146, 148, 151, 167,\n","       172, 181, 182, 194, 195, 200, 204, 215, 224, 240, 244, 246, 259,\n","       260, 261, 262, 263, 265, 269, 270, 273, 276, 285, 286, 289, 298,\n","       309, 312, 314, 315, 317, 320, 323, 335, 341, 344, 346, 347, 352,\n","       353, 357, 361, 362, 365, 368, 370, 377, 380, 381, 384, 396, 400,\n","       404, 409, 421, 425, 440, 443, 448, 451, 459, 465, 468, 471, 472,\n","       476, 479, 483, 487, 492, 493, 507, 508, 510, 515, 516, 536, 539,\n","       546, 557, 562, 581, 589, 593, 597, 604, 609, 624, 628, 633, 638,\n","       641, 650, 657, 658, 659, 663, 668, 677, 695, 696, 699, 700, 711,\n","       716, 717, 719, 739, 741, 746, 751, 762, 763, 772, 775, 778, 783,\n","       787, 792, 801, 804, 805, 812, 817, 819, 820, 822, 823, 825, 828,\n","       833, 836, 846, 849, 862, 871, 886])"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"N2LDzB_2755O","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":527},"executionInfo":{"status":"ok","timestamp":1593670248294,"user_tz":180,"elapsed":29491,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"83a5ff73-a37d-4c78-dc03-2f7d92b1d506"},"source":["doc_test_ids[test_index]"],"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n","        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n","        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n","        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n","        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n","        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n","        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n","        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n","       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n","       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n","       130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n","       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n","       156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n","       169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n","       182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n","       195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n","       208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n","       221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n","       234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246,\n","       247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259,\n","       260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272,\n","       273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n","       286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298,\n","       299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n","       312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324,\n","       325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337,\n","       338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350,\n","       351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n","       364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376,\n","       377, 378, 379, 380])"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"9hORlMAi41vy","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":340},"executionInfo":{"status":"ok","timestamp":1593670251647,"user_tz":180,"elapsed":32838,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"5b187cb8-5733-4466-8819-06116252c9ac"},"source":["!pip install transformers"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (3.0.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: tokenizers==0.8.0-rc4 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8.0rc4)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.91)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.12.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.15.1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"x0bQcArrMwCk","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593670253929,"user_tz":180,"elapsed":35117,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["import pandas as pd\n","import numpy as np\n","import itertools\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import transformers\n","import torch.utils.data as tdata\n","import torch.optim as optim\n","\n","import tqdm\n","\n","torch.manual_seed(0)\n","np.random.seed(0)"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"FDhmJ8RY4-St","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593670253932,"user_tz":180,"elapsed":35118,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"oSU-aTSudTA4","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593670255013,"user_tz":180,"elapsed":36197,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["X0_train_tensor = torch.from_numpy(X_train_matrix[train_index]).float().to(device)\n","X0_valid_tensor = torch.from_numpy(X_train_matrix[valid_index]).float().to(device)\n","X0_test_tensor = torch.from_numpy(X_test_matrix).float().to(device)"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"4lzOGqwU3lLq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593670255013,"user_tz":180,"elapsed":36190,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"524f920e-5074-40bc-f0ea-20fbf888cbd1"},"source":["np.max([len(clss) for doc, clss in train_cls_token_embeddings.items()])"],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["285"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"VvRh2dHK5Hmr","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593670255014,"user_tz":180,"elapsed":36188,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["max_len = 50"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"9Fq3PgQB7NgF","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593670255015,"user_tz":180,"elapsed":36187,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["def manual_padding(sent, max_len = 200):\n","  pad_tensor = [torch.from_numpy(np.zeros((1, 768))).float()]\n","  if len(sent) > max_len:\n","    res = sent[-max_len:]\n","  else:\n","    res = (pad_tensor * (max_len - len(sent))) + sent\n","  return res"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"id":"U6iFCg7p9011","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593670255015,"user_tz":180,"elapsed":36185,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["X1_train_tensor = torch.stack([torch.stack(manual_padding(sent=train_cls_token_embeddings[i], max_len = max_len)) for i in train_index]).squeeze(2).to(device)\n","X2_train_tensor = torch.stack([train_last_layer_embeddings[i] for i in train_index]).squeeze(1).to(device)\n","X3_train_tensor = torch.stack([torch.flatten(train_all_layers_embeddings[i].permute(1, 0, 2), start_dim=1) for i in train_index]).squeeze(1).to(device)"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"5nLhw-oqKViw","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593670255016,"user_tz":180,"elapsed":36184,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["X1_valid_tensor = torch.stack([torch.stack(manual_padding(sent=train_cls_token_embeddings[i], max_len = max_len)) for i in valid_index]).squeeze(2).to(device)\n","X2_valid_tensor = torch.stack([train_last_layer_embeddings[i] for i in valid_index]).squeeze(1).to(device)\n","X3_valid_tensor = torch.stack([torch.flatten(train_all_layers_embeddings[i].permute(1, 0, 2), start_dim=1) for i in valid_index]).squeeze(1).to(device)"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"id":"9AYQ7TYfO_uR","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593670255017,"user_tz":180,"elapsed":36181,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["X1_test_tensor = torch.stack([torch.stack(manual_padding(sent=test_cls_token_embeddings[i], max_len = max_len)) for i in test_index]).squeeze(2).to(device)\n","X2_test_tensor = torch.stack([test_last_layer_embeddings[i] for i in test_index]).squeeze(1).to(device)\n","X3_test_tensor = torch.stack([torch.flatten(test_all_layers_embeddings[i].permute(1, 0, 2), start_dim=1) for i in test_index]).squeeze(1).to(device)"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"pSOM62CnKVct","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593670255017,"user_tz":180,"elapsed":36179,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["Y_train_tensor = torch.LongTensor(np.array(Y_train)[train_index]).to(device)\n","Y_valid_tensor = torch.LongTensor(np.array(Y_train)[valid_index]).to(device)\n","Y_test_tensor = torch.LongTensor(np.array(Y_test)).to(device)"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"TxXNnfKaBXbK","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593670255019,"user_tz":180,"elapsed":36174,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"58b10daa-992f-4fca-bf4e-eb9deecde62c"},"source":["X0_train_tensor.shape"],"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([712, 239262])"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"code","metadata":{"id":"7lwdtYzhStJH","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593670255020,"user_tz":180,"elapsed":36168,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"e3933abf-77a5-45f5-996b-bfb35aaa14e0"},"source":["X1_train_tensor.shape"],"execution_count":30,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([712, 50, 768])"]},"metadata":{"tags":[]},"execution_count":30}]},{"cell_type":"code","metadata":{"id":"4cbKWwZ7StDF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593670255020,"user_tz":180,"elapsed":36161,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"17c5ed1e-e547-4c0e-bc38-8a95fe87df01"},"source":["X2_train_tensor.shape"],"execution_count":31,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([712, 768])"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"code","metadata":{"id":"YK-km_HcSsjM","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593670255021,"user_tz":180,"elapsed":36156,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"4bbb3995-68c4-4321-dc20-53584e9a0fbd"},"source":["X3_train_tensor.shape"],"execution_count":32,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([712, 9984])"]},"metadata":{"tags":[]},"execution_count":32}]},{"cell_type":"code","metadata":{"id":"OnRUTIxRQRoT","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593670255021,"user_tz":180,"elapsed":36153,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["input_dim_0 = X0_train_tensor.shape[1]\n","input_dim_2 = X2_train_tensor.shape[1]\n","input_dim_3 = X3_train_tensor.shape[1]\n","EMBEDDING_DIM = X1_train_tensor.shape[2]"],"execution_count":33,"outputs":[]},{"cell_type":"code","metadata":{"id":"fBO0s-eUTqYk","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593670255022,"user_tz":180,"elapsed":36147,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"84fa33c6-a658-4f8a-ecc4-8a391be31099"},"source":["input_dim_0"],"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/plain":["239262"]},"metadata":{"tags":[]},"execution_count":34}]},{"cell_type":"code","metadata":{"id":"BM9kem7rTqR7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593670255391,"user_tz":180,"elapsed":36509,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"30b2ffed-7e3e-4eea-e65c-ee6aea408518"},"source":["input_dim_2"],"execution_count":35,"outputs":[{"output_type":"execute_result","data":{"text/plain":["768"]},"metadata":{"tags":[]},"execution_count":35}]},{"cell_type":"code","metadata":{"id":"zPtu--rCRZI7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593670255391,"user_tz":180,"elapsed":36503,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"e96e9806-3541-423e-e963-47b182f1d2ee"},"source":["input_dim_3"],"execution_count":36,"outputs":[{"output_type":"execute_result","data":{"text/plain":["9984"]},"metadata":{"tags":[]},"execution_count":36}]},{"cell_type":"code","metadata":{"id":"Gm3d5UPCBh8g","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593670255392,"user_tz":180,"elapsed":36497,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"7bfbff82-d127-4e0e-c08c-b98f9fa2f819"},"source":["EMBEDDING_DIM"],"execution_count":37,"outputs":[{"output_type":"execute_result","data":{"text/plain":["768"]},"metadata":{"tags":[]},"execution_count":37}]},{"cell_type":"code","metadata":{"id":"Qbh-533qOJ2M","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593670255393,"user_tz":180,"elapsed":36495,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["class MyModel(nn.Module):\n","    def __init__(self):\n","        super(MyModel, self).__init__()\n","        self.conv2 = nn.Sequential(\n","          nn.Conv1d(in_channels=EMBEDDING_DIM, out_channels=64, kernel_size=2),\n","          nn.ReLU(),\n","          #nn.Conv1d(in_channels=64, out_channels=32, kernel_size=3),\n","          #nn.ReLU(),\n","          #nn.Conv1d(in_channels=32, out_channels=16, kernel_size=4),\n","          #nn.ReLU(),\n","          nn.AdaptiveMaxPool1d(1),\n","          nn.Dropout(0.3),\n","      )\n","        \n","        self.fc_out = nn.Linear(64, 2)\n","\n","        self.softmax = nn.Softmax(dim=1)\n","\n","        self.dropout = nn.Dropout(0.3)\n","        \n","    def forward(self, x2):\n","        x2 = x2.permute(0,2,1)\n","        x2 = F.normalize(x2)\n","\n","        h2 = self.conv2(x2).squeeze(2)\n","\n","        # Concatenate in dim1 (feature dimension)\n","        y = self.softmax(self.fc_out(h2))\n","        return y"],"execution_count":38,"outputs":[]},{"cell_type":"code","metadata":{"id":"i1bYTYLVQONx","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1593670255393,"user_tz":180,"elapsed":36488,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"5df41ebf-3a2d-41dc-e80c-00b678ca62be"},"source":["model = MyModel()\n","model.to(device)"],"execution_count":39,"outputs":[{"output_type":"execute_result","data":{"text/plain":["MyModel(\n","  (conv2): Sequential(\n","    (0): Conv1d(768, 64, kernel_size=(2,), stride=(1,))\n","    (1): ReLU()\n","    (2): AdaptiveMaxPool1d(output_size=1)\n","    (3): Dropout(p=0.3, inplace=False)\n","  )\n","  (fc_out): Linear(in_features=64, out_features=2, bias=True)\n","  (softmax): Softmax(dim=1)\n","  (dropout): Dropout(p=0.3, inplace=False)\n",")"]},"metadata":{"tags":[]},"execution_count":39}]},{"cell_type":"code","metadata":{"id":"6NvnlU24DsVb","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593670255394,"user_tz":180,"elapsed":36483,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"b500b450-48c8-44c2-f692-9b1d7bfb7fdb"},"source":["X0_train_tensor.shape"],"execution_count":40,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([712, 239262])"]},"metadata":{"tags":[]},"execution_count":40}]},{"cell_type":"code","metadata":{"id":"dY6VwvOBTc-K","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593670255394,"user_tz":180,"elapsed":36475,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"974f29db-7b05-4397-950b-a84b13c7d886"},"source":["X1_train_tensor.shape"],"execution_count":41,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([712, 50, 768])"]},"metadata":{"tags":[]},"execution_count":41}]},{"cell_type":"code","metadata":{"id":"XyyWGhv0Tc3d","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593670255395,"user_tz":180,"elapsed":36469,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"1f5c06f1-e0dc-4d25-db76-5a9db3c9425d"},"source":["X2_train_tensor.shape"],"execution_count":42,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([712, 768])"]},"metadata":{"tags":[]},"execution_count":42}]},{"cell_type":"code","metadata":{"id":"rCMfNXulTcvs","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593670255395,"user_tz":180,"elapsed":36462,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"35a683be-5c43-4263-bec5-3f82bb93c19b"},"source":["X3_train_tensor.shape"],"execution_count":43,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([712, 9984])"]},"metadata":{"tags":[]},"execution_count":43}]},{"cell_type":"code","metadata":{"id":"acr1hz5FQmT5","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593670255396,"user_tz":180,"elapsed":36460,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["import torch.optim as optim\n","optimizer = optim.AdamW(model.parameters(), lr=0.01)"],"execution_count":44,"outputs":[]},{"cell_type":"code","metadata":{"id":"fp5F7lhtULiq","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593670255396,"user_tz":180,"elapsed":36458,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["from torch.optim.lr_scheduler import ReduceLROnPlateau\n","scheduler = ReduceLROnPlateau(optimizer, 'min')"],"execution_count":45,"outputs":[]},{"cell_type":"code","metadata":{"id":"fGkOOoMZJ4GF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593670255397,"user_tz":180,"elapsed":36452,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"e4c97774-a383-4330-ef34-10242dc68932"},"source":["weights = [sum(Y_train)/len(Y_train), 1-sum(Y_train)/len(Y_train)]\n","class_weights = torch.FloatTensor(weights)\n","class_weights"],"execution_count":46,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0.1734, 0.8266])"]},"metadata":{"tags":[]},"execution_count":46}]},{"cell_type":"code","metadata":{"id":"nWrjkNzQQqW5","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593670255397,"user_tz":180,"elapsed":36450,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["criterion = nn.CrossEntropyLoss(weight=class_weights)"],"execution_count":47,"outputs":[]},{"cell_type":"code","metadata":{"id":"jtbi4GvTQta7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1593670380789,"user_tz":180,"elapsed":161835,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"c958171b-535d-4ce9-cb38-2bd24deeff0b"},"source":["patience = 20\n","early_stopping = EarlyStopping(patience=patience, verbose=True)\n","\n","\n","for i in range(200):\n","  model.train()\n","  optimizer.zero_grad()\n","  prediction = model(X1_train_tensor)\n","  loss = criterion(prediction, Y_train_tensor)\n","  loss.backward()\n","  optimizer.step()\n","\n","  accuracy = Accuracy(prediction, Y_train_tensor)\n","\n","  model.eval()\n","\n","  val_prediction = model(X1_valid_tensor)\n","  test_prediction = model(X1_test_tensor)\n","  val_loss = criterion(val_prediction, Y_valid_tensor)\n","  test_loss = criterion(test_prediction, Y_test_tensor)\n","\n","  val_accuracy = Accuracy(val_prediction, Y_valid_tensor)\n","  test_accuracy = Accuracy(test_prediction, Y_test_tensor)\n","\n","  early_stopping(val_loss, model)\n","\n","  if early_stopping.early_stop:\n","    print(\"Early stopping\")\n","    break\n","\n","  print(i, float(loss.cpu()), accuracy, float(val_loss.cpu()), val_accuracy, float(test_loss.cpu()), test_accuracy)\n","\n","  scheduler.step(val_loss)\n","\n","model.load_state_dict(torch.load('checkpoint.pt'))"],"execution_count":48,"outputs":[{"output_type":"stream","text":["Validation loss decreased (inf --> 0.636783).  Saving model ...\n","0 0.6947364211082458 0.1741573065519333 0.6367827653884888 0.9034090638160706 0.6550443768501282 0.8818897604942322\n","Validation loss decreased (0.636783 --> 0.583314).  Saving model ...\n","1 0.6462304592132568 0.8778089880943298 0.5833144783973694 0.8977272510528564 0.6155915260314941 0.8818897604942322\n","Validation loss decreased (0.583314 --> 0.550334).  Saving model ...\n","2 0.5962033271789551 0.8469101190567017 0.5503336787223816 0.8579545617103577 0.5887455344200134 0.8608924150466919\n","Validation loss decreased (0.550334 --> 0.533864).  Saving model ...\n","3 0.5651722550392151 0.8230336904525757 0.5338635444641113 0.8579545617103577 0.5725762248039246 0.847769021987915\n","Validation loss decreased (0.533864 --> 0.527029).  Saving model ...\n","4 0.5612683296203613 0.8117977380752563 0.527029275894165 0.8352272510528564 0.5631299018859863 0.8451443314552307\n","Validation loss decreased (0.527029 --> 0.524910).  Saving model ...\n","5 0.5383160710334778 0.8216292262077332 0.5249101519584656 0.8636363744735718 0.5638941526412964 0.8582677245140076\n","Validation loss decreased (0.524910 --> 0.523665).  Saving model ...\n","6 0.5477779507637024 0.8370786309242249 0.5236651301383972 0.8522727489471436 0.5555433034896851 0.847769021987915\n","EarlyStopping counter: 1 out of 20\n","7 0.5635012984275818 0.783707857131958 0.5266662836074829 0.75 0.5518466234207153 0.8057742714881897\n","EarlyStopping counter: 2 out of 20\n","8 0.5347300171852112 0.7443820238113403 0.5265033841133118 0.7443181872367859 0.550122082233429 0.8057742714881897\n","EarlyStopping counter: 3 out of 20\n","9 0.5322620868682861 0.7471910119056702 0.52397620677948 0.7897727489471436 0.5450061559677124 0.8398950099945068\n","EarlyStopping counter: 4 out of 20\n","10 0.5330912470817566 0.7865168452262878 0.5258561968803406 0.8409090638160706 0.5475562810897827 0.8451443314552307\n","EarlyStopping counter: 5 out of 20\n","11 0.5262153744697571 0.834269642829895 0.5243052244186401 0.7954545617103577 0.5413132309913635 0.8398950099945068\n","EarlyStopping counter: 6 out of 20\n","12 0.5331429243087769 0.7724719047546387 0.5239809155464172 0.7556818127632141 0.5399737358093262 0.8188976645469666\n","Validation loss decreased (0.523665 --> 0.523573).  Saving model ...\n","13 0.519148588180542 0.773876428604126 0.5235728025436401 0.7784090638160706 0.5376874208450317 0.834645688533783\n","Validation loss decreased (0.523573 --> 0.523359).  Saving model ...\n","14 0.5069843530654907 0.7977527976036072 0.5233587622642517 0.8068181872367859 0.5365625023841858 0.8425197005271912\n","Validation loss decreased (0.523359 --> 0.522244).  Saving model ...\n","15 0.5174606442451477 0.8146067261695862 0.5222441554069519 0.8011363744735718 0.5344024300575256 0.8372703194618225\n","Validation loss decreased (0.522244 --> 0.520716).  Saving model ...\n","16 0.5278840661048889 0.7935393452644348 0.5207157135009766 0.7386363744735718 0.536669135093689 0.7926509380340576\n","Validation loss decreased (0.520716 --> 0.518918).  Saving model ...\n","17 0.5239248871803284 0.757022500038147 0.5189181566238403 0.7613636255264282 0.5325337052345276 0.8110235929489136\n","EarlyStopping counter: 1 out of 20\n","18 0.5056008100509644 0.7991573214530945 0.5214948058128357 0.8409090638160706 0.5359141826629639 0.8608924150466919\n","EarlyStopping counter: 2 out of 20\n","19 0.5048204064369202 0.8483145833015442 0.5245417952537537 0.8579545617103577 0.5460070371627808 0.8635170459747314\n","EarlyStopping counter: 3 out of 20\n","20 0.515906810760498 0.8665730357170105 0.5195021629333496 0.8409090638160706 0.5350872874259949 0.8608924150466919\n","Validation loss decreased (0.518918 --> 0.512925).  Saving model ...\n","21 0.4992348551750183 0.8637640476226807 0.5129250288009644 0.7670454382896423 0.5277261137962341 0.8110235929489136\n","EarlyStopping counter: 1 out of 20\n","22 0.5084852576255798 0.800561785697937 0.5203509330749512 0.7102272510528564 0.5524131655693054 0.7060367465019226\n","Validation loss decreased (0.512925 --> 0.512442).  Saving model ...\n","23 0.5204776525497437 0.7120786309242249 0.5124415755271912 0.7215909361839294 0.5374729633331299 0.7559055089950562\n","Validation loss decreased (0.512442 --> 0.509267).  Saving model ...\n","24 0.5033666491508484 0.7528089880943298 0.509267270565033 0.8068181872367859 0.5224800705909729 0.8530183434486389\n","EarlyStopping counter: 1 out of 20\n","25 0.49422547221183777 0.8426966071128845 0.5194230675697327 0.8636363744735718 0.5444649457931519 0.8845144510269165\n","EarlyStopping counter: 2 out of 20\n","26 0.5035693049430847 0.8876404762268066 0.5210583209991455 0.875 0.549466073513031 0.8818897604942322\n","EarlyStopping counter: 3 out of 20\n","27 0.5007531046867371 0.8960674405097961 0.514164924621582 0.8693181872367859 0.5371431708335876 0.8818897604942322\n","Validation loss decreased (0.509267 --> 0.500900).  Saving model ...\n","28 0.49681395292282104 0.8792135119438171 0.500900387763977 0.8125 0.5186315774917603 0.847769021987915\n","EarlyStopping counter: 1 out of 20\n","29 0.4716096520423889 0.8426966071128845 0.5032822489738464 0.7329545617103577 0.5338523387908936 0.7637795209884644\n","EarlyStopping counter: 2 out of 20\n","30 0.49957823753356934 0.7724719047546387 0.5050479769706726 0.7329545617103577 0.5381536483764648 0.7454068064689636\n","Validation loss decreased (0.500900 --> 0.493050).  Saving model ...\n","31 0.4991647005081177 0.7514045238494873 0.4930495321750641 0.8068181872367859 0.521372377872467 0.8031495809555054\n","Validation loss decreased (0.493050 --> 0.493010).  Saving model ...\n","32 0.47773557901382446 0.8089887499809265 0.49301037192344666 0.8409090638160706 0.5169069766998291 0.8608924150466919\n","EarlyStopping counter: 1 out of 20\n","33 0.4754374027252197 0.867977499961853 0.4970119595527649 0.8465909361839294 0.5236722826957703 0.8845144510269165\n","EarlyStopping counter: 2 out of 20\n","34 0.4850105941295624 0.8764045238494873 0.4958319365978241 0.8522727489471436 0.5235483646392822 0.887139081954956\n","Validation loss decreased (0.493010 --> 0.488581).  Saving model ...\n","35 0.47832101583480835 0.8904494643211365 0.4885806143283844 0.8409090638160706 0.5145354866981506 0.8635170459747314\n","Validation loss decreased (0.488581 --> 0.485559).  Saving model ...\n","36 0.470125287771225 0.8693820238113403 0.485559344291687 0.8352272510528564 0.5153146982192993 0.8162729740142822\n","EarlyStopping counter: 1 out of 20\n","37 0.46792519092559814 0.8370786309242249 0.49312323331832886 0.7784090638160706 0.5254360437393188 0.7795275449752808\n","EarlyStopping counter: 2 out of 20\n","38 0.48996224999427795 0.7752808928489685 0.4873238503932953 0.8125 0.5180448889732361 0.8057742714881897\n","Validation loss decreased (0.485559 --> 0.484052).  Saving model ...\n","39 0.4793345332145691 0.8047752976417542 0.48405203223228455 0.8352272510528564 0.5101508498191833 0.8608924150466919\n","EarlyStopping counter: 1 out of 20\n","40 0.4705609083175659 0.8707864880561829 0.49085187911987305 0.8693181872367859 0.519170880317688 0.887139081954956\n","EarlyStopping counter: 2 out of 20\n","41 0.4652591943740845 0.9129213690757751 0.49291059374809265 0.8693181872367859 0.5231473445892334 0.8897637724876404\n","EarlyStopping counter: 3 out of 20\n","42 0.4733400046825409 0.8960674405097961 0.48712995648384094 0.8465909361839294 0.51374351978302 0.8845144510269165\n","Validation loss decreased (0.484052 --> 0.481740).  Saving model ...\n","43 0.4640977084636688 0.9030898809432983 0.48173987865448 0.8409090638160706 0.509053647518158 0.8530183434486389\n","EarlyStopping counter: 1 out of 20\n","44 0.4556485712528229 0.8567415475845337 0.48378148674964905 0.8352272510528564 0.5128255486488342 0.8162729740142822\n","EarlyStopping counter: 2 out of 20\n","45 0.46434518694877625 0.8314606547355652 0.4828132092952728 0.8352272510528564 0.5103062987327576 0.8398950099945068\n","EarlyStopping counter: 3 out of 20\n","46 0.4647296369075775 0.8455055952072144 0.4832890033721924 0.8409090638160706 0.5079471468925476 0.8608924150466919\n","EarlyStopping counter: 4 out of 20\n","47 0.4436364471912384 0.8848314881324768 0.48669782280921936 0.8522727489471436 0.5112760066986084 0.8897637724876404\n","EarlyStopping counter: 5 out of 20\n","48 0.45047008991241455 0.9185393452644348 0.4870101809501648 0.8579545617103577 0.5123368501663208 0.8897637724876404\n","EarlyStopping counter: 6 out of 20\n","49 0.46230921149253845 0.9101123809814453 0.4823743402957916 0.8465909361839294 0.5071221590042114 0.8766404390335083\n","Validation loss decreased (0.481740 --> 0.481022).  Saving model ...\n","50 0.45123663544654846 0.898876428604126 0.4810217022895813 0.8295454382896423 0.5080264210700989 0.8372703194618225\n","EarlyStopping counter: 1 out of 20\n","51 0.45196613669395447 0.8721910119056702 0.48214277625083923 0.8238636255264282 0.5101518630981445 0.8267716765403748\n","Validation loss decreased (0.481022 --> 0.479099).  Saving model ...\n","52 0.45419400930404663 0.8469101190567017 0.4790986478328705 0.8409090638160706 0.5056204795837402 0.8451443314552307\n","EarlyStopping counter: 1 out of 20\n","53 0.44949451088905334 0.8792135119438171 0.47949016094207764 0.8579545617103577 0.5052019953727722 0.8845144510269165\n","EarlyStopping counter: 2 out of 20\n","54 0.44592973589897156 0.9129213690757751 0.48237937688827515 0.875 0.5092235207557678 0.8897637724876404\n","EarlyStopping counter: 3 out of 20\n","55 0.45566073060035706 0.9143258333206177 0.4805200695991516 0.8636363744735718 0.5060710906982422 0.8897637724876404\n","Validation loss decreased (0.479099 --> 0.477952).  Saving model ...\n","56 0.44554969668388367 0.9171348214149475 0.4779523015022278 0.8465909361839294 0.502555251121521 0.8661417365074158\n","EarlyStopping counter: 1 out of 20\n","57 0.4416709542274475 0.9016854166984558 0.48221173882484436 0.8238636255264282 0.5068001747131348 0.8241469860076904\n","EarlyStopping counter: 2 out of 20\n","58 0.4430200457572937 0.8665730357170105 0.48067548871040344 0.8238636255264282 0.5047301054000854 0.834645688533783\n","Validation loss decreased (0.477952 --> 0.477591).  Saving model ...\n","59 0.44611576199531555 0.8651685118675232 0.47759124636650085 0.8579545617103577 0.5009195804595947 0.8818897604942322\n","EarlyStopping counter: 1 out of 20\n","60 0.437856525182724 0.9129213690757751 0.48179158568382263 0.8806818127632141 0.5054087042808533 0.8923884630203247\n","EarlyStopping counter: 2 out of 20\n","61 0.43786266446113586 0.9297752976417542 0.4824429452419281 0.8806818127632141 0.5049035549163818 0.8976377844810486\n","EarlyStopping counter: 3 out of 20\n","62 0.44444218277931213 0.9297752976417542 0.47824546694755554 0.8522727489471436 0.49931445717811584 0.8792650699615479\n","EarlyStopping counter: 4 out of 20\n","63 0.4308667480945587 0.9171348214149475 0.4833729565143585 0.8011363744735718 0.5069177150726318 0.8267716765403748\n","EarlyStopping counter: 5 out of 20\n","64 0.4429960548877716 0.8609550595283508 0.48317140340805054 0.8068181872367859 0.5063817501068115 0.8267716765403748\n","EarlyStopping counter: 6 out of 20\n","65 0.44540566205978394 0.8497191071510315 0.4792338013648987 0.8579545617103577 0.49782663583755493 0.8792650699615479\n","EarlyStopping counter: 7 out of 20\n","66 0.4285162091255188 0.9143258333206177 0.4825916290283203 0.875 0.4981355369091034 0.9028871655464172\n","EarlyStopping counter: 8 out of 20\n","67 0.44493329524993896 0.9241573214530945 0.4815138280391693 0.875 0.49665480852127075 0.8950130939483643\n","EarlyStopping counter: 9 out of 20\n","68 0.42983120679855347 0.9241573214530945 0.47809678316116333 0.8579545617103577 0.4959701597690582 0.8792650699615479\n","EarlyStopping counter: 10 out of 20\n","69 0.4243340790271759 0.9199438095092773 0.47963935136795044 0.8181818127632141 0.5007016062736511 0.847769021987915\n","EarlyStopping counter: 11 out of 20\n","70 0.43251121044158936 0.8806179761886597 0.47793567180633545 0.8295454382896423 0.49845731258392334 0.8503937125205994\n","Validation loss decreased (0.477591 --> 0.477366).  Saving model ...\n","71 0.42142224311828613 0.8960674405097961 0.4773658514022827 0.8295454382896423 0.49751248955726624 0.8556430339813232\n","Validation loss decreased (0.477366 --> 0.476676).  Saving model ...\n","72 0.4307483732700348 0.8932584524154663 0.47667577862739563 0.8409090638160706 0.4961782395839691 0.8661417365074158\n","Validation loss decreased (0.476676 --> 0.476133).  Saving model ...\n","73 0.42867833375930786 0.898876428604126 0.47613298892974854 0.8522727489471436 0.49495208263397217 0.8766404390335083\n","Validation loss decreased (0.476133 --> 0.475842).  Saving model ...\n","74 0.41885387897491455 0.9171348214149475 0.47584185004234314 0.8636363744735718 0.49385300278663635 0.8845144510269165\n","EarlyStopping counter: 1 out of 20\n","75 0.4204375743865967 0.9115168452262878 0.47586679458618164 0.875 0.4931488037109375 0.887139081954956\n","EarlyStopping counter: 2 out of 20\n","76 0.4257141947746277 0.9185393452644348 0.47600147128105164 0.8863636255264282 0.49282994866371155 0.8897637724876404\n","EarlyStopping counter: 3 out of 20\n","77 0.42097795009613037 0.9269663095474243 0.47609299421310425 0.8806818127632141 0.49270036816596985 0.8897637724876404\n","EarlyStopping counter: 4 out of 20\n","78 0.4216689467430115 0.9227527976036072 0.4760657846927643 0.8806818127632141 0.49262988567352295 0.8923884630203247\n","EarlyStopping counter: 5 out of 20\n","79 0.42234164476394653 0.9199438095092773 0.47598323225975037 0.8806818127632141 0.4925669729709625 0.8923884630203247\n","Validation loss decreased (0.475842 --> 0.475835).  Saving model ...\n","80 0.42518702149391174 0.9213483333587646 0.4758347272872925 0.8806818127632141 0.49251604080200195 0.8923884630203247\n","Validation loss decreased (0.475835 --> 0.475588).  Saving model ...\n","81 0.42458170652389526 0.9199438095092773 0.47558802366256714 0.8863636255264282 0.49247732758522034 0.8897637724876404\n","Validation loss decreased (0.475588 --> 0.475252).  Saving model ...\n","82 0.42511552572250366 0.9185393452644348 0.47525230050086975 0.8863636255264282 0.49253854155540466 0.887139081954956\n","Validation loss decreased (0.475252 --> 0.474954).  Saving model ...\n","83 0.41974887251853943 0.925561785697937 0.4749539792537689 0.875 0.4927377998828888 0.887139081954956\n","Validation loss decreased (0.474954 --> 0.474737).  Saving model ...\n","84 0.4201483726501465 0.9269663095474243 0.47473663091659546 0.875 0.49307045340538025 0.8845144510269165\n","Validation loss decreased (0.474737 --> 0.474632).  Saving model ...\n","85 0.42549365758895874 0.9143258333206177 0.47463178634643555 0.8693181872367859 0.4933697283267975 0.8818897604942322\n","Validation loss decreased (0.474632 --> 0.474568).  Saving model ...\n","86 0.42044690251350403 0.9143258333206177 0.4745675325393677 0.8693181872367859 0.4937148690223694 0.8792650699615479\n","Validation loss decreased (0.474568 --> 0.474534).  Saving model ...\n","87 0.4224861264228821 0.9058988690376282 0.4745343029499054 0.8579545617103577 0.49382156133651733 0.8792650699615479\n","Validation loss decreased (0.474534 --> 0.474474).  Saving model ...\n","88 0.4257105588912964 0.908707857131958 0.47447407245635986 0.8579545617103577 0.4937439560890198 0.8792650699615479\n","Validation loss decreased (0.474474 --> 0.474412).  Saving model ...\n","89 0.422126829624176 0.9129213690757751 0.47441160678863525 0.8693181872367859 0.4934205412864685 0.8792650699615479\n","Validation loss decreased (0.474412 --> 0.474370).  Saving model ...\n","90 0.42532432079315186 0.9073033928871155 0.47437000274658203 0.875 0.4930231273174286 0.8818897604942322\n","EarlyStopping counter: 1 out of 20\n","91 0.4193938374519348 0.9213483333587646 0.47438541054725647 0.875 0.4926576316356659 0.8845144510269165\n","EarlyStopping counter: 2 out of 20\n","92 0.4199998676776886 0.908707857131958 0.4744569957256317 0.8806818127632141 0.49229151010513306 0.887139081954956\n","EarlyStopping counter: 3 out of 20\n","93 0.4173281490802765 0.9297752976417542 0.47463372349739075 0.8863636255264282 0.4919590950012207 0.8923884630203247\n","EarlyStopping counter: 4 out of 20\n","94 0.423202246427536 0.9171348214149475 0.47479379177093506 0.8863636255264282 0.49178650975227356 0.8923884630203247\n","EarlyStopping counter: 5 out of 20\n","95 0.4163220226764679 0.9213483333587646 0.4748309254646301 0.8863636255264282 0.49169161915779114 0.8950130939483643\n","EarlyStopping counter: 6 out of 20\n","96 0.42862972617149353 0.9241573214530945 0.4748057723045349 0.8863636255264282 0.49162808060646057 0.8950130939483643\n","EarlyStopping counter: 7 out of 20\n","97 0.4188986122608185 0.9353932738304138 0.47470352053642273 0.8863636255264282 0.49160704016685486 0.8923884630203247\n","EarlyStopping counter: 8 out of 20\n","98 0.41585731506347656 0.9241573214530945 0.474560022354126 0.8863636255264282 0.49165427684783936 0.8923884630203247\n","EarlyStopping counter: 9 out of 20\n","99 0.4133193790912628 0.9241573214530945 0.4743891656398773 0.8806818127632141 0.4918242394924164 0.887139081954956\n","Validation loss decreased (0.474370 --> 0.474297).  Saving model ...\n","100 0.42490777373313904 0.9213483333587646 0.4742966294288635 0.8806818127632141 0.4920055568218231 0.887139081954956\n","Validation loss decreased (0.474297 --> 0.474234).  Saving model ...\n","101 0.42220383882522583 0.9213483333587646 0.474234402179718 0.875 0.4922287166118622 0.8845144510269165\n","Validation loss decreased (0.474234 --> 0.474192).  Saving model ...\n","102 0.4181486666202545 0.925561785697937 0.47419166564941406 0.875 0.49245840311050415 0.8818897604942322\n","Validation loss decreased (0.474192 --> 0.474162).  Saving model ...\n","103 0.41905274987220764 0.9199438095092773 0.47416239976882935 0.8693181872367859 0.492691308259964 0.8818897604942322\n","Validation loss decreased (0.474162 --> 0.474138).  Saving model ...\n","104 0.42085105180740356 0.9115168452262878 0.4741381108760834 0.8693181872367859 0.4926002621650696 0.8818897604942322\n","Validation loss decreased (0.474138 --> 0.474127).  Saving model ...\n","105 0.42175301909446716 0.915730357170105 0.47412678599357605 0.8693181872367859 0.4923189580440521 0.8818897604942322\n","EarlyStopping counter: 1 out of 20\n","106 0.4125206768512726 0.9227527976036072 0.47415512800216675 0.8806818127632141 0.49187996983528137 0.8845144510269165\n","EarlyStopping counter: 2 out of 20\n","107 0.41910693049430847 0.9213483333587646 0.4741925597190857 0.8806818127632141 0.49157437682151794 0.8897637724876404\n","EarlyStopping counter: 3 out of 20\n","108 0.41911718249320984 0.9185393452644348 0.47424647212028503 0.8863636255264282 0.49135109782218933 0.8923884630203247\n","EarlyStopping counter: 4 out of 20\n","109 0.420092910528183 0.9213483333587646 0.4742885231971741 0.8863636255264282 0.4911898970603943 0.8923884630203247\n","EarlyStopping counter: 5 out of 20\n","110 0.4134194552898407 0.9185393452644348 0.4744136929512024 0.8863636255264282 0.4909948408603668 0.8950130939483643\n","EarlyStopping counter: 6 out of 20\n","111 0.4140644967556 0.9297752976417542 0.4744754433631897 0.8863636255264282 0.49088069796562195 0.8976377844810486\n","EarlyStopping counter: 7 out of 20\n","112 0.4250641167163849 0.9241573214530945 0.47432270646095276 0.8863636255264282 0.49086374044418335 0.8950130939483643\n","Validation loss decreased (0.474127 --> 0.474051).  Saving model ...\n","113 0.41606926918029785 0.9297752976417542 0.47405070066452026 0.8863636255264282 0.49095502495765686 0.8950130939483643\n","Validation loss decreased (0.474051 --> 0.473831).  Saving model ...\n","114 0.4150732159614563 0.932584285736084 0.47383108735084534 0.8863636255264282 0.49103888869285583 0.8950130939483643\n","Validation loss decreased (0.473831 --> 0.473565).  Saving model ...\n","115 0.42655274271965027 0.9185393452644348 0.4735647439956665 0.8806818127632141 0.49128979444503784 0.8897637724876404\n","Validation loss decreased (0.473565 --> 0.473326).  Saving model ...\n","116 0.42770299315452576 0.9073033928871155 0.4733261466026306 0.875 0.49158746004104614 0.8845144510269165\n","Validation loss decreased (0.473326 --> 0.473173).  Saving model ...\n","117 0.41521552205085754 0.915730357170105 0.4731730818748474 0.875 0.49174949526786804 0.8818897604942322\n","Validation loss decreased (0.473173 --> 0.473028).  Saving model ...\n","118 0.4139782190322876 0.915730357170105 0.47302794456481934 0.875 0.4917347729206085 0.8818897604942322\n","Validation loss decreased (0.473028 --> 0.472889).  Saving model ...\n","119 0.41842857003211975 0.9213483333587646 0.4728885591030121 0.875 0.4916515350341797 0.8818897604942322\n","Validation loss decreased (0.472889 --> 0.472777).  Saving model ...\n","120 0.41502845287323 0.9185393452644348 0.4727768301963806 0.875 0.4912125766277313 0.887139081954956\n","Validation loss decreased (0.472777 --> 0.472763).  Saving model ...\n","121 0.41843611001968384 0.9171348214149475 0.472762793302536 0.8806818127632141 0.4907087981700897 0.8950130939483643\n","EarlyStopping counter: 1 out of 20\n","122 0.4171895384788513 0.9269663095474243 0.472827285528183 0.8863636255264282 0.4903380572795868 0.8950130939483643\n","EarlyStopping counter: 2 out of 20\n","123 0.4123769700527191 0.9269663095474243 0.47286298871040344 0.8863636255264282 0.49010562896728516 0.8950130939483643\n","EarlyStopping counter: 3 out of 20\n","124 0.42091915011405945 0.9227527976036072 0.4728772044181824 0.8863636255264282 0.48995158076286316 0.8976377844810486\n","EarlyStopping counter: 4 out of 20\n","125 0.416292279958725 0.9269663095474243 0.4728526473045349 0.8920454382896423 0.4898549020290375 0.8976377844810486\n","Validation loss decreased (0.472763 --> 0.472701).  Saving model ...\n","126 0.4088996946811676 0.9410112500190735 0.4727005660533905 0.8863636255264282 0.4898482859134674 0.8950130939483643\n","Validation loss decreased (0.472701 --> 0.472596).  Saving model ...\n","127 0.4120454788208008 0.9213483333587646 0.47259601950645447 0.8863636255264282 0.4898512661457062 0.8950130939483643\n","Validation loss decreased (0.472596 --> 0.472500).  Saving model ...\n","128 0.4123917520046234 0.9297752976417542 0.4724998474121094 0.8863636255264282 0.48992735147476196 0.8950130939483643\n","Validation loss decreased (0.472500 --> 0.472386).  Saving model ...\n","129 0.4177234172821045 0.9311797618865967 0.4723857641220093 0.8806818127632141 0.49007195234298706 0.8950130939483643\n","Validation loss decreased (0.472386 --> 0.472343).  Saving model ...\n","130 0.41149207949638367 0.9311797618865967 0.47234323620796204 0.875 0.49021050333976746 0.8950130939483643\n","Validation loss decreased (0.472343 --> 0.472316).  Saving model ...\n","131 0.4118923246860504 0.9283707737922668 0.47231557965278625 0.875 0.4903252124786377 0.8923884630203247\n","Validation loss decreased (0.472316 --> 0.472288).  Saving model ...\n","132 0.419903039932251 0.9241573214530945 0.4722883999347687 0.875 0.49052929878234863 0.8923884630203247\n","Validation loss decreased (0.472288 --> 0.472255).  Saving model ...\n","133 0.4187062978744507 0.9185393452644348 0.47225531935691833 0.875 0.49074292182922363 0.887139081954956\n","Validation loss decreased (0.472255 --> 0.472188).  Saving model ...\n","134 0.4135771691799164 0.9171348214149475 0.4721882939338684 0.8693181872367859 0.4907456934452057 0.887139081954956\n","Validation loss decreased (0.472188 --> 0.472118).  Saving model ...\n","135 0.4157167077064514 0.915730357170105 0.4721176028251648 0.8693181872367859 0.4905683100223541 0.8923884630203247\n","Validation loss decreased (0.472118 --> 0.472075).  Saving model ...\n","136 0.41339677572250366 0.9227527976036072 0.4720754623413086 0.875 0.4902667999267578 0.8923884630203247\n","EarlyStopping counter: 1 out of 20\n","137 0.4084342420101166 0.925561785697937 0.47213292121887207 0.8806818127632141 0.4898074269294739 0.8950130939483643\n","EarlyStopping counter: 2 out of 20\n","138 0.4087183177471161 0.9241573214530945 0.47222381830215454 0.8806818127632141 0.4894435405731201 0.8950130939483643\n","EarlyStopping counter: 3 out of 20\n","139 0.41916587948799133 0.9213483333587646 0.4723300039768219 0.8863636255264282 0.4891875088214874 0.8976377844810486\n","EarlyStopping counter: 4 out of 20\n","140 0.40444159507751465 0.9283707737922668 0.47237566113471985 0.8920454382896423 0.4890376925468445 0.9002624750137329\n","EarlyStopping counter: 5 out of 20\n","141 0.41409602761268616 0.9339887499809265 0.47232159972190857 0.8920454382896423 0.4889218509197235 0.9002624750137329\n","Validation loss decreased (0.472075 --> 0.471975).  Saving model ...\n","142 0.4166819453239441 0.9283707737922668 0.4719747006893158 0.8920454382896423 0.4888971447944641 0.9002624750137329\n","Validation loss decreased (0.471975 --> 0.471608).  Saving model ...\n","143 0.41878172755241394 0.9311797618865967 0.4716080129146576 0.8863636255264282 0.48898154497146606 0.8976377844810486\n","Validation loss decreased (0.471608 --> 0.471329).  Saving model ...\n","144 0.4114551246166229 0.9241573214530945 0.47132864594459534 0.8806818127632141 0.4891662895679474 0.8950130939483643\n","Validation loss decreased (0.471329 --> 0.471105).  Saving model ...\n","145 0.40598973631858826 0.925561785697937 0.4711051881313324 0.875 0.4893527626991272 0.8950130939483643\n","Validation loss decreased (0.471105 --> 0.470886).  Saving model ...\n","146 0.4045999348163605 0.9269663095474243 0.4708864390850067 0.8693181872367859 0.4895448088645935 0.8897637724876404\n","Validation loss decreased (0.470886 --> 0.470738).  Saving model ...\n","147 0.415778249502182 0.9227527976036072 0.4707379639148712 0.8693181872367859 0.48951923847198486 0.8897637724876404\n","Validation loss decreased (0.470738 --> 0.470562).  Saving model ...\n","148 0.40957534313201904 0.9269663095474243 0.47056159377098083 0.8693181872367859 0.4894700348377228 0.8897637724876404\n","Validation loss decreased (0.470562 --> 0.470451).  Saving model ...\n","149 0.4145056903362274 0.915730357170105 0.47045138478279114 0.8693181872367859 0.4892815351486206 0.8923884630203247\n","Validation loss decreased (0.470451 --> 0.470291).  Saving model ...\n","150 0.41150376200675964 0.925561785697937 0.47029054164886475 0.8693181872367859 0.48919978737831116 0.8923884630203247\n","Validation loss decreased (0.470291 --> 0.470164).  Saving model ...\n","151 0.4085012674331665 0.9269663095474243 0.47016391158103943 0.8806818127632141 0.489001989364624 0.8923884630203247\n","Validation loss decreased (0.470164 --> 0.469970).  Saving model ...\n","152 0.4196021556854248 0.915730357170105 0.4699702560901642 0.8806818127632141 0.48893335461616516 0.8923884630203247\n","Validation loss decreased (0.469970 --> 0.469796).  Saving model ...\n","153 0.40746089816093445 0.9339887499809265 0.46979647874832153 0.875 0.4889453649520874 0.8923884630203247\n","Validation loss decreased (0.469796 --> 0.469697).  Saving model ...\n","154 0.4073367118835449 0.925561785697937 0.4696965515613556 0.8806818127632141 0.4888847768306732 0.8923884630203247\n","Validation loss decreased (0.469697 --> 0.469552).  Saving model ...\n","155 0.41139858961105347 0.9213483333587646 0.4695518910884857 0.875 0.48889920115470886 0.8923884630203247\n","Validation loss decreased (0.469552 --> 0.469532).  Saving model ...\n","156 0.41103747487068176 0.9213483333587646 0.4695322811603546 0.8806818127632141 0.4887302815914154 0.8923884630203247\n","Validation loss decreased (0.469532 --> 0.469505).  Saving model ...\n","157 0.4002133011817932 0.932584285736084 0.46950528025627136 0.8806818127632141 0.48858141899108887 0.8950130939483643\n","Validation loss decreased (0.469505 --> 0.469464).  Saving model ...\n","158 0.41175639629364014 0.9283707737922668 0.4694642722606659 0.8806818127632141 0.4885008633136749 0.8950130939483643\n","Validation loss decreased (0.469464 --> 0.469365).  Saving model ...\n","159 0.4101405739784241 0.932584285736084 0.46936509013175964 0.8806818127632141 0.488505095243454 0.8923884630203247\n","Validation loss decreased (0.469365 --> 0.469319).  Saving model ...\n","160 0.4147597551345825 0.9213483333587646 0.4693193733692169 0.8806818127632141 0.4883829951286316 0.8950130939483643\n","Validation loss decreased (0.469319 --> 0.469270).  Saving model ...\n","161 0.4058029353618622 0.9311797618865967 0.46927011013031006 0.8806818127632141 0.48827919363975525 0.8950130939483643\n","Validation loss decreased (0.469270 --> 0.469259).  Saving model ...\n","162 0.4082847237586975 0.9241573214530945 0.4692588150501251 0.8806818127632141 0.4881519377231598 0.8976377844810486\n","Validation loss decreased (0.469259 --> 0.469179).  Saving model ...\n","163 0.4124022424221039 0.9269663095474243 0.4691787660121918 0.8806818127632141 0.48812705278396606 0.8976377844810486\n","Validation loss decreased (0.469179 --> 0.469090).  Saving model ...\n","164 0.4041164517402649 0.9382022619247437 0.4690900146961212 0.8806818127632141 0.48816540837287903 0.8923884630203247\n","Validation loss decreased (0.469090 --> 0.468971).  Saving model ...\n","165 0.4096308648586273 0.9213483333587646 0.46897050738334656 0.8806818127632141 0.48823636770248413 0.8923884630203247\n","Validation loss decreased (0.468971 --> 0.468755).  Saving model ...\n","166 0.4049271047115326 0.9311797618865967 0.4687553942203522 0.875 0.48851680755615234 0.8897637724876404\n","Validation loss decreased (0.468755 --> 0.468672).  Saving model ...\n","167 0.4046391546726227 0.9311797618865967 0.4686722159385681 0.8693181872367859 0.48880064487457275 0.8897637724876404\n","Validation loss decreased (0.468672 --> 0.468620).  Saving model ...\n","168 0.4039568603038788 0.9241573214530945 0.46861952543258667 0.8579545617103577 0.4891101121902466 0.8897637724876404\n","EarlyStopping counter: 1 out of 20\n","169 0.40751615166664124 0.9227527976036072 0.46862176060676575 0.8579545617103577 0.48949334025382996 0.887139081954956\n","Validation loss decreased (0.468620 --> 0.468599).  Saving model ...\n","170 0.40270915627479553 0.9213483333587646 0.46859851479530334 0.8579545617103577 0.48952731490135193 0.8845144510269165\n","Validation loss decreased (0.468599 --> 0.468523).  Saving model ...\n","171 0.40535157918930054 0.925561785697937 0.46852272748947144 0.8579545617103577 0.48908552527427673 0.8897637724876404\n","EarlyStopping counter: 1 out of 20\n","172 0.4102500081062317 0.9213483333587646 0.46858513355255127 0.875 0.4884723424911499 0.8897637724876404\n","EarlyStopping counter: 2 out of 20\n","173 0.3978070914745331 0.9311797618865967 0.4686776399612427 0.875 0.4879453778266907 0.8923884630203247\n","EarlyStopping counter: 3 out of 20\n","174 0.4049643576145172 0.9283707737922668 0.4688815176486969 0.8806818127632141 0.48742347955703735 0.8976377844810486\n","EarlyStopping counter: 4 out of 20\n","175 0.403453528881073 0.9339887499809265 0.469046950340271 0.8863636255264282 0.487171471118927 0.8976377844810486\n","EarlyStopping counter: 5 out of 20\n","176 0.39336511492729187 0.9452247023582458 0.4691523611545563 0.8920454382896423 0.4869946837425232 0.9028871655464172\n","EarlyStopping counter: 6 out of 20\n","177 0.4033551812171936 0.9311797618865967 0.46915650367736816 0.8920454382896423 0.48691943287849426 0.9028871655464172\n","EarlyStopping counter: 7 out of 20\n","178 0.401206910610199 0.9311797618865967 0.46918216347694397 0.8920454382896423 0.4868308901786804 0.9028871655464172\n","EarlyStopping counter: 8 out of 20\n","179 0.39462095499038696 0.9410112500190735 0.4689561426639557 0.8920454382896423 0.48688429594039917 0.9028871655464172\n","EarlyStopping counter: 9 out of 20\n","180 0.4041111469268799 0.9353932738304138 0.4687613546848297 0.8863636255264282 0.48700904846191406 0.8976377844810486\n","EarlyStopping counter: 10 out of 20\n","181 0.4064790904521942 0.932584285736084 0.4686281383037567 0.8806818127632141 0.4873131811618805 0.8950130939483643\n","EarlyStopping counter: 11 out of 20\n","182 0.40165817737579346 0.9339887499809265 0.46856093406677246 0.875 0.4877265691757202 0.8897637724876404\n","EarlyStopping counter: 12 out of 20\n","183 0.3978566825389862 0.9241573214530945 0.46855929493904114 0.8693181872367859 0.48775482177734375 0.8897637724876404\n","EarlyStopping counter: 13 out of 20\n","184 0.40033331513404846 0.9353932738304138 0.4685588777065277 0.8693181872367859 0.48776906728744507 0.8897637724876404\n","EarlyStopping counter: 14 out of 20\n","185 0.40322285890579224 0.9213483333587646 0.4685594439506531 0.8693181872367859 0.4877570569515228 0.8897637724876404\n","EarlyStopping counter: 15 out of 20\n","186 0.3925611078739166 0.942415714263916 0.46856197714805603 0.8693181872367859 0.4877340793609619 0.8897637724876404\n","EarlyStopping counter: 16 out of 20\n","187 0.4105265438556671 0.9213483333587646 0.46856245398521423 0.8693181872367859 0.48769280314445496 0.8897637724876404\n","EarlyStopping counter: 17 out of 20\n","188 0.3930208384990692 0.932584285736084 0.4685642421245575 0.875 0.487636536359787 0.8897637724876404\n","EarlyStopping counter: 18 out of 20\n","189 0.3938133120536804 0.9367977380752563 0.46856528520584106 0.875 0.48757416009902954 0.8923884630203247\n","EarlyStopping counter: 19 out of 20\n","190 0.397060364484787 0.9410112500190735 0.4685699939727783 0.875 0.4875122904777527 0.8923884630203247\n","EarlyStopping counter: 20 out of 20\n","Early stopping\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{"tags":[]},"execution_count":48}]},{"cell_type":"code","metadata":{"id":"_ar8xXFbYwzN","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"executionInfo":{"status":"ok","timestamp":1593670380790,"user_tz":180,"elapsed":161829,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"8ece7731-f99d-47e5-8a66-60a93c470b7b"},"source":["print(Precision(prediction, Y_train_tensor))\n","print(Precision(val_prediction, Y_valid_tensor))\n","print(Precision(test_prediction, Y_test_tensor))"],"execution_count":49,"outputs":[{"output_type":"stream","text":["[0.9785714149475098, 0.7368420958518982]\n","[0.9492753744125366, 0.6052631735801697]\n","[0.9453375935554504, 0.6571428775787354]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Noxe6JaLYxag","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"executionInfo":{"status":"ok","timestamp":1593670380790,"user_tz":180,"elapsed":161822,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"3ee279a3-8d45-4e0c-b65d-6121923c19d8"},"source":["print(Recall(prediction, Y_train_tensor))\n","print(Recall(val_prediction, Y_valid_tensor))\n","print(Recall(test_prediction, Y_test_tensor))"],"execution_count":50,"outputs":[{"output_type":"stream","text":["[0.9319728016853333, 0.9032257795333862]\n","[0.8972602486610413, 0.7666666507720947]\n","[0.9245283007621765, 0.7301587462425232]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5an2w6BsYxL2","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"executionInfo":{"status":"ok","timestamp":1593670380791,"user_tz":180,"elapsed":161817,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"fa4ff139-3a4b-4ca1-f129-b7672549c374"},"source":["print(Accuracy(prediction, Y_train_tensor))\n","print(Accuracy(val_prediction, Y_valid_tensor))\n","print(Accuracy(test_prediction, Y_test_tensor))"],"execution_count":51,"outputs":[{"output_type":"stream","text":["0.9269663095474243\n","0.875\n","0.8923884630203247\n"],"name":"stdout"}]}]}