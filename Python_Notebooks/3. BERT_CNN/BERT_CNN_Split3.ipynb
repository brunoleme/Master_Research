{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of FineTuned_Split3.ipynb","provenance":[{"file_id":"1iEtoUyt4l6WoYZKnFY4vMwGIaInqm1Z7","timestamp":1592589760254},{"file_id":"1jM_MQeWnqB4LrmlAc_rZ00W9zJK7Hw_d","timestamp":1590464112416}],"collapsed_sections":[],"authorship_tag":"ABX9TyPrFi23HZ9vJ0W0knMckWoL"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"KWy32B6i5zUX","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593670560972,"user_tz":180,"elapsed":1040,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"8108e2da-6ff8-408e-847f-2e82bc74f0b7"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IUvtjwnKQx0R","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593670563624,"user_tz":180,"elapsed":3686,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["import numpy as np\n","import torch\n","\n","class EarlyStopping:\n","    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n","    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt'):\n","        \"\"\"\n","        Args:\n","            patience (int): How long to wait after last time validation loss improved.\n","                            Default: 7\n","            verbose (bool): If True, prints a message for each validation loss improvement. \n","                            Default: False\n","            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n","                            Default: 0\n","            path (str): Path for the checkpoint to be saved to.\n","                            Default: 'checkpoint.pt'\n","        \"\"\"\n","        self.patience = patience\n","        self.verbose = verbose\n","        self.counter = 0\n","        self.best_score = None\n","        self.early_stop = False\n","        self.val_loss_min = np.Inf\n","        self.delta = delta\n","        self.path = path\n","\n","    def __call__(self, val_loss, model):\n","\n","        score = -val_loss\n","\n","        if self.best_score is None:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model)\n","        elif score < self.best_score + self.delta:\n","            self.counter += 1\n","            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n","            if self.counter >= self.patience:\n","                self.early_stop = True\n","        else:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model)\n","            self.counter = 0\n","\n","    def save_checkpoint(self, val_loss, model):\n","        '''Saves model when validation loss decrease.'''\n","        if self.verbose:\n","            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n","        torch.save(model.state_dict(), self.path)\n","        self.val_loss_min = val_loss"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"WtPr52JNXzXL","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593670563625,"user_tz":180,"elapsed":3683,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["def Accuracy(prediction, observation):\n","  prediction = prediction[:,1]\n","  prediction_class = (torch.reshape(prediction, observation.shape) > 0.5).float()\n","  correct = (prediction_class == observation).float().sum()\n","  accuracy = correct/prediction_class.shape[0]\n","  return float(accuracy.cpu())\n","\n","def Precision(prediction, observation):\n","  prediction = prediction[:,1]\n","  res = []\n","  prediction_class = (torch.reshape(prediction, observation.shape) > 0.5).float()\n","  for label in [0, 1]:\n","    correct = (prediction_class[prediction_class == label] == observation[prediction_class == label]).float().sum()\n","    precision = correct/prediction_class[prediction_class == label].shape[0]\n","    res.append(float(precision.cpu()))\n","  return res\n","\n","def Recall(prediction, observation):\n","  prediction = prediction[:,1]\n","  res = []\n","  prediction_class = (torch.reshape(prediction, observation.shape) > 0.5).float()\n","  for label in [0, 1]:\n","    correct = (prediction_class[observation == label] == observation[observation == label]).float().sum()\n","    recall = correct/prediction_class[observation == label].shape[0]\n","    res.append(float(recall.cpu()))\n","  return res"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"tLrptDIu6E6A","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593670563626,"user_tz":180,"elapsed":3680,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["n_split = 3"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"uCC2fopD6JTj","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593670563626,"user_tz":180,"elapsed":3676,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["import pickle\n","import numpy as np"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"LXHTiUtW6MJX","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593670579029,"user_tz":180,"elapsed":19077,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["with open('/content/drive/My Drive/Data Master/X_train_final', 'rb') as file:\n","    X_train = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/Y_train_final', 'rb') as file:\n","    Y_train = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/X_test_final', 'rb') as file:\n","    X_test = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/Y_test_final', 'rb') as file:\n","    Y_test = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/word_index_final', 'rb') as file:\n","    word_index = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/train_last_layer_embeddings_tail_fine_tuned_split' + str(n_split) + '.pkl', 'rb') as file:\n","    train_last_layer_embeddings = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/train_all_layers_embeddings_tail_fine_tuned_split' + str(n_split) + '.pkl', 'rb') as file:\n","    train_all_layers_embeddings = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/train_cls_token_embeddings_tail_fine_tuned_split' + str(n_split) + '.pkl', 'rb') as file:\n","    train_cls_token_embeddings = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/test_last_layer_embeddings_tail_fine_tuned_split' + str(n_split) + '.pkl', 'rb') as file:\n","    test_last_layer_embeddings = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/test_all_layers_embeddings_tail_fine_tuned_split' + str(n_split) + '.pkl', 'rb') as file:\n","    test_all_layers_embeddings = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/test_cls_token_embeddings_tail_fine_tuned_split' + str(n_split) + '.pkl', 'rb') as file:\n","    test_cls_token_embeddings = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/train_index_final_split_' + str(n_split), 'rb') as file:\n","    train_index = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/valid_index_final_split_' + str(n_split), 'rb') as file:\n","    valid_index = pickle.load(file)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"3f7F7ELTH7Kc","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593670579030,"user_tz":180,"elapsed":19075,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["test_index = [i for i, _ in enumerate(X_test)]"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"7cw3aVs0tNYu","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593670579030,"user_tz":180,"elapsed":19072,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["inv_word_index = {ix : w for w, ix in word_index.items()}"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"-imDG-lFcsym","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593670583943,"user_tz":180,"elapsed":23981,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["import itertools\n","features_index = {w:ix for ix, w in enumerate(np.unique(list(itertools.chain.from_iterable(np.array(X_train)[train_index]))))}\n","inv_features_index = {ix:w for ix, w in enumerate(np.unique(list(itertools.chain.from_iterable(np.array(X_train)[train_index]))))}"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"8cMPG0UDc2LV","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593670585514,"user_tz":180,"elapsed":25549,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["X_train_matrix = np.zeros((len(X_train), len(features_index)))\n","X_test_matrix = np.zeros((len(X_test), len(features_index)))"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"weNsqkv4c5ih","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593670604072,"user_tz":180,"elapsed":44098,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["for i, x in enumerate(X_train):\n","  for w in x:\n","    if w in features_index:\n","      X_train_matrix[i,features_index[w]] += 1\n","\n","for i, x in enumerate(X_test):\n","  for w in x:\n","    if w in features_index:\n","      X_test_matrix[i,features_index[w]] += 1"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"UA9bR-8qsdkz","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593670604073,"user_tz":180,"elapsed":44097,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["data_train_doc_ids = [(i, d) for i, d in enumerate(X_train)]\n","data_test_doc_ids = [(i, d) for i, d in enumerate(X_test)]"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"fslOxq7L_dkN","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593670604074,"user_tz":180,"elapsed":44095,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["target_train_doc_ids = [(i, y) for i, y in enumerate(Y_train)]\n","target_test_doc_ids = [(i, y) for i, y in enumerate(Y_test)]"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"gBUtPIZ56-qI","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593670604074,"user_tz":180,"elapsed":44093,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["doc_train_ids = np.array([i for i, _ in data_train_doc_ids])\n","doc_test_ids = np.array([i for i, _ in data_test_doc_ids])\n","doc_train_dict = {k:v for k, v in [(i, d) for i, d in data_train_doc_ids]}\n","doc_test_dict = {k:v for k, v in [(i, d) for i, d in data_test_doc_ids]}\n","target_train_dict = {k:v for k, v in [(i, y) for i, y in target_train_doc_ids]}\n","target_test_dict = {k:v for k, v in [(i, y) for i, y in target_test_doc_ids]}"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"SNrkQqCt7wTE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":952},"executionInfo":{"status":"ok","timestamp":1593670604075,"user_tz":180,"elapsed":44091,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"ff3d610f-f1be-4be8-b227-ac5471139d81"},"source":["doc_train_ids[train_index]"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([  0,   1,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n","        14,  17,  18,  19,  23,  25,  26,  27,  28,  29,  30,  31,  33,\n","        34,  36,  37,  38,  39,  40,  41,  42,  43,  44,  45,  47,  48,\n","        50,  51,  52,  53,  54,  55,  56,  57,  60,  61,  62,  63,  64,\n","        65,  66,  67,  68,  70,  71,  72,  73,  74,  76,  77,  78,  79,\n","        80,  81,  83,  84,  85,  86,  87,  89,  90,  91,  92,  93,  94,\n","        95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107,\n","       108, 110, 112, 113, 114, 115, 116, 117, 118, 121, 122, 123, 124,\n","       125, 126, 127, 128, 129, 131, 133, 134, 135, 136, 137, 138, 139,\n","       140, 142, 143, 144, 145, 146, 147, 148, 149, 151, 152, 153, 154,\n","       155, 156, 158, 159, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n","       170, 171, 172, 173, 174, 175, 176, 177, 179, 180, 181, 182, 183,\n","       186, 189, 190, 191, 192, 193, 194, 195, 196, 198, 200, 201, 202,\n","       203, 204, 205, 206, 207, 209, 210, 211, 212, 213, 214, 215, 216,\n","       217, 218, 219, 220, 221, 222, 223, 224, 226, 227, 228, 229, 230,\n","       231, 232, 234, 235, 238, 240, 241, 242, 243, 244, 245, 246, 248,\n","       249, 251, 252, 254, 255, 256, 257, 259, 260, 261, 262, 263, 264,\n","       265, 266, 268, 269, 270, 273, 274, 275, 276, 277, 279, 280, 282,\n","       283, 284, 285, 286, 287, 288, 289, 292, 293, 294, 295, 297, 298,\n","       301, 302, 303, 305, 306, 307, 308, 309, 310, 312, 313, 314, 315,\n","       316, 317, 318, 319, 320, 321, 322, 323, 324, 328, 330, 335, 336,\n","       337, 339, 340, 341, 342, 344, 346, 347, 349, 350, 351, 352, 353,\n","       354, 355, 356, 357, 358, 359, 360, 361, 362, 364, 365, 368, 369,\n","       370, 371, 372, 373, 374, 375, 376, 377, 378, 380, 381, 383, 384,\n","       385, 386, 388, 389, 391, 392, 393, 394, 395, 396, 397, 399, 400,\n","       403, 404, 406, 408, 409, 410, 411, 412, 413, 416, 417, 418, 420,\n","       421, 422, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435,\n","       436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 448, 449, 450,\n","       451, 453, 454, 455, 456, 459, 460, 461, 462, 463, 464, 465, 467,\n","       468, 469, 470, 471, 472, 475, 476, 477, 478, 479, 481, 482, 483,\n","       484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 496, 497, 498,\n","       499, 500, 501, 502, 503, 504, 506, 507, 508, 509, 510, 511, 514,\n","       515, 516, 517, 518, 519, 520, 522, 523, 524, 525, 527, 528, 529,\n","       530, 532, 534, 536, 537, 538, 539, 540, 542, 546, 549, 550, 552,\n","       553, 555, 557, 559, 560, 562, 563, 564, 567, 568, 569, 570, 571,\n","       573, 575, 578, 581, 583, 584, 586, 588, 589, 590, 591, 592, 593,\n","       594, 595, 596, 597, 598, 599, 601, 603, 604, 608, 609, 610, 612,\n","       616, 617, 618, 619, 620, 622, 623, 624, 625, 626, 627, 628, 629,\n","       630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 641, 642, 644,\n","       645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657,\n","       658, 659, 662, 663, 664, 666, 667, 668, 669, 670, 673, 674, 675,\n","       676, 677, 678, 679, 680, 681, 682, 683, 684, 686, 687, 688, 689,\n","       690, 691, 692, 693, 694, 695, 696, 697, 699, 700, 701, 702, 703,\n","       704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716,\n","       717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729,\n","       731, 732, 733, 735, 736, 737, 738, 739, 740, 741, 744, 745, 746,\n","       747, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760,\n","       762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774,\n","       775, 776, 777, 778, 779, 780, 781, 782, 783, 786, 787, 789, 790,\n","       791, 792, 793, 794, 795, 797, 798, 799, 801, 802, 803, 804, 805,\n","       807, 808, 809, 810, 812, 813, 815, 817, 819, 820, 821, 822, 823,\n","       824, 825, 828, 829, 831, 832, 833, 834, 835, 836, 837, 838, 842,\n","       843, 845, 846, 847, 848, 849, 850, 852, 853, 854, 855, 857, 858,\n","       860, 862, 864, 865, 866, 867, 868, 869, 871, 872, 873, 874, 876,\n","       877, 878, 879, 883, 884, 885, 886, 887])"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"npzysPqN8-Pi","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":255},"executionInfo":{"status":"ok","timestamp":1593670604075,"user_tz":180,"elapsed":44088,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"04b94549-eeab-4c4d-974a-d03c9c0bbd6d"},"source":["doc_train_ids[valid_index]"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([  2,  15,  16,  20,  21,  22,  24,  32,  35,  46,  49,  58,  59,\n","        69,  75,  82,  88, 109, 111, 119, 120, 130, 132, 141, 150, 157,\n","       160, 178, 184, 185, 187, 188, 197, 199, 208, 225, 233, 236, 237,\n","       239, 247, 250, 253, 258, 267, 271, 272, 278, 281, 290, 291, 296,\n","       299, 300, 304, 311, 325, 326, 327, 329, 331, 332, 333, 334, 338,\n","       343, 345, 348, 363, 366, 367, 379, 382, 387, 390, 398, 401, 402,\n","       405, 407, 414, 415, 419, 423, 424, 446, 447, 452, 457, 458, 466,\n","       473, 474, 480, 494, 495, 505, 512, 513, 521, 526, 531, 533, 535,\n","       541, 543, 544, 545, 547, 548, 551, 554, 556, 558, 561, 565, 566,\n","       572, 574, 576, 577, 579, 580, 582, 585, 587, 600, 602, 605, 606,\n","       607, 611, 613, 614, 615, 621, 640, 643, 660, 661, 665, 671, 672,\n","       685, 698, 730, 734, 742, 743, 748, 761, 784, 785, 788, 796, 800,\n","       806, 811, 814, 816, 818, 826, 827, 830, 839, 840, 841, 844, 851,\n","       856, 859, 861, 863, 870, 875, 880, 881, 882])"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"N2LDzB_2755O","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":527},"executionInfo":{"status":"ok","timestamp":1593670604076,"user_tz":180,"elapsed":44086,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"d0477403-40ea-49a4-f2cd-0bfa46116f75"},"source":["doc_test_ids[test_index]"],"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n","        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n","        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n","        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n","        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n","        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n","        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n","        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n","       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n","       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n","       130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n","       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n","       156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n","       169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n","       182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n","       195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n","       208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n","       221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n","       234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246,\n","       247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259,\n","       260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272,\n","       273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n","       286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298,\n","       299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n","       312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324,\n","       325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337,\n","       338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350,\n","       351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n","       364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376,\n","       377, 378, 379, 380])"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"9hORlMAi41vy","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":615},"executionInfo":{"status":"ok","timestamp":1593670611541,"user_tz":180,"elapsed":51548,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"79a7caee-be40-4c58-ec0c-1b315d96ef53"},"source":["!pip install transformers"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/35/1c3f6e62d81f5f0daff1384e6d5e6c5758682a8357ebc765ece2b9def62b/transformers-3.0.0-py3-none-any.whl (754kB)\n","\u001b[K     |████████████████████████████████| 757kB 8.3MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 20.3MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Collecting tokenizers==0.8.0-rc4\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e8/bd/e5abec46af977c8a1375c1dca7cb1e5b3ec392ef279067af7f6bc50491a0/tokenizers-0.8.0rc4-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n","\u001b[K     |████████████████████████████████| 3.0MB 44.3MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n","Collecting sentencepiece\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n","\u001b[K     |████████████████████████████████| 1.1MB 44.5MB/s \n","\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.12.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.15.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=4c7ce780ee9ada8a28da92d14b73c394e62c7a04dc3127c8e5c9846185c89b4d\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built sacremoses\n","Installing collected packages: sacremoses, tokenizers, sentencepiece, transformers\n","Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.0rc4 transformers-3.0.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"x0bQcArrMwCk","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593670614264,"user_tz":180,"elapsed":54269,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["import pandas as pd\n","import numpy as np\n","import itertools\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import transformers\n","import torch.utils.data as tdata\n","import torch.optim as optim\n","\n","import tqdm\n","\n","torch.manual_seed(0)\n","np.random.seed(0)"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"FDhmJ8RY4-St","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593670614265,"user_tz":180,"elapsed":54266,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"oSU-aTSudTA4","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593670616083,"user_tz":180,"elapsed":56081,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["X0_train_tensor = torch.from_numpy(X_train_matrix[train_index]).float().to(device)\n","X0_valid_tensor = torch.from_numpy(X_train_matrix[valid_index]).float().to(device)\n","X0_test_tensor = torch.from_numpy(X_test_matrix).float().to(device)"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"4lzOGqwU3lLq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593670616084,"user_tz":180,"elapsed":56080,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"9d7607d5-c837-4bb0-c256-6264cd8698c8"},"source":["np.max([len(clss) for doc, clss in train_cls_token_embeddings.items()])"],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["285"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"VvRh2dHK5Hmr","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593670616084,"user_tz":180,"elapsed":56077,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["max_len = 50"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"9Fq3PgQB7NgF","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593670616085,"user_tz":180,"elapsed":56076,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["def manual_padding(sent, max_len = 200):\n","  pad_tensor = [torch.from_numpy(np.zeros((1, 768))).float()]\n","  if len(sent) > max_len:\n","    res = sent[-max_len:]\n","  else:\n","    res = (pad_tensor * (max_len - len(sent))) + sent\n","  return res"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"id":"U6iFCg7p9011","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593670616086,"user_tz":180,"elapsed":56074,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["X1_train_tensor = torch.stack([torch.stack(manual_padding(sent=train_cls_token_embeddings[i], max_len = max_len)) for i in train_index]).squeeze(2).to(device)\n","X2_train_tensor = torch.stack([train_last_layer_embeddings[i] for i in train_index]).squeeze(1).to(device)\n","X3_train_tensor = torch.stack([torch.flatten(train_all_layers_embeddings[i].permute(1, 0, 2), start_dim=1) for i in train_index]).squeeze(1).to(device)"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"5nLhw-oqKViw","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593670616087,"user_tz":180,"elapsed":56072,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["X1_valid_tensor = torch.stack([torch.stack(manual_padding(sent=train_cls_token_embeddings[i], max_len = max_len)) for i in valid_index]).squeeze(2).to(device)\n","X2_valid_tensor = torch.stack([train_last_layer_embeddings[i] for i in valid_index]).squeeze(1).to(device)\n","X3_valid_tensor = torch.stack([torch.flatten(train_all_layers_embeddings[i].permute(1, 0, 2), start_dim=1) for i in valid_index]).squeeze(1).to(device)"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"id":"9AYQ7TYfO_uR","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593670616087,"user_tz":180,"elapsed":56069,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["X1_test_tensor = torch.stack([torch.stack(manual_padding(sent=test_cls_token_embeddings[i], max_len = max_len)) for i in test_index]).squeeze(2).to(device)\n","X2_test_tensor = torch.stack([test_last_layer_embeddings[i] for i in test_index]).squeeze(1).to(device)\n","X3_test_tensor = torch.stack([torch.flatten(test_all_layers_embeddings[i].permute(1, 0, 2), start_dim=1) for i in test_index]).squeeze(1).to(device)"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"pSOM62CnKVct","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593670616088,"user_tz":180,"elapsed":56067,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["Y_train_tensor = torch.LongTensor(np.array(Y_train)[train_index]).to(device)\n","Y_valid_tensor = torch.LongTensor(np.array(Y_train)[valid_index]).to(device)\n","Y_test_tensor = torch.LongTensor(np.array(Y_test)).to(device)"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"TxXNnfKaBXbK","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593670616088,"user_tz":180,"elapsed":56064,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"4a739b2d-a828-4426-f4f3-92edde5b1883"},"source":["X0_train_tensor.shape"],"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([710, 245166])"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"code","metadata":{"id":"7lwdtYzhStJH","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593670616728,"user_tz":180,"elapsed":56702,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"a74846b2-612f-49a1-ef9e-4dd6ab42df5d"},"source":["X1_train_tensor.shape"],"execution_count":30,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([710, 50, 768])"]},"metadata":{"tags":[]},"execution_count":30}]},{"cell_type":"code","metadata":{"id":"4cbKWwZ7StDF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593670616728,"user_tz":180,"elapsed":56700,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"5e92534c-aa96-4e72-c833-c878863987cc"},"source":["X2_train_tensor.shape"],"execution_count":31,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([710, 768])"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"code","metadata":{"id":"YK-km_HcSsjM","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593670616729,"user_tz":180,"elapsed":56698,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"e0aeec54-350c-49b5-b6c4-f3f31f6f520e"},"source":["X3_train_tensor.shape"],"execution_count":32,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([710, 9984])"]},"metadata":{"tags":[]},"execution_count":32}]},{"cell_type":"code","metadata":{"id":"OnRUTIxRQRoT","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593670616729,"user_tz":180,"elapsed":56695,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["input_dim_0 = X0_train_tensor.shape[1]\n","input_dim_2 = X2_train_tensor.shape[1]\n","input_dim_3 = X3_train_tensor.shape[1]\n","EMBEDDING_DIM = X1_train_tensor.shape[2]"],"execution_count":33,"outputs":[]},{"cell_type":"code","metadata":{"id":"fBO0s-eUTqYk","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593670616730,"user_tz":180,"elapsed":56694,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"678951cc-2929-4387-f2d0-225b257c7f92"},"source":["input_dim_0"],"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/plain":["245166"]},"metadata":{"tags":[]},"execution_count":34}]},{"cell_type":"code","metadata":{"id":"BM9kem7rTqR7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593670616730,"user_tz":180,"elapsed":56692,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"f92af385-cfe9-4f4e-b51f-da24698f4748"},"source":["input_dim_2"],"execution_count":35,"outputs":[{"output_type":"execute_result","data":{"text/plain":["768"]},"metadata":{"tags":[]},"execution_count":35}]},{"cell_type":"code","metadata":{"id":"zPtu--rCRZI7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593670616731,"user_tz":180,"elapsed":56688,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"12a1b126-f853-4156-da96-1e6d6b1e48fa"},"source":["input_dim_3"],"execution_count":36,"outputs":[{"output_type":"execute_result","data":{"text/plain":["9984"]},"metadata":{"tags":[]},"execution_count":36}]},{"cell_type":"code","metadata":{"id":"Gm3d5UPCBh8g","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593670616731,"user_tz":180,"elapsed":56686,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"0ef2dee5-b784-40f5-a38c-cce7a705ff5c"},"source":["EMBEDDING_DIM"],"execution_count":37,"outputs":[{"output_type":"execute_result","data":{"text/plain":["768"]},"metadata":{"tags":[]},"execution_count":37}]},{"cell_type":"code","metadata":{"id":"Qbh-533qOJ2M","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593670616732,"user_tz":180,"elapsed":56685,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["class MyModel(nn.Module):\n","    def __init__(self):\n","        super(MyModel, self).__init__()\n","        self.conv2 = nn.Sequential(\n","          nn.Conv1d(in_channels=EMBEDDING_DIM, out_channels=64, kernel_size=2),\n","          nn.ReLU(),\n","          #nn.Conv1d(in_channels=64, out_channels=32, kernel_size=3),\n","          #nn.ReLU(),\n","          #nn.Conv1d(in_channels=32, out_channels=16, kernel_size=4),\n","          #nn.ReLU(),\n","          nn.AdaptiveMaxPool1d(1),\n","          nn.Dropout(0.3),\n","      )\n","        \n","        self.fc_out = nn.Linear(64, 2)\n","\n","        self.softmax = nn.Softmax(dim=1)\n","\n","        self.dropout = nn.Dropout(0.3)\n","        \n","    def forward(self, x2):\n","        x2 = x2.permute(0,2,1)\n","        x2 = F.normalize(x2)\n","\n","        h2 = self.conv2(x2).squeeze(2)\n","\n","        # Concatenate in dim1 (feature dimension)\n","        y = self.softmax(self.fc_out(h2))\n","        return y"],"execution_count":38,"outputs":[]},{"cell_type":"code","metadata":{"id":"i1bYTYLVQONx","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1593670616732,"user_tz":180,"elapsed":56682,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"f72c937c-5d38-454d-d2a0-a25c35de9f84"},"source":["model = MyModel()\n","model.to(device)"],"execution_count":39,"outputs":[{"output_type":"execute_result","data":{"text/plain":["MyModel(\n","  (conv2): Sequential(\n","    (0): Conv1d(768, 64, kernel_size=(2,), stride=(1,))\n","    (1): ReLU()\n","    (2): AdaptiveMaxPool1d(output_size=1)\n","    (3): Dropout(p=0.3, inplace=False)\n","  )\n","  (fc_out): Linear(in_features=64, out_features=2, bias=True)\n","  (softmax): Softmax(dim=1)\n","  (dropout): Dropout(p=0.3, inplace=False)\n",")"]},"metadata":{"tags":[]},"execution_count":39}]},{"cell_type":"code","metadata":{"id":"6NvnlU24DsVb","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593670616733,"user_tz":180,"elapsed":56681,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"86ddc2fc-1cef-40f9-df6d-b9f96c58e92c"},"source":["X0_train_tensor.shape"],"execution_count":40,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([710, 245166])"]},"metadata":{"tags":[]},"execution_count":40}]},{"cell_type":"code","metadata":{"id":"dY6VwvOBTc-K","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593670616733,"user_tz":180,"elapsed":56679,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"0d6ce286-6fd2-41ad-ff22-f1ab3a7157f2"},"source":["X1_train_tensor.shape"],"execution_count":41,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([710, 50, 768])"]},"metadata":{"tags":[]},"execution_count":41}]},{"cell_type":"code","metadata":{"id":"XyyWGhv0Tc3d","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593670616734,"user_tz":180,"elapsed":56677,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"c9645c14-fe24-49bd-d59e-5253e593d72c"},"source":["X2_train_tensor.shape"],"execution_count":42,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([710, 768])"]},"metadata":{"tags":[]},"execution_count":42}]},{"cell_type":"code","metadata":{"id":"rCMfNXulTcvs","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593670616735,"user_tz":180,"elapsed":56676,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"ad719436-06a6-4a68-be0c-5a5034cf63f4"},"source":["X3_train_tensor.shape"],"execution_count":43,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([710, 9984])"]},"metadata":{"tags":[]},"execution_count":43}]},{"cell_type":"code","metadata":{"id":"acr1hz5FQmT5","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593670616735,"user_tz":180,"elapsed":56674,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["import torch.optim as optim\n","optimizer = optim.AdamW(model.parameters(), lr=0.01)"],"execution_count":44,"outputs":[]},{"cell_type":"code","metadata":{"id":"fp5F7lhtULiq","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593670616736,"user_tz":180,"elapsed":56673,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["from torch.optim.lr_scheduler import ReduceLROnPlateau\n","scheduler = ReduceLROnPlateau(optimizer, 'min')"],"execution_count":45,"outputs":[]},{"cell_type":"code","metadata":{"id":"fGkOOoMZJ4GF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593670616736,"user_tz":180,"elapsed":56671,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"3e5dce1a-a9da-4b40-cefb-0dfb7f286f74"},"source":["weights = [sum(Y_train)/len(Y_train), 1-sum(Y_train)/len(Y_train)]\n","class_weights = torch.FloatTensor(weights)\n","class_weights"],"execution_count":46,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0.1734, 0.8266])"]},"metadata":{"tags":[]},"execution_count":46}]},{"cell_type":"code","metadata":{"id":"nWrjkNzQQqW5","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593670616737,"user_tz":180,"elapsed":56670,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["criterion = nn.CrossEntropyLoss(weight=class_weights)"],"execution_count":47,"outputs":[]},{"cell_type":"code","metadata":{"id":"jtbi4GvTQta7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1593670669651,"user_tz":180,"elapsed":109582,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"1815641b-36bb-4558-ba93-3b75c6718387"},"source":["patience = 20\n","early_stopping = EarlyStopping(patience=patience, verbose=True)\n","\n","\n","for i in range(200):\n","  model.train()\n","  optimizer.zero_grad()\n","  prediction = model(X1_train_tensor)\n","  loss = criterion(prediction, Y_train_tensor)\n","  loss.backward()\n","  optimizer.step()\n","\n","  accuracy = Accuracy(prediction, Y_train_tensor)\n","\n","  model.eval()\n","\n","  val_prediction = model(X1_valid_tensor)\n","  test_prediction = model(X1_test_tensor)\n","  val_loss = criterion(val_prediction, Y_valid_tensor)\n","  test_loss = criterion(test_prediction, Y_test_tensor)\n","\n","  val_accuracy = Accuracy(val_prediction, Y_valid_tensor)\n","  test_accuracy = Accuracy(test_prediction, Y_test_tensor)\n","\n","  early_stopping(val_loss, model)\n","\n","  if early_stopping.early_stop:\n","    print(\"Early stopping\")\n","    break\n","\n","  print(i, float(loss.cpu()), accuracy, float(val_loss.cpu()), val_accuracy, float(test_loss.cpu()), test_accuracy)\n","\n","  scheduler.step(val_loss)\n","\n","model.load_state_dict(torch.load('checkpoint.pt'))"],"execution_count":48,"outputs":[{"output_type":"stream","text":["Validation loss decreased (inf --> 0.666009).  Saving model ...\n","0 0.6933914422988892 0.17323943972587585 0.666008710861206 0.8595505356788635 0.6704954504966736 0.8530183434486389\n","Validation loss decreased (0.666009 --> 0.624954).  Saving model ...\n","1 0.6638115644454956 0.8647887110710144 0.6249542236328125 0.8876404762268066 0.6384706497192383 0.8635170459747314\n","Validation loss decreased (0.624954 --> 0.591190).  Saving model ...\n","2 0.6174549460411072 0.8661971688270569 0.5911898016929626 0.8202247023582458 0.6125159859657288 0.8162729740142822\n","Validation loss decreased (0.591190 --> 0.565072).  Saving model ...\n","3 0.5869490504264832 0.7915493249893188 0.5650717616081238 0.8595505356788635 0.5907087326049805 0.8503937125205994\n","Validation loss decreased (0.565072 --> 0.549291).  Saving model ...\n","4 0.5528829097747803 0.8492957949638367 0.5492911338806152 0.8707864880561829 0.576228141784668 0.8556430339813232\n","Validation loss decreased (0.549291 --> 0.538382).  Saving model ...\n","5 0.5317509174346924 0.8450704216957092 0.5383821129798889 0.8426966071128845 0.5647677183151245 0.8451443314552307\n","Validation loss decreased (0.538382 --> 0.531950).  Saving model ...\n","6 0.5290551781654358 0.8309859037399292 0.5319502949714661 0.8426966071128845 0.5565481781959534 0.8372703194618225\n","Validation loss decreased (0.531950 --> 0.528187).  Saving model ...\n","7 0.5180560350418091 0.8169013857841492 0.528187096118927 0.8483145833015442 0.5505208969116211 0.834645688533783\n","Validation loss decreased (0.528187 --> 0.526933).  Saving model ...\n","8 0.5078598260879517 0.8197183012962341 0.5269327759742737 0.8483145833015442 0.5465185046195984 0.8398950099945068\n","Validation loss decreased (0.526933 --> 0.524245).  Saving model ...\n","9 0.5094287991523743 0.8281689882278442 0.5242452621459961 0.8483145833015442 0.5418621301651001 0.834645688533783\n","Validation loss decreased (0.524245 --> 0.521920).  Saving model ...\n","10 0.49929994344711304 0.814084529876709 0.5219204425811768 0.8370786309242249 0.5375868678092957 0.8215222954750061\n","Validation loss decreased (0.521920 --> 0.520693).  Saving model ...\n","11 0.49108415842056274 0.8323943614959717 0.5206929445266724 0.8426966071128845 0.5340337753295898 0.8188976645469666\n","Validation loss decreased (0.520693 --> 0.520566).  Saving model ...\n","12 0.48935383558273315 0.825352132320404 0.5205655694007874 0.8539325594902039 0.5312701463699341 0.8398950099945068\n","Validation loss decreased (0.520566 --> 0.519848).  Saving model ...\n","13 0.48052772879600525 0.8408450484275818 0.5198484659194946 0.8539325594902039 0.5280835032463074 0.8451443314552307\n","EarlyStopping counter: 1 out of 20\n","14 0.4746433198451996 0.8366197347640991 0.5198661684989929 0.8595505356788635 0.5261741876602173 0.8503937125205994\n","EarlyStopping counter: 2 out of 20\n","15 0.47996196150779724 0.8563380241394043 0.520205557346344 0.8595505356788635 0.5253498554229736 0.8661417365074158\n","EarlyStopping counter: 3 out of 20\n","16 0.4797711670398712 0.8676056265830994 0.5210261940956116 0.8651685118675232 0.5260444283485413 0.8713910579681396\n","EarlyStopping counter: 4 out of 20\n","17 0.470948189496994 0.8746479153633118 0.5202298760414124 0.8651685118675232 0.5238872170448303 0.874015748500824\n","Validation loss decreased (0.519848 --> 0.517427).  Saving model ...\n","18 0.4705847501754761 0.877464771270752 0.5174272656440735 0.8483145833015442 0.5151046514511108 0.8530183434486389\n","EarlyStopping counter: 1 out of 20\n","19 0.48153576254844666 0.8422535061836243 0.5177404284477234 0.8202247023582458 0.5130656361579895 0.8398950099945068\n","Validation loss decreased (0.517427 --> 0.516987).  Saving model ...\n","20 0.47379636764526367 0.8464788794517517 0.5169873833656311 0.8426966071128845 0.5111228823661804 0.8503937125205994\n","Validation loss decreased (0.516987 --> 0.515535).  Saving model ...\n","21 0.46155840158462524 0.8507042527198792 0.5155351758003235 0.8426966071128845 0.5090670585632324 0.8635170459747314\n","Validation loss decreased (0.515535 --> 0.514052).  Saving model ...\n","22 0.46346515417099 0.8676056265830994 0.5140515565872192 0.8595505356788635 0.5074679255485535 0.8687664270401001\n","Validation loss decreased (0.514052 --> 0.512791).  Saving model ...\n","23 0.4536045491695404 0.8760563135147095 0.5127912759780884 0.8539325594902039 0.5051144957542419 0.8687664270401001\n","EarlyStopping counter: 1 out of 20\n","24 0.45437294244766235 0.8760563135147095 0.5142796635627747 0.8426966071128845 0.5039166808128357 0.8451443314552307\n","EarlyStopping counter: 2 out of 20\n","25 0.451023668050766 0.8450704216957092 0.5128249526023865 0.8426966071128845 0.5019018054008484 0.8503937125205994\n","Validation loss decreased (0.512791 --> 0.510950).  Saving model ...\n","26 0.46034595370292664 0.8492957949638367 0.5109499096870422 0.8426966071128845 0.49959418177604675 0.8556430339813232\n","Validation loss decreased (0.510950 --> 0.510283).  Saving model ...\n","27 0.45368388295173645 0.8760563135147095 0.5102831721305847 0.8370786309242249 0.4983517825603485 0.8556430339813232\n","Validation loss decreased (0.510283 --> 0.508023).  Saving model ...\n","28 0.44986671209335327 0.8718309998512268 0.508022665977478 0.8651685118675232 0.4956059753894806 0.874015748500824\n","Validation loss decreased (0.508023 --> 0.505794).  Saving model ...\n","29 0.45171448588371277 0.8690140843391418 0.5057938098907471 0.8651685118675232 0.4941381812095642 0.8845144510269165\n","Validation loss decreased (0.505794 --> 0.504662).  Saving model ...\n","30 0.4413968324661255 0.8929577469825745 0.5046620965003967 0.8707864880561829 0.49336880445480347 0.887139081954956\n","Validation loss decreased (0.504662 --> 0.503506).  Saving model ...\n","31 0.4325096309185028 0.908450722694397 0.5035059452056885 0.8651685118675232 0.4911353290081024 0.8897637724876404\n","Validation loss decreased (0.503506 --> 0.503002).  Saving model ...\n","32 0.43068161606788635 0.8929577469825745 0.5030023455619812 0.8539325594902039 0.4910980761051178 0.8661417365074158\n","Validation loss decreased (0.503002 --> 0.502149).  Saving model ...\n","33 0.4192699193954468 0.888732373714447 0.502149224281311 0.8483145833015442 0.4916369616985321 0.8608924150466919\n","Validation loss decreased (0.502149 --> 0.500413).  Saving model ...\n","34 0.42978939414024353 0.8802816867828369 0.500413179397583 0.8539325594902039 0.4908621609210968 0.8661417365074158\n","Validation loss decreased (0.500413 --> 0.497233).  Saving model ...\n","35 0.4242716431617737 0.8760563135147095 0.497233122587204 0.8876404762268066 0.48700079321861267 0.887139081954956\n","Validation loss decreased (0.497233 --> 0.496840).  Saving model ...\n","36 0.4154755473136902 0.905633807182312 0.49684038758277893 0.8932584524154663 0.48701968789100647 0.887139081954956\n","Validation loss decreased (0.496840 --> 0.495447).  Saving model ...\n","37 0.4203203618526459 0.9211267828941345 0.49544692039489746 0.8932584524154663 0.48651382327079773 0.8845144510269165\n","Validation loss decreased (0.495447 --> 0.493712).  Saving model ...\n","38 0.4088696241378784 0.9267605543136597 0.4937117397785187 0.8876404762268066 0.4877578318119049 0.8792650699615479\n","EarlyStopping counter: 1 out of 20\n","39 0.4170348048210144 0.8971831202507019 0.49384981393814087 0.8764045238494873 0.48974287509918213 0.8818897604942322\n","Validation loss decreased (0.493712 --> 0.491177).  Saving model ...\n","40 0.41455456614494324 0.8929577469825745 0.4911765158176422 0.898876428604126 0.486918568611145 0.8818897604942322\n","Validation loss decreased (0.491177 --> 0.490888).  Saving model ...\n","41 0.40643614530563354 0.905633807182312 0.49088796973228455 0.898876428604126 0.4857114851474762 0.8845144510269165\n","EarlyStopping counter: 1 out of 20\n","42 0.40401673316955566 0.9281690120697021 0.4914003014564514 0.898876428604126 0.48590999841690063 0.8950130939483643\n","Validation loss decreased (0.490888 --> 0.489050).  Saving model ...\n","43 0.3960574269294739 0.9450704455375671 0.4890495240688324 0.898876428604126 0.48499688506126404 0.8818897604942322\n","Validation loss decreased (0.489050 --> 0.488817).  Saving model ...\n","44 0.3986879885196686 0.919718325138092 0.48881709575653076 0.898876428604126 0.4855341613292694 0.8792650699615479\n","Validation loss decreased (0.488817 --> 0.488459).  Saving model ...\n","45 0.3940989673137665 0.9154929518699646 0.48845890164375305 0.9044944047927856 0.4844920039176941 0.887139081954956\n","Validation loss decreased (0.488459 --> 0.487588).  Saving model ...\n","46 0.4093009829521179 0.9154929518699646 0.4875876009464264 0.9044944047927856 0.4839481711387634 0.887139081954956\n","Validation loss decreased (0.487588 --> 0.486783).  Saving model ...\n","47 0.39991870522499084 0.922535240650177 0.4867831766605377 0.9044944047927856 0.48363155126571655 0.887139081954956\n","Validation loss decreased (0.486783 --> 0.486322).  Saving model ...\n","48 0.3834587633609772 0.9380281567573547 0.48632240295410156 0.9044944047927856 0.482989102602005 0.887139081954956\n","EarlyStopping counter: 1 out of 20\n","49 0.38656508922576904 0.9408450722694397 0.48707687854766846 0.9101123809814453 0.4832756817340851 0.8976377844810486\n","Validation loss decreased (0.486322 --> 0.485578).  Saving model ...\n","50 0.38901039958000183 0.9380281567573547 0.4855784475803375 0.9101123809814453 0.4822557866573334 0.8923884630203247\n","EarlyStopping counter: 1 out of 20\n","51 0.3863348364830017 0.9436619877815247 0.4856141209602356 0.8932584524154663 0.48258769512176514 0.8818897604942322\n","Validation loss decreased (0.485578 --> 0.484311).  Saving model ...\n","52 0.3817574381828308 0.9267605543136597 0.48431089520454407 0.9101123809814453 0.4817444384098053 0.8897637724876404\n","EarlyStopping counter: 1 out of 20\n","53 0.38739049434661865 0.9366196990013123 0.4851333200931549 0.915730357170105 0.48211708664894104 0.9028871655464172\n","EarlyStopping counter: 2 out of 20\n","54 0.390804260969162 0.9295774698257446 0.4876246750354767 0.9101123809814453 0.48305508494377136 0.9028871655464172\n","Validation loss decreased (0.484311 --> 0.484106).  Saving model ...\n","55 0.38326647877693176 0.9478873014450073 0.48410630226135254 0.9101123809814453 0.4809194505214691 0.8950130939483643\n","EarlyStopping counter: 1 out of 20\n","56 0.3908171057701111 0.9436619877815247 0.48501449823379517 0.8932584524154663 0.4812594950199127 0.8713910579681396\n","Validation loss decreased (0.484106 --> 0.483930).  Saving model ...\n","57 0.38158103823661804 0.9309859275817871 0.483929842710495 0.9101123809814453 0.48004817962646484 0.8897637724876404\n","EarlyStopping counter: 1 out of 20\n","58 0.3842296600341797 0.9352112412452698 0.4874460995197296 0.9101123809814453 0.4813206195831299 0.9055117964744568\n","EarlyStopping counter: 2 out of 20\n","59 0.37524548172950745 0.9535211324691772 0.49032163619995117 0.9101123809814453 0.4820324778556824 0.9055117964744568\n","EarlyStopping counter: 3 out of 20\n","60 0.3825273811817169 0.9450704455375671 0.48543038964271545 0.9044944047927856 0.479924738407135 0.8923884630203247\n","EarlyStopping counter: 4 out of 20\n","61 0.3833979070186615 0.9366196990013123 0.4841762185096741 0.8876404762268066 0.4794365465641022 0.8687664270401001\n","Validation loss decreased (0.483930 --> 0.483833).  Saving model ...\n","62 0.3793698847293854 0.9309859275817871 0.4838334321975708 0.898876428604126 0.478295236825943 0.8845144510269165\n","EarlyStopping counter: 1 out of 20\n","63 0.37799692153930664 0.9323943853378296 0.48818516731262207 0.915730357170105 0.4799846112728119 0.9002624750137329\n","EarlyStopping counter: 2 out of 20\n","64 0.3694814145565033 0.9549295902252197 0.49422135949134827 0.9101123809814453 0.48346325755119324 0.9186351895332336\n","EarlyStopping counter: 3 out of 20\n","65 0.3778378963470459 0.9633802771568298 0.48845234513282776 0.915730357170105 0.4802427589893341 0.9002624750137329\n","EarlyStopping counter: 4 out of 20\n","66 0.3724019229412079 0.9521126747131348 0.48451513051986694 0.8932584524154663 0.4776363670825958 0.8845144510269165\n","EarlyStopping counter: 5 out of 20\n","67 0.36596566438674927 0.9478873014450073 0.48485276103019714 0.8932584524154663 0.47777149081230164 0.8792650699615479\n","EarlyStopping counter: 6 out of 20\n","68 0.3786628246307373 0.9295774698257446 0.48567405343055725 0.915730357170105 0.479234516620636 0.8976377844810486\n","EarlyStopping counter: 7 out of 20\n","69 0.3667294383049011 0.9549295902252197 0.48946869373321533 0.915730357170105 0.4822717308998108 0.9160104990005493\n","EarlyStopping counter: 8 out of 20\n","70 0.3661756217479706 0.9676056504249573 0.4884500801563263 0.915730357170105 0.48174238204956055 0.913385808467865\n","EarlyStopping counter: 9 out of 20\n","71 0.3687839210033417 0.9605633616447449 0.4854559302330017 0.915730357170105 0.4794952869415283 0.9081364870071411\n","Validation loss decreased (0.483833 --> 0.483296).  Saving model ...\n","72 0.36842358112335205 0.9591549038887024 0.4832955598831177 0.915730357170105 0.4777194857597351 0.8950130939483643\n","Validation loss decreased (0.483296 --> 0.482962).  Saving model ...\n","73 0.3618531823158264 0.9591549038887024 0.48296213150024414 0.898876428604126 0.4770614206790924 0.8845144510269165\n","Validation loss decreased (0.482962 --> 0.482601).  Saving model ...\n","74 0.3713908791542053 0.9450704455375671 0.48260074853897095 0.9101123809814453 0.47693684697151184 0.8923884630203247\n","EarlyStopping counter: 1 out of 20\n","75 0.36040908098220825 0.9507042169570923 0.4867491126060486 0.915730357170105 0.4794199764728546 0.913385808467865\n","EarlyStopping counter: 2 out of 20\n","76 0.36332494020462036 0.9605633616447449 0.49317455291748047 0.915730357170105 0.4834669530391693 0.9238845109939575\n","EarlyStopping counter: 3 out of 20\n","77 0.37037959694862366 0.9690141081809998 0.49078279733657837 0.9101123809814453 0.48085859417915344 0.9212598204612732\n","Validation loss decreased (0.482601 --> 0.482497).  Saving model ...\n","78 0.3632591664791107 0.9676056504249573 0.4824972450733185 0.9044944047927856 0.47520482540130615 0.8923884630203247\n","Validation loss decreased (0.482497 --> 0.482053).  Saving model ...\n","79 0.35812273621559143 0.9591549038887024 0.4820525646209717 0.8932584524154663 0.4755898714065552 0.8766404390335083\n","EarlyStopping counter: 1 out of 20\n","80 0.36683717370033264 0.9309859275817871 0.4832194745540619 0.9101123809814453 0.4748390018939972 0.8950130939483643\n","EarlyStopping counter: 2 out of 20\n","81 0.3619510233402252 0.9535211324691772 0.4908866286277771 0.9101123809814453 0.4792335331439972 0.9160104990005493\n","EarlyStopping counter: 3 out of 20\n","82 0.3600475490093231 0.9676056504249573 0.4921073019504547 0.9101123809814453 0.48044663667678833 0.9212598204612732\n","EarlyStopping counter: 4 out of 20\n","83 0.3621231019496918 0.9704225063323975 0.48659437894821167 0.9101123809814453 0.4760352373123169 0.9028871655464172\n","EarlyStopping counter: 5 out of 20\n","84 0.3518463969230652 0.9661971926689148 0.48327216506004333 0.9044944047927856 0.47446995973587036 0.8897637724876404\n","EarlyStopping counter: 6 out of 20\n","85 0.35598671436309814 0.9521126747131348 0.48432910442352295 0.9101123809814453 0.4745769798755646 0.8950130939483643\n","EarlyStopping counter: 7 out of 20\n","86 0.3530641496181488 0.9633802771568298 0.4895581305027008 0.9101123809814453 0.47796812653541565 0.9238845109939575\n","EarlyStopping counter: 8 out of 20\n","87 0.3608335852622986 0.9690141081809998 0.491599440574646 0.915730357170105 0.4799085855484009 0.9265092015266418\n","EarlyStopping counter: 9 out of 20\n","88 0.3592599630355835 0.9661971926689148 0.487350195646286 0.9101123809814453 0.4759292006492615 0.9055117964744568\n","EarlyStopping counter: 10 out of 20\n","89 0.35092586278915405 0.9661971926689148 0.48563721776008606 0.898876428604126 0.4747816026210785 0.8897637724876404\n","EarlyStopping counter: 11 out of 20\n","90 0.3512197434902191 0.9619718194007874 0.4864691197872162 0.9101123809814453 0.47520121932029724 0.8976377844810486\n","EarlyStopping counter: 12 out of 20\n","91 0.3494742810726166 0.9718309640884399 0.48668456077575684 0.9101123809814453 0.47536221146583557 0.8976377844810486\n","EarlyStopping counter: 13 out of 20\n","92 0.3506392240524292 0.9647887349128723 0.487118124961853 0.9101123809814453 0.4756894111633301 0.9028871655464172\n","EarlyStopping counter: 14 out of 20\n","93 0.35230380296707153 0.9718309640884399 0.4875580966472626 0.9101123809814453 0.4760642647743225 0.9107611775398254\n","EarlyStopping counter: 15 out of 20\n","94 0.3484422266483307 0.9690141081809998 0.4880390167236328 0.9101123809814453 0.4765096604824066 0.9107611775398254\n","EarlyStopping counter: 16 out of 20\n","95 0.3483644723892212 0.9774647951126099 0.4885239005088806 0.9101123809814453 0.4769940674304962 0.9160104990005493\n","EarlyStopping counter: 17 out of 20\n","96 0.35034608840942383 0.9732394218444824 0.48874321579933167 0.9101123809814453 0.4772452712059021 0.9160104990005493\n","EarlyStopping counter: 18 out of 20\n","97 0.3568440079689026 0.9718309640884399 0.4886809289455414 0.9101123809814453 0.47721222043037415 0.9160104990005493\n","EarlyStopping counter: 19 out of 20\n","98 0.3533337116241455 0.9704225063323975 0.4885130226612091 0.9101123809814453 0.47705820202827454 0.9160104990005493\n","EarlyStopping counter: 20 out of 20\n","Early stopping\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{"tags":[]},"execution_count":48}]},{"cell_type":"code","metadata":{"id":"_ar8xXFbYwzN","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"ok","timestamp":1593670669653,"user_tz":180,"elapsed":109582,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"3b1f4bdb-e442-414f-e821-4a6d2dd3a4a8"},"source":["print(Precision(prediction, Y_train_tensor))\n","print(Precision(val_prediction, Y_valid_tensor))\n","print(Precision(test_prediction, Y_test_tensor))"],"execution_count":49,"outputs":[{"output_type":"stream","text":["[0.9948006868362427, 0.902255654335022]\n","[0.9337748289108276, 0.7777777910232544]\n","[0.9439252614974976, 0.75]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Noxe6JaLYxag","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"ok","timestamp":1593670669653,"user_tz":180,"elapsed":109580,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"1049ec5b-2b70-4065-88cd-2c8a72e06948"},"source":["print(Recall(prediction, Y_train_tensor))\n","print(Recall(val_prediction, Y_valid_tensor))\n","print(Recall(test_prediction, Y_test_tensor))"],"execution_count":50,"outputs":[{"output_type":"stream","text":["[0.9778534770011902, 0.9756097793579102]\n","[0.9591836929321289, 0.6774193644523621]\n","[0.9528301954269409, 0.7142857313156128]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5an2w6BsYxL2","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"ok","timestamp":1593670669654,"user_tz":180,"elapsed":109579,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"aefa9298-580d-42d8-a57d-ac8d9de12556"},"source":["print(Accuracy(prediction, Y_train_tensor))\n","print(Accuracy(val_prediction, Y_valid_tensor))\n","print(Accuracy(test_prediction, Y_test_tensor))"],"execution_count":51,"outputs":[{"output_type":"stream","text":["0.9774647951126099\n","0.9101123809814453\n","0.913385808467865\n"],"name":"stdout"}]}]}