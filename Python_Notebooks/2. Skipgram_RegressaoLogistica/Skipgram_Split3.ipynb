{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of Split3.ipynb","provenance":[{"file_id":"14KPhEaLtEQ-3fWkVAI3FS3oG1ZVh5JgR","timestamp":1592791894993},{"file_id":"1LfBzJg-B1BHT4FjFHTG-N1ao8xQ0tak_","timestamp":1592628202131},{"file_id":"1ly17dl3w8rGXAPtd1owJFslx4RVJE78c","timestamp":1592607825372},{"file_id":"1VIBcIIFR_YFlSguO_JGlnJbFzyAcT6YH","timestamp":1592464333044},{"file_id":"1dZvMRgPPkRVGa_4BZ1Tvoom_U4pjwmRX","timestamp":1592435543596},{"file_id":"12Sf257YUAwzmSXOlE3llOhi0N1YVUbM7","timestamp":1583376883298}],"collapsed_sections":[],"authorship_tag":"ABX9TyMR38Z0wT4VWxbpWmGenlYV"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"JQrQmaLj0UuZ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"executionInfo":{"status":"ok","timestamp":1593325548425,"user_tz":180,"elapsed":38652,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"84573b93-7645-409a-d8da-6bee33487a19"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JjEPtibx-EJD","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593325550578,"user_tz":180,"elapsed":40801,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["import numpy as np\n","import torch\n","\n","class EarlyStopping:\n","    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n","    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt'):\n","        \"\"\"\n","        Args:\n","            patience (int): How long to wait after last time validation loss improved.\n","                            Default: 7\n","            verbose (bool): If True, prints a message for each validation loss improvement. \n","                            Default: False\n","            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n","                            Default: 0\n","            path (str): Path for the checkpoint to be saved to.\n","                            Default: 'checkpoint.pt'\n","        \"\"\"\n","        self.patience = patience\n","        self.verbose = verbose\n","        self.counter = 0\n","        self.best_score = None\n","        self.early_stop = False\n","        self.val_loss_min = np.Inf\n","        self.delta = delta\n","        self.path = path\n","\n","    def __call__(self, val_loss, model):\n","\n","        score = -val_loss\n","\n","        if self.best_score is None:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model)\n","        elif score < self.best_score + self.delta:\n","            self.counter += 1\n","            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n","            if self.counter >= self.patience:\n","                self.early_stop = True\n","        else:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model)\n","            self.counter = 0\n","\n","    def save_checkpoint(self, val_loss, model):\n","        '''Saves model when validation loss decrease.'''\n","        if self.verbose:\n","            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n","        torch.save(model.state_dict(), self.path)\n","        self.val_loss_min = val_loss"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"tjGPuXgoqulz","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593325550579,"user_tz":180,"elapsed":40800,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["def Accuracy(prediction, observation):\n","  prediction = prediction[:,1]\n","  prediction_class = (torch.reshape(prediction, observation.shape) > 0.5).float()\n","  correct = (prediction_class == observation).float().sum()\n","  accuracy = correct/prediction_class.shape[0]\n","  return float(accuracy.cpu())\n","\n","def Precision(prediction, observation):\n","  prediction = prediction[:,1]\n","  res = []\n","  prediction_class = (torch.reshape(prediction, observation.shape) > 0.5).float()\n","  for label in [0, 1]:\n","    correct = (prediction_class[prediction_class == label] == observation[prediction_class == label]).float().sum()\n","    precision = correct/prediction_class[prediction_class == label].shape[0]\n","    res.append(float(precision.cpu()))\n","  return res\n","\n","def Recall(prediction, observation):\n","  prediction = prediction[:,1]\n","  res = []\n","  prediction_class = (torch.reshape(prediction, observation.shape) > 0.5).float()\n","  for label in [0, 1]:\n","    correct = (prediction_class[observation == label] == observation[observation == label]).float().sum()\n","    recall = correct/prediction_class[observation == label].shape[0]\n","    res.append(float(recall.cpu()))\n","  return res"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"sgz5Ea8a1wKr","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593325550580,"user_tz":180,"elapsed":40799,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["n_split = 3"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"cutkFU0k1Pkv","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593325550581,"user_tz":180,"elapsed":40797,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["import pickle\n","import pandas as pd\n","import numpy as np"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"wSJO5A951VXh","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593325555948,"user_tz":180,"elapsed":46162,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["with open('/content/drive/My Drive/Data Master/X_train_final', 'rb') as file:\n","    X_train = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/Y_train_final', 'rb') as file:\n","    Y_train = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/X_test_final', 'rb') as file:\n","    X_test = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/Y_test_final', 'rb') as file:\n","    Y_test = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/word_index_final', 'rb') as file:\n","    word_index = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/train_index_final_split_' + str(n_split), 'rb') as file:\n","    train_index = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/valid_index_final_split_' + str(n_split), 'rb') as file:\n","    valid_index = pickle.load(file)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"NPV3Nq3Hu1wq","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593325555949,"user_tz":180,"elapsed":46161,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["inv_word_index = {ix : w for w, ix in word_index.items()}"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"3WX_0ZRprLyw","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593325574850,"user_tz":180,"elapsed":65056,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"f3d1e886-4839-41b7-d9b7-d3ed21efcfff"},"source":["errors = []\n","embeddings_index = {}\n","f = open('/content/drive/My Drive/Data Master/skip_s50.txt')\n","for line in f:\n","    values = line.split()\n","    word = values[0]\n","    try:\n","      coefs = np.asarray(values[1:], dtype='float32')\n","    except:\n","      errors.append(line)\n","    embeddings_index[word] = coefs\n","f.close()\n","\n","print('Found %s word vectors.' % len(embeddings_index))"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Found 929595 word vectors.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"I8FQmZNarZuK","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1593325574851,"user_tz":180,"elapsed":65052,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"482a8ee1-6c1f-46e1-a9b0-a23bb8f91ce3"},"source":["print(len(embeddings_index))\n","print(len(errors))"],"execution_count":9,"outputs":[{"output_type":"stream","text":["929595\n","4\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jsrBZxIdsSLP","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593325574851,"user_tz":180,"elapsed":65049,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["EMBEDDING_DIM = 50\n","errors_2 = []\n","nomatchs = []\n","\n","X_train_matrix = np.zeros((len(X_train), EMBEDDING_DIM))\n","X_test_matrix = np.zeros((len(X_test), EMBEDDING_DIM))"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"jK0pn81usdvI","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593325601098,"user_tz":180,"elapsed":91294,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["for i, x in enumerate(X_train):\n","  for w in x:\n","    embedding_vector = embeddings_index.get(inv_word_index[w])\n","    if embedding_vector is not None:\n","        # words not found in embedding index will be all-zeros.\n","        try:\n","          X_train_matrix[i] += embedding_vector\n","        except:\n","          errors_2.append([word, len(embedding_vector), embedding_vector])\n","    else:\n","      nomatchs.append(word)"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"suJPilq5vUG6","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593325611955,"user_tz":180,"elapsed":102149,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["for i, x in enumerate(X_test):\n","  for w in x:\n","    embedding_vector = embeddings_index.get(inv_word_index[w])\n","    if embedding_vector is not None:\n","        # words not found in embedding index will be all-zeros.\n","        try:\n","          X_test_matrix[i] += embedding_vector\n","        except:\n","          errors_2.append([word, len(embedding_vector), embedding_vector])\n","    else:\n","      nomatchs.append(word)"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"yeZBNSItuefx","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593325611956,"user_tz":180,"elapsed":102145,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"ab5388da-3d75-49ab-e890-5a796256a64b"},"source":["X_train_matrix.shape"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(888, 50)"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"9d4attfQ0i-Q","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593325611956,"user_tz":180,"elapsed":102142,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"twcFT-Hl3fqP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593325611957,"user_tz":180,"elapsed":102138,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"b4e61154-5e58-48f7-d70f-7458be407da0"},"source":["input_dim = X_train_matrix.shape[1]\n","input_dim"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["50"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"9fbXl191nZhK","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593325611958,"user_tz":180,"elapsed":102137,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["class LogisticRegression (nn.Module):\n","\n","  def __init__(self):\n","    super(LogisticRegression, self).__init__()\n","\n","    self.fc1 = nn.Linear(input_dim, 2)\n","                                \n","    self.softmax = nn.Softmax(dim=1)\n","\n","  def forward(self, x):\n","    x = F.normalize(x)\n","    y = self.softmax(self.fc1(x))\n","\n","    return y"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"0rnUcqchBE91","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593325611958,"user_tz":180,"elapsed":102134,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["X_train_tensor = torch.from_numpy(X_train_matrix[train_index]).float()\n","Y_train_tensor = torch.LongTensor(np.array(Y_train[train_index]))\n","\n","X_valid_tensor = torch.from_numpy(X_train_matrix[valid_index]).float()\n","Y_valid_tensor = torch.LongTensor(np.array(Y_train[valid_index]))\n","\n","X_test_tensor = torch.from_numpy(X_test_matrix).float()\n","Y_test_tensor = torch.LongTensor(np.array(Y_test))"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"Cgzf7IEqnyN4","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593325611959,"user_tz":180,"elapsed":102133,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["model = LogisticRegression()"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"ykKjpHS-cAin","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593325611959,"user_tz":180,"elapsed":102131,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["torch.manual_seed(0)\n","np.random.seed(0)"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"SV0Da5qu98-C","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593325611960,"user_tz":180,"elapsed":102130,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["import torch.optim as optim\n","optimizer = optim.AdamW(model.parameters(), lr=0.01)"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"umD2BmIGcI7r","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593325611961,"user_tz":180,"elapsed":102129,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["from torch.optim.lr_scheduler import ReduceLROnPlateau\n","scheduler = ReduceLROnPlateau(optimizer, 'min')"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"DyPG7P5GcLp-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593325611961,"user_tz":180,"elapsed":102123,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"df614207-f213-4ff1-9074-4deb7083cd2f"},"source":["weights = [sum(Y_train)/len(Y_train), 1-sum(Y_train)/len(Y_train)]\n","class_weights = torch.FloatTensor(weights)\n","class_weights"],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0.1734, 0.8266])"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"8-F96WAE98zI","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593325611962,"user_tz":180,"elapsed":102122,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["criterion = nn.CrossEntropyLoss(weight=class_weights)"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"E7KgiIq398rR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1593325615623,"user_tz":180,"elapsed":105778,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"3c01e91a-4086-43ec-d4dd-8c54a631df7c"},"source":["patience = 20\n","early_stopping = EarlyStopping(patience=patience, verbose=True)\n","\n","\n","for i in range(1000):\n","  model.train()\n","  optimizer.zero_grad()\n","  prediction = model(X_train_tensor)\n","  loss = criterion(prediction, Y_train_tensor)\n","  loss.backward()\n","  optimizer.step()\n","\n","  accuracy = Accuracy(prediction, Y_train_tensor)\n","\n","  model.eval()\n","\n","  val_prediction = model(X_valid_tensor)\n","  test_prediction = model(X_test_tensor)\n","  val_loss = criterion(val_prediction, Y_valid_tensor)\n","  test_loss = criterion(test_prediction, Y_test_tensor)\n","\n","  val_accuracy = Accuracy(val_prediction, Y_valid_tensor)\n","  test_accuracy = Accuracy(test_prediction, Y_test_tensor)\n","\n","  early_stopping(val_loss, model)\n","\n","  if early_stopping.early_stop:\n","    print(\"Early stopping\")\n","    break\n","\n","  print(i, float(loss.cpu()), accuracy, float(val_loss.cpu()), val_accuracy, float(test_loss.cpu()), test_accuracy)\n","\n","  scheduler.step(val_loss)\n","\n","model.load_state_dict(torch.load('checkpoint.pt'))"],"execution_count":24,"outputs":[{"output_type":"stream","text":["Validation loss decreased (inf --> 0.693224).  Saving model ...\n","0 0.6952829360961914 0.17183098196983337 0.6932238340377808 0.24719101190567017 0.6940518021583557 0.20734907686710358\n","Validation loss decreased (0.693224 --> 0.692186).  Saving model ...\n","1 0.6937997937202454 0.22535210847854614 0.6921861171722412 0.7640449404716492 0.6927857398986816 0.7821522355079651\n","Validation loss decreased (0.692186 --> 0.691171).  Saving model ...\n","2 0.6924973130226135 0.7760563492774963 0.6911705136299133 0.8314606547355652 0.6917514801025391 0.8293963074684143\n","Validation loss decreased (0.691171 --> 0.690119).  Saving model ...\n","3 0.6912261247634888 0.8338028192520142 0.6901188492774963 0.8314606547355652 0.6908230185508728 0.8320209980010986\n","Validation loss decreased (0.690119 --> 0.689037).  Saving model ...\n","4 0.6899295449256897 0.8422535061836243 0.6890368461608887 0.8370786309242249 0.6899538636207581 0.8398950099945068\n","Validation loss decreased (0.689037 --> 0.687947).  Saving model ...\n","5 0.6886116862297058 0.8521126508712769 0.6879472136497498 0.8258426785469055 0.6891245245933533 0.8451443314552307\n","Validation loss decreased (0.687947 --> 0.686867).  Saving model ...\n","6 0.6872930526733398 0.8633802533149719 0.6868669986724854 0.7977527976036072 0.688319206237793 0.7716535329818726\n","Validation loss decreased (0.686867 --> 0.685803).  Saving model ...\n","7 0.6859880685806274 0.814084529876709 0.6858030557632446 0.7696629166603088 0.6875167489051819 0.6850393414497375\n","Validation loss decreased (0.685803 --> 0.684751).  Saving model ...\n","8 0.6846998333930969 0.7225351929664612 0.6847506165504456 0.7078651785850525 0.686695396900177 0.6246719360351562\n","Validation loss decreased (0.684751 --> 0.683703).  Saving model ...\n","9 0.6834205389022827 0.6647887229919434 0.6837032437324524 0.6910112500190735 0.6858365535736084 0.6115485429763794\n","Validation loss decreased (0.683703 --> 0.682659).  Saving model ...\n","10 0.6821429133415222 0.6633802652359009 0.6826589107513428 0.7303370833396912 0.6849403381347656 0.6377952694892883\n","Validation loss decreased (0.682659 --> 0.681620).  Saving model ...\n","11 0.6808619499206543 0.6873239278793335 0.6816195845603943 0.7471910119056702 0.6840172410011292 0.6850393414497375\n","Validation loss decreased (0.681620 --> 0.680589).  Saving model ...\n","12 0.679581880569458 0.719718337059021 0.680588960647583 0.7696629166603088 0.6830845475196838 0.7322834730148315\n","Validation loss decreased (0.680589 --> 0.679570).  Saving model ...\n","13 0.6783074140548706 0.7549296021461487 0.6795702576637268 0.7865168452262878 0.6821593046188354 0.76115483045578\n","Validation loss decreased (0.679570 --> 0.678560).  Saving model ...\n","14 0.6770433187484741 0.7816901206970215 0.6785600781440735 0.7977527976036072 0.6812537908554077 0.7742782235145569\n","Validation loss decreased (0.678560 --> 0.677554).  Saving model ...\n","15 0.6757908463478088 0.8084506988525391 0.6775535941123962 0.8033707737922668 0.6803733110427856 0.787401556968689\n","Validation loss decreased (0.677554 --> 0.676546).  Saving model ...\n","16 0.6745455861091614 0.814084529876709 0.6765459775924683 0.7977527976036072 0.679517924785614 0.787401556968689\n","Validation loss decreased (0.676546 --> 0.675536).  Saving model ...\n","17 0.6733061075210571 0.811267614364624 0.6755359172821045 0.7977527976036072 0.6786872744560242 0.7821522355079651\n","Validation loss decreased (0.675536 --> 0.674525).  Saving model ...\n","18 0.6720697283744812 0.811267614364624 0.6745249032974243 0.7921348214149475 0.6778765916824341 0.7795275449752808\n","Validation loss decreased (0.674525 --> 0.673518).  Saving model ...\n","19 0.6708399057388306 0.8084506988525391 0.6735177040100098 0.7921348214149475 0.6770815849304199 0.7664042115211487\n","Validation loss decreased (0.673518 --> 0.672518).  Saving model ...\n","20 0.6696178317070007 0.7887324094772339 0.672517716884613 0.7865168452262878 0.6762961149215698 0.7585301995277405\n","Validation loss decreased (0.672518 --> 0.671527).  Saving model ...\n","21 0.66840660572052 0.7774648070335388 0.6715272665023804 0.7752808928489685 0.6755118370056152 0.7454068064689636\n","Validation loss decreased (0.671527 --> 0.670547).  Saving model ...\n","22 0.6672042012214661 0.7774648070335388 0.6705470085144043 0.7752808928489685 0.6747234463691711 0.7427821755409241\n","Validation loss decreased (0.670547 --> 0.669577).  Saving model ...\n","23 0.6660104990005493 0.7746478915214539 0.6695767641067505 0.7752808928489685 0.6739270091056824 0.7427821755409241\n","Validation loss decreased (0.669577 --> 0.668617).  Saving model ...\n","24 0.6648242473602295 0.7746478915214539 0.6686167120933533 0.7752808928489685 0.6731240749359131 0.7427821755409241\n","Validation loss decreased (0.668617 --> 0.667667).  Saving model ...\n","25 0.6636435389518738 0.7746478915214539 0.6676673293113708 0.7808988690376282 0.6723199486732483 0.7532808184623718\n","Validation loss decreased (0.667667 --> 0.666727).  Saving model ...\n","26 0.6624724268913269 0.783098578453064 0.6667273640632629 0.7865168452262878 0.6715220212936401 0.7637795209884644\n","Validation loss decreased (0.666727 --> 0.665795).  Saving model ...\n","27 0.6613104343414307 0.7873239517211914 0.6657954454421997 0.7921348214149475 0.6707345247268677 0.7637795209884644\n","Validation loss decreased (0.665795 --> 0.664868).  Saving model ...\n","28 0.6601584553718567 0.7873239517211914 0.6648677587509155 0.7977527976036072 0.6699625253677368 0.7690288424491882\n","Validation loss decreased (0.664868 --> 0.663943).  Saving model ...\n","29 0.6590154767036438 0.7901408672332764 0.6639427542686462 0.7977527976036072 0.6692068576812744 0.7690288424491882\n","Validation loss decreased (0.663943 --> 0.663020).  Saving model ...\n","30 0.6578813791275024 0.7901408672332764 0.6630197167396545 0.7977527976036072 0.6684669852256775 0.7690288424491882\n","Validation loss decreased (0.663020 --> 0.662101).  Saving model ...\n","31 0.6567552089691162 0.7901408672332764 0.6621005535125732 0.7977527976036072 0.6677394509315491 0.7664042115211487\n","Validation loss decreased (0.662101 --> 0.661187).  Saving model ...\n","32 0.6556383967399597 0.7915493249893188 0.661186933517456 0.7921348214149475 0.6670221090316772 0.76115483045578\n","Validation loss decreased (0.661187 --> 0.660282).  Saving model ...\n","33 0.6545304656028748 0.7901408672332764 0.6602823138237 0.7865168452262878 0.6663110852241516 0.7585301995277405\n","Validation loss decreased (0.660282 --> 0.659388).  Saving model ...\n","34 0.6534326672554016 0.7873239517211914 0.6593876481056213 0.7808988690376282 0.6656020283699036 0.7559055089950562\n","Validation loss decreased (0.659388 --> 0.658504).  Saving model ...\n","35 0.6523445844650269 0.7887324094772339 0.6585038900375366 0.7808988690376282 0.6648926138877869 0.7559055089950562\n","Validation loss decreased (0.658504 --> 0.657631).  Saving model ...\n","36 0.6512652635574341 0.7901408672332764 0.6576311588287354 0.7865168452262878 0.6641836166381836 0.7585301995277405\n","Validation loss decreased (0.657631 --> 0.656769).  Saving model ...\n","37 0.6501950025558472 0.7887324094772339 0.6567692160606384 0.7977527976036072 0.6634767651557922 0.7585301995277405\n","Validation loss decreased (0.656769 --> 0.655916).  Saving model ...\n","38 0.6491339206695557 0.7929577231407166 0.655916154384613 0.7977527976036072 0.6627753376960754 0.7637795209884644\n","Validation loss decreased (0.655916 --> 0.655070).  Saving model ...\n","39 0.6480823159217834 0.7929577231407166 0.6550702452659607 0.7977527976036072 0.6620826125144958 0.7637795209884644\n","Validation loss decreased (0.655070 --> 0.654230).  Saving model ...\n","40 0.6470398306846619 0.7929577231407166 0.6542298197746277 0.7977527976036072 0.6614011526107788 0.7664042115211487\n","Validation loss decreased (0.654230 --> 0.653393).  Saving model ...\n","41 0.646007239818573 0.7929577231407166 0.6533926725387573 0.7977527976036072 0.6607306599617004 0.7664042115211487\n","Validation loss decreased (0.653393 --> 0.652560).  Saving model ...\n","42 0.6449841260910034 0.7929577231407166 0.6525598168373108 0.7977527976036072 0.6600711941719055 0.7664042115211487\n","Validation loss decreased (0.652560 --> 0.651732).  Saving model ...\n","43 0.6439694762229919 0.7929577231407166 0.6517323851585388 0.7977527976036072 0.6594216227531433 0.7637795209884644\n","Validation loss decreased (0.651732 --> 0.650912).  Saving model ...\n","44 0.6429635286331177 0.7929577231407166 0.6509121656417847 0.7977527976036072 0.6587780117988586 0.7637795209884644\n","Validation loss decreased (0.650912 --> 0.650101).  Saving model ...\n","45 0.6419678926467896 0.7957746386528015 0.6501011252403259 0.7977527976036072 0.6581385731697083 0.76115483045578\n","Validation loss decreased (0.650101 --> 0.649300).  Saving model ...\n","46 0.6409810781478882 0.794366180896759 0.6492998003959656 0.7977527976036072 0.657502293586731 0.76115483045578\n","Validation loss decreased (0.649300 --> 0.648509).  Saving model ...\n","47 0.6400037407875061 0.794366180896759 0.6485093235969543 0.7977527976036072 0.6568672060966492 0.7637795209884644\n","Validation loss decreased (0.648509 --> 0.647728).  Saving model ...\n","48 0.6390343904495239 0.794366180896759 0.6477282643318176 0.7977527976036072 0.65623539686203 0.7637795209884644\n","Validation loss decreased (0.647728 --> 0.646956).  Saving model ...\n","49 0.6380749940872192 0.794366180896759 0.6469562649726868 0.7977527976036072 0.655609130859375 0.7664042115211487\n","Validation loss decreased (0.646956 --> 0.646191).  Saving model ...\n","50 0.6371239423751831 0.794366180896759 0.646190881729126 0.7977527976036072 0.65498948097229 0.7664042115211487\n","Validation loss decreased (0.646191 --> 0.645431).  Saving model ...\n","51 0.6361818313598633 0.7957746386528015 0.6454306244850159 0.7977527976036072 0.6543774008750916 0.7664042115211487\n","Validation loss decreased (0.645431 --> 0.644675).  Saving model ...\n","52 0.635248601436615 0.794366180896759 0.6446747779846191 0.7977527976036072 0.6537743806838989 0.7690288424491882\n","Validation loss decreased (0.644675 --> 0.643924).  Saving model ...\n","53 0.6343243718147278 0.7957746386528015 0.6439237594604492 0.7977527976036072 0.6531798243522644 0.7690288424491882\n","Validation loss decreased (0.643924 --> 0.643179).  Saving model ...\n","54 0.6334081888198853 0.794366180896759 0.6431785821914673 0.7977527976036072 0.6525912880897522 0.7690288424491882\n","Validation loss decreased (0.643179 --> 0.642441).  Saving model ...\n","55 0.6325013637542725 0.794366180896759 0.6424405574798584 0.7977527976036072 0.652008056640625 0.7690288424491882\n","Validation loss decreased (0.642441 --> 0.641710).  Saving model ...\n","56 0.6316033005714417 0.794366180896759 0.6417104601860046 0.7977527976036072 0.6514290571212769 0.7690288424491882\n","Validation loss decreased (0.641710 --> 0.640990).  Saving model ...\n","57 0.6307132244110107 0.794366180896759 0.6409899592399597 0.7977527976036072 0.650852382183075 0.7690288424491882\n","Validation loss decreased (0.640990 --> 0.640278).  Saving model ...\n","58 0.6298314929008484 0.7957746386528015 0.6402782201766968 0.7977527976036072 0.6502792835235596 0.7690288424491882\n","Validation loss decreased (0.640278 --> 0.639575).  Saving model ...\n","59 0.6289578676223755 0.7957746386528015 0.6395748853683472 0.7977527976036072 0.649709165096283 0.7716535329818726\n","Validation loss decreased (0.639575 --> 0.638879).  Saving model ...\n","60 0.6280927062034607 0.7985915541648865 0.6388785243034363 0.7977527976036072 0.6491453051567078 0.7716535329818726\n","Validation loss decreased (0.638879 --> 0.638187).  Saving model ...\n","61 0.6272359490394592 0.800000011920929 0.6381874084472656 0.7977527976036072 0.6485872268676758 0.7716535329818726\n","Validation loss decreased (0.638187 --> 0.637501).  Saving model ...\n","62 0.6263870596885681 0.800000011920929 0.6375011801719666 0.7977527976036072 0.6480355262756348 0.7716535329818726\n","Validation loss decreased (0.637501 --> 0.636819).  Saving model ...\n","63 0.6255457997322083 0.800000011920929 0.6368193626403809 0.7977527976036072 0.6474896669387817 0.7716535329818726\n","Validation loss decreased (0.636819 --> 0.636143).  Saving model ...\n","64 0.6247127652168274 0.800000011920929 0.6361426711082458 0.7977527976036072 0.6469501852989197 0.7716535329818726\n","Validation loss decreased (0.636143 --> 0.635472).  Saving model ...\n","65 0.6238875389099121 0.7985915541648865 0.635472297668457 0.7977527976036072 0.6464154720306396 0.7716535329818726\n","Validation loss decreased (0.635472 --> 0.634809).  Saving model ...\n","66 0.6230696439743042 0.7985915541648865 0.6348090171813965 0.7977527976036072 0.6458845138549805 0.7716535329818726\n","Validation loss decreased (0.634809 --> 0.634154).  Saving model ...\n","67 0.6222600936889648 0.7985915541648865 0.6341537237167358 0.7977527976036072 0.6453564763069153 0.7716535329818726\n","Validation loss decreased (0.634154 --> 0.633506).  Saving model ...\n","68 0.621457576751709 0.797183096408844 0.6335057020187378 0.7977527976036072 0.6448318958282471 0.7716535329818726\n","Validation loss decreased (0.633506 --> 0.632865).  Saving model ...\n","69 0.6206632852554321 0.797183096408844 0.6328650712966919 0.7977527976036072 0.6443106532096863 0.7716535329818726\n","Validation loss decreased (0.632865 --> 0.632231).  Saving model ...\n","70 0.6198756098747253 0.7985915541648865 0.6322309374809265 0.7977527976036072 0.643794059753418 0.7716535329818726\n","Validation loss decreased (0.632231 --> 0.631601).  Saving model ...\n","71 0.619096040725708 0.7985915541648865 0.6316012740135193 0.7977527976036072 0.6432822942733765 0.7716535329818726\n","Validation loss decreased (0.631601 --> 0.630976).  Saving model ...\n","72 0.6183227300643921 0.8028169274330139 0.6309763193130493 0.7977527976036072 0.6427760720252991 0.7742782235145569\n","Validation loss decreased (0.630976 --> 0.630356).  Saving model ...\n","73 0.6175567507743835 0.8028169274330139 0.630355715751648 0.7977527976036072 0.6422745585441589 0.7742782235145569\n","Validation loss decreased (0.630356 --> 0.629740).  Saving model ...\n","74 0.6167986392974854 0.8028169274330139 0.6297396421432495 0.7977527976036072 0.641778290271759 0.7795275449752808\n","Validation loss decreased (0.629740 --> 0.629130).  Saving model ...\n","75 0.6160471439361572 0.8028169274330139 0.6291297078132629 0.7921348214149475 0.6412857174873352 0.7795275449752808\n","Validation loss decreased (0.629130 --> 0.628526).  Saving model ...\n","76 0.6153027415275574 0.8028169274330139 0.628525972366333 0.7921348214149475 0.6407968997955322 0.7795275449752808\n","Validation loss decreased (0.628526 --> 0.627929).  Saving model ...\n","77 0.6145647168159485 0.8028169274330139 0.6279289126396179 0.7921348214149475 0.6403107047080994 0.7795275449752808\n","Validation loss decreased (0.627929 --> 0.627338).  Saving model ...\n","78 0.6138334274291992 0.8028169274330139 0.6273379325866699 0.7921348214149475 0.6398282051086426 0.7795275449752808\n","Validation loss decreased (0.627338 --> 0.626753).  Saving model ...\n","79 0.6131091713905334 0.8028169274330139 0.6267529726028442 0.7921348214149475 0.6393488049507141 0.7795275449752808\n","Validation loss decreased (0.626753 --> 0.626173).  Saving model ...\n","80 0.6123915910720825 0.8028169274330139 0.626173198223114 0.7921348214149475 0.6388739943504333 0.7795275449752808\n","Validation loss decreased (0.626173 --> 0.625598).  Saving model ...\n","81 0.611680805683136 0.8056337833404541 0.6255979537963867 0.7921348214149475 0.6384028792381287 0.7795275449752808\n","Validation loss decreased (0.625598 --> 0.625027).  Saving model ...\n","82 0.6109758615493774 0.8070422410964966 0.6250266432762146 0.7921348214149475 0.6379361748695374 0.7795275449752808\n","Validation loss decreased (0.625027 --> 0.624459).  Saving model ...\n","83 0.6102774739265442 0.8084506988525391 0.6244592666625977 0.7921348214149475 0.6374740600585938 0.7795275449752808\n","Validation loss decreased (0.624459 --> 0.623897).  Saving model ...\n","84 0.6095849871635437 0.8084506988525391 0.6238971948623657 0.7921348214149475 0.6370153427124023 0.7821522355079651\n","Validation loss decreased (0.623897 --> 0.623340).  Saving model ...\n","85 0.6088995933532715 0.8084506988525391 0.623339831829071 0.7921348214149475 0.6365606188774109 0.7821522355079651\n","Validation loss decreased (0.623340 --> 0.622788).  Saving model ...\n","86 0.6082196831703186 0.8084506988525391 0.6227877736091614 0.7921348214149475 0.6361089944839478 0.7821522355079651\n","Validation loss decreased (0.622788 --> 0.622241).  Saving model ...\n","87 0.6075462698936462 0.8084506988525391 0.622241199016571 0.7921348214149475 0.6356601119041443 0.7847769260406494\n","Validation loss decreased (0.622241 --> 0.621700).  Saving model ...\n","88 0.6068783402442932 0.811267614364624 0.6217001080513 0.7921348214149475 0.6352142095565796 0.7847769260406494\n","Validation loss decreased (0.621700 --> 0.621164).  Saving model ...\n","89 0.606216311454773 0.811267614364624 0.6211639642715454 0.7921348214149475 0.634772002696991 0.7847769260406494\n","Validation loss decreased (0.621164 --> 0.620632).  Saving model ...\n","90 0.6055607199668884 0.811267614364624 0.6206318140029907 0.7865168452262878 0.6343327164649963 0.7847769260406494\n","Validation loss decreased (0.620632 --> 0.620104).  Saving model ...\n","91 0.6049104332923889 0.8126760721206665 0.6201037168502808 0.7865168452262878 0.6338974833488464 0.787401556968689\n","Validation loss decreased (0.620104 --> 0.619579).  Saving model ...\n","92 0.6042659282684326 0.8126760721206665 0.6195791959762573 0.7865168452262878 0.6334662437438965 0.787401556968689\n","Validation loss decreased (0.619579 --> 0.619058).  Saving model ...\n","93 0.6036271452903748 0.8126760721206665 0.61905837059021 0.7865168452262878 0.6330389380455017 0.787401556968689\n","Validation loss decreased (0.619058 --> 0.618542).  Saving model ...\n","94 0.6029940843582153 0.8126760721206665 0.6185424327850342 0.7865168452262878 0.6326138973236084 0.787401556968689\n","Validation loss decreased (0.618542 --> 0.618031).  Saving model ...\n","95 0.6023666262626648 0.8126760721206665 0.6180309057235718 0.7865168452262878 0.6321923732757568 0.787401556968689\n","Validation loss decreased (0.618031 --> 0.617524).  Saving model ...\n","96 0.6017444133758545 0.8126760721206665 0.617523729801178 0.7865168452262878 0.6317738890647888 0.787401556968689\n","Validation loss decreased (0.617524 --> 0.617021).  Saving model ...\n","97 0.6011275053024292 0.8126760721206665 0.6170212626457214 0.7865168452262878 0.631357729434967 0.787401556968689\n","Validation loss decreased (0.617021 --> 0.616523).  Saving model ...\n","98 0.6005160212516785 0.814084529876709 0.6165233254432678 0.7865168452262878 0.6309449076652527 0.787401556968689\n","Validation loss decreased (0.616523 --> 0.616029).  Saving model ...\n","99 0.5999096035957336 0.814084529876709 0.6160291433334351 0.7865168452262878 0.6305346488952637 0.787401556968689\n","Validation loss decreased (0.616029 --> 0.615539).  Saving model ...\n","100 0.599308967590332 0.814084529876709 0.6155386567115784 0.7865168452262878 0.6301283240318298 0.787401556968689\n","Validation loss decreased (0.615539 --> 0.615051).  Saving model ...\n","101 0.5987123847007751 0.814084529876709 0.61505126953125 0.7865168452262878 0.6297248601913452 0.787401556968689\n","Validation loss decreased (0.615051 --> 0.614567).  Saving model ...\n","102 0.5981216430664062 0.814084529876709 0.6145674586296082 0.7865168452262878 0.6293246150016785 0.787401556968689\n","Validation loss decreased (0.614567 --> 0.614087).  Saving model ...\n","103 0.5975357294082642 0.814084529876709 0.6140873432159424 0.7865168452262878 0.6289272904396057 0.787401556968689\n","Validation loss decreased (0.614087 --> 0.613611).  Saving model ...\n","104 0.5969542860984802 0.814084529876709 0.6136111617088318 0.7865168452262878 0.6285326480865479 0.787401556968689\n","Validation loss decreased (0.613611 --> 0.613139).  Saving model ...\n","105 0.5963782072067261 0.8154929280281067 0.6131389737129211 0.7865168452262878 0.6281408667564392 0.787401556968689\n","Validation loss decreased (0.613139 --> 0.612671).  Saving model ...\n","106 0.5958067774772644 0.8154929280281067 0.6126708388328552 0.7865168452262878 0.6277515888214111 0.787401556968689\n","Validation loss decreased (0.612671 --> 0.612206).  Saving model ...\n","107 0.5952401161193848 0.8169013857841492 0.6122061014175415 0.7865168452262878 0.6273649334907532 0.7900262475013733\n","Validation loss decreased (0.612206 --> 0.611745).  Saving model ...\n","108 0.5946782231330872 0.8183098435401917 0.6117450594902039 0.7865168452262878 0.6269811391830444 0.7900262475013733\n","Validation loss decreased (0.611745 --> 0.611287).  Saving model ...\n","109 0.5941206812858582 0.8183098435401917 0.6112871766090393 0.7865168452262878 0.6265999674797058 0.7926509380340576\n","Validation loss decreased (0.611287 --> 0.610833).  Saving model ...\n","110 0.5935676693916321 0.8183098435401917 0.6108325719833374 0.7865168452262878 0.6262219548225403 0.7926509380340576\n","Validation loss decreased (0.610833 --> 0.610381).  Saving model ...\n","111 0.5930196642875671 0.8183098435401917 0.610381007194519 0.7865168452262878 0.6258467435836792 0.7926509380340576\n","Validation loss decreased (0.610381 --> 0.609933).  Saving model ...\n","112 0.5924761295318604 0.8197183012962341 0.6099326610565186 0.7865168452262878 0.6254735589027405 0.7979002594947815\n","Validation loss decreased (0.609933 --> 0.609488).  Saving model ...\n","113 0.5919366478919983 0.8197183012962341 0.6094877123832703 0.7865168452262878 0.6251037120819092 0.7979002594947815\n","Validation loss decreased (0.609488 --> 0.609046).  Saving model ...\n","114 0.5914017558097839 0.8197183012962341 0.6090459227561951 0.7921348214149475 0.6247361898422241 0.7979002594947815\n","Validation loss decreased (0.609046 --> 0.608608).  Saving model ...\n","115 0.5908712148666382 0.8197183012962341 0.6086077094078064 0.7921348214149475 0.6243704557418823 0.7979002594947815\n","Validation loss decreased (0.608608 --> 0.608173).  Saving model ...\n","116 0.5903443694114685 0.8197183012962341 0.6081726551055908 0.7921348214149475 0.6240079402923584 0.7979002594947815\n","Validation loss decreased (0.608173 --> 0.607741).  Saving model ...\n","117 0.5898216366767883 0.8197183012962341 0.6077408790588379 0.7921348214149475 0.6236472725868225 0.7979002594947815\n","Validation loss decreased (0.607741 --> 0.607312).  Saving model ...\n","118 0.5893043279647827 0.8197183012962341 0.6073119044303894 0.7977527976036072 0.6232892274856567 0.7979002594947815\n","Validation loss decreased (0.607312 --> 0.606885).  Saving model ...\n","119 0.5887901186943054 0.8211267590522766 0.6068854928016663 0.7977527976036072 0.6229340434074402 0.7979002594947815\n","Validation loss decreased (0.606885 --> 0.606462).  Saving model ...\n","120 0.5882798433303833 0.8211267590522766 0.6064620614051819 0.7977527976036072 0.6225805878639221 0.7979002594947815\n","Validation loss decreased (0.606462 --> 0.606041).  Saving model ...\n","121 0.5877737402915955 0.8225352168083191 0.6060413718223572 0.7977527976036072 0.622230589389801 0.7979002594947815\n","Validation loss decreased (0.606041 --> 0.605624).  Saving model ...\n","122 0.5872719287872314 0.8225352168083191 0.6056237816810608 0.7977527976036072 0.6218822598457336 0.7979002594947815\n","Validation loss decreased (0.605624 --> 0.605209).  Saving model ...\n","123 0.5867739915847778 0.8225352168083191 0.6052091121673584 0.7977527976036072 0.6215361952781677 0.7979002594947815\n","Validation loss decreased (0.605209 --> 0.604797).  Saving model ...\n","124 0.5862792730331421 0.8225352168083191 0.6047971844673157 0.7977527976036072 0.6211923956871033 0.7979002594947815\n","Validation loss decreased (0.604797 --> 0.604388).  Saving model ...\n","125 0.5857887268066406 0.8225352168083191 0.6043880581855774 0.7977527976036072 0.6208510398864746 0.8005249500274658\n","Validation loss decreased (0.604388 --> 0.603982).  Saving model ...\n","126 0.5853027701377869 0.8225352168083191 0.6039820313453674 0.7977527976036072 0.6205118894577026 0.8031495809555054\n","Validation loss decreased (0.603982 --> 0.603578).  Saving model ...\n","127 0.5848190188407898 0.8239436745643616 0.6035783290863037 0.7977527976036072 0.620174765586853 0.8031495809555054\n","Validation loss decreased (0.603578 --> 0.603177).  Saving model ...\n","128 0.5843395590782166 0.8239436745643616 0.6031771302223206 0.7977527976036072 0.6198398470878601 0.8031495809555054\n","Validation loss decreased (0.603177 --> 0.602779).  Saving model ...\n","129 0.5838639140129089 0.8239436745643616 0.6027786731719971 0.7977527976036072 0.6195071935653687 0.8031495809555054\n","Validation loss decreased (0.602779 --> 0.602382).  Saving model ...\n","130 0.5833920240402222 0.825352132320404 0.6023823618888855 0.7977527976036072 0.619176983833313 0.8031495809555054\n","Validation loss decreased (0.602382 --> 0.601989).  Saving model ...\n","131 0.582923412322998 0.825352132320404 0.6019887924194336 0.8033707737922668 0.6188485026359558 0.8057742714881897\n","Validation loss decreased (0.601989 --> 0.601598).  Saving model ...\n","132 0.5824582576751709 0.8267605900764465 0.601597785949707 0.8033707737922668 0.6185222864151001 0.8057742714881897\n","Validation loss decreased (0.601598 --> 0.601210).  Saving model ...\n","133 0.581996738910675 0.8267605900764465 0.6012095808982849 0.8033707737922668 0.6181978583335876 0.8057742714881897\n","Validation loss decreased (0.601210 --> 0.600824).  Saving model ...\n","134 0.5815386176109314 0.8267605900764465 0.6008235812187195 0.8033707737922668 0.6178757548332214 0.8057742714881897\n","Validation loss decreased (0.600824 --> 0.600440).  Saving model ...\n","135 0.5810843110084534 0.8267605900764465 0.6004400253295898 0.8033707737922668 0.6175554394721985 0.8057742714881897\n","Validation loss decreased (0.600440 --> 0.600059).  Saving model ...\n","136 0.5806320309638977 0.8267605900764465 0.6000587344169617 0.8033707737922668 0.617237389087677 0.8057742714881897\n","Validation loss decreased (0.600059 --> 0.599680).  Saving model ...\n","137 0.5801838636398315 0.8267605900764465 0.5996795892715454 0.8033707737922668 0.6169209480285645 0.8057742714881897\n","Validation loss decreased (0.599680 --> 0.599303).  Saving model ...\n","138 0.5797386765480042 0.8267605900764465 0.5993028283119202 0.8033707737922668 0.6166067123413086 0.8057742714881897\n","Validation loss decreased (0.599303 --> 0.598928).  Saving model ...\n","139 0.5792970657348633 0.8267605900764465 0.5989282131195068 0.8033707737922668 0.6162947416305542 0.8057742714881897\n","Validation loss decreased (0.598928 --> 0.598556).  Saving model ...\n","140 0.5788589715957642 0.8267605900764465 0.5985559225082397 0.8033707737922668 0.6159839630126953 0.8057742714881897\n","Validation loss decreased (0.598556 --> 0.598186).  Saving model ...\n","141 0.5784233212471008 0.8267605900764465 0.5981858968734741 0.8089887499809265 0.6156754493713379 0.8057742714881897\n","Validation loss decreased (0.598186 --> 0.597818).  Saving model ...\n","142 0.5779910087585449 0.8267605900764465 0.59781813621521 0.8089887499809265 0.6153691411018372 0.8057742714881897\n","Validation loss decreased (0.597818 --> 0.597453).  Saving model ...\n","143 0.5775619745254517 0.8267605900764465 0.5974525809288025 0.8089887499809265 0.6150643825531006 0.8057742714881897\n","Validation loss decreased (0.597453 --> 0.597089).  Saving model ...\n","144 0.5771353840827942 0.8281689882278442 0.5970890522003174 0.8089887499809265 0.6147617697715759 0.8057742714881897\n","Validation loss decreased (0.597089 --> 0.596728).  Saving model ...\n","145 0.576712429523468 0.8281689882278442 0.596727728843689 0.8089887499809265 0.614460289478302 0.808398962020874\n","Validation loss decreased (0.596728 --> 0.596368).  Saving model ...\n","146 0.5762923955917358 0.8295774459838867 0.5963683724403381 0.8033707737922668 0.6141612529754639 0.808398962020874\n","Validation loss decreased (0.596368 --> 0.596011).  Saving model ...\n","147 0.5758757591247559 0.8295774459838867 0.5960110425949097 0.8033707737922668 0.6138632893562317 0.808398962020874\n","Validation loss decreased (0.596011 --> 0.595656).  Saving model ...\n","148 0.5754610300064087 0.8309859037399292 0.595655620098114 0.8033707737922668 0.6135679483413696 0.808398962020874\n","Validation loss decreased (0.595656 --> 0.595302).  Saving model ...\n","149 0.575049877166748 0.8309859037399292 0.5953024625778198 0.8033707737922668 0.6132737994194031 0.808398962020874\n","Validation loss decreased (0.595302 --> 0.594951).  Saving model ...\n","150 0.5746411085128784 0.8309859037399292 0.594951331615448 0.8033707737922668 0.6129816770553589 0.808398962020874\n","Validation loss decreased (0.594951 --> 0.594602).  Saving model ...\n","151 0.5742350816726685 0.8309859037399292 0.5946019291877747 0.8033707737922668 0.6126914024353027 0.808398962020874\n","Validation loss decreased (0.594602 --> 0.594255).  Saving model ...\n","152 0.5738320350646973 0.8309859037399292 0.5942545533180237 0.8033707737922668 0.612402617931366 0.808398962020874\n","Validation loss decreased (0.594255 --> 0.593909).  Saving model ...\n","153 0.5734320282936096 0.8309859037399292 0.5939091444015503 0.8033707737922668 0.6121149063110352 0.808398962020874\n","Validation loss decreased (0.593909 --> 0.593565).  Saving model ...\n","154 0.573034405708313 0.8323943614959717 0.5935654640197754 0.8033707737922668 0.6118298768997192 0.808398962020874\n","Validation loss decreased (0.593565 --> 0.593224).  Saving model ...\n","155 0.572639524936676 0.8323943614959717 0.5932236313819885 0.8033707737922668 0.6115458011627197 0.808398962020874\n","Validation loss decreased (0.593224 --> 0.592884).  Saving model ...\n","156 0.5722478032112122 0.8323943614959717 0.5928837656974792 0.8033707737922668 0.6112636923789978 0.808398962020874\n","Validation loss decreased (0.592884 --> 0.592546).  Saving model ...\n","157 0.5718581676483154 0.8323943614959717 0.5925455689430237 0.8033707737922668 0.6109828948974609 0.8110235929489136\n","Validation loss decreased (0.592546 --> 0.592209).  Saving model ...\n","158 0.5714711546897888 0.8323943614959717 0.5922090411186218 0.8033707737922668 0.6107040643692017 0.8110235929489136\n","Validation loss decreased (0.592209 --> 0.591875).  Saving model ...\n","159 0.5710862874984741 0.8323943614959717 0.5918746590614319 0.8033707737922668 0.6104264259338379 0.8110235929489136\n","Validation loss decreased (0.591875 --> 0.591542).  Saving model ...\n","160 0.5707051753997803 0.8338028192520142 0.5915418863296509 0.8033707737922668 0.6101507544517517 0.8110235929489136\n","Validation loss decreased (0.591542 --> 0.591211).  Saving model ...\n","161 0.5703256726264954 0.8338028192520142 0.5912112593650818 0.8033707737922668 0.6098761558532715 0.8110235929489136\n","Validation loss decreased (0.591211 --> 0.590882).  Saving model ...\n","162 0.5699490904808044 0.8338028192520142 0.5908817052841187 0.8089887499809265 0.6096035838127136 0.8110235929489136\n","Validation loss decreased (0.590882 --> 0.590554).  Saving model ...\n","163 0.5695743560791016 0.8338028192520142 0.5905541777610779 0.8089887499809265 0.6093318462371826 0.8110235929489136\n","Validation loss decreased (0.590554 --> 0.590228).  Saving model ...\n","164 0.5692025423049927 0.8338028192520142 0.5902281999588013 0.8089887499809265 0.6090624928474426 0.8136482834815979\n","Validation loss decreased (0.590228 --> 0.589904).  Saving model ...\n","165 0.5688331723213196 0.8338028192520142 0.5899037718772888 0.8089887499809265 0.6087940335273743 0.8136482834815979\n","Validation loss decreased (0.589904 --> 0.589581).  Saving model ...\n","166 0.5684660077095032 0.8338028192520142 0.5895811915397644 0.8089887499809265 0.608527421951294 0.8162729740142822\n","Validation loss decreased (0.589581 --> 0.589260).  Saving model ...\n","167 0.568101167678833 0.8338028192520142 0.5892602801322937 0.8089887499809265 0.6082618236541748 0.8162729740142822\n","Validation loss decreased (0.589260 --> 0.588941).  Saving model ...\n","168 0.5677390694618225 0.8338028192520142 0.5889407992362976 0.8089887499809265 0.6079984903335571 0.8162729740142822\n","Validation loss decreased (0.588941 --> 0.588623).  Saving model ...\n","169 0.5673794746398926 0.8338028192520142 0.5886229276657104 0.8089887499809265 0.6077356934547424 0.8162729740142822\n","Validation loss decreased (0.588623 --> 0.588307).  Saving model ...\n","170 0.5670211911201477 0.8338028192520142 0.5883066058158875 0.8089887499809265 0.6074747443199158 0.8162729740142822\n","Validation loss decreased (0.588307 --> 0.587992).  Saving model ...\n","171 0.5666657090187073 0.8338028192520142 0.5879921913146973 0.8089887499809265 0.6072151064872742 0.8162729740142822\n","Validation loss decreased (0.587992 --> 0.587679).  Saving model ...\n","172 0.5663127303123474 0.8338028192520142 0.5876789093017578 0.8089887499809265 0.6069568395614624 0.8162729740142822\n","Validation loss decreased (0.587679 --> 0.587367).  Saving model ...\n","173 0.5659613013267517 0.8338028192520142 0.5873673558235168 0.8089887499809265 0.6067001819610596 0.8162729740142822\n","Validation loss decreased (0.587367 --> 0.587057).  Saving model ...\n","174 0.5656132698059082 0.8352112770080566 0.58705735206604 0.8089887499809265 0.6064446568489075 0.8162729740142822\n","Validation loss decreased (0.587057 --> 0.586749).  Saving model ...\n","175 0.5652665495872498 0.8352112770080566 0.5867486000061035 0.8089887499809265 0.60619056224823 0.8162729740142822\n","Validation loss decreased (0.586749 --> 0.586441).  Saving model ...\n","176 0.5649216175079346 0.8366197347640991 0.5864413976669312 0.8089887499809265 0.6059378981590271 0.8162729740142822\n","Validation loss decreased (0.586441 --> 0.586136).  Saving model ...\n","177 0.5645795464515686 0.8366197347640991 0.5861355662345886 0.8146067261695862 0.6056866645812988 0.8162729740142822\n","Validation loss decreased (0.586136 --> 0.585832).  Saving model ...\n","178 0.5642392039299011 0.8380281925201416 0.5858316421508789 0.8146067261695862 0.6054359078407288 0.8136482834815979\n","Validation loss decreased (0.585832 --> 0.585529).  Saving model ...\n","179 0.5639017820358276 0.8380281925201416 0.5855287313461304 0.8146067261695862 0.6051873564720154 0.8136482834815979\n","Validation loss decreased (0.585529 --> 0.585227).  Saving model ...\n","180 0.5635647773742676 0.8394365906715393 0.5852274298667908 0.8146067261695862 0.6049401164054871 0.8136482834815979\n","Validation loss decreased (0.585227 --> 0.584927).  Saving model ...\n","181 0.5632311105728149 0.8394365906715393 0.5849274396896362 0.8146067261695862 0.6046934723854065 0.8136482834815979\n","Validation loss decreased (0.584927 --> 0.584629).  Saving model ...\n","182 0.5628991723060608 0.8394365906715393 0.5846291184425354 0.8146067261695862 0.6044487953186035 0.8136482834815979\n","Validation loss decreased (0.584629 --> 0.584332).  Saving model ...\n","183 0.5625687837600708 0.8394365906715393 0.5843318104743958 0.8146067261695862 0.6042050123214722 0.8136482834815979\n","Validation loss decreased (0.584332 --> 0.584036).  Saving model ...\n","184 0.5622413754463196 0.8394365906715393 0.5840358734130859 0.8146067261695862 0.603962779045105 0.8136482834815979\n","Validation loss decreased (0.584036 --> 0.583742).  Saving model ...\n","185 0.5619149804115295 0.8394365906715393 0.5837417244911194 0.8146067261695862 0.6037213206291199 0.8136482834815979\n","Validation loss decreased (0.583742 --> 0.583448).  Saving model ...\n","186 0.5615912079811096 0.8408450484275818 0.5834482908248901 0.8146067261695862 0.6034813523292542 0.8136482834815979\n","Validation loss decreased (0.583448 --> 0.583157).  Saving model ...\n","187 0.561269223690033 0.8408450484275818 0.583156943321228 0.8146067261695862 0.6032425761222839 0.8136482834815979\n","Validation loss decreased (0.583157 --> 0.582866).  Saving model ...\n","188 0.5609489679336548 0.8422535061836243 0.5828662514686584 0.8146067261695862 0.6030054092407227 0.8136482834815979\n","Validation loss decreased (0.582866 --> 0.582577).  Saving model ...\n","189 0.5606306195259094 0.8422535061836243 0.5825771689414978 0.8146067261695862 0.6027687191963196 0.8136482834815979\n","Validation loss decreased (0.582577 --> 0.582289).  Saving model ...\n","190 0.5603137016296387 0.8422535061836243 0.5822892189025879 0.8146067261695862 0.6025338768959045 0.8136482834815979\n","Validation loss decreased (0.582289 --> 0.582003).  Saving model ...\n","191 0.5599994659423828 0.8422535061836243 0.5820027589797974 0.8146067261695862 0.602299690246582 0.8136482834815979\n","Validation loss decreased (0.582003 --> 0.581718).  Saving model ...\n","192 0.559687077999115 0.8422535061836243 0.5817176699638367 0.8146067261695862 0.602067232131958 0.8136482834815979\n","Validation loss decreased (0.581718 --> 0.581433).  Saving model ...\n","193 0.5593764185905457 0.8422535061836243 0.5814332962036133 0.8146067261695862 0.6018351912498474 0.8162729740142822\n","Validation loss decreased (0.581433 --> 0.581151).  Saving model ...\n","194 0.5590673089027405 0.8436619639396667 0.5811507701873779 0.8146067261695862 0.6016047596931458 0.8162729740142822\n","Validation loss decreased (0.581151 --> 0.580869).  Saving model ...\n","195 0.5587599277496338 0.8436619639396667 0.5808692574501038 0.8146067261695862 0.6013757586479187 0.8162729740142822\n","Validation loss decreased (0.580869 --> 0.580589).  Saving model ...\n","196 0.5584542155265808 0.8450704216957092 0.5805888772010803 0.8146067261695862 0.6011470556259155 0.8162729740142822\n","Validation loss decreased (0.580589 --> 0.580310).  Saving model ...\n","197 0.5581506490707397 0.8450704216957092 0.5803098082542419 0.8146067261695862 0.6009201407432556 0.8162729740142822\n","Validation loss decreased (0.580310 --> 0.580032).  Saving model ...\n","198 0.5578488707542419 0.8436619639396667 0.5800319314002991 0.8146067261695862 0.600693941116333 0.8162729740142822\n","Validation loss decreased (0.580032 --> 0.579755).  Saving model ...\n","199 0.557548463344574 0.8436619639396667 0.5797552466392517 0.8146067261695862 0.6004690527915955 0.8162729740142822\n","Validation loss decreased (0.579755 --> 0.579480).  Saving model ...\n","200 0.5572500824928284 0.8436619639396667 0.5794796943664551 0.8146067261695862 0.6002453565597534 0.8162729740142822\n","Validation loss decreased (0.579480 --> 0.579206).  Saving model ...\n","201 0.5569528937339783 0.8450704216957092 0.5792055726051331 0.8146067261695862 0.6000226140022278 0.8162729740142822\n","Validation loss decreased (0.579206 --> 0.578932).  Saving model ...\n","202 0.556658148765564 0.8450704216957092 0.5789322853088379 0.8146067261695862 0.5998008847236633 0.8162729740142822\n","Validation loss decreased (0.578932 --> 0.578660).  Saving model ...\n","203 0.5563645362854004 0.8450704216957092 0.5786604881286621 0.8146067261695862 0.5995806455612183 0.8162729740142822\n","Validation loss decreased (0.578660 --> 0.578390).  Saving model ...\n","204 0.5560722351074219 0.8464788794517517 0.578389585018158 0.8146067261695862 0.5993608236312866 0.8162729740142822\n","Validation loss decreased (0.578390 --> 0.578120).  Saving model ...\n","205 0.5557821989059448 0.8464788794517517 0.5781198740005493 0.8146067261695862 0.5991423726081848 0.8162729740142822\n","Validation loss decreased (0.578120 --> 0.577851).  Saving model ...\n","206 0.555493950843811 0.8464788794517517 0.5778513550758362 0.8202247023582458 0.598924994468689 0.8162729740142822\n","Validation loss decreased (0.577851 --> 0.577584).  Saving model ...\n","207 0.5552069544792175 0.8464788794517517 0.5775839686393738 0.8202247023582458 0.5987088084220886 0.8162729740142822\n","Validation loss decreased (0.577584 --> 0.577318).  Saving model ...\n","208 0.5549214482307434 0.8464788794517517 0.5773176550865173 0.8202247023582458 0.5984931588172913 0.8188976645469666\n","Validation loss decreased (0.577318 --> 0.577052).  Saving model ...\n","209 0.5546373724937439 0.8464788794517517 0.5770524740219116 0.8202247023582458 0.5982787609100342 0.8188976645469666\n","Validation loss decreased (0.577052 --> 0.576788).  Saving model ...\n","210 0.5543553829193115 0.8464788794517517 0.5767882466316223 0.8202247023582458 0.5980654358863831 0.8188976645469666\n","Validation loss decreased (0.576788 --> 0.576525).  Saving model ...\n","211 0.5540744662284851 0.8450704216957092 0.5765253305435181 0.8202247023582458 0.5978532433509827 0.8188976645469666\n","Validation loss decreased (0.576525 --> 0.576263).  Saving model ...\n","212 0.553795576095581 0.8450704216957092 0.5762634873390198 0.8202247023582458 0.5976417064666748 0.8188976645469666\n","Validation loss decreased (0.576263 --> 0.576003).  Saving model ...\n","213 0.5535178184509277 0.8450704216957092 0.5760026574134827 0.8202247023582458 0.5974315404891968 0.8188976645469666\n","Validation loss decreased (0.576003 --> 0.575743).  Saving model ...\n","214 0.5532414317131042 0.8450704216957092 0.5757430791854858 0.8202247023582458 0.5972219109535217 0.8188976645469666\n","Validation loss decreased (0.575743 --> 0.575484).  Saving model ...\n","215 0.5529673099517822 0.8450704216957092 0.5754841566085815 0.8202247023582458 0.5970133543014526 0.8188976645469666\n","Validation loss decreased (0.575484 --> 0.575227).  Saving model ...\n","216 0.5526940226554871 0.8450704216957092 0.5752265453338623 0.8202247023582458 0.5968060493469238 0.8188976645469666\n","Validation loss decreased (0.575227 --> 0.574970).  Saving model ...\n","217 0.5524224042892456 0.8450704216957092 0.5749698281288147 0.8202247023582458 0.5965995788574219 0.8188976645469666\n","Validation loss decreased (0.574970 --> 0.574714).  Saving model ...\n","218 0.5521522164344788 0.8450704216957092 0.5747141242027283 0.8202247023582458 0.5963940620422363 0.8188976645469666\n","Validation loss decreased (0.574714 --> 0.574459).  Saving model ...\n","219 0.551883339881897 0.8450704216957092 0.5744594931602478 0.8202247023582458 0.5961893796920776 0.8188976645469666\n","Validation loss decreased (0.574459 --> 0.574206).  Saving model ...\n","220 0.5516160130500793 0.8450704216957092 0.5742059946060181 0.8202247023582458 0.5959855914115906 0.8188976645469666\n","Validation loss decreased (0.574206 --> 0.573954).  Saving model ...\n","221 0.5513501763343811 0.8450704216957092 0.5739535689353943 0.8202247023582458 0.5957827568054199 0.8188976645469666\n","Validation loss decreased (0.573954 --> 0.573702).  Saving model ...\n","222 0.5510855913162231 0.8450704216957092 0.5737021565437317 0.8202247023582458 0.5955810546875 0.8188976645469666\n","Validation loss decreased (0.573702 --> 0.573452).  Saving model ...\n","223 0.5508227348327637 0.8450704216957092 0.5734515190124512 0.8202247023582458 0.5953798294067383 0.8188976645469666\n","Validation loss decreased (0.573452 --> 0.573202).  Saving model ...\n","224 0.5505611896514893 0.8450704216957092 0.5732020139694214 0.8202247023582458 0.5951801538467407 0.8188976645469666\n","Validation loss decreased (0.573202 --> 0.572954).  Saving model ...\n","225 0.5503000020980835 0.8450704216957092 0.5729535818099976 0.8258426785469055 0.5949808359146118 0.8188976645469666\n","Validation loss decreased (0.572954 --> 0.572706).  Saving model ...\n","226 0.5500420928001404 0.8450704216957092 0.5727059245109558 0.8258426785469055 0.5947825908660889 0.8188976645469666\n","Validation loss decreased (0.572706 --> 0.572459).  Saving model ...\n","227 0.5497837066650391 0.8450704216957092 0.5724594593048096 0.8258426785469055 0.5945852398872375 0.8188976645469666\n","Validation loss decreased (0.572459 --> 0.572214).  Saving model ...\n","228 0.5495277643203735 0.8450704216957092 0.5722139477729797 0.8258426785469055 0.5943886637687683 0.8188976645469666\n","Validation loss decreased (0.572214 --> 0.571969).  Saving model ...\n","229 0.5492728352546692 0.8450704216957092 0.5719690918922424 0.8258426785469055 0.5941933393478394 0.8188976645469666\n","Validation loss decreased (0.571969 --> 0.571725).  Saving model ...\n","230 0.5490192174911499 0.8464788794517517 0.5717251300811768 0.8258426785469055 0.5939984321594238 0.8188976645469666\n","Validation loss decreased (0.571725 --> 0.571483).  Saving model ...\n","231 0.5487667918205261 0.8464788794517517 0.5714828372001648 0.8258426785469055 0.5938042402267456 0.8188976645469666\n","Validation loss decreased (0.571483 --> 0.571241).  Saving model ...\n","232 0.5485159754753113 0.8464788794517517 0.5712409019470215 0.8258426785469055 0.5936114192008972 0.8188976645469666\n","Validation loss decreased (0.571241 --> 0.571000).  Saving model ...\n","233 0.5482661724090576 0.8464788794517517 0.5710000395774841 0.8258426785469055 0.5934194326400757 0.8188976645469666\n","Validation loss decreased (0.571000 --> 0.570760).  Saving model ...\n","234 0.5480181574821472 0.8464788794517517 0.5707598328590393 0.8258426785469055 0.5932279229164124 0.8188976645469666\n","Validation loss decreased (0.570760 --> 0.570521).  Saving model ...\n","235 0.5477705001831055 0.8464788794517517 0.5705208778381348 0.8258426785469055 0.5930373072624207 0.8188976645469666\n","Validation loss decreased (0.570521 --> 0.570283).  Saving model ...\n","236 0.5475249886512756 0.8478873372077942 0.5702828168869019 0.8258426785469055 0.5928476452827454 0.8188976645469666\n","Validation loss decreased (0.570283 --> 0.570046).  Saving model ...\n","237 0.5472797751426697 0.8492957949638367 0.5700457692146301 0.8258426785469055 0.5926588773727417 0.8188976645469666\n","Validation loss decreased (0.570046 --> 0.569809).  Saving model ...\n","238 0.5470365285873413 0.8492957949638367 0.5698093175888062 0.8258426785469055 0.5924707651138306 0.8188976645469666\n","Validation loss decreased (0.569809 --> 0.569574).  Saving model ...\n","239 0.5467944741249084 0.8492957949638367 0.5695739984512329 0.8258426785469055 0.5922834873199463 0.8188976645469666\n","Validation loss decreased (0.569574 --> 0.569339).  Saving model ...\n","240 0.546553373336792 0.8492957949638367 0.569339394569397 0.8258426785469055 0.5920970439910889 0.8188976645469666\n","Validation loss decreased (0.569339 --> 0.569106).  Saving model ...\n","241 0.5463137626647949 0.8492957949638367 0.569105863571167 0.8258426785469055 0.5919114947319031 0.8188976645469666\n","Validation loss decreased (0.569106 --> 0.568873).  Saving model ...\n","242 0.5460745096206665 0.8492957949638367 0.5688731670379639 0.8258426785469055 0.5917266607284546 0.8188976645469666\n","Validation loss decreased (0.568873 --> 0.568641).  Saving model ...\n","243 0.5458377003669739 0.8492957949638367 0.5686413049697876 0.8258426785469055 0.5915423631668091 0.8188976645469666\n","Validation loss decreased (0.568641 --> 0.568410).  Saving model ...\n","244 0.5456017851829529 0.8492957949638367 0.5684104561805725 0.8258426785469055 0.5913593769073486 0.8188976645469666\n","Validation loss decreased (0.568410 --> 0.568180).  Saving model ...\n","245 0.5453662276268005 0.8492957949638367 0.5681802034378052 0.8258426785469055 0.5911766886711121 0.8188976645469666\n","Validation loss decreased (0.568180 --> 0.567951).  Saving model ...\n","246 0.545132577419281 0.8492957949638367 0.5679512619972229 0.8258426785469055 0.5909950137138367 0.8188976645469666\n","Validation loss decreased (0.567951 --> 0.567723).  Saving model ...\n","247 0.5448998808860779 0.8492957949638367 0.5677226781845093 0.8258426785469055 0.5908143520355225 0.8162729740142822\n","Validation loss decreased (0.567723 --> 0.567495).  Saving model ...\n","248 0.5446682572364807 0.8492957949638367 0.5674950480461121 0.8258426785469055 0.5906338095664978 0.8162729740142822\n","Validation loss decreased (0.567495 --> 0.567269).  Saving model ...\n","249 0.5444375872612 0.8492957949638367 0.5672685503959656 0.8258426785469055 0.5904545187950134 0.8162729740142822\n","Validation loss decreased (0.567269 --> 0.567043).  Saving model ...\n","250 0.5442083477973938 0.8492957949638367 0.5670425295829773 0.8258426785469055 0.5902759432792664 0.8162729740142822\n","Validation loss decreased (0.567043 --> 0.566817).  Saving model ...\n","251 0.5439801216125488 0.8492957949638367 0.5668174624443054 0.8258426785469055 0.590097963809967 0.8162729740142822\n","Validation loss decreased (0.566817 --> 0.566594).  Saving model ...\n","252 0.5437533259391785 0.8492957949638367 0.5665935277938843 0.8314606547355652 0.5899209976196289 0.8188976645469666\n","Validation loss decreased (0.566594 --> 0.566370).  Saving model ...\n","253 0.543527364730835 0.8507042527198792 0.5663699507713318 0.8314606547355652 0.5897442102432251 0.8215222954750061\n","Validation loss decreased (0.566370 --> 0.566148).  Saving model ...\n","254 0.5433022975921631 0.8507042527198792 0.5661476850509644 0.8314606547355652 0.5895687937736511 0.8215222954750061\n","Validation loss decreased (0.566148 --> 0.565926).  Saving model ...\n","255 0.5430783033370972 0.8507042527198792 0.5659260153770447 0.8314606547355652 0.5893934965133667 0.8215222954750061\n","Validation loss decreased (0.565926 --> 0.565705).  Saving model ...\n","256 0.5428559184074402 0.8507042527198792 0.5657050013542175 0.8314606547355652 0.5892195701599121 0.8215222954750061\n","Validation loss decreased (0.565705 --> 0.565485).  Saving model ...\n","257 0.5426338315010071 0.8507042527198792 0.5654850006103516 0.8314606547355652 0.5890457630157471 0.8241469860076904\n","Validation loss decreased (0.565485 --> 0.565266).  Saving model ...\n","258 0.5424132347106934 0.8507042527198792 0.5652658343315125 0.8314606547355652 0.588873028755188 0.8241469860076904\n","Validation loss decreased (0.565266 --> 0.565047).  Saving model ...\n","259 0.5421938300132751 0.8507042527198792 0.5650472640991211 0.8314606547355652 0.5887011885643005 0.8241469860076904\n","Validation loss decreased (0.565047 --> 0.564830).  Saving model ...\n","260 0.5419754981994629 0.8492957949638367 0.5648297667503357 0.8314606547355652 0.5885294079780579 0.8241469860076904\n","Validation loss decreased (0.564830 --> 0.564613).  Saving model ...\n","261 0.5417578220367432 0.8507042527198792 0.564612627029419 0.8314606547355652 0.5883589386940002 0.8241469860076904\n","Validation loss decreased (0.564613 --> 0.564397).  Saving model ...\n","262 0.5415412783622742 0.8507042527198792 0.5643967390060425 0.8314606547355652 0.5881887078285217 0.8241469860076904\n","Validation loss decreased (0.564397 --> 0.564181).  Saving model ...\n","263 0.5413252115249634 0.8507042527198792 0.5641813278198242 0.8370786309242249 0.5880197882652283 0.8267716765403748\n","Validation loss decreased (0.564181 --> 0.563967).  Saving model ...\n","264 0.541111409664154 0.8507042527198792 0.5639669299125671 0.8370786309242249 0.5878508687019348 0.8241469860076904\n","Validation loss decreased (0.563967 --> 0.563753).  Saving model ...\n","265 0.540897786617279 0.8507042527198792 0.5637530088424683 0.8370786309242249 0.5876829028129578 0.8241469860076904\n","Validation loss decreased (0.563753 --> 0.563540).  Saving model ...\n","266 0.5406854152679443 0.8507042527198792 0.5635401010513306 0.8370786309242249 0.5875158309936523 0.8241469860076904\n","Validation loss decreased (0.563540 --> 0.563328).  Saving model ...\n","267 0.540473997592926 0.8492957949638367 0.5633278489112854 0.8370786309242249 0.5873491168022156 0.8241469860076904\n","Validation loss decreased (0.563328 --> 0.563117).  Saving model ...\n","268 0.5402634143829346 0.8492957949638367 0.5631166696548462 0.8370786309242249 0.5871831178665161 0.8241469860076904\n","Validation loss decreased (0.563117 --> 0.562906).  Saving model ...\n","269 0.5400540828704834 0.8492957949638367 0.5629057884216309 0.8370786309242249 0.5870178937911987 0.8241469860076904\n","Validation loss decreased (0.562906 --> 0.562696).  Saving model ...\n","270 0.5398455262184143 0.8492957949638367 0.5626958012580872 0.8370786309242249 0.5868531465530396 0.8241469860076904\n","Validation loss decreased (0.562696 --> 0.562487).  Saving model ...\n","271 0.5396377444267273 0.8492957949638367 0.5624865293502808 0.8370786309242249 0.5866893529891968 0.8241469860076904\n","Validation loss decreased (0.562487 --> 0.562278).  Saving model ...\n","272 0.5394313335418701 0.8492957949638367 0.5622782111167908 0.8370786309242249 0.5865259766578674 0.8241469860076904\n","Validation loss decreased (0.562278 --> 0.562071).  Saving model ...\n","273 0.539225697517395 0.8492957949638367 0.5620705485343933 0.8370786309242249 0.5863634943962097 0.8241469860076904\n","Validation loss decreased (0.562071 --> 0.561864).  Saving model ...\n","274 0.5390210151672363 0.8492957949638367 0.5618635416030884 0.8370786309242249 0.5862013697624207 0.8241469860076904\n","Validation loss decreased (0.561864 --> 0.561657).  Saving model ...\n","275 0.5388169288635254 0.8492957949638367 0.5616573095321655 0.8370786309242249 0.5860400795936584 0.8241469860076904\n","Validation loss decreased (0.561657 --> 0.561452).  Saving model ...\n","276 0.5386144518852234 0.8507042527198792 0.5614518523216248 0.8370786309242249 0.5858793258666992 0.8241469860076904\n","Validation loss decreased (0.561452 --> 0.561247).  Saving model ...\n","277 0.5384124517440796 0.8507042527198792 0.5612470507621765 0.8370786309242249 0.585719108581543 0.8241469860076904\n","Validation loss decreased (0.561247 --> 0.561043).  Saving model ...\n","278 0.538211464881897 0.8507042527198792 0.5610429644584656 0.8370786309242249 0.5855596661567688 0.8241469860076904\n","Validation loss decreased (0.561043 --> 0.560840).  Saving model ...\n","279 0.538011372089386 0.8507042527198792 0.5608397722244263 0.8370786309242249 0.5854007601737976 0.8241469860076904\n","Validation loss decreased (0.560840 --> 0.560637).  Saving model ...\n","280 0.5378120541572571 0.8507042527198792 0.5606371164321899 0.8370786309242249 0.5852426290512085 0.8241469860076904\n","Validation loss decreased (0.560637 --> 0.560435).  Saving model ...\n","281 0.5376136302947998 0.8507042527198792 0.5604351758956909 0.8426966071128845 0.5850849747657776 0.8241469860076904\n","Validation loss decreased (0.560435 --> 0.560234).  Saving model ...\n","282 0.5374161601066589 0.8507042527198792 0.5602341294288635 0.8426966071128845 0.584928035736084 0.8241469860076904\n","Validation loss decreased (0.560234 --> 0.560034).  Saving model ...\n","283 0.537219762802124 0.8507042527198792 0.5600336194038391 0.8426966071128845 0.5847713947296143 0.8241469860076904\n","Validation loss decreased (0.560034 --> 0.559834).  Saving model ...\n","284 0.5370238423347473 0.8507042527198792 0.5598338842391968 0.8426966071128845 0.5846158266067505 0.8241469860076904\n","Validation loss decreased (0.559834 --> 0.559635).  Saving model ...\n","285 0.5368292331695557 0.8507042527198792 0.5596348643302917 0.8426966071128845 0.5844606757164001 0.8241469860076904\n","Validation loss decreased (0.559635 --> 0.559436).  Saving model ...\n","286 0.5366352200508118 0.8507042527198792 0.5594363212585449 0.8426966071128845 0.584306001663208 0.8241469860076904\n","Validation loss decreased (0.559436 --> 0.559239).  Saving model ...\n","287 0.5364423990249634 0.8507042527198792 0.5592387318611145 0.8426966071128845 0.5841521620750427 0.8267716765403748\n","Validation loss decreased (0.559239 --> 0.559042).  Saving model ...\n","288 0.5362495183944702 0.8507042527198792 0.5590417981147766 0.8426966071128845 0.5839985013008118 0.8267716765403748\n","Validation loss decreased (0.559042 --> 0.558845).  Saving model ...\n","289 0.5360585451126099 0.8507042527198792 0.5588453412055969 0.8426966071128845 0.5838459730148315 0.8267716765403748\n","Validation loss decreased (0.558845 --> 0.558650).  Saving model ...\n","290 0.535868227481842 0.8507042527198792 0.5586495995521545 0.8426966071128845 0.5836936831474304 0.8267716765403748\n","Validation loss decreased (0.558650 --> 0.558455).  Saving model ...\n","291 0.5356783270835876 0.8507042527198792 0.5584548115730286 0.8426966071128845 0.5835422873497009 0.8267716765403748\n","Validation loss decreased (0.558455 --> 0.558261).  Saving model ...\n","292 0.5354894995689392 0.8521126508712769 0.5582606196403503 0.8426966071128845 0.5833911299705505 0.8267716765403748\n","Validation loss decreased (0.558261 --> 0.558067).  Saving model ...\n","293 0.5353016257286072 0.8521126508712769 0.5580668449401855 0.8426966071128845 0.5832408666610718 0.8267716765403748\n","Validation loss decreased (0.558067 --> 0.557874).  Saving model ...\n","294 0.5351138710975647 0.8535211086273193 0.5578738451004028 0.8483145833015442 0.5830909609794617 0.8267716765403748\n","Validation loss decreased (0.557874 --> 0.557682).  Saving model ...\n","295 0.5349281430244446 0.8535211086273193 0.5576816201210022 0.8483145833015442 0.5829416513442993 0.8267716765403748\n","Validation loss decreased (0.557682 --> 0.557490).  Saving model ...\n","296 0.5347421765327454 0.8535211086273193 0.5574900507926941 0.8426966071128845 0.5827925205230713 0.8267716765403748\n","Validation loss decreased (0.557490 --> 0.557299).  Saving model ...\n","297 0.5345572829246521 0.8535211086273193 0.557299017906189 0.8426966071128845 0.5826444029808044 0.8293963074684143\n","Validation loss decreased (0.557299 --> 0.557109).  Saving model ...\n","298 0.5343732833862305 0.8535211086273193 0.5571088194847107 0.8426966071128845 0.5824968814849854 0.8293963074684143\n","Validation loss decreased (0.557109 --> 0.556919).  Saving model ...\n","299 0.5341900587081909 0.8535211086273193 0.5569193363189697 0.8426966071128845 0.5823500156402588 0.8293963074684143\n","Validation loss decreased (0.556919 --> 0.556730).  Saving model ...\n","300 0.534007728099823 0.8535211086273193 0.5567304491996765 0.8426966071128845 0.5822029709815979 0.8293963074684143\n","Validation loss decreased (0.556730 --> 0.556542).  Saving model ...\n","301 0.5338260531425476 0.8535211086273193 0.556541919708252 0.8426966071128845 0.5820573568344116 0.8293963074684143\n","Validation loss decreased (0.556542 --> 0.556354).  Saving model ...\n","302 0.5336452126502991 0.8535211086273193 0.5563539266586304 0.8426966071128845 0.5819116830825806 0.8293963074684143\n","Validation loss decreased (0.556354 --> 0.556167).  Saving model ...\n","303 0.5334648489952087 0.8535211086273193 0.5561671257019043 0.8426966071128845 0.5817668437957764 0.8293963074684143\n","Validation loss decreased (0.556167 --> 0.555981).  Saving model ...\n","304 0.5332854986190796 0.8535211086273193 0.5559809803962708 0.8426966071128845 0.581622302532196 0.8293963074684143\n","Validation loss decreased (0.555981 --> 0.555795).  Saving model ...\n","305 0.5331071615219116 0.8535211086273193 0.5557950735092163 0.8426966071128845 0.5814787745475769 0.8293963074684143\n","Validation loss decreased (0.555795 --> 0.555610).  Saving model ...\n","306 0.5329292416572571 0.8535211086273193 0.555609941482544 0.8426966071128845 0.5813353657722473 0.8293963074684143\n","Validation loss decreased (0.555610 --> 0.555425).  Saving model ...\n","307 0.5327524542808533 0.8549295663833618 0.5554252862930298 0.8483145833015442 0.5811927914619446 0.8293963074684143\n","Validation loss decreased (0.555425 --> 0.555241).  Saving model ...\n","308 0.5325758457183838 0.8549295663833618 0.5552414059638977 0.8483145833015442 0.5810502767562866 0.8293963074684143\n","Validation loss decreased (0.555241 --> 0.555058).  Saving model ...\n","309 0.5323998332023621 0.8549295663833618 0.5550581216812134 0.8483145833015442 0.5809087753295898 0.8293963074684143\n","Validation loss decreased (0.555058 --> 0.554875).  Saving model ...\n","310 0.5322255492210388 0.8549295663833618 0.5548754930496216 0.8483145833015442 0.5807676911354065 0.8293963074684143\n","Validation loss decreased (0.554875 --> 0.554693).  Saving model ...\n","311 0.5320514440536499 0.8549295663833618 0.5546934008598328 0.8483145833015442 0.5806270241737366 0.8320209980010986\n","Validation loss decreased (0.554693 --> 0.554512).  Saving model ...\n","312 0.5318777561187744 0.8549295663833618 0.554512083530426 0.8483145833015442 0.580486536026001 0.8320209980010986\n","Validation loss decreased (0.554512 --> 0.554331).  Saving model ...\n","313 0.5317050814628601 0.8549295663833618 0.5543311834335327 0.8483145833015442 0.5803471207618713 0.8320209980010986\n","Validation loss decreased (0.554331 --> 0.554151).  Saving model ...\n","314 0.5315326452255249 0.8549295663833618 0.5541511178016663 0.8483145833015442 0.5802079439163208 0.8320209980010986\n","Validation loss decreased (0.554151 --> 0.553971).  Saving model ...\n","315 0.5313612818717957 0.8549295663833618 0.5539714694023132 0.8483145833015442 0.5800693035125732 0.8320209980010986\n","Validation loss decreased (0.553971 --> 0.553792).  Saving model ...\n","316 0.5311912298202515 0.8549295663833618 0.5537922978401184 0.8483145833015442 0.5799309015274048 0.8320209980010986\n","Validation loss decreased (0.553792 --> 0.553614).  Saving model ...\n","317 0.5310211777687073 0.8549295663833618 0.5536139607429504 0.8483145833015442 0.5797934532165527 0.8320209980010986\n","Validation loss decreased (0.553614 --> 0.553436).  Saving model ...\n","318 0.5308518409729004 0.8549295663833618 0.5534363985061646 0.8483145833015442 0.5796563625335693 0.8320209980010986\n","Validation loss decreased (0.553436 --> 0.553259).  Saving model ...\n","319 0.5306834578514099 0.8549295663833618 0.5532587170600891 0.8483145833015442 0.5795196294784546 0.8320209980010986\n","Validation loss decreased (0.553259 --> 0.553082).  Saving model ...\n","320 0.5305159091949463 0.8549295663833618 0.5530824065208435 0.8483145833015442 0.579383373260498 0.8320209980010986\n","Validation loss decreased (0.553082 --> 0.552907).  Saving model ...\n","321 0.5303488969802856 0.8549295663833618 0.5529065132141113 0.8483145833015442 0.5792480111122131 0.8320209980010986\n","Validation loss decreased (0.552907 --> 0.552731).  Saving model ...\n","322 0.5301826596260071 0.8549295663833618 0.552730917930603 0.8483145833015442 0.5791128873825073 0.8320209980010986\n","Validation loss decreased (0.552731 --> 0.552556).  Saving model ...\n","323 0.5300161242485046 0.8549295663833618 0.552556037902832 0.8483145833015442 0.5789783596992493 0.8320209980010986\n","Validation loss decreased (0.552556 --> 0.552382).  Saving model ...\n","324 0.5298512578010559 0.8549295663833618 0.5523819923400879 0.8483145833015442 0.5788441896438599 0.834645688533783\n","Validation loss decreased (0.552382 --> 0.552208).  Saving model ...\n","325 0.5296871066093445 0.8549295663833618 0.5522083044052124 0.8483145833015442 0.5787103176116943 0.834645688533783\n","Validation loss decreased (0.552208 --> 0.552035).  Saving model ...\n","326 0.5295231342315674 0.8549295663833618 0.5520352721214294 0.8483145833015442 0.5785770416259766 0.834645688533783\n","Validation loss decreased (0.552035 --> 0.551863).  Saving model ...\n","327 0.5293602347373962 0.8549295663833618 0.5518626570701599 0.8483145833015442 0.5784446001052856 0.834645688533783\n","Validation loss decreased (0.551863 --> 0.551691).  Saving model ...\n","328 0.5291981101036072 0.8563380241394043 0.5516906380653381 0.8483145833015442 0.5783119797706604 0.834645688533783\n","Validation loss decreased (0.551691 --> 0.551519).  Saving model ...\n","329 0.529035747051239 0.8563380241394043 0.5515193939208984 0.8483145833015442 0.5781806111335754 0.834645688533783\n","Validation loss decreased (0.551519 --> 0.551349).  Saving model ...\n","330 0.5288744568824768 0.8577464818954468 0.5513485074043274 0.8483145833015442 0.5780488848686218 0.834645688533783\n","Validation loss decreased (0.551349 --> 0.551178).  Saving model ...\n","331 0.5287140607833862 0.8577464818954468 0.5511783957481384 0.8483145833015442 0.5779181718826294 0.834645688533783\n","Validation loss decreased (0.551178 --> 0.551009).  Saving model ...\n","332 0.5285542607307434 0.8577464818954468 0.5510087013244629 0.8483145833015442 0.5777877569198608 0.834645688533783\n","Validation loss decreased (0.551009 --> 0.550839).  Saving model ...\n","333 0.5283954739570618 0.8577464818954468 0.5508394837379456 0.8483145833015442 0.5776578783988953 0.834645688533783\n","Validation loss decreased (0.550839 --> 0.550671).  Saving model ...\n","334 0.5282365083694458 0.8577464818954468 0.5506710410118103 0.8483145833015442 0.5775282979011536 0.8372703194618225\n","Validation loss decreased (0.550671 --> 0.550503).  Saving model ...\n","335 0.5280783772468567 0.8577464818954468 0.5505030155181885 0.8483145833015442 0.5773995518684387 0.8372703194618225\n","Validation loss decreased (0.550503 --> 0.550336).  Saving model ...\n","336 0.5279209017753601 0.8577464818954468 0.550335705280304 0.8483145833015442 0.5772708058357239 0.8372703194618225\n","Validation loss decreased (0.550336 --> 0.550169).  Saving model ...\n","337 0.527764618396759 0.8577464818954468 0.5501686334609985 0.8483145833015442 0.5771425366401672 0.8372703194618225\n","Validation loss decreased (0.550169 --> 0.550002).  Saving model ...\n","338 0.5276084542274475 0.8591549396514893 0.5500022172927856 0.8483145833015442 0.577014684677124 0.8372703194618225\n","Validation loss decreased (0.550002 --> 0.549836).  Saving model ...\n","339 0.5274527668952942 0.8591549396514893 0.5498364567756653 0.8483145833015442 0.5768875479698181 0.8372703194618225\n","Validation loss decreased (0.549836 --> 0.549671).  Saving model ...\n","340 0.527297854423523 0.8591549396514893 0.549670934677124 0.8483145833015442 0.5767610669136047 0.8372703194618225\n","Validation loss decreased (0.549671 --> 0.549506).  Saving model ...\n","341 0.5271435379981995 0.8591549396514893 0.549506425857544 0.8483145833015442 0.5766345858573914 0.8372703194618225\n","Validation loss decreased (0.549506 --> 0.549342).  Saving model ...\n","342 0.5269898772239685 0.8591549396514893 0.5493420362472534 0.8539325594902039 0.5765089392662048 0.8372703194618225\n","Validation loss decreased (0.549342 --> 0.549179).  Saving model ...\n","343 0.526836633682251 0.8591549396514893 0.5491785407066345 0.8539325594902039 0.5763833522796631 0.8372703194618225\n","Validation loss decreased (0.549179 --> 0.549015).  Saving model ...\n","344 0.5266842246055603 0.8591549396514893 0.549015462398529 0.8539325594902039 0.5762583613395691 0.8372703194618225\n","Validation loss decreased (0.549015 --> 0.548853).  Saving model ...\n","345 0.5265321135520935 0.8591549396514893 0.548852801322937 0.8539325594902039 0.5761335492134094 0.834645688533783\n","Validation loss decreased (0.548853 --> 0.548691).  Saving model ...\n","346 0.5263810157775879 0.8591549396514893 0.548690915107727 0.8539325594902039 0.5760096311569214 0.834645688533783\n","Validation loss decreased (0.548691 --> 0.548529).  Saving model ...\n","347 0.5262301564216614 0.8591549396514893 0.5485292077064514 0.8539325594902039 0.575885534286499 0.8372703194618225\n","Validation loss decreased (0.548529 --> 0.548368).  Saving model ...\n","348 0.5260798335075378 0.8591549396514893 0.5483682155609131 0.8539325594902039 0.5757625699043274 0.8372703194618225\n","Validation loss decreased (0.548368 --> 0.548208).  Saving model ...\n","349 0.525929868221283 0.8577464818954468 0.5482078194618225 0.8539325594902039 0.5756394267082214 0.8372703194618225\n","Validation loss decreased (0.548208 --> 0.548048).  Saving model ...\n","350 0.5257810950279236 0.8577464818954468 0.5480477213859558 0.8539325594902039 0.5755172371864319 0.8372703194618225\n","Validation loss decreased (0.548048 --> 0.547888).  Saving model ...\n","351 0.5256326794624329 0.8577464818954468 0.5478883981704712 0.8539325594902039 0.5753952860832214 0.8372703194618225\n","Validation loss decreased (0.547888 --> 0.547729).  Saving model ...\n","352 0.5254847407341003 0.8577464818954468 0.5477294325828552 0.8539325594902039 0.5752735733985901 0.8372703194618225\n","Validation loss decreased (0.547729 --> 0.547571).  Saving model ...\n","353 0.5253373384475708 0.8577464818954468 0.547571063041687 0.8539325594902039 0.5751523971557617 0.8372703194618225\n","Validation loss decreased (0.547571 --> 0.547413).  Saving model ...\n","354 0.5251908302307129 0.8577464818954468 0.5474132299423218 0.8539325594902039 0.5750314593315125 0.8372703194618225\n","Validation loss decreased (0.547413 --> 0.547256).  Saving model ...\n","355 0.5250440835952759 0.8591549396514893 0.5472556352615356 0.8539325594902039 0.5749112367630005 0.8372703194618225\n","Validation loss decreased (0.547256 --> 0.547099).  Saving model ...\n","356 0.5248987674713135 0.8591549396514893 0.5470988154411316 0.8539325594902039 0.5747911930084229 0.8372703194618225\n","Validation loss decreased (0.547099 --> 0.546943).  Saving model ...\n","357 0.5247535109519958 0.8591549396514893 0.5469425916671753 0.8539325594902039 0.5746713280677795 0.8372703194618225\n","Validation loss decreased (0.546943 --> 0.546787).  Saving model ...\n","358 0.5246086716651917 0.8591549396514893 0.5467867255210876 0.8539325594902039 0.5745523571968079 0.8372703194618225\n","Validation loss decreased (0.546787 --> 0.546631).  Saving model ...\n","359 0.5244647264480591 0.8591549396514893 0.5466312170028687 0.8539325594902039 0.5744335651397705 0.8372703194618225\n","Validation loss decreased (0.546631 --> 0.546476).  Saving model ...\n","360 0.5243212580680847 0.8591549396514893 0.5464763045310974 0.8539325594902039 0.574315071105957 0.8372703194618225\n","Validation loss decreased (0.546476 --> 0.546322).  Saving model ...\n","361 0.5241783261299133 0.8591549396514893 0.5463221073150635 0.8539325594902039 0.5741974711418152 0.8372703194618225\n","Validation loss decreased (0.546322 --> 0.546168).  Saving model ...\n","362 0.5240358710289001 0.8591549396514893 0.5461680889129639 0.8539325594902039 0.574079692363739 0.8372703194618225\n","Validation loss decreased (0.546168 --> 0.546015).  Saving model ...\n","363 0.5238937735557556 0.8591549396514893 0.5460148453712463 0.8539325594902039 0.5739626288414001 0.8372703194618225\n","Validation loss decreased (0.546015 --> 0.545862).  Saving model ...\n","364 0.5237528085708618 0.8591549396514893 0.5458619594573975 0.8539325594902039 0.5738460421562195 0.8372703194618225\n","Validation loss decreased (0.545862 --> 0.545709).  Saving model ...\n","365 0.5236116051673889 0.8591549396514893 0.5457094311714172 0.8539325594902039 0.5737294554710388 0.8372703194618225\n","Validation loss decreased (0.545709 --> 0.545558).  Saving model ...\n","366 0.5234711766242981 0.8591549396514893 0.5455575585365295 0.8539325594902039 0.5736138224601746 0.8372703194618225\n","Validation loss decreased (0.545558 --> 0.545406).  Saving model ...\n","367 0.5233311653137207 0.8591549396514893 0.5454062223434448 0.8539325594902039 0.5734983086585999 0.8372703194618225\n","Validation loss decreased (0.545406 --> 0.545255).  Saving model ...\n","368 0.5231918692588806 0.8591549396514893 0.545255184173584 0.8539325594902039 0.5733824372291565 0.8372703194618225\n","Validation loss decreased (0.545255 --> 0.545105).  Saving model ...\n","369 0.5230532288551331 0.8605633974075317 0.5451048016548157 0.8539325594902039 0.5732679963111877 0.8372703194618225\n","Validation loss decreased (0.545105 --> 0.544955).  Saving model ...\n","370 0.5229147672653198 0.8605633974075317 0.5449548363685608 0.8539325594902039 0.5731533765792847 0.8372703194618225\n","Validation loss decreased (0.544955 --> 0.544805).  Saving model ...\n","371 0.5227769613265991 0.8605633974075317 0.5448052287101746 0.8539325594902039 0.5730393528938293 0.8372703194618225\n","Validation loss decreased (0.544805 --> 0.544656).  Saving model ...\n","372 0.5226399302482605 0.8605633974075317 0.5446562170982361 0.8539325594902039 0.5729258060455322 0.8372703194618225\n","Validation loss decreased (0.544656 --> 0.544508).  Saving model ...\n","373 0.5225029587745667 0.8605633974075317 0.5445075035095215 0.8539325594902039 0.5728124380111694 0.8372703194618225\n","Validation loss decreased (0.544508 --> 0.544360).  Saving model ...\n","374 0.5223666429519653 0.8605633974075317 0.5443596839904785 0.8539325594902039 0.5726996064186096 0.8372703194618225\n","Validation loss decreased (0.544360 --> 0.544212).  Saving model ...\n","375 0.522230863571167 0.8605633974075317 0.5442123413085938 0.8539325594902039 0.5725868940353394 0.8372703194618225\n","Validation loss decreased (0.544212 --> 0.544065).  Saving model ...\n","376 0.5220955610275269 0.8605633974075317 0.5440650582313538 0.8539325594902039 0.5724747180938721 0.8372703194618225\n","Validation loss decreased (0.544065 --> 0.543918).  Saving model ...\n","377 0.5219607353210449 0.8605633974075317 0.5439180731773376 0.8539325594902039 0.5723627805709839 0.8372703194618225\n","Validation loss decreased (0.543918 --> 0.543772).  Saving model ...\n","378 0.5218260288238525 0.8633802533149719 0.5437719821929932 0.8595505356788635 0.5722513794898987 0.8372703194618225\n","Validation loss decreased (0.543772 --> 0.543626).  Saving model ...\n","379 0.5216923356056213 0.8633802533149719 0.5436261892318726 0.8595505356788635 0.5721403360366821 0.8372703194618225\n","Validation loss decreased (0.543626 --> 0.543481).  Saving model ...\n","380 0.521558940410614 0.8633802533149719 0.5434808731079102 0.8595505356788635 0.5720298290252686 0.8372703194618225\n","Validation loss decreased (0.543481 --> 0.543336).  Saving model ...\n","381 0.521425724029541 0.8633802533149719 0.5433361530303955 0.8539325594902039 0.571919322013855 0.8372703194618225\n","Validation loss decreased (0.543336 --> 0.543192).  Saving model ...\n","382 0.521293580532074 0.8633802533149719 0.5431918501853943 0.8539325594902039 0.5718090534210205 0.8372703194618225\n","Validation loss decreased (0.543192 --> 0.543048).  Saving model ...\n","383 0.5211615562438965 0.8633802533149719 0.5430480241775513 0.8539325594902039 0.5716997981071472 0.8372703194618225\n","Validation loss decreased (0.543048 --> 0.542904).  Saving model ...\n","384 0.5210297107696533 0.8647887110710144 0.5429043769836426 0.8539325594902039 0.5715903639793396 0.8372703194618225\n","Validation loss decreased (0.542904 --> 0.542761).  Saving model ...\n","385 0.5208991765975952 0.8647887110710144 0.5427613854408264 0.8539325594902039 0.5714814066886902 0.8398950099945068\n","Validation loss decreased (0.542761 --> 0.542619).  Saving model ...\n","386 0.5207684636116028 0.8647887110710144 0.5426188111305237 0.8539325594902039 0.5713727474212646 0.8398950099945068\n","Validation loss decreased (0.542619 --> 0.542477).  Saving model ...\n","387 0.5206380486488342 0.8647887110710144 0.5424767136573792 0.8539325594902039 0.5712645053863525 0.8398950099945068\n","Validation loss decreased (0.542477 --> 0.542335).  Saving model ...\n","388 0.5205086469650269 0.8647887110710144 0.542335033416748 0.8539325594902039 0.5711565017700195 0.8398950099945068\n","Validation loss decreased (0.542335 --> 0.542194).  Saving model ...\n","389 0.5203794836997986 0.8647887110710144 0.5421937704086304 0.8539325594902039 0.5710492134094238 0.8398950099945068\n","Validation loss decreased (0.542194 --> 0.542053).  Saving model ...\n","390 0.520250678062439 0.8647887110710144 0.5420529246330261 0.8539325594902039 0.5709421038627625 0.8398950099945068\n","Validation loss decreased (0.542053 --> 0.541913).  Saving model ...\n","391 0.5201219916343689 0.8647887110710144 0.5419126749038696 0.8539325594902039 0.5708350539207458 0.8372703194618225\n","Validation loss decreased (0.541913 --> 0.541773).  Saving model ...\n","392 0.5199946165084839 0.8647887110710144 0.541772723197937 0.8539325594902039 0.5707283616065979 0.8372703194618225\n","Validation loss decreased (0.541773 --> 0.541633).  Saving model ...\n","393 0.5198671221733093 0.8647887110710144 0.5416333079338074 0.8539325594902039 0.5706225633621216 0.8372703194618225\n","Validation loss decreased (0.541633 --> 0.541494).  Saving model ...\n","394 0.5197399854660034 0.8647887110710144 0.5414942502975464 0.8539325594902039 0.57051682472229 0.8372703194618225\n","Validation loss decreased (0.541494 --> 0.541356).  Saving model ...\n","395 0.5196133852005005 0.8661971688270569 0.5413556694984436 0.8539325594902039 0.5704113841056824 0.8372703194618225\n","Validation loss decreased (0.541356 --> 0.541217).  Saving model ...\n","396 0.5194873213768005 0.8661971688270569 0.5412173271179199 0.8539325594902039 0.5703060626983643 0.8372703194618225\n","Validation loss decreased (0.541217 --> 0.541080).  Saving model ...\n","397 0.5193617343902588 0.8661971688270569 0.5410797595977783 0.8539325594902039 0.5702012181282043 0.8372703194618225\n","Validation loss decreased (0.541080 --> 0.540942).  Saving model ...\n","398 0.5192365646362305 0.8661971688270569 0.5409424304962158 0.8539325594902039 0.5700966715812683 0.8398950099945068\n","Validation loss decreased (0.540942 --> 0.540806).  Saving model ...\n","399 0.5191116333007812 0.8661971688270569 0.5408055782318115 0.8539325594902039 0.5699926614761353 0.8398950099945068\n","Validation loss decreased (0.540806 --> 0.540669).  Saving model ...\n","400 0.5189874768257141 0.8661971688270569 0.5406690835952759 0.8539325594902039 0.569888710975647 0.8398950099945068\n","Validation loss decreased (0.540669 --> 0.540533).  Saving model ...\n","401 0.5188631415367126 0.8676056265830994 0.5405330061912537 0.8539325594902039 0.5697851181030273 0.8398950099945068\n","Validation loss decreased (0.540533 --> 0.540397).  Saving model ...\n","402 0.5187397599220276 0.8676056265830994 0.5403972864151001 0.8539325594902039 0.5696820616722107 0.8398950099945068\n","Validation loss decreased (0.540397 --> 0.540262).  Saving model ...\n","403 0.5186166167259216 0.8676056265830994 0.5402622222900391 0.8539325594902039 0.5695792436599731 0.8398950099945068\n","Validation loss decreased (0.540262 --> 0.540127).  Saving model ...\n","404 0.5184938311576843 0.8676056265830994 0.5401273369789124 0.8539325594902039 0.5694769024848938 0.8398950099945068\n","Validation loss decreased (0.540127 --> 0.539993).  Saving model ...\n","405 0.5183717012405396 0.8676056265830994 0.5399929881095886 0.8539325594902039 0.5693750381469727 0.8398950099945068\n","Validation loss decreased (0.539993 --> 0.539859).  Saving model ...\n","406 0.5182496905326843 0.8676056265830994 0.5398589372634888 0.8539325594902039 0.5692728757858276 0.8398950099945068\n","Validation loss decreased (0.539859 --> 0.539725).  Saving model ...\n","407 0.5181284546852112 0.8676056265830994 0.5397254824638367 0.8595505356788635 0.5691715478897095 0.8398950099945068\n","Validation loss decreased (0.539725 --> 0.539593).  Saving model ...\n","408 0.5180071592330933 0.8676056265830994 0.5395925045013428 0.8595505356788635 0.5690701603889465 0.8398950099945068\n","Validation loss decreased (0.539593 --> 0.539460).  Saving model ...\n","409 0.517886757850647 0.8676056265830994 0.5394596457481384 0.8595505356788635 0.5689692497253418 0.8398950099945068\n","Validation loss decreased (0.539460 --> 0.539327).  Saving model ...\n","410 0.5177663564682007 0.8676056265830994 0.5393272042274475 0.8595505356788635 0.5688683986663818 0.8398950099945068\n","Validation loss decreased (0.539327 --> 0.539196).  Saving model ...\n","411 0.5176464915275574 0.8676056265830994 0.5391955971717834 0.8595505356788635 0.5687684416770935 0.8398950099945068\n","Validation loss decreased (0.539196 --> 0.539064).  Saving model ...\n","412 0.517527163028717 0.8676056265830994 0.5390640497207642 0.8595505356788635 0.5686684846878052 0.8398950099945068\n","Validation loss decreased (0.539064 --> 0.538933).  Saving model ...\n","413 0.517408013343811 0.8676056265830994 0.5389330983161926 0.8595505356788635 0.5685688257217407 0.8398950099945068\n","Validation loss decreased (0.538933 --> 0.538802).  Saving model ...\n","414 0.5172894597053528 0.8676056265830994 0.5388022065162659 0.8595505356788635 0.5684695243835449 0.8398950099945068\n","Validation loss decreased (0.538802 --> 0.538672).  Saving model ...\n","415 0.5171716213226318 0.8676056265830994 0.5386719703674316 0.8595505356788635 0.5683704614639282 0.8398950099945068\n","Validation loss decreased (0.538672 --> 0.538542).  Saving model ...\n","416 0.5170530080795288 0.8676056265830994 0.5385420918464661 0.8595505356788635 0.5682716965675354 0.8398950099945068\n","Validation loss decreased (0.538542 --> 0.538413).  Saving model ...\n","417 0.5169360041618347 0.8676056265830994 0.5384126305580139 0.8595505356788635 0.5681732296943665 0.8398950099945068\n","Validation loss decreased (0.538413 --> 0.538284).  Saving model ...\n","418 0.5168187022209167 0.8676056265830994 0.5382837057113647 0.8595505356788635 0.5680757164955139 0.8398950099945068\n","Validation loss decreased (0.538284 --> 0.538155).  Saving model ...\n","419 0.5167022347450256 0.8676056265830994 0.5381550192832947 0.8595505356788635 0.5679775476455688 0.8398950099945068\n","Validation loss decreased (0.538155 --> 0.538027).  Saving model ...\n","420 0.5165863633155823 0.8676056265830994 0.5380266308784485 0.8595505356788635 0.5678799152374268 0.8398950099945068\n","Validation loss decreased (0.538027 --> 0.537899).  Saving model ...\n","421 0.5164698958396912 0.8676056265830994 0.5378987193107605 0.8595505356788635 0.5677827000617981 0.8398950099945068\n","Validation loss decreased (0.537899 --> 0.537771).  Saving model ...\n","422 0.5163545608520508 0.8676056265830994 0.5377711057662964 0.8595505356788635 0.5676857233047485 0.8398950099945068\n","Validation loss decreased (0.537771 --> 0.537644).  Saving model ...\n","423 0.5162392854690552 0.8676056265830994 0.5376441478729248 0.8595505356788635 0.5675892233848572 0.8398950099945068\n","Validation loss decreased (0.537644 --> 0.537517).  Saving model ...\n","424 0.5161245465278625 0.8676056265830994 0.5375174880027771 0.8595505356788635 0.5674929022789001 0.8398950099945068\n","Validation loss decreased (0.537517 --> 0.537391).  Saving model ...\n","425 0.5160102844238281 0.8676056265830994 0.5373913049697876 0.8595505356788635 0.5673967003822327 0.8398950099945068\n","Validation loss decreased (0.537391 --> 0.537265).  Saving model ...\n","426 0.5158961415290833 0.8676056265830994 0.537264883518219 0.8595505356788635 0.5673010349273682 0.8398950099945068\n","Validation loss decreased (0.537265 --> 0.537140).  Saving model ...\n","427 0.5157821774482727 0.8676056265830994 0.5371395349502563 0.8595505356788635 0.5672059059143066 0.8398950099945068\n","Validation loss decreased (0.537140 --> 0.537015).  Saving model ...\n","428 0.5156689286231995 0.8676056265830994 0.5370145440101624 0.8595505356788635 0.5671106576919556 0.8398950099945068\n","Validation loss decreased (0.537015 --> 0.536890).  Saving model ...\n","429 0.5155560970306396 0.8676056265830994 0.5368895530700684 0.8595505356788635 0.5670158267021179 0.8372703194618225\n","Validation loss decreased (0.536890 --> 0.536765).  Saving model ...\n","430 0.5154436230659485 0.8676056265830994 0.5367650985717773 0.8595505356788635 0.5669212341308594 0.8372703194618225\n","Validation loss decreased (0.536765 --> 0.536641).  Saving model ...\n","431 0.5153310894966125 0.8676056265830994 0.5366407632827759 0.8595505356788635 0.5668268203735352 0.834645688533783\n","Validation loss decreased (0.536641 --> 0.536517).  Saving model ...\n","432 0.5152196884155273 0.8676056265830994 0.536517322063446 0.8595505356788635 0.5667330026626587 0.834645688533783\n","Validation loss decreased (0.536517 --> 0.536394).  Saving model ...\n","433 0.515108048915863 0.8676056265830994 0.5363940596580505 0.8595505356788635 0.5666393637657166 0.834645688533783\n","Validation loss decreased (0.536394 --> 0.536271).  Saving model ...\n","434 0.5149969458580017 0.8676056265830994 0.5362709164619446 0.8595505356788635 0.5665462017059326 0.834645688533783\n","Validation loss decreased (0.536271 --> 0.536148).  Saving model ...\n","435 0.514886200428009 0.8676056265830994 0.5361483097076416 0.8595505356788635 0.5664526224136353 0.834645688533783\n","Validation loss decreased (0.536148 --> 0.536026).  Saving model ...\n","436 0.5147759318351746 0.8676056265830994 0.536026120185852 0.8595505356788635 0.5663597583770752 0.834645688533783\n","Validation loss decreased (0.536026 --> 0.535904).  Saving model ...\n","437 0.5146656632423401 0.8676056265830994 0.5359042286872864 0.8595505356788635 0.566267728805542 0.834645688533783\n","Validation loss decreased (0.535904 --> 0.535783).  Saving model ...\n","438 0.5145560503005981 0.8676056265830994 0.5357828140258789 0.8595505356788635 0.5661750435829163 0.834645688533783\n","Validation loss decreased (0.535783 --> 0.535662).  Saving model ...\n","439 0.5144467353820801 0.8676056265830994 0.5356617569923401 0.8595505356788635 0.5660831332206726 0.834645688533783\n","Validation loss decreased (0.535662 --> 0.535541).  Saving model ...\n","440 0.5143375396728516 0.8676056265830994 0.5355411171913147 0.8595505356788635 0.5659914612770081 0.834645688533783\n","Validation loss decreased (0.535541 --> 0.535421).  Saving model ...\n","441 0.5142293572425842 0.8676056265830994 0.5354207754135132 0.8595505356788635 0.5658997893333435 0.834645688533783\n","Validation loss decreased (0.535421 --> 0.535301).  Saving model ...\n","442 0.5141207575798035 0.8690140843391418 0.535300612449646 0.8595505356788635 0.5658083558082581 0.834645688533783\n","Validation loss decreased (0.535301 --> 0.535181).  Saving model ...\n","443 0.5140126347541809 0.8690140843391418 0.5351809859275818 0.8595505356788635 0.5657179951667786 0.834645688533783\n","Validation loss decreased (0.535181 --> 0.535062).  Saving model ...\n","444 0.5139048099517822 0.8690140843391418 0.5350615978240967 0.8595505356788635 0.565626859664917 0.834645688533783\n","Validation loss decreased (0.535062 --> 0.534943).  Saving model ...\n","445 0.5137978792190552 0.8690140843391418 0.5349427461624146 0.8595505356788635 0.565536379814148 0.834645688533783\n","Validation loss decreased (0.534943 --> 0.534824).  Saving model ...\n","446 0.5136904120445251 0.8690140843391418 0.5348242521286011 0.8595505356788635 0.5654464960098267 0.834645688533783\n","Validation loss decreased (0.534824 --> 0.534706).  Saving model ...\n","447 0.5135840773582458 0.8690140843391418 0.5347058773040771 0.8595505356788635 0.5653566122055054 0.834645688533783\n","Validation loss decreased (0.534706 --> 0.534588).  Saving model ...\n","448 0.5134777426719666 0.8690140843391418 0.5345878601074219 0.8595505356788635 0.5652670860290527 0.834645688533783\n","Validation loss decreased (0.534588 --> 0.534470).  Saving model ...\n","449 0.5133716464042664 0.8690140843391418 0.5344704389572144 0.8595505356788635 0.5651777982711792 0.834645688533783\n","Validation loss decreased (0.534470 --> 0.534353).  Saving model ...\n","450 0.5132659077644348 0.8690140843391418 0.5343531370162964 0.8595505356788635 0.5650887489318848 0.834645688533783\n","Validation loss decreased (0.534353 --> 0.534236).  Saving model ...\n","451 0.5131613612174988 0.8690140843391418 0.5342364311218262 0.8595505356788635 0.5649999976158142 0.834645688533783\n","Validation loss decreased (0.534236 --> 0.534120).  Saving model ...\n","452 0.5130557417869568 0.8676056265830994 0.5341199636459351 0.8595505356788635 0.5649116039276123 0.834645688533783\n","Validation loss decreased (0.534120 --> 0.534004).  Saving model ...\n","453 0.5129513144493103 0.8676056265830994 0.5340036153793335 0.8595505356788635 0.5648231506347656 0.834645688533783\n","Validation loss decreased (0.534004 --> 0.533888).  Saving model ...\n","454 0.5128470659255981 0.8676056265830994 0.533888041973114 0.8595505356788635 0.5647351145744324 0.834645688533783\n","Validation loss decreased (0.533888 --> 0.533773).  Saving model ...\n","455 0.5127429366111755 0.8676056265830994 0.5337725281715393 0.8595505356788635 0.5646477341651917 0.834645688533783\n","Validation loss decreased (0.533773 --> 0.533657).  Saving model ...\n","456 0.5126386880874634 0.8676056265830994 0.5336573719978333 0.8595505356788635 0.5645598769187927 0.834645688533783\n","Validation loss decreased (0.533657 --> 0.533543).  Saving model ...\n","457 0.5125352740287781 0.8676056265830994 0.5335427522659302 0.8595505356788635 0.5644729733467102 0.834645688533783\n","Validation loss decreased (0.533543 --> 0.533428).  Saving model ...\n","458 0.5124322772026062 0.8676056265830994 0.5334283113479614 0.8595505356788635 0.5643858313560486 0.834645688533783\n","Validation loss decreased (0.533428 --> 0.533314).  Saving model ...\n","459 0.5123294591903687 0.8676056265830994 0.5333143472671509 0.8595505356788635 0.5642991662025452 0.834645688533783\n","Validation loss decreased (0.533314 --> 0.533200).  Saving model ...\n","460 0.5122275352478027 0.8690140843391418 0.5332004427909851 0.8595505356788635 0.5642126202583313 0.834645688533783\n","Validation loss decreased (0.533200 --> 0.533087).  Saving model ...\n","461 0.5121250152587891 0.8690140843391418 0.533086895942688 0.8595505356788635 0.5641262531280518 0.834645688533783\n","Validation loss decreased (0.533087 --> 0.532974).  Saving model ...\n","462 0.5120233297348022 0.8690140843391418 0.532974123954773 0.8651685118675232 0.5640401244163513 0.834645688533783\n","Validation loss decreased (0.532974 --> 0.532861).  Saving model ...\n","463 0.5119214653968811 0.8690140843391418 0.5328611731529236 0.8651685118675232 0.5639544725418091 0.834645688533783\n","Validation loss decreased (0.532861 --> 0.532749).  Saving model ...\n","464 0.5118203163146973 0.8690140843391418 0.5327488780021667 0.8651685118675232 0.5638691782951355 0.834645688533783\n","Validation loss decreased (0.532749 --> 0.532637).  Saving model ...\n","465 0.5117196440696716 0.8690140843391418 0.532636821269989 0.8651685118675232 0.5637843608856201 0.834645688533783\n","Validation loss decreased (0.532637 --> 0.532525).  Saving model ...\n","466 0.5116192102432251 0.8704225420951843 0.5325251817703247 0.8651685118675232 0.5636990070343018 0.834645688533783\n","Validation loss decreased (0.532525 --> 0.532414).  Saving model ...\n","467 0.5115182399749756 0.8704225420951843 0.5324139595031738 0.8651685118675232 0.5636144876480103 0.834645688533783\n","Validation loss decreased (0.532414 --> 0.532303).  Saving model ...\n","468 0.5114185810089111 0.8704225420951843 0.5323025584220886 0.8651685118675232 0.5635297894477844 0.834645688533783\n","Validation loss decreased (0.532303 --> 0.532192).  Saving model ...\n","469 0.5113189220428467 0.8704225420951843 0.5321916937828064 0.8651685118675232 0.563445508480072 0.834645688533783\n","Validation loss decreased (0.532192 --> 0.532081).  Saving model ...\n","470 0.5112194418907166 0.8704225420951843 0.5320814251899719 0.8651685118675232 0.5633612275123596 0.834645688533783\n","Validation loss decreased (0.532081 --> 0.531971).  Saving model ...\n","471 0.5111204385757446 0.8704225420951843 0.5319712162017822 0.8651685118675232 0.563277542591095 0.834645688533783\n","Validation loss decreased (0.531971 --> 0.531861).  Saving model ...\n","472 0.5110216736793518 0.8704225420951843 0.5318613052368164 0.8651685118675232 0.5631940364837646 0.834645688533783\n","Validation loss decreased (0.531861 --> 0.531752).  Saving model ...\n","473 0.510922908782959 0.8704225420951843 0.5317520499229431 0.8651685118675232 0.5631107091903687 0.834645688533783\n","Validation loss decreased (0.531752 --> 0.531643).  Saving model ...\n","474 0.5108248591423035 0.8704225420951843 0.531642735004425 0.8651685118675232 0.5630279779434204 0.834645688533783\n","Validation loss decreased (0.531643 --> 0.531534).  Saving model ...\n","475 0.5107267498970032 0.8704225420951843 0.53153395652771 0.8651685118675232 0.5629448294639587 0.8398950099945068\n","Validation loss decreased (0.531534 --> 0.531426).  Saving model ...\n","476 0.5106292366981506 0.8704225420951843 0.5314255952835083 0.8651685118675232 0.5628623962402344 0.8398950099945068\n","Validation loss decreased (0.531426 --> 0.531317).  Saving model ...\n","477 0.5105318427085876 0.8704225420951843 0.5313172340393066 0.8651685118675232 0.56277996301651 0.8398950099945068\n","Validation loss decreased (0.531317 --> 0.531209).  Saving model ...\n","478 0.5104346871376038 0.8704225420951843 0.5312092900276184 0.8651685118675232 0.5626974105834961 0.8398950099945068\n","Validation loss decreased (0.531209 --> 0.531102).  Saving model ...\n","479 0.5103380680084229 0.8704225420951843 0.5311015844345093 0.8651685118675232 0.5626159310340881 0.8398950099945068\n","Validation loss decreased (0.531102 --> 0.530994).  Saving model ...\n","480 0.5102414488792419 0.8704225420951843 0.5309944748878479 0.8651685118675232 0.5625340938568115 0.8398950099945068\n","Validation loss decreased (0.530994 --> 0.530888).  Saving model ...\n","481 0.510145366191864 0.8704225420951843 0.5308875441551208 0.8651685118675232 0.5624525547027588 0.8398950099945068\n","Validation loss decreased (0.530888 --> 0.530781).  Saving model ...\n","482 0.5100491642951965 0.8704225420951843 0.5307808518409729 0.8651685118675232 0.5623717904090881 0.8398950099945068\n","Validation loss decreased (0.530781 --> 0.530675).  Saving model ...\n","483 0.5099536776542664 0.8704225420951843 0.5306747555732727 0.8651685118675232 0.5622907876968384 0.8398950099945068\n","Validation loss decreased (0.530675 --> 0.530568).  Saving model ...\n","484 0.509858250617981 0.8704225420951843 0.5305684804916382 0.8651685118675232 0.562209963798523 0.8398950099945068\n","Validation loss decreased (0.530568 --> 0.530463).  Saving model ...\n","485 0.5097631812095642 0.8704225420951843 0.5304628014564514 0.8707864880561829 0.5621294379234314 0.8398950099945068\n","Validation loss decreased (0.530463 --> 0.530357).  Saving model ...\n","486 0.5096683502197266 0.8704225420951843 0.5303574204444885 0.8707864880561829 0.5620492100715637 0.8398950099945068\n","Validation loss decreased (0.530357 --> 0.530253).  Saving model ...\n","487 0.5095736980438232 0.8704225420951843 0.5302525162696838 0.8707864880561829 0.5619692802429199 0.8398950099945068\n","Validation loss decreased (0.530253 --> 0.530147).  Saving model ...\n","488 0.5094793438911438 0.8704225420951843 0.5301474928855896 0.8707864880561829 0.5618892312049866 0.8398950099945068\n","Validation loss decreased (0.530147 --> 0.530043).  Saving model ...\n","489 0.509385347366333 0.8704225420951843 0.5300428867340088 0.8707864880561829 0.561809778213501 0.8398950099945068\n","Validation loss decreased (0.530043 --> 0.529939).  Saving model ...\n","490 0.5092918276786804 0.8704225420951843 0.5299389362335205 0.8707864880561829 0.5617299675941467 0.8398950099945068\n","Validation loss decreased (0.529939 --> 0.529835).  Saving model ...\n","491 0.5091977715492249 0.8704225420951843 0.5298349261283875 0.8707864880561829 0.561651349067688 0.8398950099945068\n","Validation loss decreased (0.529835 --> 0.529731).  Saving model ...\n","492 0.5091047286987305 0.8704225420951843 0.5297313928604126 0.8707864880561829 0.5615720748901367 0.8398950099945068\n","Validation loss decreased (0.529731 --> 0.529628).  Saving model ...\n","493 0.5090116858482361 0.8704225420951843 0.5296280384063721 0.8707864880561829 0.5614932775497437 0.8398950099945068\n","Validation loss decreased (0.529628 --> 0.529525).  Saving model ...\n","494 0.5089194774627686 0.8704225420951843 0.5295251607894897 0.8707864880561829 0.5614147186279297 0.8398950099945068\n","Validation loss decreased (0.529525 --> 0.529422).  Saving model ...\n","495 0.5088267922401428 0.8704225420951843 0.5294224619865417 0.8707864880561829 0.5613366961479187 0.8398950099945068\n","Validation loss decreased (0.529422 --> 0.529320).  Saving model ...\n","496 0.5087345838546753 0.8704225420951843 0.5293199419975281 0.8707864880561829 0.5612584948539734 0.8398950099945068\n","Validation loss decreased (0.529320 --> 0.529218).  Saving model ...\n","497 0.5086427927017212 0.8704225420951843 0.5292181372642517 0.8707864880561829 0.5611805319786072 0.8398950099945068\n","Validation loss decreased (0.529218 --> 0.529116).  Saving model ...\n","498 0.5085510015487671 0.8704225420951843 0.5291159749031067 0.8707864880561829 0.5611029863357544 0.8398950099945068\n","Validation loss decreased (0.529116 --> 0.529014).  Saving model ...\n","499 0.5084595680236816 0.8704225420951843 0.5290143489837646 0.8707864880561829 0.5610254406929016 0.8398950099945068\n","Validation loss decreased (0.529014 --> 0.528913).  Saving model ...\n","500 0.5083689093589783 0.8704225420951843 0.5289130210876465 0.8707864880561829 0.5609482526779175 0.8398950099945068\n","Validation loss decreased (0.528913 --> 0.528812).  Saving model ...\n","501 0.5082778334617615 0.8704225420951843 0.5288124084472656 0.8707864880561829 0.5608707666397095 0.8398950099945068\n","Validation loss decreased (0.528812 --> 0.528712).  Saving model ...\n","502 0.5081871747970581 0.8704225420951843 0.5287116765975952 0.8707864880561829 0.5607942938804626 0.8398950099945068\n","Validation loss decreased (0.528712 --> 0.528611).  Saving model ...\n","503 0.5080966949462891 0.8704225420951843 0.5286113619804382 0.8707864880561829 0.5607179403305054 0.8398950099945068\n","Validation loss decreased (0.528611 --> 0.528511).  Saving model ...\n","504 0.5080069303512573 0.8704225420951843 0.5285112857818604 0.8707864880561829 0.560641348361969 0.8398950099945068\n","Validation loss decreased (0.528511 --> 0.528411).  Saving model ...\n","505 0.507917046546936 0.8690140843391418 0.5284112691879272 0.8707864880561829 0.560565173625946 0.8398950099945068\n","Validation loss decreased (0.528411 --> 0.528312).  Saving model ...\n","506 0.5078271627426147 0.8704225420951843 0.5283119678497314 0.8707864880561829 0.5604891180992126 0.8398950099945068\n","Validation loss decreased (0.528312 --> 0.528213).  Saving model ...\n","507 0.5077379941940308 0.8704225420951843 0.5282125473022461 0.8707864880561829 0.5604135394096375 0.8398950099945068\n","Validation loss decreased (0.528213 --> 0.528114).  Saving model ...\n","508 0.5076488852500916 0.8704225420951843 0.528113603591919 0.8707864880561829 0.560338020324707 0.8398950099945068\n","Validation loss decreased (0.528114 --> 0.528015).  Saving model ...\n","509 0.507560133934021 0.8704225420951843 0.5280148983001709 0.8707864880561829 0.5602623224258423 0.8398950099945068\n","Validation loss decreased (0.528015 --> 0.527917).  Saving model ...\n","510 0.50747150182724 0.8704225420951843 0.527916669845581 0.8707864880561829 0.5601872801780701 0.8398950099945068\n","Validation loss decreased (0.527917 --> 0.527819).  Saving model ...\n","511 0.5073831081390381 0.8704225420951843 0.5278185606002808 0.8707864880561829 0.5601122379302979 0.8398950099945068\n","Validation loss decreased (0.527819 --> 0.527720).  Saving model ...\n","512 0.5072950124740601 0.8718309998512268 0.5277204513549805 0.8707864880561829 0.5600376725196838 0.8398950099945068\n","Validation loss decreased (0.527720 --> 0.527623).  Saving model ...\n","513 0.5072072148323059 0.8718309998512268 0.5276229977607727 0.8707864880561829 0.5599632263183594 0.8398950099945068\n","Validation loss decreased (0.527623 --> 0.527526).  Saving model ...\n","514 0.5071196556091309 0.8718309998512268 0.5275258421897888 0.8707864880561829 0.5598887801170349 0.8398950099945068\n","Validation loss decreased (0.527526 --> 0.527429).  Saving model ...\n","515 0.5070325136184692 0.8718309998512268 0.527428925037384 0.8707864880561829 0.5598145127296448 0.8398950099945068\n","Validation loss decreased (0.527429 --> 0.527332).  Saving model ...\n","516 0.5069445967674255 0.8718309998512268 0.5273317098617554 0.8707864880561829 0.5597406625747681 0.8398950099945068\n","Validation loss decreased (0.527332 --> 0.527236).  Saving model ...\n","517 0.5068580508232117 0.8718309998512268 0.5272355079650879 0.8707864880561829 0.5596667528152466 0.8398950099945068\n","Validation loss decreased (0.527236 --> 0.527139).  Saving model ...\n","518 0.5067712068557739 0.8718309998512268 0.5271392464637756 0.8707864880561829 0.5595932602882385 0.8398950099945068\n","Validation loss decreased (0.527139 --> 0.527043).  Saving model ...\n","519 0.5066846609115601 0.8718309998512268 0.527043342590332 0.8707864880561829 0.5595199465751648 0.8398950099945068\n","Validation loss decreased (0.527043 --> 0.526948).  Saving model ...\n","520 0.5065991282463074 0.8718309998512268 0.5269476771354675 0.8707864880561829 0.5594465136528015 0.8398950099945068\n","Validation loss decreased (0.526948 --> 0.526853).  Saving model ...\n","521 0.5065125823020935 0.8718309998512268 0.526852548122406 0.8707864880561829 0.5593738555908203 0.8398950099945068\n","Validation loss decreased (0.526853 --> 0.526757).  Saving model ...\n","522 0.5064269304275513 0.8718309998512268 0.5267571210861206 0.8707864880561829 0.5593006610870361 0.8398950099945068\n","Validation loss decreased (0.526757 --> 0.526662).  Saving model ...\n","523 0.5063415169715881 0.8718309998512268 0.5266622304916382 0.8707864880561829 0.5592283606529236 0.8398950099945068\n","Validation loss decreased (0.526662 --> 0.526568).  Saving model ...\n","524 0.5062559247016907 0.8718309998512268 0.5265676975250244 0.8707864880561829 0.559156060218811 0.8398950099945068\n","Validation loss decreased (0.526568 --> 0.526473).  Saving model ...\n","525 0.506170928478241 0.8718309998512268 0.526473343372345 0.8707864880561829 0.5590837597846985 0.8398950099945068\n","Validation loss decreased (0.526473 --> 0.526379).  Saving model ...\n","526 0.5060862898826599 0.8718309998512268 0.5263791680335999 0.8707864880561829 0.5590115785598755 0.8398950099945068\n","Validation loss decreased (0.526379 --> 0.526285).  Saving model ...\n","527 0.506001353263855 0.8718309998512268 0.5262853503227234 0.8707864880561829 0.5589398741722107 0.8398950099945068\n","Validation loss decreased (0.526285 --> 0.526192).  Saving model ...\n","528 0.5059172511100769 0.8718309998512268 0.5261918902397156 0.8707864880561829 0.5588684678077698 0.8398950099945068\n","Validation loss decreased (0.526192 --> 0.526099).  Saving model ...\n","529 0.5058332681655884 0.8718309998512268 0.5260986089706421 0.8707864880561829 0.5587968826293945 0.8398950099945068\n","Validation loss decreased (0.526099 --> 0.526006).  Saving model ...\n","530 0.5057490468025208 0.8704225420951843 0.5260055065155029 0.8707864880561829 0.5587254166603088 0.8398950099945068\n","Validation loss decreased (0.526006 --> 0.525913).  Saving model ...\n","531 0.5056654810905457 0.8704225420951843 0.5259130001068115 0.8707864880561829 0.5586546063423157 0.8398950099945068\n","Validation loss decreased (0.525913 --> 0.525820).  Saving model ...\n","532 0.5055819749832153 0.8704225420951843 0.5258204340934753 0.8707864880561829 0.5585837960243225 0.8398950099945068\n","Validation loss decreased (0.525820 --> 0.525728).  Saving model ...\n","533 0.5054990649223328 0.8704225420951843 0.5257279276847839 0.8707864880561829 0.5585130453109741 0.8398950099945068\n","Validation loss decreased (0.525728 --> 0.525636).  Saving model ...\n","534 0.5054157972335815 0.8704225420951843 0.5256361961364746 0.8707864880561829 0.558442234992981 0.8398950099945068\n","Validation loss decreased (0.525636 --> 0.525544).  Saving model ...\n","535 0.5053331255912781 0.8704225420951843 0.5255444049835205 0.8707864880561829 0.5583723783493042 0.8398950099945068\n","Validation loss decreased (0.525544 --> 0.525453).  Saving model ...\n","536 0.5052505135536194 0.8704225420951843 0.5254529714584351 0.8707864880561829 0.558302104473114 0.8398950099945068\n","Validation loss decreased (0.525453 --> 0.525362).  Saving model ...\n","537 0.5051679611206055 0.8704225420951843 0.5253616571426392 0.8707864880561829 0.5582318902015686 0.8398950099945068\n","Validation loss decreased (0.525362 --> 0.525271).  Saving model ...\n","538 0.5050856471061707 0.8704225420951843 0.525270938873291 0.8707864880561829 0.5581621527671814 0.8398950099945068\n","Validation loss decreased (0.525271 --> 0.525180).  Saving model ...\n","539 0.5050036907196045 0.8704225420951843 0.5251800417900085 0.8707864880561829 0.5580926537513733 0.8398950099945068\n","Validation loss decreased (0.525180 --> 0.525089).  Saving model ...\n","540 0.5049223303794861 0.8704225420951843 0.52508944272995 0.8707864880561829 0.5580229163169861 0.8398950099945068\n","Validation loss decreased (0.525089 --> 0.524999).  Saving model ...\n","541 0.5048403739929199 0.8704225420951843 0.5249993801116943 0.8707864880561829 0.5579541325569153 0.8398950099945068\n","Validation loss decreased (0.524999 --> 0.524909).  Saving model ...\n","542 0.5047592520713806 0.8704225420951843 0.5249094367027283 0.8707864880561829 0.5578851103782654 0.8398950099945068\n","Validation loss decreased (0.524909 --> 0.524819).  Saving model ...\n","543 0.5046785473823547 0.8704225420951843 0.5248194336891174 0.8707864880561829 0.5578158497810364 0.8398950099945068\n","Validation loss decreased (0.524819 --> 0.524730).  Saving model ...\n","544 0.504597544670105 0.8718309998512268 0.5247302055358887 0.8707864880561829 0.5577471852302551 0.8398950099945068\n","Validation loss decreased (0.524730 --> 0.524641).  Saving model ...\n","545 0.5045168399810791 0.8718309998512268 0.5246408581733704 0.8707864880561829 0.557678759098053 0.8398950099945068\n","Validation loss decreased (0.524641 --> 0.524552).  Saving model ...\n","546 0.5044366121292114 0.8732394576072693 0.5245519876480103 0.8707864880561829 0.5576105117797852 0.8398950099945068\n","Validation loss decreased (0.524552 --> 0.524463).  Saving model ...\n","547 0.5043559670448303 0.8732394576072693 0.5244633555412292 0.8707864880561829 0.5575422048568726 0.8398950099945068\n","Validation loss decreased (0.524463 --> 0.524375).  Saving model ...\n","548 0.504275918006897 0.8732394576072693 0.5243749022483826 0.8707864880561829 0.5574744343757629 0.8398950099945068\n","Validation loss decreased (0.524375 --> 0.524286).  Saving model ...\n","549 0.5041964650154114 0.8732394576072693 0.5242863297462463 0.8707864880561829 0.5574063062667847 0.8398950099945068\n","Validation loss decreased (0.524286 --> 0.524198).  Saving model ...\n","550 0.5041165351867676 0.8732394576072693 0.5241983532905579 0.8707864880561829 0.5573389530181885 0.8398950099945068\n","Validation loss decreased (0.524198 --> 0.524111).  Saving model ...\n","551 0.5040372610092163 0.8732394576072693 0.5241105556488037 0.8707864880561829 0.5572710037231445 0.8398950099945068\n","Validation loss decreased (0.524111 --> 0.524023).  Saving model ...\n","552 0.5039581656455994 0.8732394576072693 0.5240229964256287 0.8707864880561829 0.5572036504745483 0.8398950099945068\n","Validation loss decreased (0.524023 --> 0.523936).  Saving model ...\n","553 0.5038789510726929 0.8732394576072693 0.523935854434967 0.8707864880561829 0.5571366548538208 0.8398950099945068\n","Validation loss decreased (0.523936 --> 0.523849).  Saving model ...\n","554 0.5037998557090759 0.8732394576072693 0.5238486528396606 0.8707864880561829 0.5570695996284485 0.8398950099945068\n","Validation loss decreased (0.523849 --> 0.523762).  Saving model ...\n","555 0.5037211179733276 0.8732394576072693 0.5237618088722229 0.8707864880561829 0.5570030808448792 0.8398950099945068\n","Validation loss decreased (0.523762 --> 0.523675).  Saving model ...\n","556 0.5036429166793823 0.8732394576072693 0.5236753225326538 0.8707864880561829 0.5569359660148621 0.8398950099945068\n","Validation loss decreased (0.523675 --> 0.523589).  Saving model ...\n","557 0.5035646557807922 0.8732394576072693 0.5235889554023743 0.8707864880561829 0.5568698644638062 0.8398950099945068\n","Validation loss decreased (0.523589 --> 0.523503).  Saving model ...\n","558 0.5034869909286499 0.8732394576072693 0.5235028266906738 0.8707864880561829 0.5568034052848816 0.8398950099945068\n","Validation loss decreased (0.523503 --> 0.523417).  Saving model ...\n","559 0.5034091472625732 0.8732394576072693 0.5234169363975525 0.8707864880561829 0.5567371845245361 0.8398950099945068\n","Validation loss decreased (0.523417 --> 0.523331).  Saving model ...\n","560 0.5033315420150757 0.8732394576072693 0.5233311653137207 0.8707864880561829 0.5566712617874146 0.8398950099945068\n","Validation loss decreased (0.523331 --> 0.523246).  Saving model ...\n","561 0.5032539963722229 0.8732394576072693 0.5232458710670471 0.8707864880561829 0.5566053986549377 0.8398950099945068\n","Validation loss decreased (0.523246 --> 0.523161).  Saving model ...\n","562 0.5031770467758179 0.8732394576072693 0.5231607556343079 0.8707864880561829 0.55653977394104 0.8398950099945068\n","Validation loss decreased (0.523161 --> 0.523076).  Saving model ...\n","563 0.5030995607376099 0.8732394576072693 0.523075520992279 0.8707864880561829 0.5564742088317871 0.8398950099945068\n","Validation loss decreased (0.523076 --> 0.522991).  Saving model ...\n","564 0.5030225515365601 0.8732394576072693 0.5229909420013428 0.8707864880561829 0.5564091801643372 0.8398950099945068\n","Validation loss decreased (0.522991 --> 0.522906).  Saving model ...\n","565 0.5029463768005371 0.8746479153633118 0.5229064226150513 0.8707864880561829 0.5563437342643738 0.8398950099945068\n","Validation loss decreased (0.522906 --> 0.522822).  Saving model ...\n","566 0.5028696656227112 0.8746479153633118 0.5228222012519836 0.8707864880561829 0.5562788248062134 0.8398950099945068\n","Validation loss decreased (0.522822 --> 0.522738).  Saving model ...\n","567 0.5027938485145569 0.8746479153633118 0.5227379202842712 0.8707864880561829 0.5562141537666321 0.8398950099945068\n","Validation loss decreased (0.522738 --> 0.522654).  Saving model ...\n","568 0.5027173757553101 0.8746479153633118 0.5226541757583618 0.8707864880561829 0.5561492443084717 0.8398950099945068\n","Validation loss decreased (0.522654 --> 0.522571).  Saving model ...\n","569 0.5026415586471558 0.8746479153633118 0.5225706696510315 0.8707864880561829 0.5560849905014038 0.8398950099945068\n","Validation loss decreased (0.522571 --> 0.522487).  Saving model ...\n","570 0.5025657415390015 0.8746479153633118 0.5224871039390564 0.8707864880561829 0.5560202598571777 0.8398950099945068\n","Validation loss decreased (0.522487 --> 0.522404).  Saving model ...\n","571 0.5024903416633606 0.8746479153633118 0.5224042534828186 0.8707864880561829 0.555956244468689 0.8398950099945068\n","Validation loss decreased (0.522404 --> 0.522321).  Saving model ...\n","572 0.5024150013923645 0.8746479153633118 0.5223211646080017 0.8707864880561829 0.5558923482894897 0.8398950099945068\n","Validation loss decreased (0.522321 --> 0.522239).  Saving model ...\n","573 0.502339780330658 0.8746479153633118 0.522238552570343 0.8707864880561829 0.5558283925056458 0.8398950099945068\n","Validation loss decreased (0.522239 --> 0.522156).  Saving model ...\n","574 0.5022649168968201 0.8746479153633118 0.5221560597419739 0.8707864880561829 0.5557641386985779 0.8398950099945068\n","Validation loss decreased (0.522156 --> 0.522074).  Saving model ...\n","575 0.5021899342536926 0.8746479153633118 0.5220738053321838 0.8707864880561829 0.555700957775116 0.8398950099945068\n","Validation loss decreased (0.522074 --> 0.521992).  Saving model ...\n","576 0.5021154880523682 0.8746479153633118 0.5219916701316833 0.8707864880561829 0.5556374192237854 0.8398950099945068\n","Validation loss decreased (0.521992 --> 0.521910).  Saving model ...\n","577 0.5020411610603333 0.8746479153633118 0.5219095945358276 0.8707864880561829 0.5555744767189026 0.8398950099945068\n","Validation loss decreased (0.521910 --> 0.521828).  Saving model ...\n","578 0.5019667148590088 0.8746479153633118 0.5218284130096436 0.8707864880561829 0.555510938167572 0.8398950099945068\n","Validation loss decreased (0.521828 --> 0.521747).  Saving model ...\n","579 0.5018928050994873 0.8746479153633118 0.5217466354370117 0.8707864880561829 0.5554478764533997 0.8398950099945068\n","Validation loss decreased (0.521747 --> 0.521666).  Saving model ...\n","580 0.5018192529678345 0.8746479153633118 0.5216655135154724 0.8707864880561829 0.5553850531578064 0.8398950099945068\n","Validation loss decreased (0.521666 --> 0.521585).  Saving model ...\n","581 0.5017452836036682 0.8746479153633118 0.521584689617157 0.8707864880561829 0.5553228259086609 0.8398950099945068\n","Validation loss decreased (0.521585 --> 0.521504).  Saving model ...\n","582 0.5016714930534363 0.8746479153633118 0.5215039253234863 0.8707864880561829 0.5552602410316467 0.8398950099945068\n","Validation loss decreased (0.521504 --> 0.521424).  Saving model ...\n","583 0.501598596572876 0.8746479153633118 0.5214235782623291 0.8707864880561829 0.5551979541778564 0.8398950099945068\n","Validation loss decreased (0.521424 --> 0.521343).  Saving model ...\n","584 0.5015254020690918 0.8746479153633118 0.5213430523872375 0.8707864880561829 0.5551358461380005 0.8398950099945068\n","Validation loss decreased (0.521343 --> 0.521263).  Saving model ...\n","585 0.5014523267745972 0.8746479153633118 0.521263062953949 0.8707864880561829 0.5550732612609863 0.8398950099945068\n","Validation loss decreased (0.521263 --> 0.521183).  Saving model ...\n","586 0.5013794898986816 0.8746479153633118 0.52118319272995 0.8707864880561829 0.555011510848999 0.8398950099945068\n","Validation loss decreased (0.521183 --> 0.521103).  Saving model ...\n","587 0.5013068318367004 0.8746479153633118 0.5211033821105957 0.8707864880561829 0.5549500584602356 0.8372703194618225\n","Validation loss decreased (0.521103 --> 0.521024).  Saving model ...\n","588 0.5012343525886536 0.8760563135147095 0.5210238695144653 0.8707864880561829 0.5548884272575378 0.8372703194618225\n","Validation loss decreased (0.521024 --> 0.520945).  Saving model ...\n","589 0.5011625289916992 0.8760563135147095 0.5209445953369141 0.8707864880561829 0.5548268556594849 0.8372703194618225\n","Validation loss decreased (0.520945 --> 0.520865).  Saving model ...\n","590 0.5010898113250732 0.8760563135147095 0.5208654999732971 0.8707864880561829 0.5547659397125244 0.8372703194618225\n","Validation loss decreased (0.520865 --> 0.520787).  Saving model ...\n","591 0.5010181665420532 0.8760563135147095 0.520786702632904 0.8707864880561829 0.5547044277191162 0.8372703194618225\n","Validation loss decreased (0.520787 --> 0.520708).  Saving model ...\n","592 0.5009464025497437 0.8760563135147095 0.5207080245018005 0.8707864880561829 0.5546432733535767 0.8372703194618225\n","Validation loss decreased (0.520708 --> 0.520630).  Saving model ...\n","593 0.5008750557899475 0.8760563135147095 0.5206296443939209 0.8707864880561829 0.5545827150344849 0.8398950099945068\n","Validation loss decreased (0.520630 --> 0.520551).  Saving model ...\n","594 0.5008037090301514 0.8760563135147095 0.520551323890686 0.8707864880561829 0.5545217990875244 0.8398950099945068\n","Validation loss decreased (0.520551 --> 0.520473).  Saving model ...\n","595 0.5007318258285522 0.8760563135147095 0.5204733610153198 0.8707864880561829 0.5544613599777222 0.8398950099945068\n","Validation loss decreased (0.520473 --> 0.520395).  Saving model ...\n","596 0.5006614327430725 0.8760563135147095 0.5203954577445984 0.8707864880561829 0.5544007420539856 0.8398950099945068\n","Validation loss decreased (0.520395 --> 0.520318).  Saving model ...\n","597 0.5005903244018555 0.8760563135147095 0.5203178524971008 0.8707864880561829 0.5543405413627625 0.8398950099945068\n","Validation loss decreased (0.520318 --> 0.520240).  Saving model ...\n","598 0.5005197525024414 0.8760563135147095 0.5202404260635376 0.8707864880561829 0.5542808175086975 0.8398950099945068\n","Validation loss decreased (0.520240 --> 0.520163).  Saving model ...\n","599 0.500449001789093 0.8760563135147095 0.5201632976531982 0.8707864880561829 0.5542200207710266 0.8398950099945068\n","Validation loss decreased (0.520163 --> 0.520086).  Saving model ...\n","600 0.500378429889679 0.8760563135147095 0.5200862288475037 0.8707864880561829 0.5541606545448303 0.8398950099945068\n","Validation loss decreased (0.520086 --> 0.520009).  Saving model ...\n","601 0.5003085136413574 0.8760563135147095 0.520009458065033 0.8707864880561829 0.554100751876831 0.8398950099945068\n","Validation loss decreased (0.520009 --> 0.519933).  Saving model ...\n","602 0.5002385377883911 0.8760563135147095 0.5199328660964966 0.8707864880561829 0.5540410876274109 0.8398950099945068\n","Validation loss decreased (0.519933 --> 0.519857).  Saving model ...\n","603 0.5001683235168457 0.8760563135147095 0.5198565125465393 0.8707864880561829 0.5539818406105042 0.8398950099945068\n","Validation loss decreased (0.519857 --> 0.519780).  Saving model ...\n","604 0.5000987648963928 0.8760563135147095 0.5197803974151611 0.8707864880561829 0.5539223551750183 0.8398950099945068\n","Validation loss decreased (0.519780 --> 0.519704).  Saving model ...\n","605 0.5000292062759399 0.8760563135147095 0.5197041630744934 0.8707864880561829 0.5538632869720459 0.8398950099945068\n","Validation loss decreased (0.519704 --> 0.519629).  Saving model ...\n","606 0.49995917081832886 0.8760563135147095 0.5196285247802734 0.8707864880561829 0.5538044571876526 0.8398950099945068\n","Validation loss decreased (0.519629 --> 0.519553).  Saving model ...\n","607 0.4998904764652252 0.8760563135147095 0.5195527672767639 0.8707864880561829 0.553745448589325 0.8398950099945068\n","Validation loss decreased (0.519553 --> 0.519477).  Saving model ...\n","608 0.4998212456703186 0.8760563135147095 0.5194771885871887 0.8707864880561829 0.553686797618866 0.8398950099945068\n","Validation loss decreased (0.519477 --> 0.519402).  Saving model ...\n","609 0.4997522234916687 0.8760563135147095 0.5194022059440613 0.8707864880561829 0.553628146648407 0.8398950099945068\n","Validation loss decreased (0.519402 --> 0.519327).  Saving model ...\n","610 0.4996833801269531 0.8760563135147095 0.5193271636962891 0.8707864880561829 0.5535696148872375 0.8398950099945068\n","Validation loss decreased (0.519327 --> 0.519252).  Saving model ...\n","611 0.4996148645877838 0.8760563135147095 0.5192523002624512 0.8707864880561829 0.553511381149292 0.8398950099945068\n","Validation loss decreased (0.519252 --> 0.519178).  Saving model ...\n","612 0.49954643845558167 0.8760563135147095 0.5191776156425476 0.8707864880561829 0.5534531474113464 0.8398950099945068\n","Validation loss decreased (0.519178 --> 0.519103).  Saving model ...\n","613 0.49947863817214966 0.8760563135147095 0.5191030502319336 0.8707864880561829 0.5533948540687561 0.8398950099945068\n","Validation loss decreased (0.519103 --> 0.519029).  Saving model ...\n","614 0.49941033124923706 0.8760563135147095 0.5190287828445435 0.8707864880561829 0.5533369779586792 0.8398950099945068\n","Validation loss decreased (0.519029 --> 0.518955).  Saving model ...\n","615 0.4993416666984558 0.8760563135147095 0.5189546346664429 0.8707864880561829 0.5532791018486023 0.8398950099945068\n","Validation loss decreased (0.518955 --> 0.518881).  Saving model ...\n","616 0.49927422404289246 0.8760563135147095 0.5188809037208557 0.8707864880561829 0.5532213449478149 0.8398950099945068\n","Validation loss decreased (0.518881 --> 0.518807).  Saving model ...\n","617 0.4992069900035858 0.8760563135147095 0.5188068151473999 0.8707864880561829 0.5531637668609619 0.8398950099945068\n","Validation loss decreased (0.518807 --> 0.518734).  Saving model ...\n","618 0.49913883209228516 0.8760563135147095 0.518733561038971 0.8707864880561829 0.5531066656112671 0.8398950099945068\n","Validation loss decreased (0.518734 --> 0.518660).  Saving model ...\n","619 0.49907156825065613 0.8760563135147095 0.5186602473258972 0.8707864880561829 0.5530493259429932 0.8398950099945068\n","Validation loss decreased (0.518660 --> 0.518587).  Saving model ...\n","620 0.49900445342063904 0.8760563135147095 0.518587052822113 0.8707864880561829 0.5529922842979431 0.8398950099945068\n","Validation loss decreased (0.518587 --> 0.518514).  Saving model ...\n","621 0.49893757700920105 0.8760563135147095 0.5185143351554871 0.8707864880561829 0.5529352426528931 0.8398950099945068\n","Validation loss decreased (0.518514 --> 0.518441).  Saving model ...\n","622 0.4988706409931183 0.8760563135147095 0.5184414982795715 0.8707864880561829 0.5528781414031982 0.8398950099945068\n","Validation loss decreased (0.518441 --> 0.518369).  Saving model ...\n","623 0.4988038241863251 0.8760563135147095 0.5183687210083008 0.8707864880561829 0.5528212189674377 0.8398950099945068\n","Validation loss decreased (0.518369 --> 0.518296).  Saving model ...\n","624 0.49873706698417664 0.8760563135147095 0.5182964205741882 0.8707864880561829 0.552764892578125 0.8398950099945068\n","Validation loss decreased (0.518296 --> 0.518224).  Saving model ...\n","625 0.4986707270145416 0.8760563135147095 0.5182244181632996 0.8707864880561829 0.5527085065841675 0.8425197005271912\n","Validation loss decreased (0.518224 --> 0.518152).  Saving model ...\n","626 0.498604416847229 0.8760563135147095 0.5181522369384766 0.8707864880561829 0.5526518225669861 0.8425197005271912\n","Validation loss decreased (0.518152 --> 0.518080).  Saving model ...\n","627 0.49853813648223877 0.8760563135147095 0.5180803537368774 0.8707864880561829 0.5525956153869629 0.8425197005271912\n","Validation loss decreased (0.518080 --> 0.518009).  Saving model ...\n","628 0.49847233295440674 0.8760563135147095 0.518008828163147 0.8707864880561829 0.5525394678115845 0.8425197005271912\n","Validation loss decreased (0.518009 --> 0.517937).  Saving model ...\n","629 0.49840670824050903 0.8760563135147095 0.5179372429847717 0.8707864880561829 0.5524840354919434 0.8425197005271912\n","Validation loss decreased (0.517937 --> 0.517866).  Saving model ...\n","630 0.4983406066894531 0.8760563135147095 0.5178658366203308 0.8707864880561829 0.5524277687072754 0.8425197005271912\n","Validation loss decreased (0.517866 --> 0.517795).  Saving model ...\n","631 0.49827513098716736 0.8760563135147095 0.5177947282791138 0.8707864880561829 0.5523720383644104 0.8425197005271912\n","Validation loss decreased (0.517795 --> 0.517724).  Saving model ...\n","632 0.4982094466686249 0.8760563135147095 0.5177239775657654 0.8707864880561829 0.5523166060447693 0.8425197005271912\n","Validation loss decreased (0.517724 --> 0.517653).  Saving model ...\n","633 0.4981441795825958 0.8760563135147095 0.517653226852417 0.8707864880561829 0.5522610545158386 0.8425197005271912\n","Validation loss decreased (0.517653 --> 0.517582).  Saving model ...\n","634 0.49807918071746826 0.8760563135147095 0.5175822973251343 0.8707864880561829 0.5522053837776184 0.8425197005271912\n","Validation loss decreased (0.517582 --> 0.517512).  Saving model ...\n","635 0.4980136752128601 0.8760563135147095 0.5175119638442993 0.8707864880561829 0.5521504282951355 0.8451443314552307\n","Validation loss decreased (0.517512 --> 0.517442).  Saving model ...\n","636 0.49794888496398926 0.8760563135147095 0.5174418687820435 0.8707864880561829 0.5520954132080078 0.8451443314552307\n","Validation loss decreased (0.517442 --> 0.517372).  Saving model ...\n","637 0.49788475036621094 0.8760563135147095 0.5173717141151428 0.8707864880561829 0.5520399808883667 0.8451443314552307\n","Validation loss decreased (0.517372 --> 0.517302).  Saving model ...\n","638 0.4978199601173401 0.8760563135147095 0.5173017382621765 0.8707864880561829 0.551985502243042 0.8451443314552307\n","Validation loss decreased (0.517302 --> 0.517232).  Saving model ...\n","639 0.4977557063102722 0.8760563135147095 0.5172321796417236 0.8707864880561829 0.5519306063652039 0.8451443314552307\n","Validation loss decreased (0.517232 --> 0.517163).  Saving model ...\n","640 0.49769124388694763 0.8760563135147095 0.5171626806259155 0.8707864880561829 0.5518759489059448 0.8451443314552307\n","Validation loss decreased (0.517163 --> 0.517093).  Saving model ...\n","641 0.4976275563240051 0.8760563135147095 0.5170931220054626 0.8707864880561829 0.5518211722373962 0.8451443314552307\n","Validation loss decreased (0.517093 --> 0.517024).  Saving model ...\n","642 0.4975634515285492 0.8760563135147095 0.5170240998268127 0.8707864880561829 0.5517671704292297 0.8451443314552307\n","Validation loss decreased (0.517024 --> 0.516955).  Saving model ...\n","643 0.4974993169307709 0.8760563135147095 0.5169550180435181 0.8707864880561829 0.5517129898071289 0.8451443314552307\n","Validation loss decreased (0.516955 --> 0.516886).  Saving model ...\n","644 0.49743568897247314 0.8760563135147095 0.5168863534927368 0.8707864880561829 0.5516586303710938 0.8451443314552307\n","Validation loss decreased (0.516886 --> 0.516818).  Saving model ...\n","645 0.49737200140953064 0.8760563135147095 0.5168176293373108 0.8707864880561829 0.5516043901443481 0.8451443314552307\n","Validation loss decreased (0.516818 --> 0.516749).  Saving model ...\n","646 0.4973086714744568 0.8760563135147095 0.5167489051818848 0.8707864880561829 0.5515507459640503 0.8451443314552307\n","Validation loss decreased (0.516749 --> 0.516681).  Saving model ...\n","647 0.49724501371383667 0.8760563135147095 0.5166806578636169 0.8707864880561829 0.5514968633651733 0.8451443314552307\n","Validation loss decreased (0.516681 --> 0.516612).  Saving model ...\n","648 0.4971819519996643 0.8760563135147095 0.5166124701499939 0.8707864880561829 0.5514432787895203 0.8451443314552307\n","Validation loss decreased (0.516612 --> 0.516544).  Saving model ...\n","649 0.49711874127388 0.8760563135147095 0.5165444612503052 0.8707864880561829 0.5513895153999329 0.8451443314552307\n","Validation loss decreased (0.516544 --> 0.516477).  Saving model ...\n","650 0.49705612659454346 0.8760563135147095 0.5164768695831299 0.8707864880561829 0.5513362288475037 0.8451443314552307\n","Validation loss decreased (0.516477 --> 0.516409).  Saving model ...\n","651 0.4969932734966278 0.8760563135147095 0.5164090991020203 0.8707864880561829 0.5512829422950745 0.8451443314552307\n","Validation loss decreased (0.516409 --> 0.516342).  Saving model ...\n","652 0.4969307780265808 0.8760563135147095 0.5163415670394897 0.8707864880561829 0.5512297749519348 0.8451443314552307\n","Validation loss decreased (0.516342 --> 0.516274).  Saving model ...\n","653 0.49686822295188904 0.8760563135147095 0.5162742137908936 0.8707864880561829 0.5511766672134399 0.8451443314552307\n","Validation loss decreased (0.516274 --> 0.516207).  Saving model ...\n","654 0.49680590629577637 0.8760563135147095 0.5162071585655212 0.8707864880561829 0.5511234402656555 0.8451443314552307\n","Validation loss decreased (0.516207 --> 0.516140).  Saving model ...\n","655 0.4967437982559204 0.8760563135147095 0.5161400437355042 0.8707864880561829 0.5510708093643188 0.8451443314552307\n","Validation loss decreased (0.516140 --> 0.516073).  Saving model ...\n","656 0.49668166041374207 0.877464771270752 0.5160732865333557 0.8707864880561829 0.5510181188583374 0.8451443314552307\n","Validation loss decreased (0.516073 --> 0.516007).  Saving model ...\n","657 0.4966192841529846 0.877464771270752 0.516006588935852 0.8707864880561829 0.5509653687477112 0.8451443314552307\n","Validation loss decreased (0.516007 --> 0.515940).  Saving model ...\n","658 0.4965575635433197 0.877464771270752 0.5159399509429932 0.8707864880561829 0.5509130954742432 0.8451443314552307\n","Validation loss decreased (0.515940 --> 0.515874).  Saving model ...\n","659 0.49649620056152344 0.877464771270752 0.5158738493919373 0.8707864880561829 0.5508606433868408 0.8451443314552307\n","Validation loss decreased (0.515874 --> 0.515808).  Saving model ...\n","660 0.4964348077774048 0.877464771270752 0.515807569026947 0.8707864880561829 0.5508085489273071 0.8451443314552307\n","Validation loss decreased (0.515808 --> 0.515742).  Saving model ...\n","661 0.49637314677238464 0.877464771270752 0.5157415270805359 0.8707864880561829 0.5507560968399048 0.8451443314552307\n","Validation loss decreased (0.515742 --> 0.515676).  Saving model ...\n","662 0.4963114261627197 0.877464771270752 0.5156758427619934 0.8707864880561829 0.5507040619850159 0.8451443314552307\n","Validation loss decreased (0.515676 --> 0.515610).  Saving model ...\n","663 0.4962509870529175 0.877464771270752 0.5156100392341614 0.8707864880561829 0.550652265548706 0.8451443314552307\n","Validation loss decreased (0.515610 --> 0.515544).  Saving model ...\n","664 0.49618959426879883 0.877464771270752 0.5155444145202637 0.8707864880561829 0.5506000518798828 0.8451443314552307\n","Validation loss decreased (0.515544 --> 0.515479).  Saving model ...\n","665 0.4961290955543518 0.877464771270752 0.5154790282249451 0.8707864880561829 0.550548255443573 0.8451443314552307\n","Validation loss decreased (0.515479 --> 0.515414).  Saving model ...\n","666 0.49606746435165405 0.877464771270752 0.5154138803482056 0.8707864880561829 0.5504968762397766 0.8451443314552307\n","Validation loss decreased (0.515414 --> 0.515349).  Saving model ...\n","667 0.49600741267204285 0.877464771270752 0.5153487920761108 0.8707864880561829 0.5504457354545593 0.8451443314552307\n","Validation loss decreased (0.515349 --> 0.515284).  Saving model ...\n","668 0.4959465563297272 0.877464771270752 0.5152839422225952 0.8707864880561829 0.5503939986228943 0.8451443314552307\n","Validation loss decreased (0.515284 --> 0.515219).  Saving model ...\n","669 0.49588659405708313 0.877464771270752 0.5152192115783691 0.8707864880561829 0.5503426194190979 0.8451443314552307\n","Validation loss decreased (0.515219 --> 0.515155).  Saving model ...\n","670 0.4958258867263794 0.877464771270752 0.5151545405387878 0.8707864880561829 0.5502911806106567 0.8451443314552307\n","Validation loss decreased (0.515155 --> 0.515090).  Saving model ...\n","671 0.4957660436630249 0.877464771270752 0.5150902271270752 0.8707864880561829 0.5502404570579529 0.8451443314552307\n","Validation loss decreased (0.515090 --> 0.515026).  Saving model ...\n","672 0.49570566415786743 0.877464771270752 0.5150258541107178 0.8764045238494873 0.5501895546913147 0.847769021987915\n","Validation loss decreased (0.515026 --> 0.514962).  Saving model ...\n","673 0.49564623832702637 0.877464771270752 0.5149617791175842 0.8764045238494873 0.5501386523246765 0.847769021987915\n","Validation loss decreased (0.514962 --> 0.514898).  Saving model ...\n","674 0.4955863356590271 0.877464771270752 0.5148977041244507 0.8764045238494873 0.5500877499580383 0.8503937125205994\n","Validation loss decreased (0.514898 --> 0.514834).  Saving model ...\n","675 0.49552640318870544 0.877464771270752 0.5148339867591858 0.8764045238494873 0.5500370860099792 0.8503937125205994\n","Validation loss decreased (0.514834 --> 0.514770).  Saving model ...\n","676 0.49546706676483154 0.877464771270752 0.5147702693939209 0.8764045238494873 0.5499863624572754 0.8503937125205994\n","Validation loss decreased (0.514770 --> 0.514707).  Saving model ...\n","677 0.49540776014328003 0.877464771270752 0.5147067904472351 0.8764045238494873 0.5499365925788879 0.8503937125205994\n","Validation loss decreased (0.514707 --> 0.514643).  Saving model ...\n","678 0.49534857273101807 0.877464771270752 0.5146433115005493 0.8764045238494873 0.5498856902122498 0.8503937125205994\n","Validation loss decreased (0.514643 --> 0.514580).  Saving model ...\n","679 0.4952891170978546 0.877464771270752 0.514580488204956 0.8764045238494873 0.549835741519928 0.8503937125205994\n","Validation loss decreased (0.514580 --> 0.514517).  Saving model ...\n","680 0.49522992968559265 0.877464771270752 0.5145171880722046 0.8764045238494873 0.5497856140136719 0.8503937125205994\n","Validation loss decreased (0.514517 --> 0.514454).  Saving model ...\n","681 0.4951712489128113 0.877464771270752 0.5144542455673218 0.8764045238494873 0.5497353672981262 0.8503937125205994\n","Validation loss decreased (0.514454 --> 0.514391).  Saving model ...\n","682 0.4951121211051941 0.877464771270752 0.5143914818763733 0.8764045238494873 0.5496856570243835 0.8503937125205994\n","Validation loss decreased (0.514391 --> 0.514329).  Saving model ...\n","683 0.49505382776260376 0.877464771270752 0.5143287777900696 0.8764045238494873 0.5496357679367065 0.8503937125205994\n","Validation loss decreased (0.514329 --> 0.514266).  Saving model ...\n","684 0.4949951767921448 0.877464771270752 0.5142663717269897 0.8764045238494873 0.5495859384536743 0.8503937125205994\n","Validation loss decreased (0.514266 --> 0.514204).  Saving model ...\n","685 0.4949367642402649 0.877464771270752 0.5142040252685547 0.8764045238494873 0.5495365858078003 0.8503937125205994\n","Validation loss decreased (0.514204 --> 0.514142).  Saving model ...\n","686 0.4948784410953522 0.877464771270752 0.5141419172286987 0.8764045238494873 0.5494868159294128 0.8503937125205994\n","Validation loss decreased (0.514142 --> 0.514080).  Saving model ...\n","687 0.4948202073574066 0.877464771270752 0.5140798091888428 0.8764045238494873 0.5494375824928284 0.8503937125205994\n","Validation loss decreased (0.514080 --> 0.514018).  Saving model ...\n","688 0.4947620928287506 0.877464771270752 0.5140180587768555 0.8764045238494873 0.5493883490562439 0.8503937125205994\n","Validation loss decreased (0.514018 --> 0.513956).  Saving model ...\n","689 0.49470385909080505 0.877464771270752 0.5139561891555786 0.8764045238494873 0.5493394136428833 0.8503937125205994\n","Validation loss decreased (0.513956 --> 0.513895).  Saving model ...\n","690 0.4946463406085968 0.877464771270752 0.51389479637146 0.8764045238494873 0.5492899417877197 0.8503937125205994\n","Validation loss decreased (0.513895 --> 0.513833).  Saving model ...\n","691 0.49458813667297363 0.877464771270752 0.5138332843780518 0.8764045238494873 0.5492411255836487 0.8503937125205994\n","Validation loss decreased (0.513833 --> 0.513772).  Saving model ...\n","692 0.494530588388443 0.877464771270752 0.5137721300125122 0.8764045238494873 0.5491920709609985 0.8503937125205994\n","Validation loss decreased (0.513772 --> 0.513711).  Saving model ...\n","693 0.4944736361503601 0.877464771270752 0.5137107372283936 0.8764045238494873 0.5491432547569275 0.8503937125205994\n","Validation loss decreased (0.513711 --> 0.513650).  Saving model ...\n","694 0.49441614747047424 0.877464771270752 0.5136500000953674 0.8764045238494873 0.5490944981575012 0.8503937125205994\n","Validation loss decreased (0.513650 --> 0.513589).  Saving model ...\n","695 0.49435850977897644 0.877464771270752 0.513589084148407 0.8764045238494873 0.5490461587905884 0.8503937125205994\n","Validation loss decreased (0.513589 --> 0.513528).  Saving model ...\n","696 0.4943014681339264 0.877464771270752 0.5135282278060913 0.8764045238494873 0.5489976406097412 0.8503937125205994\n","Validation loss decreased (0.513528 --> 0.513468).  Saving model ...\n","697 0.4942443072795868 0.877464771270752 0.5134678483009338 0.8764045238494873 0.5489492416381836 0.8503937125205994\n","Validation loss decreased (0.513468 --> 0.513407).  Saving model ...\n","698 0.49418750405311584 0.877464771270752 0.5134072303771973 0.8764045238494873 0.548900842666626 0.8503937125205994\n","Validation loss decreased (0.513407 --> 0.513347).  Saving model ...\n","699 0.494130939245224 0.877464771270752 0.5133469700813293 0.8764045238494873 0.5488526821136475 0.8503937125205994\n","Validation loss decreased (0.513347 --> 0.513287).  Saving model ...\n","700 0.4940742552280426 0.877464771270752 0.513286828994751 0.8764045238494873 0.548804759979248 0.8503937125205994\n","Validation loss decreased (0.513287 --> 0.513227).  Saving model ...\n","701 0.4940173923969269 0.877464771270752 0.5132268071174622 0.8764045238494873 0.5487565994262695 0.8503937125205994\n","Validation loss decreased (0.513227 --> 0.513167).  Saving model ...\n","702 0.4939610958099365 0.877464771270752 0.5131670236587524 0.8764045238494873 0.5487088561058044 0.8503937125205994\n","Validation loss decreased (0.513167 --> 0.513107).  Saving model ...\n","703 0.4939045310020447 0.877464771270752 0.5131071209907532 0.8764045238494873 0.5486608743667603 0.8503937125205994\n","Validation loss decreased (0.513107 --> 0.513048).  Saving model ...\n","704 0.49384817481040955 0.877464771270752 0.5130476951599121 0.8764045238494873 0.548613429069519 0.8503937125205994\n","Validation loss decreased (0.513048 --> 0.512988).  Saving model ...\n","705 0.49379199743270874 0.877464771270752 0.5129883289337158 0.8764045238494873 0.5485655069351196 0.8503937125205994\n","Validation loss decreased (0.512988 --> 0.512929).  Saving model ...\n","706 0.49373599886894226 0.877464771270752 0.5129289627075195 0.8764045238494873 0.5485183000564575 0.8503937125205994\n","Validation loss decreased (0.512929 --> 0.512870).  Saving model ...\n","707 0.4936804473400116 0.877464771270752 0.5128697752952576 0.8764045238494873 0.5484706163406372 0.8503937125205994\n","Validation loss decreased (0.512870 --> 0.512811).  Saving model ...\n","708 0.493624210357666 0.877464771270752 0.5128107070922852 0.8764045238494873 0.548423707485199 0.8503937125205994\n","Validation loss decreased (0.512811 --> 0.512752).  Saving model ...\n","709 0.49356842041015625 0.877464771270752 0.512752115726471 0.8764045238494873 0.5483762621879578 0.8503937125205994\n","Validation loss decreased (0.512752 --> 0.512693).  Saving model ...\n","710 0.4935130476951599 0.877464771270752 0.512692928314209 0.8764045238494873 0.54832923412323 0.8503937125205994\n","Validation loss decreased (0.512693 --> 0.512635).  Saving model ...\n","711 0.49345719814300537 0.877464771270752 0.5126345157623291 0.8764045238494873 0.5482819676399231 0.8503937125205994\n","Validation loss decreased (0.512635 --> 0.512576).  Saving model ...\n","712 0.4934023320674896 0.877464771270752 0.5125758051872253 0.8764045238494873 0.5482347011566162 0.8503937125205994\n","Validation loss decreased (0.512576 --> 0.512517).  Saving model ...\n","713 0.49334684014320374 0.877464771270752 0.5125173926353455 0.8764045238494873 0.5481878519058228 0.8503937125205994\n","Validation loss decreased (0.512517 --> 0.512459).  Saving model ...\n","714 0.4932914674282074 0.877464771270752 0.5124594569206238 0.8764045238494873 0.5481413006782532 0.8503937125205994\n","Validation loss decreased (0.512459 --> 0.512401).  Saving model ...\n","715 0.4932364821434021 0.877464771270752 0.5124014019966125 0.8764045238494873 0.5480947494506836 0.8503937125205994\n","Validation loss decreased (0.512401 --> 0.512343).  Saving model ...\n","716 0.49318158626556396 0.8788732290267944 0.512343168258667 0.8764045238494873 0.5480479598045349 0.8503937125205994\n","Validation loss decreased (0.512343 --> 0.512285).  Saving model ...\n","717 0.49312669038772583 0.8788732290267944 0.5122854113578796 0.8764045238494873 0.5480018854141235 0.8503937125205994\n","Validation loss decreased (0.512285 --> 0.512228).  Saving model ...\n","718 0.4930720031261444 0.8788732290267944 0.5122277736663818 0.8764045238494873 0.547955334186554 0.8503937125205994\n","Validation loss decreased (0.512228 --> 0.512170).  Saving model ...\n","719 0.4930177330970764 0.8802816867828369 0.5121700763702393 0.8764045238494873 0.5479089617729187 0.8503937125205994\n","Validation loss decreased (0.512170 --> 0.512113).  Saving model ...\n","720 0.49296286702156067 0.8802816867828369 0.5121126770973206 0.8764045238494873 0.547862708568573 0.8503937125205994\n","Validation loss decreased (0.512113 --> 0.512056).  Saving model ...\n","721 0.492908239364624 0.8802816867828369 0.512055516242981 0.8764045238494873 0.547816812992096 0.8503937125205994\n","Validation loss decreased (0.512056 --> 0.511998).  Saving model ...\n","722 0.49285393953323364 0.8802816867828369 0.5119984149932861 0.8764045238494873 0.5477705001831055 0.8503937125205994\n","Validation loss decreased (0.511998 --> 0.511941).  Saving model ...\n","723 0.4927998483181 0.8802816867828369 0.5119413137435913 0.8764045238494873 0.5477246046066284 0.8503937125205994\n","Validation loss decreased (0.511941 --> 0.511884).  Saving model ...\n","724 0.492745578289032 0.8802816867828369 0.5118842720985413 0.8764045238494873 0.5476790070533752 0.8503937125205994\n","Validation loss decreased (0.511884 --> 0.511828).  Saving model ...\n","725 0.4926918148994446 0.8802816867828369 0.5118276476860046 0.8764045238494873 0.5476330518722534 0.8503937125205994\n","Validation loss decreased (0.511828 --> 0.511771).  Saving model ...\n","726 0.49263766407966614 0.8802816867828369 0.5117710828781128 0.8764045238494873 0.5475874543190002 0.8503937125205994\n","Validation loss decreased (0.511771 --> 0.511714).  Saving model ...\n","727 0.49258363246917725 0.8802816867828369 0.5117144584655762 0.8764045238494873 0.5475419759750366 0.8503937125205994\n","Validation loss decreased (0.511714 --> 0.511658).  Saving model ...\n","728 0.4925304651260376 0.8802816867828369 0.5116581320762634 0.8764045238494873 0.5474964380264282 0.8503937125205994\n","Validation loss decreased (0.511658 --> 0.511602).  Saving model ...\n","729 0.4924767017364502 0.8802816867828369 0.5116016268730164 0.8764045238494873 0.5474506616592407 0.8503937125205994\n","Validation loss decreased (0.511602 --> 0.511545).  Saving model ...\n","730 0.4924231171607971 0.8802816867828369 0.5115454196929932 0.8764045238494873 0.5474055409431458 0.8503937125205994\n","Validation loss decreased (0.511545 --> 0.511490).  Saving model ...\n","731 0.49236929416656494 0.8802816867828369 0.511489748954773 0.8764045238494873 0.5473601818084717 0.8503937125205994\n","Validation loss decreased (0.511490 --> 0.511434).  Saving model ...\n","732 0.4923163652420044 0.8802816867828369 0.5114336609840393 0.8764045238494873 0.5473155379295349 0.8503937125205994\n","Validation loss decreased (0.511434 --> 0.511378).  Saving model ...\n","733 0.49226322770118713 0.8802816867828369 0.5113779902458191 0.8764045238494873 0.5472701787948608 0.8503937125205994\n","Validation loss decreased (0.511378 --> 0.511322).  Saving model ...\n","734 0.4922100603580475 0.8802816867828369 0.5113221406936646 0.8764045238494873 0.5472252368927002 0.8503937125205994\n","Validation loss decreased (0.511322 --> 0.511267).  Saving model ...\n","735 0.49215683341026306 0.8802816867828369 0.5112667679786682 0.8764045238494873 0.5471804141998291 0.8503937125205994\n","Validation loss decreased (0.511267 --> 0.511211).  Saving model ...\n","736 0.49210405349731445 0.8802816867828369 0.5112112760543823 0.8764045238494873 0.547135591506958 0.8503937125205994\n","Validation loss decreased (0.511211 --> 0.511156).  Saving model ...\n","737 0.4920510947704315 0.8802816867828369 0.5111560821533203 0.8764045238494873 0.5470907688140869 0.8503937125205994\n","Validation loss decreased (0.511156 --> 0.511101).  Saving model ...\n","738 0.4919988811016083 0.8802816867828369 0.5111008286476135 0.8764045238494873 0.5470462441444397 0.8503937125205994\n","Validation loss decreased (0.511101 --> 0.511046).  Saving model ...\n","739 0.49194616079330444 0.8802816867828369 0.5110459327697754 0.8764045238494873 0.5470019578933716 0.8503937125205994\n","Validation loss decreased (0.511046 --> 0.510991).  Saving model ...\n","740 0.4918932020664215 0.8802816867828369 0.5109908580780029 0.8764045238494873 0.5469571948051453 0.8503937125205994\n","Validation loss decreased (0.510991 --> 0.510936).  Saving model ...\n","741 0.49184074997901917 0.8802816867828369 0.5109362006187439 0.8764045238494873 0.5469130277633667 0.8503937125205994\n","Validation loss decreased (0.510936 --> 0.510881).  Saving model ...\n","742 0.49178892374038696 0.8802816867828369 0.5108813643455505 0.8764045238494873 0.5468689799308777 0.8503937125205994\n","Validation loss decreased (0.510881 --> 0.510827).  Saving model ...\n","743 0.4917365312576294 0.8802816867828369 0.5108266472816467 0.8764045238494873 0.5468242168426514 0.8503937125205994\n","Validation loss decreased (0.510827 --> 0.510773).  Saving model ...\n","744 0.4916844964027405 0.8802816867828369 0.5107725262641907 0.8764045238494873 0.5467805862426758 0.8503937125205994\n","Validation loss decreased (0.510773 --> 0.510718).  Saving model ...\n","745 0.4916321635246277 0.8802816867828369 0.5107181668281555 0.8764045238494873 0.5467362403869629 0.8503937125205994\n","Validation loss decreased (0.510718 --> 0.510664).  Saving model ...\n","746 0.491580605506897 0.8802816867828369 0.510664165019989 0.8764045238494873 0.546692430973053 0.8503937125205994\n","Validation loss decreased (0.510664 --> 0.510610).  Saving model ...\n","747 0.49152871966362 0.8802816867828369 0.5106099843978882 0.8764045238494873 0.5466486811637878 0.8503937125205994\n","Validation loss decreased (0.510610 --> 0.510556).  Saving model ...\n","748 0.49147698283195496 0.8802816867828369 0.5105558633804321 0.8764045238494873 0.5466049909591675 0.8503937125205994\n","Validation loss decreased (0.510556 --> 0.510502).  Saving model ...\n","749 0.4914248287677765 0.8802816867828369 0.5105020999908447 0.8764045238494873 0.5465611219406128 0.8503937125205994\n","Validation loss decreased (0.510502 --> 0.510448).  Saving model ...\n","750 0.491373747587204 0.8802816867828369 0.5104484558105469 0.8764045238494873 0.5465174317359924 0.8503937125205994\n","Validation loss decreased (0.510448 --> 0.510395).  Saving model ...\n","751 0.49132174253463745 0.8802816867828369 0.5103950500488281 0.8764045238494873 0.546474039554596 0.8503937125205994\n","Validation loss decreased (0.510395 --> 0.510341).  Saving model ...\n","752 0.49127092957496643 0.8802816867828369 0.5103413462638855 0.8764045238494873 0.5464307069778442 0.8503937125205994\n","Validation loss decreased (0.510341 --> 0.510288).  Saving model ...\n","753 0.49121958017349243 0.8802816867828369 0.5102881789207458 0.8764045238494873 0.5463871359825134 0.8503937125205994\n","Validation loss decreased (0.510288 --> 0.510235).  Saving model ...\n","754 0.49116843938827515 0.8802816867828369 0.5102347135543823 0.8764045238494873 0.5463439226150513 0.8503937125205994\n","Validation loss decreased (0.510235 --> 0.510182).  Saving model ...\n","755 0.491117388010025 0.8802816867828369 0.5101816654205322 0.8764045238494873 0.5463008880615234 0.8503937125205994\n","Validation loss decreased (0.510182 --> 0.510129).  Saving model ...\n","756 0.4910658597946167 0.8802816867828369 0.510128915309906 0.8764045238494873 0.546257734298706 0.8503937125205994\n","Validation loss decreased (0.510129 --> 0.510076).  Saving model ...\n","757 0.49101513624191284 0.8802816867828369 0.5100758671760559 0.8764045238494873 0.5462144613265991 0.8503937125205994\n","Validation loss decreased (0.510076 --> 0.510023).  Saving model ...\n","758 0.4909641444683075 0.8802816867828369 0.5100229978561401 0.8764045238494873 0.5461716651916504 0.8503937125205994\n","Validation loss decreased (0.510023 --> 0.509970).  Saving model ...\n","759 0.49091362953186035 0.8802816867828369 0.5099704265594482 0.8764045238494873 0.5461287498474121 0.8503937125205994\n","Validation loss decreased (0.509970 --> 0.509918).  Saving model ...\n","760 0.49086296558380127 0.8802816867828369 0.5099179744720459 0.8764045238494873 0.546085774898529 0.8503937125205994\n","Validation loss decreased (0.509918 --> 0.509865).  Saving model ...\n","761 0.4908125102519989 0.8802816867828369 0.5098653435707092 0.8764045238494873 0.5460432171821594 0.8503937125205994\n","Validation loss decreased (0.509865 --> 0.509813).  Saving model ...\n","762 0.490761935710907 0.8802816867828369 0.509813129901886 0.8764045238494873 0.5460007786750793 0.8503937125205994\n","Validation loss decreased (0.509813 --> 0.509761).  Saving model ...\n","763 0.4907114803791046 0.8802816867828369 0.5097607970237732 0.8764045238494873 0.5459581613540649 0.8503937125205994\n","Validation loss decreased (0.509761 --> 0.509709).  Saving model ...\n","764 0.4906616806983948 0.8802816867828369 0.509708821773529 0.8764045238494873 0.5459153652191162 0.8503937125205994\n","Validation loss decreased (0.509709 --> 0.509657).  Saving model ...\n","765 0.4906112551689148 0.8816901445388794 0.509656548500061 0.8764045238494873 0.54587322473526 0.8503937125205994\n","Validation loss decreased (0.509657 --> 0.509605).  Saving model ...\n","766 0.49056097865104675 0.8816901445388794 0.5096047520637512 0.8764045238494873 0.5458309054374695 0.8503937125205994\n","Validation loss decreased (0.509605 --> 0.509553).  Saving model ...\n","767 0.4905107319355011 0.8816901445388794 0.5095529556274414 0.8764045238494873 0.5457887053489685 0.8503937125205994\n","Validation loss decreased (0.509553 --> 0.509501).  Saving model ...\n","768 0.49046117067337036 0.8816901445388794 0.5095013976097107 0.8764045238494873 0.5457465648651123 0.8503937125205994\n","Validation loss decreased (0.509501 --> 0.509450).  Saving model ...\n","769 0.4904112219810486 0.8816901445388794 0.5094500184059143 0.8764045238494873 0.5457045435905457 0.8503937125205994\n","Validation loss decreased (0.509450 --> 0.509398).  Saving model ...\n","770 0.4903614819049835 0.8816901445388794 0.5093984007835388 0.8764045238494873 0.5456623435020447 0.8503937125205994\n","Validation loss decreased (0.509398 --> 0.509347).  Saving model ...\n","771 0.49031224846839905 0.8816901445388794 0.5093469619750977 0.882022500038147 0.5456201434135437 0.8503937125205994\n","Validation loss decreased (0.509347 --> 0.509296).  Saving model ...\n","772 0.4902624487876892 0.8816901445388794 0.5092960596084595 0.882022500038147 0.5455784201622009 0.8503937125205994\n","Validation loss decreased (0.509296 --> 0.509245).  Saving model ...\n","773 0.4902127683162689 0.8816901445388794 0.5092447996139526 0.882022500038147 0.5455368161201477 0.8503937125205994\n","Validation loss decreased (0.509245 --> 0.509194).  Saving model ...\n","774 0.4901635944843292 0.8816901445388794 0.5091937184333801 0.8876404762268066 0.5454950332641602 0.8530183434486389\n","Validation loss decreased (0.509194 --> 0.509143).  Saving model ...\n","775 0.4901142716407776 0.8816901445388794 0.5091428160667419 0.8876404762268066 0.5454534888267517 0.8556430339813232\n","Validation loss decreased (0.509143 --> 0.509092).  Saving model ...\n","776 0.4900650084018707 0.8816901445388794 0.5090921521186829 0.8876404762268066 0.5454117059707642 0.8556430339813232\n","Validation loss decreased (0.509092 --> 0.509042).  Saving model ...\n","777 0.4900159537792206 0.8816901445388794 0.5090415477752686 0.8876404762268066 0.5453703999519348 0.8556430339813232\n","Validation loss decreased (0.509042 --> 0.508991).  Saving model ...\n","778 0.48996686935424805 0.8816901445388794 0.5089907646179199 0.8876404762268066 0.5453290939331055 0.8556430339813232\n","Validation loss decreased (0.508991 --> 0.508940).  Saving model ...\n","779 0.48991766571998596 0.8816901445388794 0.5089402794837952 0.8876404762268066 0.5452877283096313 0.8556430339813232\n","Validation loss decreased (0.508940 --> 0.508890).  Saving model ...\n","780 0.4898686408996582 0.8816901445388794 0.5088899731636047 0.8876404762268066 0.5452464818954468 0.8556430339813232\n","Validation loss decreased (0.508890 --> 0.508840).  Saving model ...\n","781 0.4898201525211334 0.8816901445388794 0.5088397860527039 0.8876404762268066 0.5452051758766174 0.8556430339813232\n","Validation loss decreased (0.508840 --> 0.508790).  Saving model ...\n","782 0.48977163434028625 0.8816901445388794 0.5087895393371582 0.8876404762268066 0.5451640486717224 0.8556430339813232\n","Validation loss decreased (0.508790 --> 0.508740).  Saving model ...\n","783 0.4897228479385376 0.8816901445388794 0.5087396502494812 0.8876404762268066 0.545123279094696 0.8556430339813232\n","Validation loss decreased (0.508740 --> 0.508690).  Saving model ...\n","784 0.48967453837394714 0.8816901445388794 0.5086895227432251 0.882022500038147 0.5450823903083801 0.8556430339813232\n","Validation loss decreased (0.508690 --> 0.508640).  Saving model ...\n","785 0.4896257221698761 0.8816901445388794 0.5086397528648376 0.882022500038147 0.5450413823127747 0.8556430339813232\n","Validation loss decreased (0.508640 --> 0.508590).  Saving model ...\n","786 0.4895772337913513 0.8816901445388794 0.5085899829864502 0.882022500038147 0.5450004935264587 0.8556430339813232\n","Validation loss decreased (0.508590 --> 0.508541).  Saving model ...\n","787 0.48952943086624146 0.8816901445388794 0.5085405111312866 0.882022500038147 0.5449597835540771 0.8556430339813232\n","Validation loss decreased (0.508541 --> 0.508491).  Saving model ...\n","788 0.4894808530807495 0.8816901445388794 0.508491039276123 0.882022500038147 0.5449193120002747 0.8556430339813232\n","Validation loss decreased (0.508491 --> 0.508441).  Saving model ...\n","789 0.4894329607486725 0.8816901445388794 0.5084414482116699 0.882022500038147 0.5448787808418274 0.8556430339813232\n","Validation loss decreased (0.508441 --> 0.508392).  Saving model ...\n","790 0.4893852174282074 0.8816901445388794 0.5083922147750854 0.882022500038147 0.544838011264801 0.8556430339813232\n","Validation loss decreased (0.508392 --> 0.508343).  Saving model ...\n","791 0.4893367290496826 0.8816901445388794 0.5083429217338562 0.882022500038147 0.5447980165481567 0.8556430339813232\n","Validation loss decreased (0.508343 --> 0.508294).  Saving model ...\n","792 0.48928916454315186 0.8816901445388794 0.5082940459251404 0.882022500038147 0.5447573065757751 0.8556430339813232\n","Validation loss decreased (0.508294 --> 0.508245).  Saving model ...\n","793 0.4892411231994629 0.8816901445388794 0.5082449913024902 0.882022500038147 0.5447167754173279 0.8556430339813232\n","Validation loss decreased (0.508245 --> 0.508196).  Saving model ...\n","794 0.48919373750686646 0.8816901445388794 0.5081959366798401 0.882022500038147 0.5446767807006836 0.8556430339813232\n","Validation loss decreased (0.508196 --> 0.508147).  Saving model ...\n","795 0.48914581537246704 0.8816901445388794 0.5081471800804138 0.882022500038147 0.544636607170105 0.8556430339813232\n","Validation loss decreased (0.508147 --> 0.508098).  Saving model ...\n","796 0.48909834027290344 0.8816901445388794 0.5080983638763428 0.882022500038147 0.5445964336395264 0.8556430339813232\n","Validation loss decreased (0.508098 --> 0.508050).  Saving model ...\n","797 0.48905062675476074 0.8816901445388794 0.508049726486206 0.882022500038147 0.5445566773414612 0.8556430339813232\n","Validation loss decreased (0.508050 --> 0.508002).  Saving model ...\n","798 0.48900336027145386 0.8816901445388794 0.5080015063285828 0.882022500038147 0.5445165038108826 0.8556430339813232\n","Validation loss decreased (0.508002 --> 0.507953).  Saving model ...\n","799 0.48895618319511414 0.8816901445388794 0.5079526901245117 0.882022500038147 0.5444768667221069 0.8556430339813232\n","Validation loss decreased (0.507953 --> 0.507905).  Saving model ...\n","800 0.488908976316452 0.8816901445388794 0.5079045295715332 0.882022500038147 0.544437050819397 0.8556430339813232\n","Validation loss decreased (0.507905 --> 0.507856).  Saving model ...\n","801 0.48886173963546753 0.8816901445388794 0.5078561902046204 0.882022500038147 0.5443972945213318 0.8556430339813232\n","Validation loss decreased (0.507856 --> 0.507808).  Saving model ...\n","802 0.4888147711753845 0.8816901445388794 0.5078083872795105 0.882022500038147 0.5443577170372009 0.8556430339813232\n","Validation loss decreased (0.507808 --> 0.507760).  Saving model ...\n","803 0.4887676239013672 0.8816901445388794 0.5077602863311768 0.882022500038147 0.5443179607391357 0.8556430339813232\n","Validation loss decreased (0.507760 --> 0.507712).  Saving model ...\n","804 0.48872110247612 0.8816901445388794 0.5077124238014221 0.882022500038147 0.5442787408828735 0.8556430339813232\n","Validation loss decreased (0.507712 --> 0.507665).  Saving model ...\n","805 0.4886738359928131 0.8830986022949219 0.5076646208763123 0.882022500038147 0.5442392230033875 0.8556430339813232\n","Validation loss decreased (0.507665 --> 0.507617).  Saving model ...\n","806 0.48862695693969727 0.8830986022949219 0.5076168179512024 0.882022500038147 0.5441997051239014 0.8556430339813232\n","Validation loss decreased (0.507617 --> 0.507569).  Saving model ...\n","807 0.4885806441307068 0.8830986022949219 0.5075690746307373 0.882022500038147 0.5441603660583496 0.8556430339813232\n","Validation loss decreased (0.507569 --> 0.507522).  Saving model ...\n","808 0.4885338544845581 0.8830986022949219 0.5075218081474304 0.882022500038147 0.5441209673881531 0.8556430339813232\n","Validation loss decreased (0.507522 --> 0.507474).  Saving model ...\n","809 0.48848724365234375 0.8830986022949219 0.5074743032455444 0.882022500038147 0.5440819263458252 0.8556430339813232\n","Validation loss decreased (0.507474 --> 0.507427).  Saving model ...\n","810 0.48844075202941895 0.8830986022949219 0.5074268579483032 0.882022500038147 0.5440430045127869 0.8556430339813232\n","Validation loss decreased (0.507427 --> 0.507380).  Saving model ...\n","811 0.4883946180343628 0.8830986022949219 0.5073796510696411 0.882022500038147 0.5440036654472351 0.8556430339813232\n","Validation loss decreased (0.507380 --> 0.507332).  Saving model ...\n","812 0.48834842443466187 0.8830986022949219 0.507332444190979 0.882022500038147 0.5439648628234863 0.8556430339813232\n","Validation loss decreased (0.507332 --> 0.507285).  Saving model ...\n","813 0.48830223083496094 0.8830986022949219 0.5072854161262512 0.882022500038147 0.5439258813858032 0.8556430339813232\n","Validation loss decreased (0.507285 --> 0.507239).  Saving model ...\n","814 0.48825597763061523 0.8830986022949219 0.5072386860847473 0.882022500038147 0.543887197971344 0.8556430339813232\n","Validation loss decreased (0.507239 --> 0.507191).  Saving model ...\n","815 0.488209992647171 0.8830986022949219 0.5071914792060852 0.882022500038147 0.54384845495224 0.8556430339813232\n","Validation loss decreased (0.507191 --> 0.507145).  Saving model ...\n","816 0.4881639778614044 0.8830986022949219 0.5071447491645813 0.882022500038147 0.5438098311424255 0.8556430339813232\n","Validation loss decreased (0.507145 --> 0.507098).  Saving model ...\n","817 0.488118052482605 0.8830986022949219 0.5070979595184326 0.882022500038147 0.5437709093093872 0.8556430339813232\n","Validation loss decreased (0.507098 --> 0.507052).  Saving model ...\n","818 0.48807206749916077 0.8830986022949219 0.5070515871047974 0.882022500038147 0.543732762336731 0.8556430339813232\n","Validation loss decreased (0.507052 --> 0.507005).  Saving model ...\n","819 0.4880262613296509 0.8830986022949219 0.5070050954818726 0.882022500038147 0.5436941385269165 0.8556430339813232\n","Validation loss decreased (0.507005 --> 0.506958).  Saving model ...\n","820 0.48798054456710815 0.8830986022949219 0.5069584846496582 0.882022500038147 0.5436555743217468 0.8556430339813232\n","Validation loss decreased (0.506958 --> 0.506912).  Saving model ...\n","821 0.487934947013855 0.8830986022949219 0.5069124102592468 0.882022500038147 0.5436170101165771 0.8556430339813232\n","Validation loss decreased (0.506912 --> 0.506866).  Saving model ...\n","822 0.4878896176815033 0.8830986022949219 0.5068662762641907 0.882022500038147 0.5435789823532104 0.8556430339813232\n","Validation loss decreased (0.506866 --> 0.506820).  Saving model ...\n","823 0.4878441393375397 0.8830986022949219 0.506820023059845 0.882022500038147 0.5435407757759094 0.8556430339813232\n","Validation loss decreased (0.506820 --> 0.506774).  Saving model ...\n","824 0.48779886960983276 0.8830986022949219 0.5067740678787231 0.882022500038147 0.543502688407898 0.8556430339813232\n","Validation loss decreased (0.506774 --> 0.506728).  Saving model ...\n","825 0.4877535402774811 0.8830986022949219 0.5067281126976013 0.882022500038147 0.5434645414352417 0.8556430339813232\n","Validation loss decreased (0.506728 --> 0.506682).  Saving model ...\n","826 0.48770830035209656 0.8830986022949219 0.5066821575164795 0.882022500038147 0.543426513671875 0.8556430339813232\n","Validation loss decreased (0.506682 --> 0.506637).  Saving model ...\n","827 0.4876626431941986 0.8845070600509644 0.5066365003585815 0.882022500038147 0.5433886647224426 0.8556430339813232\n","Validation loss decreased (0.506637 --> 0.506591).  Saving model ...\n","828 0.4876178503036499 0.8845070600509644 0.5065905451774597 0.882022500038147 0.5433506369590759 0.8556430339813232\n","Validation loss decreased (0.506591 --> 0.506545).  Saving model ...\n","829 0.4875730276107788 0.8845070600509644 0.5065450668334961 0.882022500038147 0.5433127880096436 0.8556430339813232\n","Validation loss decreased (0.506545 --> 0.506500).  Saving model ...\n","830 0.4875277280807495 0.8845070600509644 0.506499707698822 0.882022500038147 0.5432749390602112 0.8556430339813232\n","Validation loss decreased (0.506500 --> 0.506454).  Saving model ...\n","831 0.4874829053878784 0.8845070600509644 0.506454348564148 0.882022500038147 0.5432371497154236 0.8556430339813232\n","Validation loss decreased (0.506454 --> 0.506409).  Saving model ...\n","832 0.4874383807182312 0.8845070600509644 0.5064089894294739 0.882022500038147 0.5431996583938599 0.8556430339813232\n","Validation loss decreased (0.506409 --> 0.506364).  Saving model ...\n","833 0.48739364743232727 0.8845070600509644 0.5063636302947998 0.882022500038147 0.5431621670722961 0.8556430339813232\n","Validation loss decreased (0.506364 --> 0.506319).  Saving model ...\n","834 0.48734843730926514 0.8845070600509644 0.5063186883926392 0.882022500038147 0.5431245565414429 0.8556430339813232\n","Validation loss decreased (0.506319 --> 0.506274).  Saving model ...\n","835 0.4873041808605194 0.8845070600509644 0.5062735080718994 0.882022500038147 0.5430871844291687 0.8556430339813232\n","Validation loss decreased (0.506274 --> 0.506229).  Saving model ...\n","836 0.48725956678390503 0.8845070600509644 0.506228506565094 0.882022500038147 0.543049693107605 0.8556430339813232\n","Validation loss decreased (0.506229 --> 0.506184).  Saving model ...\n","837 0.4872148334980011 0.8845070600509644 0.5061835646629333 0.882022500038147 0.5430123805999756 0.8556430339813232\n","Validation loss decreased (0.506184 --> 0.506139).  Saving model ...\n","838 0.48717039823532104 0.8845070600509644 0.506138801574707 0.882022500038147 0.5429753661155701 0.8556430339813232\n","Validation loss decreased (0.506139 --> 0.506094).  Saving model ...\n","839 0.48712632060050964 0.8845070600509644 0.5060939788818359 0.882022500038147 0.5429377555847168 0.8556430339813232\n","Validation loss decreased (0.506094 --> 0.506050).  Saving model ...\n","840 0.48708242177963257 0.8845070600509644 0.5060495138168335 0.882022500038147 0.5429010987281799 0.8556430339813232\n","Validation loss decreased (0.506050 --> 0.506005).  Saving model ...\n","841 0.48703816533088684 0.8845070600509644 0.5060048699378967 0.882022500038147 0.5428635478019714 0.8556430339813232\n","Validation loss decreased (0.506005 --> 0.505961).  Saving model ...\n","842 0.48699408769607544 0.8845070600509644 0.5059607028961182 0.882022500038147 0.5428264737129211 0.8556430339813232\n","Validation loss decreased (0.505961 --> 0.505916).  Saving model ...\n","843 0.4869496822357178 0.8845070600509644 0.505916178226471 0.882022500038147 0.5427898168563843 0.8556430339813232\n","Validation loss decreased (0.505916 --> 0.505872).  Saving model ...\n","844 0.48690569400787354 0.8845070600509644 0.5058720111846924 0.882022500038147 0.542752742767334 0.8556430339813232\n","Validation loss decreased (0.505872 --> 0.505828).  Saving model ...\n","845 0.48686179518699646 0.8845070600509644 0.5058276057243347 0.882022500038147 0.5427165031433105 0.8556430339813232\n","Validation loss decreased (0.505828 --> 0.505784).  Saving model ...\n","846 0.48681795597076416 0.8845070600509644 0.5057836771011353 0.882022500038147 0.5426793694496155 0.8556430339813232\n","Validation loss decreased (0.505784 --> 0.505739).  Saving model ...\n","847 0.486774206161499 0.8845070600509644 0.5057393908500671 0.882022500038147 0.5426424145698547 0.8556430339813232\n","Validation loss decreased (0.505739 --> 0.505696).  Saving model ...\n","848 0.48673078417778015 0.8845070600509644 0.5056955218315125 0.882022500038147 0.5426060557365417 0.8556430339813232\n","Validation loss decreased (0.505696 --> 0.505652).  Saving model ...\n","849 0.4866870939731598 0.8845070600509644 0.5056518316268921 0.882022500038147 0.5425692200660706 0.8556430339813232\n","Validation loss decreased (0.505652 --> 0.505608).  Saving model ...\n","850 0.48664361238479614 0.8845070600509644 0.5056080222129822 0.882022500038147 0.5425329804420471 0.8556430339813232\n","Validation loss decreased (0.505608 --> 0.505564).  Saving model ...\n","851 0.4866001307964325 0.8845070600509644 0.5055643916130066 0.882022500038147 0.5424960255622864 0.8556430339813232\n","Validation loss decreased (0.505564 --> 0.505521).  Saving model ...\n","852 0.4865567684173584 0.8845070600509644 0.5055206418037415 0.882022500038147 0.542460024356842 0.8556430339813232\n","Validation loss decreased (0.505521 --> 0.505477).  Saving model ...\n","853 0.4865129590034485 0.8845070600509644 0.5054770112037659 0.882022500038147 0.5424235463142395 0.8556430339813232\n","Validation loss decreased (0.505477 --> 0.505434).  Saving model ...\n","854 0.48647013306617737 0.8845070600509644 0.5054336190223694 0.882022500038147 0.5423871278762817 0.8556430339813232\n","Validation loss decreased (0.505434 --> 0.505390).  Saving model ...\n","855 0.48642686009407043 0.8845070600509644 0.5053902268409729 0.882022500038147 0.5423510074615479 0.8556430339813232\n","Validation loss decreased (0.505390 --> 0.505347).  Saving model ...\n","856 0.48638346791267395 0.8845070600509644 0.5053470134735107 0.882022500038147 0.5423149466514587 0.8556430339813232\n","Validation loss decreased (0.505347 --> 0.505304).  Saving model ...\n","857 0.48634016513824463 0.8845070600509644 0.5053038001060486 0.882022500038147 0.5422788262367249 0.8556430339813232\n","Validation loss decreased (0.505304 --> 0.505261).  Saving model ...\n","858 0.4862975478172302 0.8845070600509644 0.5052608251571655 0.882022500038147 0.5422427654266357 0.8556430339813232\n","Validation loss decreased (0.505261 --> 0.505218).  Saving model ...\n","859 0.4862547516822815 0.8845070600509644 0.5052177906036377 0.882022500038147 0.5422068238258362 0.8556430339813232\n","Validation loss decreased (0.505218 --> 0.505175).  Saving model ...\n","860 0.48621177673339844 0.8845070600509644 0.5051748156547546 0.882022500038147 0.5421710014343262 0.8556430339813232\n","Validation loss decreased (0.505175 --> 0.505132).  Saving model ...\n","861 0.48616886138916016 0.8845070600509644 0.5051319003105164 0.882022500038147 0.5421351194381714 0.8556430339813232\n","Validation loss decreased (0.505132 --> 0.505089).  Saving model ...\n","862 0.48612645268440247 0.8845070600509644 0.5050891637802124 0.882022500038147 0.5420990586280823 0.8556430339813232\n","Validation loss decreased (0.505089 --> 0.505046).  Saving model ...\n","863 0.48608335852622986 0.8845070600509644 0.5050463080406189 0.882022500038147 0.5420634746551514 0.8556430339813232\n","Validation loss decreased (0.505046 --> 0.505004).  Saving model ...\n","864 0.48604080080986023 0.8845070600509644 0.5050035715103149 0.882022500038147 0.5420279502868652 0.8582677245140076\n","Validation loss decreased (0.505004 --> 0.504961).  Saving model ...\n","865 0.48599836230278015 0.8845070600509644 0.5049610137939453 0.882022500038147 0.5419920086860657 0.8582677245140076\n","Validation loss decreased (0.504961 --> 0.504919).  Saving model ...\n","866 0.48595550656318665 0.8845070600509644 0.5049185156822205 0.882022500038147 0.5419566035270691 0.8582677245140076\n","Validation loss decreased (0.504919 --> 0.504876).  Saving model ...\n","867 0.48591333627700806 0.8845070600509644 0.5048762559890747 0.882022500038147 0.5419214367866516 0.8582677245140076\n","Validation loss decreased (0.504876 --> 0.504834).  Saving model ...\n","868 0.4858708381652832 0.8845070600509644 0.5048338174819946 0.8876404762268066 0.5418856739997864 0.8582677245140076\n","Validation loss decreased (0.504834 --> 0.504792).  Saving model ...\n","869 0.48582878708839417 0.8845070600509644 0.5047916769981384 0.8876404762268066 0.5418502688407898 0.8582677245140076\n","Validation loss decreased (0.504792 --> 0.504749).  Saving model ...\n","870 0.48578667640686035 0.8845070600509644 0.5047494769096375 0.8876404762268066 0.5418150424957275 0.8582677245140076\n","Validation loss decreased (0.504749 --> 0.504707).  Saving model ...\n","871 0.48574450612068176 0.8845070600509644 0.5047072768211365 0.8876404762268066 0.5417798757553101 0.8582677245140076\n","Validation loss decreased (0.504707 --> 0.504665).  Saving model ...\n","872 0.4857024550437927 0.8845070600509644 0.5046653151512146 0.8876404762268066 0.5417443513870239 0.8582677245140076\n","Validation loss decreased (0.504665 --> 0.504623).  Saving model ...\n","873 0.4856603443622589 0.8845070600509644 0.504623293876648 0.8876404762268066 0.5417091846466064 0.8582677245140076\n","Validation loss decreased (0.504623 --> 0.504581).  Saving model ...\n","874 0.4856182336807251 0.8845070600509644 0.5045814514160156 0.8876404762268066 0.541674017906189 0.8582677245140076\n","Validation loss decreased (0.504581 --> 0.504540).  Saving model ...\n","875 0.48557621240615845 0.8845070600509644 0.5045398473739624 0.8876404762268066 0.5416393280029297 0.8582677245140076\n","Validation loss decreased (0.504540 --> 0.504498).  Saving model ...\n","876 0.48553451895713806 0.8845070600509644 0.5044981241226196 0.8876404762268066 0.5416041612625122 0.8582677245140076\n","Validation loss decreased (0.504498 --> 0.504456).  Saving model ...\n","877 0.4854927062988281 0.8845070600509644 0.5044562220573425 0.8876404762268066 0.5415692925453186 0.8582677245140076\n","Validation loss decreased (0.504456 --> 0.504415).  Saving model ...\n","878 0.4854509234428406 0.8845070600509644 0.504414975643158 0.8876404762268066 0.5415343046188354 0.8582677245140076\n","Validation loss decreased (0.504415 --> 0.504373).  Saving model ...\n","879 0.48540934920310974 0.8845070600509644 0.5043731927871704 0.8876404762268066 0.5414995551109314 0.8582677245140076\n","Validation loss decreased (0.504373 --> 0.504332).  Saving model ...\n","880 0.4853675663471222 0.8845070600509644 0.5043317675590515 0.8876404762268066 0.5414647459983826 0.8582677245140076\n","Validation loss decreased (0.504332 --> 0.504291).  Saving model ...\n","881 0.48532599210739136 0.8845070600509644 0.5042905211448669 0.8876404762268066 0.5414301156997681 0.8582677245140076\n","Validation loss decreased (0.504291 --> 0.504249).  Saving model ...\n","882 0.4852847158908844 0.8845070600509644 0.504249095916748 0.8876404762268066 0.5413953065872192 0.8582677245140076\n","Validation loss decreased (0.504249 --> 0.504208).  Saving model ...\n","883 0.4852431118488312 0.8845070600509644 0.5042082071304321 0.8876404762268066 0.5413607358932495 0.8582677245140076\n","Validation loss decreased (0.504208 --> 0.504167).  Saving model ...\n","884 0.4852016270160675 0.8845070600509644 0.5041671395301819 0.8876404762268066 0.5413260459899902 0.8582677245140076\n","Validation loss decreased (0.504167 --> 0.504126).  Saving model ...\n","885 0.48516011238098145 0.8845070600509644 0.5041257739067078 0.8876404762268066 0.5412915945053101 0.8582677245140076\n","Validation loss decreased (0.504126 --> 0.504085).  Saving model ...\n","886 0.4851190745830536 0.8845070600509644 0.5040847659111023 0.8876404762268066 0.5412570834159851 0.8582677245140076\n","Validation loss decreased (0.504085 --> 0.504044).  Saving model ...\n","887 0.4850781261920929 0.8845070600509644 0.504044234752655 0.8876404762268066 0.541222870349884 0.8582677245140076\n","Validation loss decreased (0.504044 --> 0.504003).  Saving model ...\n","888 0.485036700963974 0.8845070600509644 0.5040032863616943 0.8876404762268066 0.5411885380744934 0.8582677245140076\n","Validation loss decreased (0.504003 --> 0.503962).  Saving model ...\n","889 0.48499584197998047 0.8845070600509644 0.5039623975753784 0.8876404762268066 0.5411545038223267 0.8582677245140076\n","Validation loss decreased (0.503962 --> 0.503922).  Saving model ...\n","890 0.48495495319366455 0.8845070600509644 0.5039219856262207 0.8876404762268066 0.5411202311515808 0.8582677245140076\n","Validation loss decreased (0.503922 --> 0.503881).  Saving model ...\n","891 0.48491400480270386 0.8845070600509644 0.5038811564445496 0.8876404762268066 0.541085958480835 0.8582677245140076\n","Validation loss decreased (0.503881 --> 0.503841).  Saving model ...\n","892 0.48487281799316406 0.8845070600509644 0.5038407444953918 0.8876404762268066 0.5410515666007996 0.8582677245140076\n","Validation loss decreased (0.503841 --> 0.503800).  Saving model ...\n","893 0.4848323464393616 0.8845070600509644 0.5038003921508789 0.8876404762268066 0.5410176515579224 0.8582677245140076\n","Validation loss decreased (0.503800 --> 0.503760).  Saving model ...\n","894 0.4847915470600128 0.8845070600509644 0.5037597417831421 0.8876404762268066 0.5409839749336243 0.8582677245140076\n","Validation loss decreased (0.503760 --> 0.503719).  Saving model ...\n","895 0.48475074768066406 0.8845070600509644 0.5037194490432739 0.8876404762268066 0.5409500002861023 0.8582677245140076\n","Validation loss decreased (0.503719 --> 0.503679).  Saving model ...\n","896 0.4847102463245392 0.8845070600509644 0.5036793947219849 0.8876404762268066 0.5409159064292908 0.8582677245140076\n","Validation loss decreased (0.503679 --> 0.503639).  Saving model ...\n","897 0.4846695065498352 0.8845070600509644 0.5036390423774719 0.8876404762268066 0.5408821105957031 0.8582677245140076\n","Validation loss decreased (0.503639 --> 0.503599).  Saving model ...\n","898 0.48462891578674316 0.8845070600509644 0.5035989880561829 0.8876404762268066 0.5408483743667603 0.8582677245140076\n","Validation loss decreased (0.503599 --> 0.503559).  Saving model ...\n","899 0.4845883250236511 0.8845070600509644 0.5035589933395386 0.8876404762268066 0.5408148169517517 0.8582677245140076\n","Validation loss decreased (0.503559 --> 0.503519).  Saving model ...\n","900 0.48454779386520386 0.8845070600509644 0.5035188794136047 0.8876404762268066 0.5407809019088745 0.8582677245140076\n","Validation loss decreased (0.503519 --> 0.503479).  Saving model ...\n","901 0.4845075011253357 0.8845070600509644 0.5034790635108948 0.8876404762268066 0.5407474637031555 0.8582677245140076\n","Validation loss decreased (0.503479 --> 0.503439).  Saving model ...\n","902 0.4844677746295929 0.8845070600509644 0.5034390687942505 0.8876404762268066 0.5407134294509888 0.8582677245140076\n","Validation loss decreased (0.503439 --> 0.503400).  Saving model ...\n","903 0.48442745208740234 0.8845070600509644 0.5033995509147644 0.8876404762268066 0.5406799912452698 0.8582677245140076\n","Validation loss decreased (0.503400 --> 0.503360).  Saving model ...\n","904 0.48438718914985657 0.8845070600509644 0.5033597946166992 0.8876404762268066 0.5406468510627747 0.8582677245140076\n","Validation loss decreased (0.503360 --> 0.503320).  Saving model ...\n","905 0.48434722423553467 0.8845070600509644 0.5033200979232788 0.8876404762268066 0.5406132936477661 0.8582677245140076\n","Validation loss decreased (0.503320 --> 0.503281).  Saving model ...\n","906 0.4843069016933441 0.8845070600509644 0.5032806396484375 0.8876404762268066 0.5405800342559814 0.8582677245140076\n","Validation loss decreased (0.503281 --> 0.503241).  Saving model ...\n","907 0.48426681756973267 0.8845070600509644 0.5032411217689514 0.8876404762268066 0.5405466556549072 0.8582677245140076\n","Validation loss decreased (0.503241 --> 0.503202).  Saving model ...\n","908 0.48422715067863464 0.8845070600509644 0.5032016038894653 0.8876404762268066 0.5405132174491882 0.8582677245140076\n","Validation loss decreased (0.503202 --> 0.503162).  Saving model ...\n","909 0.4841872751712799 0.8845070600509644 0.5031623840332031 0.8876404762268066 0.5404804348945618 0.8582677245140076\n","Validation loss decreased (0.503162 --> 0.503123).  Saving model ...\n","910 0.4841471314430237 0.8845070600509644 0.5031229257583618 0.8876404762268066 0.5404471755027771 0.8582677245140076\n","Validation loss decreased (0.503123 --> 0.503084).  Saving model ...\n","911 0.4841079115867615 0.8845070600509644 0.5030840039253235 0.8876404762268066 0.5404141545295715 0.8582677245140076\n","Validation loss decreased (0.503084 --> 0.503045).  Saving model ...\n","912 0.4840676784515381 0.8845070600509644 0.5030446648597717 0.8876404762268066 0.5403808951377869 0.8582677245140076\n","Validation loss decreased (0.503045 --> 0.503006).  Saving model ...\n","913 0.4840278923511505 0.8830986022949219 0.5030055642127991 0.8876404762268066 0.5403478741645813 0.8582677245140076\n","Validation loss decreased (0.503006 --> 0.502967).  Saving model ...\n","914 0.4839882552623749 0.8830986022949219 0.502966582775116 0.8876404762268066 0.5403149127960205 0.8582677245140076\n","Validation loss decreased (0.502967 --> 0.502928).  Saving model ...\n","915 0.48394909501075745 0.8830986022949219 0.5029276609420776 0.8876404762268066 0.540282130241394 0.8582677245140076\n","Validation loss decreased (0.502928 --> 0.502889).  Saving model ...\n","916 0.48390936851501465 0.8830986022949219 0.5028886198997498 0.8876404762268066 0.540249228477478 0.8582677245140076\n","Validation loss decreased (0.502889 --> 0.502850).  Saving model ...\n","917 0.4838702082633972 0.8830986022949219 0.5028498768806458 0.8876404762268066 0.5402167439460754 0.8582677245140076\n","Validation loss decreased (0.502850 --> 0.502811).  Saving model ...\n","918 0.4838305115699768 0.8830986022949219 0.502811074256897 0.8876404762268066 0.5401838421821594 0.8582677245140076\n","Validation loss decreased (0.502811 --> 0.502773).  Saving model ...\n","919 0.4837912321090698 0.8830986022949219 0.5027725100517273 0.8876404762268066 0.540151059627533 0.8582677245140076\n","Validation loss decreased (0.502773 --> 0.502734).  Saving model ...\n","920 0.48375195264816284 0.8830986022949219 0.5027337670326233 0.8876404762268066 0.540118396282196 0.8582677245140076\n","Validation loss decreased (0.502734 --> 0.502695).  Saving model ...\n","921 0.4837127923965454 0.8830986022949219 0.5026953220367432 0.8876404762268066 0.5400855541229248 0.8582677245140076\n","Validation loss decreased (0.502695 --> 0.502657).  Saving model ...\n","922 0.4836737811565399 0.8830986022949219 0.5026568174362183 0.8876404762268066 0.5400531888008118 0.8582677245140076\n","Validation loss decreased (0.502657 --> 0.502618).  Saving model ...\n","923 0.483634352684021 0.8830986022949219 0.5026184320449829 0.8876404762268066 0.5400206446647644 0.8582677245140076\n","Validation loss decreased (0.502618 --> 0.502580).  Saving model ...\n","924 0.48359546065330505 0.8830986022949219 0.5025801658630371 0.8876404762268066 0.5399883389472961 0.8582677245140076\n","Validation loss decreased (0.502580 --> 0.502542).  Saving model ...\n","925 0.48355650901794434 0.8830986022949219 0.502541720867157 0.8876404762268066 0.5399560332298279 0.8582677245140076\n","Validation loss decreased (0.502542 --> 0.502503).  Saving model ...\n","926 0.48351773619651794 0.8830986022949219 0.5025033950805664 0.8876404762268066 0.5399235486984253 0.8582677245140076\n","Validation loss decreased (0.502503 --> 0.502465).  Saving model ...\n","927 0.48347896337509155 0.8830986022949219 0.5024651885032654 0.8876404762268066 0.539891242980957 0.8582677245140076\n","Validation loss decreased (0.502465 --> 0.502427).  Saving model ...\n","928 0.4834398627281189 0.8830986022949219 0.5024272203445435 0.8876404762268066 0.5398592948913574 0.8582677245140076\n","Validation loss decreased (0.502427 --> 0.502389).  Saving model ...\n","929 0.48340120911598206 0.8830986022949219 0.5023892521858215 0.8876404762268066 0.5398269891738892 0.8582677245140076\n","Validation loss decreased (0.502389 --> 0.502351).  Saving model ...\n","930 0.4833625555038452 0.8830986022949219 0.5023511052131653 0.8876404762268066 0.539794921875 0.8582677245140076\n","Validation loss decreased (0.502351 --> 0.502313).  Saving model ...\n","931 0.4833233654499054 0.8830986022949219 0.5023133158683777 0.8876404762268066 0.539762556552887 0.8582677245140076\n","Validation loss decreased (0.502313 --> 0.502275).  Saving model ...\n","932 0.48328495025634766 0.8830986022949219 0.5022753477096558 0.8876404762268066 0.5397309064865112 0.8582677245140076\n","Validation loss decreased (0.502275 --> 0.502238).  Saving model ...\n","933 0.48324650526046753 0.8830986022949219 0.5022376179695129 0.8876404762268066 0.5396984219551086 0.8582677245140076\n","Validation loss decreased (0.502238 --> 0.502200).  Saving model ...\n","934 0.4832077920436859 0.8830986022949219 0.5021998286247253 0.8876404762268066 0.5396665930747986 0.8582677245140076\n","Validation loss decreased (0.502200 --> 0.502162).  Saving model ...\n","935 0.48316970467567444 0.8830986022949219 0.5021622180938721 0.8876404762268066 0.5396347045898438 0.8582677245140076\n","Validation loss decreased (0.502162 --> 0.502125).  Saving model ...\n","936 0.4831309914588928 0.8830986022949219 0.5021247863769531 0.8876404762268066 0.5396031141281128 0.8582677245140076\n","Validation loss decreased (0.502125 --> 0.502087).  Saving model ...\n","937 0.48309266567230225 0.8830986022949219 0.5020871758460999 0.8876404762268066 0.5395713448524475 0.8582677245140076\n","Validation loss decreased (0.502087 --> 0.502049).  Saving model ...\n","938 0.48305439949035645 0.8830986022949219 0.502049446105957 0.8876404762268066 0.5395392775535583 0.8582677245140076\n","Validation loss decreased (0.502049 --> 0.502012).  Saving model ...\n","939 0.4830159544944763 0.8830986022949219 0.5020121335983276 0.8876404762268066 0.5395076870918274 0.8582677245140076\n","Validation loss decreased (0.502012 --> 0.501975).  Saving model ...\n","940 0.4829781949520111 0.8830986022949219 0.5019748210906982 0.8876404762268066 0.5394758582115173 0.8582677245140076\n","Validation loss decreased (0.501975 --> 0.501938).  Saving model ...\n","941 0.4829399585723877 0.8830986022949219 0.5019375085830688 0.8876404762268066 0.539444088935852 0.8582677245140076\n","Validation loss decreased (0.501938 --> 0.501900).  Saving model ...\n","942 0.48290151357650757 0.8830986022949219 0.5019002556800842 0.8876404762268066 0.5394124984741211 0.8582677245140076\n","Validation loss decreased (0.501900 --> 0.501863).  Saving model ...\n","943 0.4828638434410095 0.8830986022949219 0.5018630027770996 0.8876404762268066 0.5393811464309692 0.8582677245140076\n","Validation loss decreased (0.501863 --> 0.501826).  Saving model ...\n","944 0.48282569646835327 0.8830986022949219 0.501825749874115 0.8876404762268066 0.5393499135971069 0.8582677245140076\n","Validation loss decreased (0.501826 --> 0.501789).  Saving model ...\n","945 0.48278748989105225 0.8830986022949219 0.501788854598999 0.8876404762268066 0.539318323135376 0.8582677245140076\n","Validation loss decreased (0.501789 --> 0.501751).  Saving model ...\n","946 0.4827498495578766 0.8830986022949219 0.5017514824867249 0.8876404762268066 0.5392873287200928 0.8582677245140076\n","Validation loss decreased (0.501751 --> 0.501715).  Saving model ...\n","947 0.482712060213089 0.8830986022949219 0.5017147660255432 0.8876404762268066 0.5392557382583618 0.8582677245140076\n","Validation loss decreased (0.501715 --> 0.501678).  Saving model ...\n","948 0.4826743006706238 0.8830986022949219 0.5016780495643616 0.8876404762268066 0.53922438621521 0.8582677245140076\n","Validation loss decreased (0.501678 --> 0.501641).  Saving model ...\n","949 0.48263683915138245 0.8830986022949219 0.5016412138938904 0.8876404762268066 0.5391932725906372 0.8582677245140076\n","Validation loss decreased (0.501641 --> 0.501604).  Saving model ...\n","950 0.4825989305973053 0.8830986022949219 0.5016043782234192 0.8876404762268066 0.5391619801521301 0.8582677245140076\n","Validation loss decreased (0.501604 --> 0.501568).  Saving model ...\n","951 0.4825612008571625 0.8830986022949219 0.501567542552948 0.8876404762268066 0.5391309261322021 0.8582677245140076\n","Validation loss decreased (0.501568 --> 0.501531).  Saving model ...\n","952 0.48252370953559875 0.8830986022949219 0.5015308856964111 0.8876404762268066 0.5390998721122742 0.8582677245140076\n","Validation loss decreased (0.501531 --> 0.501495).  Saving model ...\n","953 0.48248597979545593 0.8830986022949219 0.5014945268630981 0.8876404762268066 0.5390686988830566 0.8582677245140076\n","Validation loss decreased (0.501495 --> 0.501458).  Saving model ...\n","954 0.48244839906692505 0.8830986022949219 0.5014578700065613 0.8876404762268066 0.5390377044677734 0.8582677245140076\n","Validation loss decreased (0.501458 --> 0.501421).  Saving model ...\n","955 0.48241087794303894 0.8830986022949219 0.5014212727546692 0.8876404762268066 0.5390069484710693 0.8582677245140076\n","Validation loss decreased (0.501421 --> 0.501385).  Saving model ...\n","956 0.48237377405166626 0.8830986022949219 0.501384973526001 0.8876404762268066 0.53897625207901 0.8582677245140076\n","Validation loss decreased (0.501385 --> 0.501349).  Saving model ...\n","957 0.4823363721370697 0.8830986022949219 0.5013485550880432 0.8876404762268066 0.5389449000358582 0.8582677245140076\n","Validation loss decreased (0.501349 --> 0.501312).  Saving model ...\n","958 0.482298880815506 0.8830986022949219 0.5013123750686646 0.8876404762268066 0.5389143824577332 0.8582677245140076\n","Validation loss decreased (0.501312 --> 0.501276).  Saving model ...\n","959 0.48226213455200195 0.8845070600509644 0.5012762546539307 0.8876404762268066 0.5388835072517395 0.8582677245140076\n","Validation loss decreased (0.501276 --> 0.501240).  Saving model ...\n","960 0.48222455382347107 0.8845070600509644 0.5012399554252625 0.8876404762268066 0.5388529896736145 0.8582677245140076\n","Validation loss decreased (0.501240 --> 0.501204).  Saving model ...\n","961 0.48218753933906555 0.8845070600509644 0.5012036561965942 0.8876404762268066 0.5388222336769104 0.8582677245140076\n","Validation loss decreased (0.501204 --> 0.501168).  Saving model ...\n","962 0.48215070366859436 0.8845070600509644 0.5011675357818604 0.8876404762268066 0.5387919545173645 0.8582677245140076\n","Validation loss decreased (0.501168 --> 0.501132).  Saving model ...\n","963 0.4821135699748993 0.8845070600509644 0.501131534576416 0.8876404762268066 0.5387610793113708 0.8582677245140076\n","Validation loss decreased (0.501132 --> 0.501096).  Saving model ...\n","964 0.4820760190486908 0.8845070600509644 0.5010956525802612 0.8876404762268066 0.5387304425239563 0.8582677245140076\n","Validation loss decreased (0.501096 --> 0.501060).  Saving model ...\n","965 0.48203885555267334 0.8845070600509644 0.501059889793396 0.8876404762268066 0.5386999249458313 0.8582677245140076\n","Validation loss decreased (0.501060 --> 0.501024).  Saving model ...\n","966 0.48200252652168274 0.8845070600509644 0.5010238885879517 0.8876404762268066 0.5386697053909302 0.8582677245140076\n","Validation loss decreased (0.501024 --> 0.500988).  Saving model ...\n","967 0.4819656014442444 0.8845070600509644 0.5009880065917969 0.8876404762268066 0.5386390686035156 0.8582677245140076\n","Validation loss decreased (0.500988 --> 0.500953).  Saving model ...\n","968 0.48192885518074036 0.8845070600509644 0.5009526610374451 0.8876404762268066 0.5386090278625488 0.8582677245140076\n","Validation loss decreased (0.500953 --> 0.500917).  Saving model ...\n","969 0.4818922281265259 0.8845070600509644 0.5009165406227112 0.8876404762268066 0.5385783910751343 0.8582677245140076\n","Validation loss decreased (0.500917 --> 0.500881).  Saving model ...\n","970 0.4818558394908905 0.8845070600509644 0.5008809566497803 0.8876404762268066 0.5385481715202332 0.8582677245140076\n","Validation loss decreased (0.500881 --> 0.500845).  Saving model ...\n","971 0.4818187952041626 0.8845070600509644 0.5008454322814941 0.8876404762268066 0.5385178923606873 0.8582677245140076\n","Validation loss decreased (0.500845 --> 0.500810).  Saving model ...\n","972 0.48178228735923767 0.8845070600509644 0.5008100867271423 0.8876404762268066 0.5384877324104309 0.8582677245140076\n","Validation loss decreased (0.500810 --> 0.500774).  Saving model ...\n","973 0.4817454516887665 0.8845070600509644 0.5007742643356323 0.8876404762268066 0.5384576320648193 0.8582677245140076\n","Validation loss decreased (0.500774 --> 0.500739).  Saving model ...\n","974 0.4817090332508087 0.8845070600509644 0.5007390975952148 0.8876404762268066 0.5384277701377869 0.8582677245140076\n","Validation loss decreased (0.500739 --> 0.500704).  Saving model ...\n","975 0.48167240619659424 0.8845070600509644 0.5007035732269287 0.8876404762268066 0.538397490978241 0.8582677245140076\n","Validation loss decreased (0.500704 --> 0.500668).  Saving model ...\n","976 0.4816362261772156 0.8845070600509644 0.5006683468818665 0.8876404762268066 0.538367509841919 0.8582677245140076\n","Validation loss decreased (0.500668 --> 0.500633).  Saving model ...\n","977 0.48159968852996826 0.8845070600509644 0.5006331205368042 0.8876404762268066 0.5383376479148865 0.8582677245140076\n","Validation loss decreased (0.500633 --> 0.500598).  Saving model ...\n","978 0.48156365752220154 0.8845070600509644 0.5005978941917419 0.8876404762268066 0.5383079648017883 0.8582677245140076\n","Validation loss decreased (0.500598 --> 0.500563).  Saving model ...\n","979 0.4815271198749542 0.8845070600509644 0.5005627870559692 0.8876404762268066 0.538277804851532 0.8582677245140076\n","Validation loss decreased (0.500563 --> 0.500528).  Saving model ...\n","980 0.4814911484718323 0.8845070600509644 0.5005276799201965 0.8876404762268066 0.5382480025291443 0.8582677245140076\n","Validation loss decreased (0.500528 --> 0.500493).  Saving model ...\n","981 0.4814545810222626 0.8845070600509644 0.5004925727844238 0.8876404762268066 0.5382183790206909 0.8582677245140076\n","Validation loss decreased (0.500493 --> 0.500457).  Saving model ...\n","982 0.48141855001449585 0.8845070600509644 0.5004574060440063 0.8876404762268066 0.5381884574890137 0.8608924150466919\n","Validation loss decreased (0.500457 --> 0.500423).  Saving model ...\n","983 0.4813826382160187 0.8845070600509644 0.5004226565361023 0.8876404762268066 0.5381590127944946 0.8608924150466919\n","Validation loss decreased (0.500423 --> 0.500388).  Saving model ...\n","984 0.48134645819664 0.8845070600509644 0.5003875494003296 0.8876404762268066 0.5381293296813965 0.8608924150466919\n","Validation loss decreased (0.500388 --> 0.500353).  Saving model ...\n","985 0.4813106656074524 0.8845070600509644 0.5003529191017151 0.8876404762268066 0.5380995869636536 0.8608924150466919\n","Validation loss decreased (0.500353 --> 0.500318).  Saving model ...\n","986 0.4812745153903961 0.8845070600509644 0.5003183484077454 0.8876404762268066 0.5380699038505554 0.8608924150466919\n","Validation loss decreased (0.500318 --> 0.500283).  Saving model ...\n","987 0.4812386929988861 0.8845070600509644 0.5002833008766174 0.8876404762268066 0.5380404591560364 0.8608924150466919\n","Validation loss decreased (0.500283 --> 0.500249).  Saving model ...\n","988 0.48120298981666565 0.8845070600509644 0.5002486705780029 0.8876404762268066 0.5380110144615173 0.8608924150466919\n","Validation loss decreased (0.500249 --> 0.500214).  Saving model ...\n","989 0.48116666078567505 0.8845070600509644 0.5002142786979675 0.8876404762268066 0.5379816293716431 0.8608924150466919\n","Validation loss decreased (0.500214 --> 0.500179).  Saving model ...\n","990 0.481130987405777 0.8845070600509644 0.5001794099807739 0.8876404762268066 0.5379521250724792 0.8608924150466919\n","Validation loss decreased (0.500179 --> 0.500145).  Saving model ...\n","991 0.48109543323516846 0.8845070600509644 0.5001451373100281 0.8876404762268066 0.5379229784011841 0.8608924150466919\n","Validation loss decreased (0.500145 --> 0.500111).  Saving model ...\n","992 0.48105955123901367 0.8845070600509644 0.5001105070114136 0.8876404762268066 0.5378936529159546 0.8608924150466919\n","Validation loss decreased (0.500111 --> 0.500076).  Saving model ...\n","993 0.4810240566730499 0.8845070600509644 0.5000760555267334 0.8876404762268066 0.5378644466400146 0.8608924150466919\n","Validation loss decreased (0.500076 --> 0.500042).  Saving model ...\n","994 0.480988472700119 0.8859155178070068 0.500041663646698 0.8876404762268066 0.5378351807594299 0.8608924150466919\n","Validation loss decreased (0.500042 --> 0.500007).  Saving model ...\n","995 0.48095273971557617 0.8859155178070068 0.5000073313713074 0.8876404762268066 0.53780597448349 0.8608924150466919\n","Validation loss decreased (0.500007 --> 0.499973).  Saving model ...\n","996 0.4809173345565796 0.8859155178070068 0.49997299909591675 0.8876404762268066 0.53777676820755 0.8608924150466919\n","Validation loss decreased (0.499973 --> 0.499939).  Saving model ...\n","997 0.4808817207813263 0.8859155178070068 0.4999389946460724 0.8876404762268066 0.5377478003501892 0.8608924150466919\n","Validation loss decreased (0.499939 --> 0.499905).  Saving model ...\n","998 0.4808462858200073 0.8859155178070068 0.4999047815799713 0.8876404762268066 0.5377185344696045 0.8608924150466919\n","Validation loss decreased (0.499905 --> 0.499871).  Saving model ...\n","999 0.48081114888191223 0.8859155178070068 0.499870628118515 0.8876404762268066 0.5376895666122437 0.8608924150466919\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"id":"erpioWsYtaUa","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"executionInfo":{"status":"ok","timestamp":1593325615624,"user_tz":180,"elapsed":105773,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"e7f990b8-14bf-49cc-af64-e5cba926dd58"},"source":["print(Precision(prediction, Y_train_tensor))\n","print(Precision(val_prediction, Y_valid_tensor))\n","print(Precision(test_prediction, Y_test_tensor))"],"execution_count":25,"outputs":[{"output_type":"stream","text":["[0.9566786885261536, 0.6346153616905212]\n","[0.9440559148788452, 0.6571428775787354]\n","[0.9260450005531311, 0.5714285969734192]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Qu2e4Qh38lp4","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"executionInfo":{"status":"ok","timestamp":1593325615624,"user_tz":180,"elapsed":105768,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"0b5193b2-3c7a-4dbc-98fa-15a5ad8486cd"},"source":["print(Recall(prediction, Y_train_tensor))\n","print(Recall(val_prediction, Y_valid_tensor))\n","print(Recall(test_prediction, Y_test_tensor))"],"execution_count":26,"outputs":[{"output_type":"stream","text":["[0.9028961062431335, 0.8048780560493469]\n","[0.918367326259613, 0.7419354915618896]\n","[0.9056603908538818, 0.6349206566810608]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5IoA1jJGBW2Q","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"executionInfo":{"status":"ok","timestamp":1593325615625,"user_tz":180,"elapsed":105763,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"12b42ca6-4969-440d-beb6-1360a6119c1e"},"source":["print(Accuracy(prediction, Y_train_tensor))\n","print(Accuracy(val_prediction, Y_valid_tensor))\n","print(Accuracy(test_prediction, Y_test_tensor))"],"execution_count":27,"outputs":[{"output_type":"stream","text":["0.8859155178070068\n","0.8876404762268066\n","0.8608924150466919\n"],"name":"stdout"}]}]}