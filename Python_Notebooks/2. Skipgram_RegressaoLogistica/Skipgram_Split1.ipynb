{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of Split1.ipynb","provenance":[{"file_id":"14KPhEaLtEQ-3fWkVAI3FS3oG1ZVh5JgR","timestamp":1592791894993},{"file_id":"1LfBzJg-B1BHT4FjFHTG-N1ao8xQ0tak_","timestamp":1592628202131},{"file_id":"1ly17dl3w8rGXAPtd1owJFslx4RVJE78c","timestamp":1592607825372},{"file_id":"1VIBcIIFR_YFlSguO_JGlnJbFzyAcT6YH","timestamp":1592464333044},{"file_id":"1dZvMRgPPkRVGa_4BZ1Tvoom_U4pjwmRX","timestamp":1592435543596},{"file_id":"12Sf257YUAwzmSXOlE3llOhi0N1YVUbM7","timestamp":1583376883298}],"collapsed_sections":[],"authorship_tag":"ABX9TyOGDwpcbWVhduQgTt540387"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"JQrQmaLj0UuZ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593325176833,"user_tz":180,"elapsed":586,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"b8067255-4dc6-49e8-8c4e-5f3bb88d6368"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JjEPtibx-EJD","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593325178252,"user_tz":180,"elapsed":1996,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["import numpy as np\n","import torch\n","\n","class EarlyStopping:\n","    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n","    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt'):\n","        \"\"\"\n","        Args:\n","            patience (int): How long to wait after last time validation loss improved.\n","                            Default: 7\n","            verbose (bool): If True, prints a message for each validation loss improvement. \n","                            Default: False\n","            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n","                            Default: 0\n","            path (str): Path for the checkpoint to be saved to.\n","                            Default: 'checkpoint.pt'\n","        \"\"\"\n","        self.patience = patience\n","        self.verbose = verbose\n","        self.counter = 0\n","        self.best_score = None\n","        self.early_stop = False\n","        self.val_loss_min = np.Inf\n","        self.delta = delta\n","        self.path = path\n","\n","    def __call__(self, val_loss, model):\n","\n","        score = -val_loss\n","\n","        if self.best_score is None:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model)\n","        elif score < self.best_score + self.delta:\n","            self.counter += 1\n","            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n","            if self.counter >= self.patience:\n","                self.early_stop = True\n","        else:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model)\n","            self.counter = 0\n","\n","    def save_checkpoint(self, val_loss, model):\n","        '''Saves model when validation loss decrease.'''\n","        if self.verbose:\n","            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n","        torch.save(model.state_dict(), self.path)\n","        self.val_loss_min = val_loss"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"tjGPuXgoqulz","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593325178253,"user_tz":180,"elapsed":1991,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["def Accuracy(prediction, observation):\n","  prediction = prediction[:,1]\n","  prediction_class = (torch.reshape(prediction, observation.shape) > 0.5).float()\n","  correct = (prediction_class == observation).float().sum()\n","  accuracy = correct/prediction_class.shape[0]\n","  return float(accuracy.cpu())\n","\n","def Precision(prediction, observation):\n","  prediction = prediction[:,1]\n","  res = []\n","  prediction_class = (torch.reshape(prediction, observation.shape) > 0.5).float()\n","  for label in [0, 1]:\n","    correct = (prediction_class[prediction_class == label] == observation[prediction_class == label]).float().sum()\n","    precision = correct/prediction_class[prediction_class == label].shape[0]\n","    res.append(float(precision.cpu()))\n","  return res\n","\n","def Recall(prediction, observation):\n","  prediction = prediction[:,1]\n","  res = []\n","  prediction_class = (torch.reshape(prediction, observation.shape) > 0.5).float()\n","  for label in [0, 1]:\n","    correct = (prediction_class[observation == label] == observation[observation == label]).float().sum()\n","    recall = correct/prediction_class[observation == label].shape[0]\n","    res.append(float(recall.cpu()))\n","  return res"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"sgz5Ea8a1wKr","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593325178254,"user_tz":180,"elapsed":1987,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["n_split = 1"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"cutkFU0k1Pkv","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593325178254,"user_tz":180,"elapsed":1983,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["import pickle\n","import pandas as pd\n","import numpy as np"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"wSJO5A951VXh","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593325178527,"user_tz":180,"elapsed":2251,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["with open('/content/drive/My Drive/Data Master/X_train_final', 'rb') as file:\n","    X_train = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/Y_train_final', 'rb') as file:\n","    Y_train = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/X_test_final', 'rb') as file:\n","    X_test = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/Y_test_final', 'rb') as file:\n","    Y_test = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/word_index_final', 'rb') as file:\n","    word_index = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/train_index_final_split_' + str(n_split), 'rb') as file:\n","    train_index = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/valid_index_final_split_' + str(n_split), 'rb') as file:\n","    valid_index = pickle.load(file)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"NPV3Nq3Hu1wq","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593325178795,"user_tz":180,"elapsed":2512,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["inv_word_index = {ix : w for w, ix in word_index.items()}"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"3WX_0ZRprLyw","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593325194656,"user_tz":180,"elapsed":18367,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"7c6d53b1-1cc4-4587-d1d0-8a70a82abbe2"},"source":["errors = []\n","embeddings_index = {}\n","f = open('/content/drive/My Drive/Data Master/skip_s50.txt')\n","for line in f:\n","    values = line.split()\n","    word = values[0]\n","    try:\n","      coefs = np.asarray(values[1:], dtype='float32')\n","    except:\n","      errors.append(line)\n","    embeddings_index[word] = coefs\n","f.close()\n","\n","print('Found %s word vectors.' % len(embeddings_index))"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Found 929595 word vectors.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"I8FQmZNarZuK","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1593325194656,"user_tz":180,"elapsed":18360,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"7b16dd2a-cd22-42f4-92be-7234ed5dc282"},"source":["print(len(embeddings_index))\n","print(len(errors))"],"execution_count":9,"outputs":[{"output_type":"stream","text":["929595\n","4\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jsrBZxIdsSLP","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593325194657,"user_tz":180,"elapsed":18355,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["EMBEDDING_DIM = 50\n","errors_2 = []\n","nomatchs = []\n","\n","X_train_matrix = np.zeros((len(X_train), EMBEDDING_DIM))\n","X_test_matrix = np.zeros((len(X_test), EMBEDDING_DIM))"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"jK0pn81usdvI","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593325222052,"user_tz":180,"elapsed":45746,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["for i, x in enumerate(X_train):\n","  for w in x:\n","    embedding_vector = embeddings_index.get(inv_word_index[w])\n","    if embedding_vector is not None:\n","        # words not found in embedding index will be all-zeros.\n","        try:\n","          X_train_matrix[i] += embedding_vector\n","        except:\n","          errors_2.append([word, len(embedding_vector), embedding_vector])\n","    else:\n","      nomatchs.append(word)"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"suJPilq5vUG6","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593325236217,"user_tz":180,"elapsed":59906,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["for i, x in enumerate(X_test):\n","  for w in x:\n","    embedding_vector = embeddings_index.get(inv_word_index[w])\n","    if embedding_vector is not None:\n","        # words not found in embedding index will be all-zeros.\n","        try:\n","          X_test_matrix[i] += embedding_vector\n","        except:\n","          errors_2.append([word, len(embedding_vector), embedding_vector])\n","    else:\n","      nomatchs.append(word)"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"yeZBNSItuefx","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593325236217,"user_tz":180,"elapsed":59900,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"4f4b4bf7-9725-4f16-c2b9-684dbca8e89c"},"source":["X_train_matrix.shape"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(888, 50)"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"9d4attfQ0i-Q","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593325236218,"user_tz":180,"elapsed":59896,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"twcFT-Hl3fqP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593325236218,"user_tz":180,"elapsed":59890,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"3c199a50-0692-4eb6-f548-5a78c4629d32"},"source":["input_dim = X_train_matrix.shape[1]\n","input_dim"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["50"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"9fbXl191nZhK","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593325236219,"user_tz":180,"elapsed":59885,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["class LogisticRegression (nn.Module):\n","\n","  def __init__(self):\n","    super(LogisticRegression, self).__init__()\n","\n","    self.fc1 = nn.Linear(input_dim, 2)\n","                                \n","    self.softmax = nn.Softmax(dim=1)\n","\n","  def forward(self, x):\n","    x = F.normalize(x)\n","    y = self.softmax(self.fc1(x))\n","\n","    return y"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"0rnUcqchBE91","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593325236219,"user_tz":180,"elapsed":59880,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["X_train_tensor = torch.from_numpy(X_train_matrix[train_index]).float()\n","Y_train_tensor = torch.LongTensor(np.array(Y_train[train_index]))\n","\n","X_valid_tensor = torch.from_numpy(X_train_matrix[valid_index]).float()\n","Y_valid_tensor = torch.LongTensor(np.array(Y_train[valid_index]))\n","\n","X_test_tensor = torch.from_numpy(X_test_matrix).float()\n","Y_test_tensor = torch.LongTensor(np.array(Y_test))"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"Cgzf7IEqnyN4","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593325236220,"user_tz":180,"elapsed":59877,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["model = LogisticRegression()"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"ykKjpHS-cAin","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593325236220,"user_tz":180,"elapsed":59870,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["torch.manual_seed(0)\n","np.random.seed(0)"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"SV0Da5qu98-C","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593325236221,"user_tz":180,"elapsed":59867,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["import torch.optim as optim\n","optimizer = optim.AdamW(model.parameters(), lr=0.01)"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"umD2BmIGcI7r","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593325236223,"user_tz":180,"elapsed":59865,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["from torch.optim.lr_scheduler import ReduceLROnPlateau\n","scheduler = ReduceLROnPlateau(optimizer, 'min')"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"DyPG7P5GcLp-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593325236223,"user_tz":180,"elapsed":59859,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"57f2ae72-15fb-4973-f8a1-7f1ed0192dde"},"source":["weights = [sum(Y_train)/len(Y_train), 1-sum(Y_train)/len(Y_train)]\n","class_weights = torch.FloatTensor(weights)\n","class_weights"],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0.1734, 0.8266])"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"8-F96WAE98zI","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593325236224,"user_tz":180,"elapsed":59855,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["criterion = nn.CrossEntropyLoss(weight=class_weights)"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"E7KgiIq398rR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1593325240362,"user_tz":180,"elapsed":63987,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"94999870-73c0-487f-a06e-8bd420febcc9"},"source":["patience = 20\n","early_stopping = EarlyStopping(patience=patience, verbose=True)\n","\n","\n","for i in range(1000):\n","  model.train()\n","  optimizer.zero_grad()\n","  prediction = model(X_train_tensor)\n","  loss = criterion(prediction, Y_train_tensor)\n","  loss.backward()\n","  optimizer.step()\n","\n","  accuracy = Accuracy(prediction, Y_train_tensor)\n","\n","  model.eval()\n","\n","  val_prediction = model(X_valid_tensor)\n","  test_prediction = model(X_test_tensor)\n","  val_loss = criterion(val_prediction, Y_valid_tensor)\n","  test_loss = criterion(test_prediction, Y_test_tensor)\n","\n","  val_accuracy = Accuracy(val_prediction, Y_valid_tensor)\n","  test_accuracy = Accuracy(test_prediction, Y_test_tensor)\n","\n","  early_stopping(val_loss, model)\n","\n","  if early_stopping.early_stop:\n","    print(\"Early stopping\")\n","    break\n","\n","  print(i, float(loss.cpu()), accuracy, float(val_loss.cpu()), val_accuracy, float(test_loss.cpu()), test_accuracy)\n","\n","  scheduler.step(val_loss)\n","\n","model.load_state_dict(torch.load('checkpoint.pt'))"],"execution_count":24,"outputs":[{"output_type":"stream","text":["Validation loss decreased (inf --> 0.690813).  Saving model ...\n","0 0.6914150714874268 0.8464788794517517 0.6908131837844849 0.5955055952072144 0.6910659074783325 0.5879265069961548\n","Validation loss decreased (0.690813 --> 0.689725).  Saving model ...\n","1 0.6900490522384644 0.5957746505737305 0.6897246837615967 0.533707857131958 0.6902281641960144 0.4881889820098877\n","Validation loss decreased (0.689725 --> 0.688645).  Saving model ...\n","2 0.6887190341949463 0.5309858918190002 0.68864506483078 0.617977499961853 0.6892673373222351 0.6036745309829712\n","Validation loss decreased (0.688645 --> 0.687577).  Saving model ...\n","3 0.6873822808265686 0.611267626285553 0.6875774264335632 0.7078651785850525 0.6882728934288025 0.6902887225151062\n","Validation loss decreased (0.687577 --> 0.686520).  Saving model ...\n","4 0.6860509514808655 0.7366197109222412 0.6865195035934448 0.7752808928489685 0.6872990131378174 0.7795275449752808\n","Validation loss decreased (0.686520 --> 0.685460).  Saving model ...\n","5 0.6847303509712219 0.7873239517211914 0.6854603290557861 0.7977527976036072 0.6863704919815063 0.808398962020874\n","Validation loss decreased (0.685460 --> 0.684394).  Saving model ...\n","6 0.6834173798561096 0.7929577231407166 0.684394121170044 0.7865168452262878 0.68548583984375 0.7979002594947815\n","Validation loss decreased (0.684394 --> 0.683326).  Saving model ...\n","7 0.6821061372756958 0.7957746386528015 0.6833258271217346 0.7528089880943298 0.6846326589584351 0.7559055089950562\n","Validation loss decreased (0.683326 --> 0.682262).  Saving model ...\n","8 0.6808004975318909 0.783098578453064 0.6822620034217834 0.7528089880943298 0.6837952733039856 0.7165354490280151\n","Validation loss decreased (0.682262 --> 0.681207).  Saving model ...\n","9 0.6795037984848022 0.7647887468338013 0.6812073588371277 0.7303370833396912 0.6829549670219421 0.6981627345085144\n","Validation loss decreased (0.681207 --> 0.680164).  Saving model ...\n","10 0.6782158613204956 0.7577464580535889 0.6801635026931763 0.7359550595283508 0.6820973753929138 0.7007874250411987\n","Validation loss decreased (0.680164 --> 0.679130).  Saving model ...\n","11 0.6769348978996277 0.7577464580535889 0.6791298985481262 0.7415730357170105 0.6812217235565186 0.7086614370346069\n","Validation loss decreased (0.679130 --> 0.678107).  Saving model ...\n","12 0.6756588220596313 0.7633802890777588 0.6781066060066223 0.7584269642829895 0.6803401708602905 0.7191600799560547\n","Validation loss decreased (0.678107 --> 0.677092).  Saving model ...\n","13 0.6743911504745483 0.7718309760093689 0.6770924925804138 0.7584269642829895 0.6794660687446594 0.748031497001648\n","Validation loss decreased (0.677092 --> 0.676082).  Saving model ...\n","14 0.6731317639350891 0.7816901206970215 0.67608243227005 0.7584269642829895 0.6786103844642639 0.7559055089950562\n","Validation loss decreased (0.676082 --> 0.675073).  Saving model ...\n","15 0.6718828082084656 0.794366180896759 0.6750726103782654 0.7584269642829895 0.6777776479721069 0.7585301995277405\n","Validation loss decreased (0.675073 --> 0.674064).  Saving model ...\n","16 0.6706405878067017 0.7957746386528015 0.674064040184021 0.7584269642829895 0.6769658923149109 0.7532808184623718\n","Validation loss decreased (0.674064 --> 0.673059).  Saving model ...\n","17 0.6694051623344421 0.7901408672332764 0.6730589270591736 0.7584269642829895 0.676169216632843 0.7427821755409241\n","Validation loss decreased (0.673059 --> 0.672062).  Saving model ...\n","18 0.6681796908378601 0.783098578453064 0.6720621585845947 0.7528089880943298 0.6753780245780945 0.7375327944755554\n","Validation loss decreased (0.672062 --> 0.671076).  Saving model ...\n","19 0.6669629216194153 0.7788732647895813 0.6710761189460754 0.7528089880943298 0.6745851635932922 0.7349081635475159\n","Validation loss decreased (0.671076 --> 0.670101).  Saving model ...\n","20 0.6657556295394897 0.7774648070335388 0.6701013445854187 0.7528089880943298 0.6737862229347229 0.7375327944755554\n","Validation loss decreased (0.670101 --> 0.669138).  Saving model ...\n","21 0.6645569801330566 0.783098578453064 0.6691383123397827 0.7528089880943298 0.6729850769042969 0.7401574850082397\n","Validation loss decreased (0.669138 --> 0.668185).  Saving model ...\n","22 0.663366436958313 0.7845070362091064 0.6681845784187317 0.7584269642829895 0.6721893548965454 0.748031497001648\n","Validation loss decreased (0.668185 --> 0.667236).  Saving model ...\n","23 0.6621863842010498 0.7859154939651489 0.6672364473342896 0.7584269642829895 0.6714068055152893 0.7532808184623718\n","Validation loss decreased (0.667236 --> 0.666291).  Saving model ...\n","24 0.6610153913497925 0.7901408672332764 0.6662914156913757 0.7584269642829895 0.6706401109695435 0.7532808184623718\n","Validation loss decreased (0.666291 --> 0.665349).  Saving model ...\n","25 0.6598531603813171 0.7901408672332764 0.6653491258621216 0.7584269642829895 0.6698896288871765 0.7506561875343323\n","Validation loss decreased (0.665349 --> 0.664411).  Saving model ...\n","26 0.6587006449699402 0.7887324094772339 0.6644113659858704 0.7528089880943298 0.6691508293151855 0.748031497001648\n","Validation loss decreased (0.664411 --> 0.663483).  Saving model ...\n","27 0.6575575470924377 0.7873239517211914 0.6634827256202698 0.7528089880943298 0.6684176921844482 0.7401574850082397\n","Validation loss decreased (0.663483 --> 0.662565).  Saving model ...\n","28 0.6564239859580994 0.7859154939651489 0.6625649929046631 0.7528089880943298 0.6676850914955139 0.7401574850082397\n","Validation loss decreased (0.662565 --> 0.661659).  Saving model ...\n","29 0.6553001403808594 0.7873239517211914 0.6616590619087219 0.7528089880943298 0.6669520139694214 0.7427821755409241\n","Validation loss decreased (0.661659 --> 0.660764).  Saving model ...\n","30 0.6541857719421387 0.7859154939651489 0.6607643961906433 0.7528089880943298 0.6662213802337646 0.748031497001648\n","Validation loss decreased (0.660764 --> 0.659878).  Saving model ...\n","31 0.6530811190605164 0.7901408672332764 0.6598778367042542 0.7584269642829895 0.6654980182647705 0.7532808184623718\n","Validation loss decreased (0.659878 --> 0.658996).  Saving model ...\n","32 0.6519861817359924 0.7915493249893188 0.6589956283569336 0.7640449404716492 0.6647864580154419 0.7559055089950562\n","Validation loss decreased (0.658996 --> 0.658117).  Saving model ...\n","33 0.6509008407592773 0.7915493249893188 0.6581173539161682 0.7584269642829895 0.66408771276474 0.7559055089950562\n","Validation loss decreased (0.658117 --> 0.657244).  Saving model ...\n","34 0.6498253345489502 0.7915493249893188 0.6572438478469849 0.7584269642829895 0.6634002923965454 0.7559055089950562\n","Validation loss decreased (0.657244 --> 0.656377).  Saving model ...\n","35 0.6487584114074707 0.7915493249893188 0.6563774347305298 0.7584269642829895 0.6627199649810791 0.7506561875343323\n","Validation loss decreased (0.656377 --> 0.655521).  Saving model ...\n","36 0.6477020382881165 0.7929577231407166 0.6555212140083313 0.7584269642829895 0.6620431542396545 0.748031497001648\n","Validation loss decreased (0.655521 --> 0.654676).  Saving model ...\n","37 0.6466551423072815 0.7915493249893188 0.6546762585639954 0.7584269642829895 0.6613674163818359 0.7506561875343323\n","Validation loss decreased (0.654676 --> 0.653842).  Saving model ...\n","38 0.6456179022789001 0.7929577231407166 0.6538422703742981 0.7584269642829895 0.6606945395469666 0.7559055089950562\n","Validation loss decreased (0.653842 --> 0.653016).  Saving model ...\n","39 0.6445904970169067 0.7929577231407166 0.6530163288116455 0.7584269642829895 0.6600275039672852 0.7559055089950562\n","Validation loss decreased (0.653016 --> 0.652196).  Saving model ...\n","40 0.6435716152191162 0.7929577231407166 0.6521961092948914 0.7640449404716492 0.6593702435493469 0.7559055089950562\n","Validation loss decreased (0.652196 --> 0.651380).  Saving model ...\n","41 0.6425633430480957 0.7915493249893188 0.6513797640800476 0.7584269642829895 0.6587230563163757 0.7559055089950562\n","Validation loss decreased (0.651380 --> 0.650568).  Saving model ...\n","42 0.6415642499923706 0.7915493249893188 0.6505681276321411 0.7584269642829895 0.6580849885940552 0.7559055089950562\n","Validation loss decreased (0.650568 --> 0.649764).  Saving model ...\n","43 0.6405739784240723 0.7915493249893188 0.6497640013694763 0.7584269642829895 0.6574527621269226 0.7559055089950562\n","Validation loss decreased (0.649764 --> 0.648969).  Saving model ...\n","44 0.6395931243896484 0.7915493249893188 0.6489694118499756 0.7584269642829895 0.6568242311477661 0.7532808184623718\n","Validation loss decreased (0.648969 --> 0.648186).  Saving model ...\n","45 0.6386216878890991 0.7915493249893188 0.6481858491897583 0.7584269642829895 0.6561971306800842 0.7559055089950562\n","Validation loss decreased (0.648186 --> 0.647411).  Saving model ...\n","46 0.6376594305038452 0.7915493249893188 0.6474112868309021 0.7640449404716492 0.6555740237236023 0.7585301995277405\n","Validation loss decreased (0.647411 --> 0.646644).  Saving model ...\n","47 0.6367064714431763 0.7929577231407166 0.6466437578201294 0.7696629166603088 0.6549568176269531 0.76115483045578\n","Validation loss decreased (0.646644 --> 0.645882).  Saving model ...\n","48 0.635762095451355 0.7929577231407166 0.6458815932273865 0.7696629166603088 0.6543480157852173 0.76115483045578\n","Validation loss decreased (0.645882 --> 0.645123).  Saving model ...\n","49 0.6348268985748291 0.7929577231407166 0.6451231837272644 0.7696629166603088 0.6537472009658813 0.76115483045578\n","Validation loss decreased (0.645123 --> 0.644371).  Saving model ...\n","50 0.6339003443717957 0.7929577231407166 0.6443707942962646 0.7696629166603088 0.6531531810760498 0.76115483045578\n","Validation loss decreased (0.644371 --> 0.643626).  Saving model ...\n","51 0.6329821944236755 0.7929577231407166 0.6436260342597961 0.7696629166603088 0.6525634527206421 0.76115483045578\n","Validation loss decreased (0.643626 --> 0.642891).  Saving model ...\n","52 0.6320732831954956 0.7929577231407166 0.6428909301757812 0.7696629166603088 0.6519761681556702 0.76115483045578\n","Validation loss decreased (0.642891 --> 0.642165).  Saving model ...\n","53 0.6311725378036499 0.7929577231407166 0.6421651244163513 0.7696629166603088 0.6513914465904236 0.76115483045578\n","Validation loss decreased (0.642165 --> 0.641446).  Saving model ...\n","54 0.630280613899231 0.7957746386528015 0.6414464116096497 0.7752808928489685 0.6508113741874695 0.7637795209884644\n","Validation loss decreased (0.641446 --> 0.640733).  Saving model ...\n","55 0.6293969750404358 0.7985915541648865 0.6407328844070435 0.7752808928489685 0.6502377986907959 0.7637795209884644\n","Validation loss decreased (0.640733 --> 0.640024).  Saving model ...\n","56 0.6285214424133301 0.800000011920929 0.6400237679481506 0.7752808928489685 0.6496708393096924 0.7664042115211487\n","Validation loss decreased (0.640024 --> 0.639320).  Saving model ...\n","57 0.6276546716690063 0.8014084696769714 0.6393198370933533 0.7752808928489685 0.6491097211837769 0.7664042115211487\n","Validation loss decreased (0.639320 --> 0.638623).  Saving model ...\n","58 0.6267954111099243 0.8014084696769714 0.6386228203773499 0.7752808928489685 0.6485533714294434 0.7664042115211487\n","Validation loss decreased (0.638623 --> 0.637934).  Saving model ...\n","59 0.6259443759918213 0.8014084696769714 0.6379339694976807 0.7752808928489685 0.6479994058609009 0.7690288424491882\n","Validation loss decreased (0.637934 --> 0.637253).  Saving model ...\n","60 0.6251006722450256 0.8014084696769714 0.637252926826477 0.7752808928489685 0.6474485397338867 0.7716535329818726\n","Validation loss decreased (0.637253 --> 0.636579).  Saving model ...\n","61 0.6242655515670776 0.8014084696769714 0.6365793347358704 0.7752808928489685 0.6469006538391113 0.7742782235145569\n","Validation loss decreased (0.636579 --> 0.635911).  Saving model ...\n","62 0.6234379410743713 0.8014084696769714 0.6359107494354248 0.7752808928489685 0.6463585495948792 0.7742782235145569\n","Validation loss decreased (0.635911 --> 0.635247).  Saving model ...\n","63 0.6226174831390381 0.8028169274330139 0.6352466344833374 0.7752808928489685 0.6458218693733215 0.7742782235145569\n","Validation loss decreased (0.635247 --> 0.634587).  Saving model ...\n","64 0.6218045353889465 0.8028169274330139 0.6345871090888977 0.7752808928489685 0.6452904343605042 0.7769029140472412\n","Validation loss decreased (0.634587 --> 0.633934).  Saving model ...\n","65 0.620999276638031 0.8028169274330139 0.6339340209960938 0.7808988690376282 0.6447626352310181 0.7742782235145569\n","Validation loss decreased (0.633934 --> 0.633288).  Saving model ...\n","66 0.6202014684677124 0.8028169274330139 0.6332877278327942 0.7808988690376282 0.6442379355430603 0.7742782235145569\n","Validation loss decreased (0.633288 --> 0.632649).  Saving model ...\n","67 0.6194109320640564 0.8028169274330139 0.6326491236686707 0.7808988690376282 0.6437159776687622 0.7742782235145569\n","Validation loss decreased (0.632649 --> 0.632017).  Saving model ...\n","68 0.6186267137527466 0.8028169274330139 0.6320165991783142 0.7865168452262878 0.6431970596313477 0.7821522355079651\n","Validation loss decreased (0.632017 --> 0.631389).  Saving model ...\n","69 0.6178506016731262 0.8028169274330139 0.6313890218734741 0.7865168452262878 0.6426824927330017 0.7821522355079651\n","Validation loss decreased (0.631389 --> 0.630766).  Saving model ...\n","70 0.6170799136161804 0.8028169274330139 0.6307656764984131 0.7865168452262878 0.6421736478805542 0.7821522355079651\n","Validation loss decreased (0.630766 --> 0.630147).  Saving model ...\n","71 0.6163170337677002 0.8028169274330139 0.6301469802856445 0.7865168452262878 0.6416682004928589 0.7821522355079651\n","Validation loss decreased (0.630147 --> 0.629534).  Saving model ...\n","72 0.6155598759651184 0.8028169274330139 0.6295340657234192 0.7865168452262878 0.641166627407074 0.7821522355079651\n","Validation loss decreased (0.629534 --> 0.628927).  Saving model ...\n","73 0.6148104071617126 0.8028169274330139 0.6289272904396057 0.7865168452262878 0.6406672596931458 0.7821522355079651\n","Validation loss decreased (0.628927 --> 0.628327).  Saving model ...\n","74 0.6140676736831665 0.8028169274330139 0.6283270716667175 0.7865168452262878 0.6401709914207458 0.7821522355079651\n","Validation loss decreased (0.628327 --> 0.627732).  Saving model ...\n","75 0.6133304834365845 0.8042253255844116 0.6277322769165039 0.7865168452262878 0.6396780610084534 0.7821522355079651\n","Validation loss decreased (0.627732 --> 0.627142).  Saving model ...\n","76 0.6125998497009277 0.8042253255844116 0.6271421313285828 0.7865168452262878 0.6391889452934265 0.7847769260406494\n","Validation loss decreased (0.627142 --> 0.626556).  Saving model ...\n","77 0.6118754744529724 0.8056337833404541 0.626555860042572 0.7865168452262878 0.638704240322113 0.787401556968689\n","Validation loss decreased (0.626556 --> 0.625974).  Saving model ...\n","78 0.6111577153205872 0.8056337833404541 0.6259742975234985 0.7865168452262878 0.6382232308387756 0.787401556968689\n","Validation loss decreased (0.625974 --> 0.625398).  Saving model ...\n","79 0.610445499420166 0.8070422410964966 0.6253980398178101 0.7865168452262878 0.6377450823783875 0.787401556968689\n","Validation loss decreased (0.625398 --> 0.624828).  Saving model ...\n","80 0.6097394227981567 0.8070422410964966 0.6248276829719543 0.7921348214149475 0.6372694969177246 0.7900262475013733\n","Validation loss decreased (0.624828 --> 0.624263).  Saving model ...\n","81 0.6090396642684937 0.8070422410964966 0.6242625713348389 0.7921348214149475 0.6367967128753662 0.7900262475013733\n","Validation loss decreased (0.624263 --> 0.623702).  Saving model ...\n","82 0.6083452701568604 0.8070422410964966 0.6237024068832397 0.7921348214149475 0.6363269686698914 0.7900262475013733\n","Validation loss decreased (0.623702 --> 0.623146).  Saving model ...\n","83 0.6076570749282837 0.8070422410964966 0.6231462359428406 0.7921348214149475 0.6358617544174194 0.7926509380340576\n","Validation loss decreased (0.623146 --> 0.622594).  Saving model ...\n","84 0.6069740653038025 0.8070422410964966 0.6225941777229309 0.7921348214149475 0.6353987455368042 0.7926509380340576\n","Validation loss decreased (0.622594 --> 0.622047).  Saving model ...\n","85 0.6062972545623779 0.8070422410964966 0.6220465302467346 0.7921348214149475 0.6349403262138367 0.7926509380340576\n","Validation loss decreased (0.622047 --> 0.621504).  Saving model ...\n","86 0.6056257486343384 0.8070422410964966 0.6215039491653442 0.7921348214149475 0.6344837546348572 0.7926509380340576\n","Validation loss decreased (0.621504 --> 0.620966).  Saving model ...\n","87 0.6049594283103943 0.8056337833404541 0.6209664940834045 0.7921348214149475 0.6340298652648926 0.7926509380340576\n","Validation loss decreased (0.620966 --> 0.620434).  Saving model ...\n","88 0.6042990684509277 0.8056337833404541 0.6204341053962708 0.7977527976036072 0.6335795521736145 0.7979002594947815\n","Validation loss decreased (0.620434 --> 0.619906).  Saving model ...\n","89 0.6036437749862671 0.8070422410964966 0.6199055910110474 0.8033707737922668 0.6331316828727722 0.7979002594947815\n","Validation loss decreased (0.619906 --> 0.619381).  Saving model ...\n","90 0.6029937267303467 0.8070422410964966 0.6193808317184448 0.8033707737922668 0.6326873302459717 0.7979002594947815\n","Validation loss decreased (0.619381 --> 0.618860).  Saving model ...\n","91 0.6023491024971008 0.8070422410964966 0.6188604235649109 0.8033707737922668 0.6322465538978577 0.7979002594947815\n","Validation loss decreased (0.618860 --> 0.618344).  Saving model ...\n","92 0.6017091274261475 0.8070422410964966 0.6183438301086426 0.8089887499809265 0.6318084597587585 0.7979002594947815\n","Validation loss decreased (0.618344 --> 0.617832).  Saving model ...\n","93 0.6010746359825134 0.8070422410964966 0.6178320646286011 0.8146067261695862 0.6313727498054504 0.8005249500274658\n","Validation loss decreased (0.617832 --> 0.617325).  Saving model ...\n","94 0.6004444360733032 0.8070422410964966 0.6173252463340759 0.8146067261695862 0.6309398412704468 0.8005249500274658\n","Validation loss decreased (0.617325 --> 0.616822).  Saving model ...\n","95 0.5998200178146362 0.8084506988525391 0.616822361946106 0.8146067261695862 0.6305092573165894 0.8005249500274658\n","Validation loss decreased (0.616822 --> 0.616323).  Saving model ...\n","96 0.599200427532196 0.8084506988525391 0.616322934627533 0.8146067261695862 0.6300825476646423 0.8005249500274658\n","Validation loss decreased (0.616323 --> 0.615828).  Saving model ...\n","97 0.5985853672027588 0.8098591566085815 0.6158275008201599 0.8146067261695862 0.6296582818031311 0.8005249500274658\n","Validation loss decreased (0.615828 --> 0.615336).  Saving model ...\n","98 0.597974956035614 0.8098591566085815 0.6153355240821838 0.8146067261695862 0.6292369365692139 0.8005249500274658\n","Validation loss decreased (0.615336 --> 0.614848).  Saving model ...\n","99 0.5973701477050781 0.8098591566085815 0.614848256111145 0.8146067261695862 0.6288182735443115 0.8005249500274658\n","Validation loss decreased (0.614848 --> 0.614365).  Saving model ...\n","100 0.5967694520950317 0.811267614364624 0.6143652200698853 0.8146067261695862 0.6284016966819763 0.8005249500274658\n","Validation loss decreased (0.614365 --> 0.613886).  Saving model ...\n","101 0.596172571182251 0.811267614364624 0.6138859391212463 0.8146067261695862 0.6279886364936829 0.8005249500274658\n","Validation loss decreased (0.613886 --> 0.613410).  Saving model ...\n","102 0.5955808162689209 0.811267614364624 0.6134103536605835 0.8146067261695862 0.627577543258667 0.8005249500274658\n","Validation loss decreased (0.613410 --> 0.612938).  Saving model ...\n","103 0.594994068145752 0.8126760721206665 0.6129382848739624 0.8146067261695862 0.6271699070930481 0.8005249500274658\n","Validation loss decreased (0.612938 --> 0.612470).  Saving model ...\n","104 0.5944110751152039 0.8126760721206665 0.6124695539474487 0.8146067261695862 0.6267648339271545 0.8005249500274658\n","Validation loss decreased (0.612470 --> 0.612005).  Saving model ...\n","105 0.5938329100608826 0.8126760721206665 0.612004816532135 0.8202247023582458 0.6263619065284729 0.8031495809555054\n","Validation loss decreased (0.612005 --> 0.611544).  Saving model ...\n","106 0.5932587385177612 0.8154929280281067 0.6115440726280212 0.8202247023582458 0.6259618997573853 0.8031495809555054\n","Validation loss decreased (0.611544 --> 0.611087).  Saving model ...\n","107 0.5926889181137085 0.8154929280281067 0.6110872030258179 0.8202247023582458 0.6255642771720886 0.8031495809555054\n","Validation loss decreased (0.611087 --> 0.610633).  Saving model ...\n","108 0.5921233296394348 0.8169013857841492 0.6106334924697876 0.8202247023582458 0.6251692175865173 0.8031495809555054\n","Validation loss decreased (0.610633 --> 0.610183).  Saving model ...\n","109 0.5915616750717163 0.8169013857841492 0.6101834177970886 0.8202247023582458 0.6247770190238953 0.8031495809555054\n","Validation loss decreased (0.610183 --> 0.609737).  Saving model ...\n","110 0.5910046100616455 0.8169013857841492 0.6097367405891418 0.8202247023582458 0.6243873238563538 0.8031495809555054\n","Validation loss decreased (0.609737 --> 0.609293).  Saving model ...\n","111 0.5904509425163269 0.8169013857841492 0.6092932820320129 0.8202247023582458 0.6239999532699585 0.8031495809555054\n","Validation loss decreased (0.609293 --> 0.608853).  Saving model ...\n","112 0.5899026989936829 0.8183098435401917 0.6088533401489258 0.8258426785469055 0.6236153244972229 0.8031495809555054\n","Validation loss decreased (0.608853 --> 0.608417).  Saving model ...\n","113 0.5893571376800537 0.8197183012962341 0.6084173321723938 0.8258426785469055 0.6232327222824097 0.8031495809555054\n","Validation loss decreased (0.608417 --> 0.607985).  Saving model ...\n","114 0.5888158679008484 0.8197183012962341 0.6079845428466797 0.8258426785469055 0.6228523254394531 0.8005249500274658\n","Validation loss decreased (0.607985 --> 0.607555).  Saving model ...\n","115 0.5882784128189087 0.8211267590522766 0.6075549721717834 0.8258426785469055 0.6224745512008667 0.8005249500274658\n","Validation loss decreased (0.607555 --> 0.607128).  Saving model ...\n","116 0.5877450108528137 0.8211267590522766 0.607128381729126 0.8258426785469055 0.6220999360084534 0.8005249500274658\n","Validation loss decreased (0.607128 --> 0.606705).  Saving model ...\n","117 0.5872154831886292 0.8225352168083191 0.6067050695419312 0.8258426785469055 0.6217272281646729 0.8005249500274658\n","Validation loss decreased (0.606705 --> 0.606285).  Saving model ...\n","118 0.5866897702217102 0.8225352168083191 0.6062849760055542 0.8258426785469055 0.6213571429252625 0.8005249500274658\n","Validation loss decreased (0.606285 --> 0.605869).  Saving model ...\n","119 0.5861675143241882 0.8225352168083191 0.6058686971664429 0.8258426785469055 0.6209885478019714 0.8005249500274658\n","Validation loss decreased (0.605869 --> 0.605455).  Saving model ...\n","120 0.5856490731239319 0.8225352168083191 0.6054552793502808 0.8258426785469055 0.6206228733062744 0.8031495809555054\n","Validation loss decreased (0.605455 --> 0.605045).  Saving model ...\n","121 0.5851341485977173 0.8225352168083191 0.6050449013710022 0.8258426785469055 0.6202598214149475 0.8031495809555054\n","Validation loss decreased (0.605045 --> 0.604638).  Saving model ...\n","122 0.5846224427223206 0.8225352168083191 0.6046375632286072 0.8258426785469055 0.6198983788490295 0.8031495809555054\n","Validation loss decreased (0.604638 --> 0.604233).  Saving model ...\n","123 0.5841150283813477 0.8225352168083191 0.6042332053184509 0.8258426785469055 0.6195395588874817 0.8031495809555054\n","Validation loss decreased (0.604233 --> 0.603832).  Saving model ...\n","124 0.5836108326911926 0.8225352168083191 0.6038316488265991 0.8258426785469055 0.6191828846931458 0.8031495809555054\n","Validation loss decreased (0.603832 --> 0.603434).  Saving model ...\n","125 0.5831102132797241 0.8225352168083191 0.6034339666366577 0.8258426785469055 0.6188286542892456 0.8031495809555054\n","Validation loss decreased (0.603434 --> 0.603039).  Saving model ...\n","126 0.5826129913330078 0.8225352168083191 0.6030389070510864 0.8258426785469055 0.6184762716293335 0.8031495809555054\n","Validation loss decreased (0.603039 --> 0.602647).  Saving model ...\n","127 0.582118809223175 0.8239436745643616 0.60264652967453 0.8258426785469055 0.618126392364502 0.8057742714881897\n","Validation loss decreased (0.602647 --> 0.602257).  Saving model ...\n","128 0.5816282629966736 0.8239436745643616 0.6022571325302124 0.8258426785469055 0.6177783608436584 0.8057742714881897\n","Validation loss decreased (0.602257 --> 0.601871).  Saving model ...\n","129 0.5811407566070557 0.8239436745643616 0.6018707156181335 0.8258426785469055 0.6174325942993164 0.8057742714881897\n","Validation loss decreased (0.601871 --> 0.601487).  Saving model ...\n","130 0.5806571841239929 0.8239436745643616 0.6014868021011353 0.8202247023582458 0.6170891523361206 0.8057742714881897\n","Validation loss decreased (0.601487 --> 0.601106).  Saving model ...\n","131 0.5801765322685242 0.8239436745643616 0.6011062860488892 0.8202247023582458 0.6167477369308472 0.8057742714881897\n","Validation loss decreased (0.601106 --> 0.600728).  Saving model ...\n","132 0.5796988606452942 0.825352132320404 0.600728452205658 0.8202247023582458 0.6164087653160095 0.8057742714881897\n","Validation loss decreased (0.600728 --> 0.600353).  Saving model ...\n","133 0.5792246460914612 0.8267605900764465 0.6003534197807312 0.8202247023582458 0.616071343421936 0.8057742714881897\n","Validation loss decreased (0.600353 --> 0.599981).  Saving model ...\n","134 0.5787539482116699 0.8267605900764465 0.5999810695648193 0.8202247023582458 0.6157362461090088 0.8057742714881897\n","Validation loss decreased (0.599981 --> 0.599611).  Saving model ...\n","135 0.5782855153083801 0.8267605900764465 0.5996112823486328 0.8202247023582458 0.6154029369354248 0.8057742714881897\n","Validation loss decreased (0.599611 --> 0.599244).  Saving model ...\n","136 0.5778207182884216 0.8267605900764465 0.599244236946106 0.8202247023582458 0.6150721907615662 0.8057742714881897\n","Validation loss decreased (0.599244 --> 0.598880).  Saving model ...\n","137 0.5773590803146362 0.8281689882278442 0.5988801717758179 0.8202247023582458 0.6147431135177612 0.8057742714881897\n","Validation loss decreased (0.598880 --> 0.598519).  Saving model ...\n","138 0.5769001245498657 0.8295774459838867 0.5985187292098999 0.8202247023582458 0.6144160032272339 0.8057742714881897\n","Validation loss decreased (0.598519 --> 0.598160).  Saving model ...\n","139 0.5764442086219788 0.8295774459838867 0.5981596112251282 0.8202247023582458 0.6140908002853394 0.8057742714881897\n","Validation loss decreased (0.598160 --> 0.597803).  Saving model ...\n","140 0.5759907364845276 0.8295774459838867 0.597802996635437 0.8202247023582458 0.6137674450874329 0.8057742714881897\n","Validation loss decreased (0.597803 --> 0.597449).  Saving model ...\n","141 0.5755414366722107 0.8295774459838867 0.597449004650116 0.8202247023582458 0.6134463548660278 0.8057742714881897\n","Validation loss decreased (0.597449 --> 0.597098).  Saving model ...\n","142 0.5750939846038818 0.8295774459838867 0.5970976948738098 0.8202247023582458 0.613127589225769 0.8057742714881897\n","Validation loss decreased (0.597098 --> 0.596749).  Saving model ...\n","143 0.5746499300003052 0.8295774459838867 0.5967490077018738 0.8202247023582458 0.6128097772598267 0.8057742714881897\n","Validation loss decreased (0.596749 --> 0.596403).  Saving model ...\n","144 0.5742085576057434 0.8295774459838867 0.5964028239250183 0.8202247023582458 0.6124945878982544 0.8057742714881897\n","Validation loss decreased (0.596403 --> 0.596059).  Saving model ...\n","145 0.5737699270248413 0.8323943614959717 0.5960591435432434 0.8202247023582458 0.6121808290481567 0.8057742714881897\n","Validation loss decreased (0.596059 --> 0.595718).  Saving model ...\n","146 0.5733339786529541 0.8338028192520142 0.5957176685333252 0.8202247023582458 0.6118692755699158 0.8057742714881897\n","Validation loss decreased (0.595718 --> 0.595379).  Saving model ...\n","147 0.5729007124900818 0.8338028192520142 0.5953789949417114 0.8202247023582458 0.6115596294403076 0.8057742714881897\n","Validation loss decreased (0.595379 --> 0.595042).  Saving model ...\n","148 0.5724703669548035 0.8338028192520142 0.5950422883033752 0.8202247023582458 0.6112509965896606 0.8057742714881897\n","Validation loss decreased (0.595042 --> 0.594708).  Saving model ...\n","149 0.5720422863960266 0.8323943614959717 0.594708263874054 0.8202247023582458 0.6109454035758972 0.8057742714881897\n","Validation loss decreased (0.594708 --> 0.594377).  Saving model ...\n","150 0.5716179013252258 0.8323943614959717 0.5943765044212341 0.8202247023582458 0.6106410622596741 0.8057742714881897\n","Validation loss decreased (0.594377 --> 0.594047).  Saving model ...\n","151 0.5711950063705444 0.8323943614959717 0.5940473079681396 0.8202247023582458 0.6103379726409912 0.8057742714881897\n","Validation loss decreased (0.594047 --> 0.593720).  Saving model ...\n","152 0.5707754492759705 0.8323943614959717 0.5937203168869019 0.8202247023582458 0.6100372672080994 0.8057742714881897\n","Validation loss decreased (0.593720 --> 0.593395).  Saving model ...\n","153 0.570357620716095 0.8338028192520142 0.593395471572876 0.8202247023582458 0.6097384691238403 0.8057742714881897\n","Validation loss decreased (0.593395 --> 0.593073).  Saving model ...\n","154 0.5699432492256165 0.8352112770080566 0.5930728316307068 0.8202247023582458 0.6094410419464111 0.8031495809555054\n","Validation loss decreased (0.593073 --> 0.592753).  Saving model ...\n","155 0.5695316791534424 0.8366197347640991 0.5927526354789734 0.8202247023582458 0.6091453433036804 0.8057742714881897\n","Validation loss decreased (0.592753 --> 0.592435).  Saving model ...\n","156 0.5691214799880981 0.8380281925201416 0.5924347043037415 0.8202247023582458 0.6088515520095825 0.8057742714881897\n","Validation loss decreased (0.592435 --> 0.592119).  Saving model ...\n","157 0.5687147974967957 0.8366197347640991 0.5921188592910767 0.8202247023582458 0.6085593104362488 0.8057742714881897\n","Validation loss decreased (0.592119 --> 0.591805).  Saving model ...\n","158 0.5683100819587708 0.8366197347640991 0.5918053984642029 0.8202247023582458 0.6082687377929688 0.8057742714881897\n","Validation loss decreased (0.591805 --> 0.591494).  Saving model ...\n","159 0.5679073929786682 0.8366197347640991 0.5914939641952515 0.8202247023582458 0.6079798340797424 0.8057742714881897\n","Validation loss decreased (0.591494 --> 0.591185).  Saving model ...\n","160 0.567507803440094 0.8380281925201416 0.5911846160888672 0.8202247023582458 0.6076924800872803 0.808398962020874\n","Validation loss decreased (0.591185 --> 0.590877).  Saving model ...\n","161 0.5671104192733765 0.8380281925201416 0.5908774733543396 0.8202247023582458 0.6074070930480957 0.808398962020874\n","Validation loss decreased (0.590877 --> 0.590572).  Saving model ...\n","162 0.5667155385017395 0.8394365906715393 0.5905724763870239 0.8202247023582458 0.6071233153343201 0.8110235929489136\n","Validation loss decreased (0.590572 --> 0.590270).  Saving model ...\n","163 0.5663225650787354 0.8394365906715393 0.5902696847915649 0.8202247023582458 0.6068411469459534 0.8110235929489136\n","Validation loss decreased (0.590270 --> 0.589969).  Saving model ...\n","164 0.5659322738647461 0.8408450484275818 0.5899688601493835 0.8202247023582458 0.6065601706504822 0.8136482834815979\n","Validation loss decreased (0.589969 --> 0.589670).  Saving model ...\n","165 0.5655437111854553 0.8408450484275818 0.5896700620651245 0.8202247023582458 0.6062812209129333 0.8136482834815979\n","Validation loss decreased (0.589670 --> 0.589373).  Saving model ...\n","166 0.5651580095291138 0.8408450484275818 0.5893732905387878 0.8202247023582458 0.6060032844543457 0.8136482834815979\n","Validation loss decreased (0.589373 --> 0.589079).  Saving model ...\n","167 0.5647742748260498 0.8422535061836243 0.5890787243843079 0.8202247023582458 0.6057276725769043 0.8162729740142822\n","Validation loss decreased (0.589079 --> 0.588786).  Saving model ...\n","168 0.5643933415412903 0.8422535061836243 0.5887860059738159 0.8258426785469055 0.6054530739784241 0.8162729740142822\n","Validation loss decreased (0.588786 --> 0.588495).  Saving model ...\n","169 0.5640137195587158 0.8422535061836243 0.5884953737258911 0.8258426785469055 0.6051799654960632 0.8162729740142822\n","Validation loss decreased (0.588495 --> 0.588207).  Saving model ...\n","170 0.563636302947998 0.8422535061836243 0.5882065892219543 0.8258426785469055 0.6049088835716248 0.8162729740142822\n","Validation loss decreased (0.588207 --> 0.587920).  Saving model ...\n","171 0.5632617473602295 0.8422535061836243 0.5879198908805847 0.8258426785469055 0.6046386957168579 0.8162729740142822\n","Validation loss decreased (0.587920 --> 0.587635).  Saving model ...\n","172 0.5628891587257385 0.8422535061836243 0.5876348614692688 0.8258426785469055 0.6043704748153687 0.8162729740142822\n","Validation loss decreased (0.587635 --> 0.587352).  Saving model ...\n","173 0.5625186562538147 0.8422535061836243 0.5873522162437439 0.8258426785469055 0.6041035652160645 0.8162729740142822\n","Validation loss decreased (0.587352 --> 0.587071).  Saving model ...\n","174 0.5621502995491028 0.8422535061836243 0.5870710015296936 0.8258426785469055 0.6038379073143005 0.8162729740142822\n","Validation loss decreased (0.587071 --> 0.586792).  Saving model ...\n","175 0.561783492565155 0.8422535061836243 0.5867917537689209 0.8258426785469055 0.6035741567611694 0.8162729740142822\n","Validation loss decreased (0.586792 --> 0.586515).  Saving model ...\n","176 0.5614193081855774 0.8422535061836243 0.5865145921707153 0.8258426785469055 0.6033118367195129 0.8162729740142822\n","Validation loss decreased (0.586515 --> 0.586239).  Saving model ...\n","177 0.5610569715499878 0.8436619639396667 0.5862388014793396 0.8258426785469055 0.6030505299568176 0.8162729740142822\n","Validation loss decreased (0.586239 --> 0.585966).  Saving model ...\n","178 0.5606969594955444 0.8436619639396667 0.5859655141830444 0.8258426785469055 0.602790892124176 0.8162729740142822\n","Validation loss decreased (0.585966 --> 0.585694).  Saving model ...\n","179 0.5603391528129578 0.8436619639396667 0.5856935977935791 0.8258426785469055 0.6025325059890747 0.8162729740142822\n","Validation loss decreased (0.585694 --> 0.585424).  Saving model ...\n","180 0.5599825978279114 0.8436619639396667 0.5854236483573914 0.8258426785469055 0.6022757887840271 0.8188976645469666\n","Validation loss decreased (0.585424 --> 0.585155).  Saving model ...\n","181 0.5596277713775635 0.8436619639396667 0.5851553678512573 0.8258426785469055 0.6020201444625854 0.8188976645469666\n","Validation loss decreased (0.585155 --> 0.584889).  Saving model ...\n","182 0.5592760443687439 0.8436619639396667 0.5848889946937561 0.8258426785469055 0.601766049861908 0.8188976645469666\n","Validation loss decreased (0.584889 --> 0.584624).  Saving model ...\n","183 0.5589260458946228 0.8436619639396667 0.5846242308616638 0.8258426785469055 0.6015135049819946 0.8188976645469666\n","Validation loss decreased (0.584624 --> 0.584361).  Saving model ...\n","184 0.5585772395133972 0.8436619639396667 0.5843614339828491 0.8258426785469055 0.6012616157531738 0.8188976645469666\n","Validation loss decreased (0.584361 --> 0.584100).  Saving model ...\n","185 0.558230459690094 0.8436619639396667 0.584100067615509 0.8258426785469055 0.6010117530822754 0.8188976645469666\n","Validation loss decreased (0.584100 --> 0.583841).  Saving model ...\n","186 0.5578857064247131 0.8436619639396667 0.5838406682014465 0.8258426785469055 0.6007633209228516 0.8188976645469666\n","Validation loss decreased (0.583841 --> 0.583583).  Saving model ...\n","187 0.5575435161590576 0.8436619639396667 0.5835826992988586 0.8258426785469055 0.6005159616470337 0.8188976645469666\n","Validation loss decreased (0.583583 --> 0.583326).  Saving model ...\n","188 0.5572022199630737 0.8436619639396667 0.5833263993263245 0.8258426785469055 0.6002699732780457 0.8188976645469666\n","Validation loss decreased (0.583326 --> 0.583072).  Saving model ...\n","189 0.5568633079528809 0.8436619639396667 0.5830720663070679 0.8258426785469055 0.6000254154205322 0.8188976645469666\n","Validation loss decreased (0.583072 --> 0.582819).  Saving model ...\n","190 0.5565258264541626 0.8436619639396667 0.5828191637992859 0.8258426785469055 0.5997818112373352 0.8188976645469666\n","Validation loss decreased (0.582819 --> 0.582568).  Saving model ...\n","191 0.5561910271644592 0.8450704216957092 0.5825679302215576 0.8258426785469055 0.5995397567749023 0.8188976645469666\n","Validation loss decreased (0.582568 --> 0.582318).  Saving model ...\n","192 0.5558571219444275 0.8450704216957092 0.5823183059692383 0.8258426785469055 0.599298894405365 0.8188976645469666\n","Validation loss decreased (0.582318 --> 0.582070).  Saving model ...\n","193 0.5555254220962524 0.8450704216957092 0.5820701718330383 0.8258426785469055 0.5990591049194336 0.8188976645469666\n","Validation loss decreased (0.582070 --> 0.581824).  Saving model ...\n","194 0.5551947355270386 0.8450704216957092 0.5818239450454712 0.8314606547355652 0.5988206267356873 0.8188976645469666\n","Validation loss decreased (0.581824 --> 0.581579).  Saving model ...\n","195 0.5548669099807739 0.8450704216957092 0.5815789699554443 0.8314606547355652 0.5985838174819946 0.8188976645469666\n","Validation loss decreased (0.581579 --> 0.581336).  Saving model ...\n","196 0.5545399785041809 0.8464788794517517 0.581335723400116 0.8314606547355652 0.5983478426933289 0.8188976645469666\n","Validation loss decreased (0.581336 --> 0.581094).  Saving model ...\n","197 0.5542155504226685 0.8464788794517517 0.5810940265655518 0.8314606547355652 0.5981131792068481 0.8188976645469666\n","Validation loss decreased (0.581094 --> 0.580854).  Saving model ...\n","198 0.5538922548294067 0.8464788794517517 0.5808536410331726 0.8314606547355652 0.5978796482086182 0.8188976645469666\n","Validation loss decreased (0.580854 --> 0.580615).  Saving model ...\n","199 0.553571343421936 0.8478873372077942 0.5806148648262024 0.8314606547355652 0.5976476073265076 0.8215222954750061\n","Validation loss decreased (0.580615 --> 0.580378).  Saving model ...\n","200 0.5532506704330444 0.8478873372077942 0.5803781151771545 0.8314606547355652 0.597416341304779 0.8215222954750061\n","Validation loss decreased (0.580378 --> 0.580142).  Saving model ...\n","201 0.5529332160949707 0.8478873372077942 0.5801422595977783 0.8314606547355652 0.5971867442131042 0.8215222954750061\n","Validation loss decreased (0.580142 --> 0.579908).  Saving model ...\n","202 0.5526166558265686 0.8464788794517517 0.5799083113670349 0.8314606547355652 0.5969579815864563 0.8241469860076904\n","Validation loss decreased (0.579908 --> 0.579675).  Saving model ...\n","203 0.5523017048835754 0.8464788794517517 0.5796754360198975 0.8314606547355652 0.5967305898666382 0.8241469860076904\n","Validation loss decreased (0.579675 --> 0.579444).  Saving model ...\n","204 0.5519883632659912 0.8464788794517517 0.5794443488121033 0.8314606547355652 0.596504271030426 0.8241469860076904\n","Validation loss decreased (0.579444 --> 0.579214).  Saving model ...\n","205 0.551676869392395 0.8464788794517517 0.5792144536972046 0.8314606547355652 0.5962788462638855 0.8215222954750061\n","Validation loss decreased (0.579214 --> 0.578986).  Saving model ...\n","206 0.5513668656349182 0.8464788794517517 0.5789861679077148 0.8314606547355652 0.5960550904273987 0.8215222954750061\n","Validation loss decreased (0.578986 --> 0.578759).  Saving model ...\n","207 0.5510587692260742 0.8464788794517517 0.5787591934204102 0.8314606547355652 0.5958320498466492 0.8241469860076904\n","Validation loss decreased (0.578759 --> 0.578534).  Saving model ...\n","208 0.5507519245147705 0.8464788794517517 0.5785338282585144 0.8314606547355652 0.5956104397773743 0.8241469860076904\n","Validation loss decreased (0.578534 --> 0.578309).  Saving model ...\n","209 0.5504462718963623 0.8464788794517517 0.5783094763755798 0.8314606547355652 0.5953898429870605 0.8267716765403748\n","Validation loss decreased (0.578309 --> 0.578087).  Saving model ...\n","210 0.550142765045166 0.8450704216957092 0.5780866146087646 0.8314606547355652 0.5951701998710632 0.8267716765403748\n","Validation loss decreased (0.578087 --> 0.577865).  Saving model ...\n","211 0.5498407483100891 0.8450704216957092 0.5778654217720032 0.8370786309242249 0.594951868057251 0.8267716765403748\n","Validation loss decreased (0.577865 --> 0.577645).  Saving model ...\n","212 0.5495398044586182 0.8450704216957092 0.5776454210281372 0.8370786309242249 0.5947344303131104 0.8267716765403748\n","Validation loss decreased (0.577645 --> 0.577427).  Saving model ...\n","213 0.54924076795578 0.8450704216957092 0.5774267911911011 0.8370786309242249 0.5945180654525757 0.8293963074684143\n","Validation loss decreased (0.577427 --> 0.577209).  Saving model ...\n","214 0.548943042755127 0.8450704216957092 0.5772093534469604 0.8370786309242249 0.5943030714988708 0.8320209980010986\n","Validation loss decreased (0.577209 --> 0.576993).  Saving model ...\n","215 0.5486471056938171 0.8450704216957092 0.576993465423584 0.8370786309242249 0.5940890908241272 0.8320209980010986\n","Validation loss decreased (0.576993 --> 0.576779).  Saving model ...\n","216 0.5483525991439819 0.8450704216957092 0.5767785906791687 0.8370786309242249 0.5938761234283447 0.8320209980010986\n","Validation loss decreased (0.576779 --> 0.576565).  Saving model ...\n","217 0.5480596423149109 0.8450704216957092 0.5765653848648071 0.8370786309242249 0.5936642289161682 0.8320209980010986\n","Validation loss decreased (0.576565 --> 0.576353).  Saving model ...\n","218 0.5477678775787354 0.8450704216957092 0.5763533711433411 0.8370786309242249 0.593453586101532 0.8320209980010986\n","Validation loss decreased (0.576353 --> 0.576143).  Saving model ...\n","219 0.5474775433540344 0.8450704216957092 0.5761426687240601 0.8370786309242249 0.593243420124054 0.8320209980010986\n","Validation loss decreased (0.576143 --> 0.575933).  Saving model ...\n","220 0.5471884608268738 0.8478873372077942 0.5759329199790955 0.8370786309242249 0.5930347442626953 0.8320209980010986\n","Validation loss decreased (0.575933 --> 0.575725).  Saving model ...\n","221 0.5469013452529907 0.8478873372077942 0.5757246613502502 0.8370786309242249 0.5928270816802979 0.8320209980010986\n","Validation loss decreased (0.575725 --> 0.575517).  Saving model ...\n","222 0.5466154217720032 0.8478873372077942 0.575517475605011 0.8370786309242249 0.5926200747489929 0.8320209980010986\n","Validation loss decreased (0.575517 --> 0.575312).  Saving model ...\n","223 0.546330451965332 0.8478873372077942 0.5753121972084045 0.8314606547355652 0.5924145579338074 0.8320209980010986\n","Validation loss decreased (0.575312 --> 0.575108).  Saving model ...\n","224 0.5460478067398071 0.8478873372077942 0.5751075148582458 0.8314606547355652 0.5922096371650696 0.8320209980010986\n","Validation loss decreased (0.575108 --> 0.574904).  Saving model ...\n","225 0.5457661151885986 0.8478873372077942 0.5749039649963379 0.8314606547355652 0.5920059084892273 0.8320209980010986\n","Validation loss decreased (0.574904 --> 0.574702).  Saving model ...\n","226 0.545485258102417 0.8478873372077942 0.5747022032737732 0.8314606547355652 0.5918035507202148 0.834645688533783\n","Validation loss decreased (0.574702 --> 0.574501).  Saving model ...\n","227 0.5452063679695129 0.8478873372077942 0.5745013356208801 0.8314606547355652 0.5916014909744263 0.834645688533783\n","Validation loss decreased (0.574501 --> 0.574301).  Saving model ...\n","228 0.5449286103248596 0.8478873372077942 0.5743013620376587 0.8314606547355652 0.5914008021354675 0.834645688533783\n","Validation loss decreased (0.574301 --> 0.574103).  Saving model ...\n","229 0.5446527600288391 0.8478873372077942 0.5741028189659119 0.8314606547355652 0.59120112657547 0.834645688533783\n","Validation loss decreased (0.574103 --> 0.573906).  Saving model ...\n","230 0.5443772077560425 0.8478873372077942 0.5739055871963501 0.8314606547355652 0.5910022854804993 0.834645688533783\n","Validation loss decreased (0.573906 --> 0.573709).  Saving model ...\n","231 0.54410320520401 0.8478873372077942 0.5737094283103943 0.8314606547355652 0.5908045768737793 0.834645688533783\n","Validation loss decreased (0.573709 --> 0.573515).  Saving model ...\n","232 0.5438312292098999 0.8478873372077942 0.5735145211219788 0.8314606547355652 0.5906074643135071 0.8372703194618225\n","Validation loss decreased (0.573515 --> 0.573321).  Saving model ...\n","233 0.5435595512390137 0.8478873372077942 0.5733205676078796 0.8314606547355652 0.5904116630554199 0.8372703194618225\n","Validation loss decreased (0.573321 --> 0.573128).  Saving model ...\n","234 0.5432903170585632 0.8492957949638367 0.573127806186676 0.8314606547355652 0.5902165770530701 0.8372703194618225\n","Validation loss decreased (0.573128 --> 0.572936).  Saving model ...\n","235 0.5430216193199158 0.8492957949638367 0.5729362964630127 0.8314606547355652 0.5900225043296814 0.8372703194618225\n","Validation loss decreased (0.572936 --> 0.572746).  Saving model ...\n","236 0.5427541732788086 0.8492957949638367 0.572745680809021 0.8314606547355652 0.5898292660713196 0.8372703194618225\n","Validation loss decreased (0.572746 --> 0.572556).  Saving model ...\n","237 0.5424883365631104 0.8492957949638367 0.5725564360618591 0.8314606547355652 0.589637041091919 0.8372703194618225\n","Validation loss decreased (0.572556 --> 0.572368).  Saving model ...\n","238 0.5422237515449524 0.8521126508712769 0.5723679065704346 0.8314606547355652 0.5894457101821899 0.8372703194618225\n","Validation loss decreased (0.572368 --> 0.572181).  Saving model ...\n","239 0.5419607162475586 0.8521126508712769 0.5721808075904846 0.8314606547355652 0.5892555117607117 0.8372703194618225\n","Validation loss decreased (0.572181 --> 0.571995).  Saving model ...\n","240 0.5416983962059021 0.8521126508712769 0.5719947218894958 0.8314606547355652 0.5890660285949707 0.8372703194618225\n","Validation loss decreased (0.571995 --> 0.571810).  Saving model ...\n","241 0.5414370894432068 0.8521126508712769 0.5718096494674683 0.8314606547355652 0.5888774394989014 0.8372703194618225\n","Validation loss decreased (0.571810 --> 0.571626).  Saving model ...\n","242 0.5411776304244995 0.8521126508712769 0.5716257095336914 0.8314606547355652 0.5886901021003723 0.8372703194618225\n","Validation loss decreased (0.571626 --> 0.571443).  Saving model ...\n","243 0.5409196019172668 0.8521126508712769 0.5714429616928101 0.8314606547355652 0.5885028839111328 0.8372703194618225\n","Validation loss decreased (0.571443 --> 0.571261).  Saving model ...\n","244 0.5406615138053894 0.8521126508712769 0.5712608098983765 0.8314606547355652 0.5883172154426575 0.8372703194618225\n","Validation loss decreased (0.571261 --> 0.571080).  Saving model ...\n","245 0.5404059290885925 0.8507042527198792 0.5710800886154175 0.8314606547355652 0.5881319642066956 0.8372703194618225\n","Validation loss decreased (0.571080 --> 0.570900).  Saving model ...\n","246 0.5401507616043091 0.8507042527198792 0.5709003210067749 0.8314606547355652 0.5879478454589844 0.8372703194618225\n","Validation loss decreased (0.570900 --> 0.570722).  Saving model ...\n","247 0.5398971438407898 0.8492957949638367 0.5707215666770935 0.8314606547355652 0.5877647399902344 0.8372703194618225\n","Validation loss decreased (0.570722 --> 0.570544).  Saving model ...\n","248 0.5396451354026794 0.8507042527198792 0.5705435276031494 0.8314606547355652 0.5875822901725769 0.8372703194618225\n","Validation loss decreased (0.570544 --> 0.570367).  Saving model ...\n","249 0.5393935441970825 0.8507042527198792 0.5703669190406799 0.8314606547355652 0.5874010324478149 0.8372703194618225\n","Validation loss decreased (0.570367 --> 0.570191).  Saving model ...\n","250 0.5391430854797363 0.8507042527198792 0.5701911449432373 0.8314606547355652 0.5872200727462769 0.8372703194618225\n","Validation loss decreased (0.570191 --> 0.570016).  Saving model ...\n","251 0.53889399766922 0.8507042527198792 0.5700162053108215 0.8314606547355652 0.5870399475097656 0.8372703194618225\n","Validation loss decreased (0.570016 --> 0.569843).  Saving model ...\n","252 0.5386462211608887 0.8507042527198792 0.5698426365852356 0.8314606547355652 0.5868609547615051 0.8372703194618225\n","Validation loss decreased (0.569843 --> 0.569670).  Saving model ...\n","253 0.5383993983268738 0.8507042527198792 0.5696697235107422 0.8314606547355652 0.5866827964782715 0.8372703194618225\n","Validation loss decreased (0.569670 --> 0.569498).  Saving model ...\n","254 0.538153350353241 0.8507042527198792 0.5694978833198547 0.8314606547355652 0.5865054726600647 0.8372703194618225\n","Validation loss decreased (0.569498 --> 0.569327).  Saving model ...\n","255 0.5379092693328857 0.8507042527198792 0.5693270564079285 0.8314606547355652 0.5863290429115295 0.8372703194618225\n","Validation loss decreased (0.569327 --> 0.569157).  Saving model ...\n","256 0.537665605545044 0.8507042527198792 0.5691570043563843 0.8314606547355652 0.5861532092094421 0.8372703194618225\n","Validation loss decreased (0.569157 --> 0.568988).  Saving model ...\n","257 0.537423312664032 0.8507042527198792 0.568988025188446 0.8314606547355652 0.5859784483909607 0.8372703194618225\n","Validation loss decreased (0.568988 --> 0.568820).  Saving model ...\n","258 0.537182092666626 0.8507042527198792 0.5688199400901794 0.8314606547355652 0.5858042240142822 0.8372703194618225\n","Validation loss decreased (0.568820 --> 0.568653).  Saving model ...\n","259 0.5369420647621155 0.8507042527198792 0.5686526894569397 0.8314606547355652 0.5856307744979858 0.8372703194618225\n","Validation loss decreased (0.568653 --> 0.568487).  Saving model ...\n","260 0.5367029309272766 0.8507042527198792 0.5684866309165955 0.8314606547355652 0.5854583978652954 0.8372703194618225\n","Validation loss decreased (0.568487 --> 0.568321).  Saving model ...\n","261 0.5364651679992676 0.8507042527198792 0.5683212280273438 0.8314606547355652 0.585286557674408 0.8372703194618225\n","Validation loss decreased (0.568321 --> 0.568157).  Saving model ...\n","262 0.5362280607223511 0.8521126508712769 0.5681568384170532 0.8314606547355652 0.5851159691810608 0.8372703194618225\n","Validation loss decreased (0.568157 --> 0.567993).  Saving model ...\n","263 0.5359929203987122 0.8521126508712769 0.5679932832717896 0.8314606547355652 0.584945559501648 0.8372703194618225\n","Validation loss decreased (0.567993 --> 0.567831).  Saving model ...\n","264 0.5357574820518494 0.8521126508712769 0.5678309202194214 0.8314606547355652 0.5847763419151306 0.8372703194618225\n","Validation loss decreased (0.567831 --> 0.567669).  Saving model ...\n","265 0.535524308681488 0.8521126508712769 0.5676690340042114 0.8314606547355652 0.5846074819564819 0.8372703194618225\n","Validation loss decreased (0.567669 --> 0.567508).  Saving model ...\n","266 0.5352913737297058 0.8521126508712769 0.5675081014633179 0.8314606547355652 0.584439754486084 0.8372703194618225\n","Validation loss decreased (0.567508 --> 0.567348).  Saving model ...\n","267 0.5350596904754639 0.8521126508712769 0.5673483610153198 0.8314606547355652 0.5842727422714233 0.8372703194618225\n","Validation loss decreased (0.567348 --> 0.567189).  Saving model ...\n","268 0.5348294973373413 0.8521126508712769 0.56718909740448 0.8314606547355652 0.5841063261032104 0.8398950099945068\n","Validation loss decreased (0.567189 --> 0.567031).  Saving model ...\n","269 0.5345996022224426 0.8521126508712769 0.5670309066772461 0.8314606547355652 0.5839409828186035 0.8398950099945068\n","Validation loss decreased (0.567031 --> 0.566874).  Saving model ...\n","270 0.5343709588050842 0.8535211086273193 0.5668735504150391 0.8314606547355652 0.5837759375572205 0.8398950099945068\n","Validation loss decreased (0.566874 --> 0.566717).  Saving model ...\n","271 0.5341439843177795 0.8535211086273193 0.5667170882225037 0.8314606547355652 0.583611786365509 0.8398950099945068\n","Validation loss decreased (0.566717 --> 0.566561).  Saving model ...\n","272 0.5339170098304749 0.8535211086273193 0.5665613412857056 0.8314606547355652 0.5834487676620483 0.8398950099945068\n","Validation loss decreased (0.566561 --> 0.566406).  Saving model ...\n","273 0.5336912274360657 0.8535211086273193 0.5664061903953552 0.8314606547355652 0.5832861065864563 0.8398950099945068\n","Validation loss decreased (0.566406 --> 0.566252).  Saving model ...\n","274 0.5334669351577759 0.8549295663833618 0.5662524104118347 0.8314606547355652 0.5831242203712463 0.8398950099945068\n","Validation loss decreased (0.566252 --> 0.566099).  Saving model ...\n","275 0.5332435369491577 0.8563380241394043 0.566099226474762 0.8314606547355652 0.5829630494117737 0.8425197005271912\n","Validation loss decreased (0.566099 --> 0.565947).  Saving model ...\n","276 0.5330208539962769 0.8563380241394043 0.5659468770027161 0.8314606547355652 0.582802414894104 0.8425197005271912\n","Validation loss decreased (0.565947 --> 0.565795).  Saving model ...\n","277 0.532799243927002 0.8563380241394043 0.5657954216003418 0.8314606547355652 0.5826428532600403 0.8425197005271912\n","Validation loss decreased (0.565795 --> 0.565645).  Saving model ...\n","278 0.5325782299041748 0.8563380241394043 0.5656445622444153 0.8314606547355652 0.5824840664863586 0.8425197005271912\n","Validation loss decreased (0.565645 --> 0.565495).  Saving model ...\n","279 0.5323588848114014 0.8577464818954468 0.5654946565628052 0.8314606547355652 0.5823254585266113 0.8425197005271912\n","Validation loss decreased (0.565495 --> 0.565345).  Saving model ...\n","280 0.5321402549743652 0.8591549396514893 0.5653453469276428 0.8314606547355652 0.5821676850318909 0.8425197005271912\n","Validation loss decreased (0.565345 --> 0.565197).  Saving model ...\n","281 0.5319223999977112 0.8591549396514893 0.5651971101760864 0.8314606547355652 0.5820109248161316 0.8425197005271912\n","Validation loss decreased (0.565197 --> 0.565049).  Saving model ...\n","282 0.5317059755325317 0.8591549396514893 0.5650494694709778 0.8314606547355652 0.5818551778793335 0.8425197005271912\n","Validation loss decreased (0.565049 --> 0.564903).  Saving model ...\n","283 0.5314898490905762 0.8605633974075317 0.5649027228355408 0.8314606547355652 0.5816992521286011 0.8425197005271912\n","Validation loss decreased (0.564903 --> 0.564756).  Saving model ...\n","284 0.5312749147415161 0.8605633974075317 0.564756453037262 0.8314606547355652 0.5815446972846985 0.8425197005271912\n","Validation loss decreased (0.564756 --> 0.564611).  Saving model ...\n","285 0.5310608148574829 0.8605633974075317 0.5646112561225891 0.8314606547355652 0.5813906192779541 0.8425197005271912\n","Validation loss decreased (0.564611 --> 0.564467).  Saving model ...\n","286 0.5308475494384766 0.8605633974075317 0.5644667148590088 0.8314606547355652 0.5812370181083679 0.8425197005271912\n","Validation loss decreased (0.564467 --> 0.564323).  Saving model ...\n","287 0.5306357741355896 0.8605633974075317 0.5643227696418762 0.8314606547355652 0.5810846090316772 0.8425197005271912\n","Validation loss decreased (0.564323 --> 0.564180).  Saving model ...\n","288 0.5304243564605713 0.8605633974075317 0.5641798377037048 0.8314606547355652 0.5809323191642761 0.8425197005271912\n","Validation loss decreased (0.564180 --> 0.564037).  Saving model ...\n","289 0.5302137136459351 0.8605633974075317 0.5640371441841125 0.8314606547355652 0.5807807445526123 0.8425197005271912\n","Validation loss decreased (0.564037 --> 0.563896).  Saving model ...\n","290 0.530004620552063 0.8605633974075317 0.563895583152771 0.8314606547355652 0.5806302428245544 0.8398950099945068\n","Validation loss decreased (0.563896 --> 0.563755).  Saving model ...\n","291 0.5297961831092834 0.8605633974075317 0.5637547969818115 0.8314606547355652 0.5804799795150757 0.8398950099945068\n","Validation loss decreased (0.563755 --> 0.563615).  Saving model ...\n","292 0.5295881032943726 0.8605633974075317 0.5636149048805237 0.8314606547355652 0.5803309082984924 0.8398950099945068\n","Validation loss decreased (0.563615 --> 0.563476).  Saving model ...\n","293 0.5293818712234497 0.8605633974075317 0.5634755492210388 0.8314606547355652 0.5801820158958435 0.8398950099945068\n","Validation loss decreased (0.563476 --> 0.563337).  Saving model ...\n","294 0.5291758179664612 0.8605633974075317 0.5633366107940674 0.8314606547355652 0.5800336599349976 0.8398950099945068\n","Validation loss decreased (0.563337 --> 0.563199).  Saving model ...\n","295 0.5289706587791443 0.8605633974075317 0.5631988644599915 0.8314606547355652 0.5798860788345337 0.8398950099945068\n","Validation loss decreased (0.563199 --> 0.563061).  Saving model ...\n","296 0.5287660360336304 0.8605633974075317 0.5630614161491394 0.8314606547355652 0.5797392129898071 0.8398950099945068\n","Validation loss decreased (0.563061 --> 0.562925).  Saving model ...\n","297 0.528562605381012 0.8605633974075317 0.5629248023033142 0.8314606547355652 0.5795930624008179 0.8398950099945068\n","Validation loss decreased (0.562925 --> 0.562789).  Saving model ...\n","298 0.5283606648445129 0.8605633974075317 0.5627888441085815 0.8314606547355652 0.5794474482536316 0.8398950099945068\n","Validation loss decreased (0.562789 --> 0.562654).  Saving model ...\n","299 0.5281590223312378 0.8605633974075317 0.5626536011695862 0.8370786309242249 0.5793026089668274 0.8425197005271912\n","Validation loss decreased (0.562654 --> 0.562519).  Saving model ...\n","300 0.5279577374458313 0.8605633974075317 0.5625191926956177 0.8370786309242249 0.5791583061218262 0.8425197005271912\n","Validation loss decreased (0.562519 --> 0.562385).  Saving model ...\n","301 0.5277580618858337 0.8619718551635742 0.5623854398727417 0.8370786309242249 0.579014778137207 0.8425197005271912\n","Validation loss decreased (0.562385 --> 0.562252).  Saving model ...\n","302 0.5275591611862183 0.8619718551635742 0.5622519850730896 0.8370786309242249 0.5788714289665222 0.8425197005271912\n","Validation loss decreased (0.562252 --> 0.562120).  Saving model ...\n","303 0.5273610353469849 0.8619718551635742 0.5621196627616882 0.8314606547355652 0.5787291526794434 0.8425197005271912\n","Validation loss decreased (0.562120 --> 0.561988).  Saving model ...\n","304 0.5271628499031067 0.8619718551635742 0.5619878768920898 0.8314606547355652 0.5785871744155884 0.8425197005271912\n","Validation loss decreased (0.561988 --> 0.561857).  Saving model ...\n","305 0.5269668698310852 0.8619718551635742 0.5618566274642944 0.8314606547355652 0.5784457325935364 0.8425197005271912\n","Validation loss decreased (0.561857 --> 0.561726).  Saving model ...\n","306 0.5267707705497742 0.8619718551635742 0.5617259740829468 0.8314606547355652 0.5783048868179321 0.8425197005271912\n","Validation loss decreased (0.561726 --> 0.561596).  Saving model ...\n","307 0.5265758633613586 0.8619718551635742 0.561596155166626 0.8314606547355652 0.5781651735305786 0.8425197005271912\n","Validation loss decreased (0.561596 --> 0.561467).  Saving model ...\n","308 0.52638179063797 0.8619718551635742 0.5614669919013977 0.8314606547355652 0.578025758266449 0.8425197005271912\n","Validation loss decreased (0.561467 --> 0.561338).  Saving model ...\n","309 0.5261880159378052 0.8619718551635742 0.5613384246826172 0.8314606547355652 0.5778868198394775 0.8425197005271912\n","Validation loss decreased (0.561338 --> 0.561210).  Saving model ...\n","310 0.5259956121444702 0.8619718551635742 0.5612101554870605 0.8314606547355652 0.5777482390403748 0.8425197005271912\n","Validation loss decreased (0.561210 --> 0.561083).  Saving model ...\n","311 0.5258036255836487 0.8619718551635742 0.5610828995704651 0.8314606547355652 0.5776106119155884 0.8425197005271912\n","Validation loss decreased (0.561083 --> 0.560956).  Saving model ...\n","312 0.5256121754646301 0.8619718551635742 0.5609562993049622 0.8314606547355652 0.5774738192558289 0.8425197005271912\n","Validation loss decreased (0.560956 --> 0.560830).  Saving model ...\n","313 0.5254225730895996 0.8619718551635742 0.5608300566673279 0.8314606547355652 0.5773372650146484 0.8425197005271912\n","Validation loss decreased (0.560830 --> 0.560705).  Saving model ...\n","314 0.5252333283424377 0.8619718551635742 0.56070476770401 0.8314606547355652 0.5772009491920471 0.8425197005271912\n","Validation loss decreased (0.560705 --> 0.560580).  Saving model ...\n","315 0.5250443816184998 0.8619718551635742 0.5605796575546265 0.8314606547355652 0.5770655274391174 0.8451443314552307\n","Validation loss decreased (0.560580 --> 0.560456).  Saving model ...\n","316 0.5248562693595886 0.8619718551635742 0.5604555010795593 0.8314606547355652 0.5769307613372803 0.8451443314552307\n","Validation loss decreased (0.560456 --> 0.560332).  Saving model ...\n","317 0.5246690511703491 0.8619718551635742 0.5603321194648743 0.8314606547355652 0.5767968893051147 0.8451443314552307\n","Validation loss decreased (0.560332 --> 0.560209).  Saving model ...\n","318 0.5244832634925842 0.8619718551635742 0.560208797454834 0.8314606547355652 0.5766628384590149 0.8451443314552307\n","Validation loss decreased (0.560209 --> 0.560087).  Saving model ...\n","319 0.5242974758148193 0.8619718551635742 0.5600866079330444 0.8314606547355652 0.5765295624732971 0.8451443314552307\n","Validation loss decreased (0.560087 --> 0.559965).  Saving model ...\n","320 0.5241124033927917 0.8619718551635742 0.5599647164344788 0.8314606547355652 0.576397180557251 0.8451443314552307\n","Validation loss decreased (0.559965 --> 0.559843).  Saving model ...\n","321 0.5239282250404358 0.8619718551635742 0.5598432421684265 0.8314606547355652 0.5762650966644287 0.8451443314552307\n","Validation loss decreased (0.559843 --> 0.559723).  Saving model ...\n","322 0.523744523525238 0.8619718551635742 0.5597227215766907 0.8314606547355652 0.5761336088180542 0.8451443314552307\n","Validation loss decreased (0.559723 --> 0.559603).  Saving model ...\n","323 0.5235620737075806 0.8633802533149719 0.5596025586128235 0.8314606547355652 0.5760026574134827 0.8451443314552307\n","Validation loss decreased (0.559603 --> 0.559483).  Saving model ...\n","324 0.523379921913147 0.8633802533149719 0.5594828724861145 0.8314606547355652 0.5758723020553589 0.8451443314552307\n","Validation loss decreased (0.559483 --> 0.559364).  Saving model ...\n","325 0.5231989026069641 0.8633802533149719 0.5593639612197876 0.8314606547355652 0.5757424831390381 0.8451443314552307\n","Validation loss decreased (0.559364 --> 0.559246).  Saving model ...\n","326 0.5230180621147156 0.8633802533149719 0.5592457056045532 0.8314606547355652 0.5756129026412964 0.8451443314552307\n","Validation loss decreased (0.559246 --> 0.559128).  Saving model ...\n","327 0.5228387117385864 0.8633802533149719 0.5591278672218323 0.8314606547355652 0.5754842162132263 0.8451443314552307\n","Validation loss decreased (0.559128 --> 0.559011).  Saving model ...\n","328 0.5226596593856812 0.8633802533149719 0.5590105652809143 0.8314606547355652 0.5753560066223145 0.8451443314552307\n","Validation loss decreased (0.559011 --> 0.558894).  Saving model ...\n","329 0.5224817395210266 0.8647887110710144 0.5588937401771545 0.8314606547355652 0.5752280950546265 0.8451443314552307\n","Validation loss decreased (0.558894 --> 0.558778).  Saving model ...\n","330 0.5223034620285034 0.8661971688270569 0.5587775707244873 0.8314606547355652 0.575100839138031 0.8451443314552307\n","Validation loss decreased (0.558778 --> 0.558662).  Saving model ...\n","331 0.5221267938613892 0.8661971688270569 0.5586619973182678 0.8314606547355652 0.5749743580818176 0.8451443314552307\n","Validation loss decreased (0.558662 --> 0.558547).  Saving model ...\n","332 0.5219504833221436 0.8661971688270569 0.5585469007492065 0.8314606547355652 0.5748482346534729 0.8451443314552307\n","Validation loss decreased (0.558547 --> 0.558432).  Saving model ...\n","333 0.5217750072479248 0.8661971688270569 0.558432400226593 0.8314606547355652 0.574722409248352 0.8451443314552307\n","Validation loss decreased (0.558432 --> 0.558318).  Saving model ...\n","334 0.5216001272201538 0.8661971688270569 0.5583184361457825 0.8314606547355652 0.5745973587036133 0.8451443314552307\n","Validation loss decreased (0.558318 --> 0.558205).  Saving model ...\n","335 0.5214263200759888 0.8661971688270569 0.5582048892974854 0.8314606547355652 0.5744724273681641 0.8451443314552307\n","Validation loss decreased (0.558205 --> 0.558092).  Saving model ...\n","336 0.5212526917457581 0.8661971688270569 0.5580920577049255 0.8314606547355652 0.5743482112884521 0.8451443314552307\n","Validation loss decreased (0.558092 --> 0.557980).  Saving model ...\n","337 0.5210795998573303 0.8661971688270569 0.5579795837402344 0.8314606547355652 0.5742247700691223 0.8451443314552307\n","Validation loss decreased (0.557980 --> 0.557868).  Saving model ...\n","338 0.5209078192710876 0.8661971688270569 0.5578677654266357 0.8314606547355652 0.5741016864776611 0.8451443314552307\n","Validation loss decreased (0.557868 --> 0.557756).  Saving model ...\n","339 0.520736575126648 0.8647887110710144 0.5577564239501953 0.8314606547355652 0.573978841304779 0.8451443314552307\n","Validation loss decreased (0.557756 --> 0.557646).  Saving model ...\n","340 0.5205655694007874 0.8647887110710144 0.5576455593109131 0.8314606547355652 0.5738568902015686 0.8451443314552307\n","Validation loss decreased (0.557646 --> 0.557535).  Saving model ...\n","341 0.5203956365585327 0.8647887110710144 0.5575350522994995 0.8314606547355652 0.5737349987030029 0.8451443314552307\n","Validation loss decreased (0.557535 --> 0.557425).  Saving model ...\n","342 0.5202262997627258 0.8647887110710144 0.5574254989624023 0.8314606547355652 0.5736138820648193 0.8451443314552307\n","Validation loss decreased (0.557425 --> 0.557316).  Saving model ...\n","343 0.5200573205947876 0.8647887110710144 0.5573160648345947 0.8314606547355652 0.5734935402870178 0.8451443314552307\n","Validation loss decreased (0.557316 --> 0.557207).  Saving model ...\n","344 0.519889235496521 0.8647887110710144 0.5572072863578796 0.8314606547355652 0.5733728408813477 0.8451443314552307\n","Validation loss decreased (0.557207 --> 0.557099).  Saving model ...\n","345 0.5197213292121887 0.8647887110710144 0.5570990443229675 0.8314606547355652 0.5732530951499939 0.8451443314552307\n","Validation loss decreased (0.557099 --> 0.556991).  Saving model ...\n","346 0.5195547342300415 0.8647887110710144 0.5569912195205688 0.8314606547355652 0.5731340646743774 0.8451443314552307\n","Validation loss decreased (0.556991 --> 0.556884).  Saving model ...\n","347 0.519388735294342 0.8647887110710144 0.5568835735321045 0.8314606547355652 0.5730151534080505 0.8451443314552307\n","Validation loss decreased (0.556884 --> 0.556777).  Saving model ...\n","348 0.5192229747772217 0.8647887110710144 0.5567770600318909 0.8314606547355652 0.5728969573974609 0.8451443314552307\n","Validation loss decreased (0.556777 --> 0.556670).  Saving model ...\n","349 0.5190587639808655 0.8647887110710144 0.5566704273223877 0.8314606547355652 0.57277911901474 0.8451443314552307\n","Validation loss decreased (0.556670 --> 0.556565).  Saving model ...\n","350 0.5188937187194824 0.8647887110710144 0.5565645694732666 0.8314606547355652 0.5726617574691772 0.8451443314552307\n","Validation loss decreased (0.556565 --> 0.556459).  Saving model ...\n","351 0.5187299847602844 0.8647887110710144 0.5564591884613037 0.8314606547355652 0.5725448727607727 0.8451443314552307\n","Validation loss decreased (0.556459 --> 0.556354).  Saving model ...\n","352 0.5185672640800476 0.8647887110710144 0.5563544034957886 0.8314606547355652 0.5724281668663025 0.8451443314552307\n","Validation loss decreased (0.556354 --> 0.556250).  Saving model ...\n","353 0.5184047818183899 0.8647887110710144 0.5562498569488525 0.8314606547355652 0.57231205701828 0.8451443314552307\n","Validation loss decreased (0.556250 --> 0.556146).  Saving model ...\n","354 0.5182431936264038 0.8647887110710144 0.5561460256576538 0.8314606547355652 0.5721964240074158 0.8451443314552307\n","Validation loss decreased (0.556146 --> 0.556042).  Saving model ...\n","355 0.5180816650390625 0.8647887110710144 0.5560423731803894 0.8314606547355652 0.5720816254615784 0.8451443314552307\n","Validation loss decreased (0.556042 --> 0.555939).  Saving model ...\n","356 0.5179212093353271 0.8647887110710144 0.5559393167495728 0.8314606547355652 0.5719668865203857 0.8451443314552307\n","Validation loss decreased (0.555939 --> 0.555837).  Saving model ...\n","357 0.5177615284919739 0.8647887110710144 0.5558369755744934 0.8314606547355652 0.5718526840209961 0.8451443314552307\n","Validation loss decreased (0.555837 --> 0.555735).  Saving model ...\n","358 0.5176024436950684 0.8647887110710144 0.5557346940040588 0.8314606547355652 0.5717388987541199 0.8451443314552307\n","Validation loss decreased (0.555735 --> 0.555633).  Saving model ...\n","359 0.5174431204795837 0.8647887110710144 0.5556330680847168 0.8314606547355652 0.5716257095336914 0.8451443314552307\n","Validation loss decreased (0.555633 --> 0.555532).  Saving model ...\n","360 0.5172849297523499 0.8647887110710144 0.5555317997932434 0.8314606547355652 0.5715128779411316 0.8451443314552307\n","Validation loss decreased (0.555532 --> 0.555431).  Saving model ...\n","361 0.5171273350715637 0.8647887110710144 0.5554307699203491 0.8314606547355652 0.5714002251625061 0.8451443314552307\n","Validation loss decreased (0.555431 --> 0.555331).  Saving model ...\n","362 0.516970157623291 0.8647887110710144 0.5553308725357056 0.8314606547355652 0.5712883472442627 0.8451443314552307\n","Validation loss decreased (0.555331 --> 0.555231).  Saving model ...\n","363 0.5168139338493347 0.8647887110710144 0.5552306771278381 0.8314606547355652 0.5711768865585327 0.8451443314552307\n","Validation loss decreased (0.555231 --> 0.555131).  Saving model ...\n","364 0.5166585445404053 0.8661971688270569 0.5551314353942871 0.8314606547355652 0.5710656046867371 0.8451443314552307\n","Validation loss decreased (0.555131 --> 0.555032).  Saving model ...\n","365 0.5165032148361206 0.8661971688270569 0.5550321340560913 0.8314606547355652 0.5709549188613892 0.8451443314552307\n","Validation loss decreased (0.555032 --> 0.554934).  Saving model ...\n","366 0.5163487792015076 0.8661971688270569 0.5549336671829224 0.8314606547355652 0.5708447694778442 0.8451443314552307\n","Validation loss decreased (0.554934 --> 0.554835).  Saving model ...\n","367 0.5161946415901184 0.8661971688270569 0.5548354387283325 0.8314606547355652 0.570734977722168 0.8451443314552307\n","Validation loss decreased (0.554835 --> 0.554738).  Saving model ...\n","368 0.5160413980484009 0.8661971688270569 0.5547377467155457 0.8314606547355652 0.5706250071525574 0.8451443314552307\n","Validation loss decreased (0.554738 --> 0.554641).  Saving model ...\n","369 0.5158882141113281 0.8661971688270569 0.5546405911445618 0.8314606547355652 0.5705161094665527 0.8451443314552307\n","Validation loss decreased (0.554641 --> 0.554544).  Saving model ...\n","370 0.5157358646392822 0.8661971688270569 0.5545436143875122 0.8314606547355652 0.5704077482223511 0.8451443314552307\n","Validation loss decreased (0.554544 --> 0.554447).  Saving model ...\n","371 0.515584409236908 0.8661971688270569 0.5544469952583313 0.8314606547355652 0.5702992677688599 0.8451443314552307\n","Validation loss decreased (0.554447 --> 0.554351).  Saving model ...\n","372 0.5154323577880859 0.8661971688270569 0.5543510317802429 0.8314606547355652 0.5701918005943298 0.8451443314552307\n","Validation loss decreased (0.554351 --> 0.554256).  Saving model ...\n","373 0.5152820348739624 0.8661971688270569 0.5542555451393127 0.8314606547355652 0.5700840353965759 0.8451443314552307\n","Validation loss decreased (0.554256 --> 0.554160).  Saving model ...\n","374 0.5151321291923523 0.8661971688270569 0.5541602969169617 0.8314606547355652 0.5699771642684937 0.8451443314552307\n","Validation loss decreased (0.554160 --> 0.554066).  Saving model ...\n","375 0.514982283115387 0.8661971688270569 0.5540655255317688 0.8314606547355652 0.5698707699775696 0.8451443314552307\n","Validation loss decreased (0.554066 --> 0.553971).  Saving model ...\n","376 0.514833390712738 0.8661971688270569 0.5539710521697998 0.8314606547355652 0.5697643756866455 0.8451443314552307\n","Validation loss decreased (0.553971 --> 0.553877).  Saving model ...\n","377 0.5146851539611816 0.8661971688270569 0.5538771748542786 0.8314606547355652 0.5696588158607483 0.8451443314552307\n","Validation loss decreased (0.553877 --> 0.553784).  Saving model ...\n","378 0.5145374536514282 0.8661971688270569 0.5537835955619812 0.8314606547355652 0.5695533752441406 0.8451443314552307\n","Validation loss decreased (0.553784 --> 0.553691).  Saving model ...\n","379 0.5143896341323853 0.8661971688270569 0.5536905527114868 0.8314606547355652 0.5694480538368225 0.8451443314552307\n","Validation loss decreased (0.553691 --> 0.553598).  Saving model ...\n","380 0.5142427682876587 0.8661971688270569 0.5535975694656372 0.8314606547355652 0.5693435668945312 0.8451443314552307\n","Validation loss decreased (0.553598 --> 0.553505).  Saving model ...\n","381 0.5140963196754456 0.8661971688270569 0.5535052418708801 0.8370786309242249 0.5692393183708191 0.8451443314552307\n","Validation loss decreased (0.553505 --> 0.553413).  Saving model ...\n","382 0.513950526714325 0.8661971688270569 0.5534132122993469 0.8370786309242249 0.5691355466842651 0.8451443314552307\n","Validation loss decreased (0.553413 --> 0.553321).  Saving model ...\n","383 0.5138050317764282 0.8661971688270569 0.5533214807510376 0.8370786309242249 0.5690322518348694 0.8451443314552307\n","Validation loss decreased (0.553321 --> 0.553230).  Saving model ...\n","384 0.5136604309082031 0.8661971688270569 0.5532304048538208 0.8370786309242249 0.5689291954040527 0.8451443314552307\n","Validation loss decreased (0.553230 --> 0.553140).  Saving model ...\n","385 0.5135163068771362 0.8661971688270569 0.5531395077705383 0.8370786309242249 0.56882643699646 0.8451443314552307\n","Validation loss decreased (0.553140 --> 0.553049).  Saving model ...\n","386 0.5133726000785828 0.8661971688270569 0.553048849105835 0.8370786309242249 0.5687240958213806 0.8451443314552307\n","Validation loss decreased (0.553049 --> 0.552959).  Saving model ...\n","387 0.5132297277450562 0.8661971688270569 0.5529590845108032 0.8370786309242249 0.5686219930648804 0.8451443314552307\n","Validation loss decreased (0.552959 --> 0.552869).  Saving model ...\n","388 0.51308673620224 0.8661971688270569 0.5528693199157715 0.8370786309242249 0.5685206055641174 0.8451443314552307\n","Validation loss decreased (0.552869 --> 0.552780).  Saving model ...\n","389 0.5129449367523193 0.8661971688270569 0.5527799129486084 0.8370786309242249 0.5684193968772888 0.8451443314552307\n","Validation loss decreased (0.552780 --> 0.552691).  Saving model ...\n","390 0.5128031373023987 0.8661971688270569 0.5526911020278931 0.8370786309242249 0.5683183073997498 0.8451443314552307\n","Validation loss decreased (0.552691 --> 0.552602).  Saving model ...\n","391 0.5126618146896362 0.8676056265830994 0.5526023507118225 0.8370786309242249 0.5682182908058167 0.8451443314552307\n","Validation loss decreased (0.552602 --> 0.552514).  Saving model ...\n","392 0.5125213265419006 0.8676056265830994 0.5525141358375549 0.8370786309242249 0.5681179165840149 0.8451443314552307\n","Validation loss decreased (0.552514 --> 0.552426).  Saving model ...\n","393 0.5123810768127441 0.8676056265830994 0.5524263978004456 0.8370786309242249 0.5680182576179504 0.8451443314552307\n","Validation loss decreased (0.552426 --> 0.552339).  Saving model ...\n","394 0.5122414231300354 0.8676056265830994 0.5523388981819153 0.8370786309242249 0.5679188966751099 0.8451443314552307\n","Validation loss decreased (0.552339 --> 0.552252).  Saving model ...\n","395 0.5121026039123535 0.8676056265830994 0.5522518754005432 0.8370786309242249 0.5678198337554932 0.8451443314552307\n","Validation loss decreased (0.552252 --> 0.552165).  Saving model ...\n","396 0.5119636058807373 0.8690140843391418 0.552165150642395 0.8370786309242249 0.5677214860916138 0.8451443314552307\n","Validation loss decreased (0.552165 --> 0.552079).  Saving model ...\n","397 0.511825680732727 0.8690140843391418 0.552078902721405 0.8370786309242249 0.5676230192184448 0.8451443314552307\n","Validation loss decreased (0.552079 --> 0.551993).  Saving model ...\n","398 0.5116879343986511 0.8690140843391418 0.5519927144050598 0.8370786309242249 0.567524790763855 0.8451443314552307\n","Validation loss decreased (0.551993 --> 0.551907).  Saving model ...\n","399 0.5115506052970886 0.8704225420951843 0.5519067645072937 0.8370786309242249 0.5674275159835815 0.8503937125205994\n","Validation loss decreased (0.551907 --> 0.551821).  Saving model ...\n","400 0.5114139914512634 0.8704225420951843 0.5518214106559753 0.8370786309242249 0.5673304200172424 0.8503937125205994\n","Validation loss decreased (0.551821 --> 0.551737).  Saving model ...\n","401 0.5112773776054382 0.8704225420951843 0.5517366528511047 0.8370786309242249 0.5672333836555481 0.8503937125205994\n","Validation loss decreased (0.551737 --> 0.551652).  Saving model ...\n","402 0.5111416578292847 0.8704225420951843 0.5516517758369446 0.8370786309242249 0.5671365261077881 0.8503937125205994\n","Validation loss decreased (0.551652 --> 0.551567).  Saving model ...\n","403 0.5110064148902893 0.8704225420951843 0.5515674352645874 0.8370786309242249 0.5670405626296997 0.8503937125205994\n","Validation loss decreased (0.551567 --> 0.551484).  Saving model ...\n","404 0.5108717679977417 0.8704225420951843 0.5514835119247437 0.8370786309242249 0.56694495677948 0.8503937125205994\n","Validation loss decreased (0.551484 --> 0.551400).  Saving model ...\n","405 0.5107374787330627 0.8704225420951843 0.5514000058174133 0.8370786309242249 0.566849410533905 0.8530183434486389\n","Validation loss decreased (0.551400 --> 0.551317).  Saving model ...\n","406 0.5106036067008972 0.8704225420951843 0.5513166785240173 0.8370786309242249 0.5667541027069092 0.8530183434486389\n","Validation loss decreased (0.551317 --> 0.551234).  Saving model ...\n","407 0.5104697942733765 0.8704225420951843 0.5512336492538452 0.8370786309242249 0.5666592717170715 0.8530183434486389\n","Validation loss decreased (0.551234 --> 0.551151).  Saving model ...\n","408 0.5103369951248169 0.8704225420951843 0.5511511564254761 0.8370786309242249 0.5665643811225891 0.8530183434486389\n","Validation loss decreased (0.551151 --> 0.551069).  Saving model ...\n","409 0.510204553604126 0.8704225420951843 0.5510686635971069 0.8370786309242249 0.5664705634117126 0.8530183434486389\n","Validation loss decreased (0.551069 --> 0.550987).  Saving model ...\n","410 0.510072648525238 0.8704225420951843 0.5509869456291199 0.8370786309242249 0.5663769841194153 0.8530183434486389\n","Validation loss decreased (0.550987 --> 0.550905).  Saving model ...\n","411 0.5099408626556396 0.8704225420951843 0.5509051084518433 0.8370786309242249 0.5662831664085388 0.8530183434486389\n","Validation loss decreased (0.550905 --> 0.550824).  Saving model ...\n","412 0.5098096132278442 0.8704225420951843 0.5508239269256592 0.8370786309242249 0.5661897659301758 0.8530183434486389\n","Validation loss decreased (0.550824 --> 0.550743).  Saving model ...\n","413 0.5096787810325623 0.8704225420951843 0.5507428646087646 0.8370786309242249 0.56609708070755 0.8530183434486389\n","Validation loss decreased (0.550743 --> 0.550662).  Saving model ...\n","414 0.5095486044883728 0.8704225420951843 0.5506623387336731 0.8370786309242249 0.5660044550895691 0.8530183434486389\n","Validation loss decreased (0.550662 --> 0.550582).  Saving model ...\n","415 0.5094189047813416 0.8704225420951843 0.5505818128585815 0.8370786309242249 0.5659123063087463 0.8530183434486389\n","Validation loss decreased (0.550582 --> 0.550502).  Saving model ...\n","416 0.5092892646789551 0.8704225420951843 0.5505017042160034 0.8370786309242249 0.565820574760437 0.8530183434486389\n","Validation loss decreased (0.550502 --> 0.550422).  Saving model ...\n","417 0.5091610550880432 0.8704225420951843 0.5504222512245178 0.8370786309242249 0.5657286047935486 0.8530183434486389\n","Validation loss decreased (0.550422 --> 0.550343).  Saving model ...\n","418 0.509032130241394 0.8704225420951843 0.5503427982330322 0.8370786309242249 0.5656375885009766 0.8530183434486389\n","Validation loss decreased (0.550343 --> 0.550264).  Saving model ...\n","419 0.5089040994644165 0.8704225420951843 0.5502637028694153 0.8370786309242249 0.5655468702316284 0.8530183434486389\n","Validation loss decreased (0.550264 --> 0.550185).  Saving model ...\n","420 0.5087767243385315 0.8704225420951843 0.5501851439476013 0.8370786309242249 0.5654561519622803 0.8530183434486389\n","Validation loss decreased (0.550185 --> 0.550106).  Saving model ...\n","421 0.5086491703987122 0.8704225420951843 0.5501063466072083 0.8370786309242249 0.5653658509254456 0.8530183434486389\n","Validation loss decreased (0.550106 --> 0.550029).  Saving model ...\n","422 0.508522629737854 0.8704225420951843 0.5500285625457764 0.8370786309242249 0.5652757287025452 0.8530183434486389\n","Validation loss decreased (0.550029 --> 0.549951).  Saving model ...\n","423 0.5083958506584167 0.8704225420951843 0.5499506592750549 0.8370786309242249 0.5651857852935791 0.8530183434486389\n","Validation loss decreased (0.549951 --> 0.549873).  Saving model ...\n","424 0.5082701444625854 0.8704225420951843 0.5498729944229126 0.8370786309242249 0.5650965571403503 0.8530183434486389\n","Validation loss decreased (0.549873 --> 0.549796).  Saving model ...\n","425 0.5081446170806885 0.8704225420951843 0.5497957468032837 0.8370786309242249 0.565007746219635 0.8530183434486389\n","Validation loss decreased (0.549796 --> 0.549719).  Saving model ...\n","426 0.5080199837684631 0.8704225420951843 0.5497187376022339 0.8370786309242249 0.5649186372756958 0.8530183434486389\n","Validation loss decreased (0.549719 --> 0.549642).  Saving model ...\n","427 0.5078950524330139 0.8704225420951843 0.5496423244476318 0.8426966071128845 0.56482994556427 0.8530183434486389\n","Validation loss decreased (0.549642 --> 0.549566).  Saving model ...\n","428 0.5077708959579468 0.8704225420951843 0.5495659112930298 0.8426966071128845 0.5647422671318054 0.8530183434486389\n","Validation loss decreased (0.549566 --> 0.549490).  Saving model ...\n","429 0.5076469779014587 0.8704225420951843 0.5494895577430725 0.8426966071128845 0.5646541714668274 0.8530183434486389\n","Validation loss decreased (0.549490 --> 0.549414).  Saving model ...\n","430 0.5075238943099976 0.8718309998512268 0.5494140982627869 0.8426966071128845 0.5645666718482971 0.8530183434486389\n","Validation loss decreased (0.549414 --> 0.549339).  Saving model ...\n","431 0.5074007511138916 0.8718309998512268 0.5493385195732117 0.8426966071128845 0.5644792914390564 0.8530183434486389\n","Validation loss decreased (0.549339 --> 0.549263).  Saving model ...\n","432 0.5072783827781677 0.8718309998512268 0.5492633581161499 0.8426966071128845 0.5643922090530396 0.8530183434486389\n","Validation loss decreased (0.549263 --> 0.549189).  Saving model ...\n","433 0.5071560144424438 0.8718309998512268 0.5491885542869568 0.8426966071128845 0.5643054246902466 0.8530183434486389\n","Validation loss decreased (0.549189 --> 0.549114).  Saving model ...\n","434 0.5070339441299438 0.8718309998512268 0.5491136908531189 0.8426966071128845 0.5642192959785461 0.8530183434486389\n","Validation loss decreased (0.549114 --> 0.549039).  Saving model ...\n","435 0.5069125890731812 0.8718309998512268 0.5490394830703735 0.8426966071128845 0.564132809638977 0.8530183434486389\n","Validation loss decreased (0.549039 --> 0.548966).  Saving model ...\n","436 0.5067918300628662 0.8718309998512268 0.548965573310852 0.8426966071128845 0.5640469789505005 0.8530183434486389\n","Validation loss decreased (0.548966 --> 0.548892).  Saving model ...\n","437 0.5066710114479065 0.8718309998512268 0.5488918423652649 0.8426966071128845 0.5639612674713135 0.8530183434486389\n","Validation loss decreased (0.548892 --> 0.548818).  Saving model ...\n","438 0.5065511465072632 0.8718309998512268 0.5488182902336121 0.8426966071128845 0.5638760924339294 0.8530183434486389\n","Validation loss decreased (0.548818 --> 0.548745).  Saving model ...\n","439 0.5064312219619751 0.8718309998512268 0.5487450957298279 0.8426966071128845 0.5637912154197693 0.8530183434486389\n","Validation loss decreased (0.548745 --> 0.548672).  Saving model ...\n","440 0.5063118934631348 0.8718309998512268 0.5486723184585571 0.8426966071128845 0.5637061595916748 0.8530183434486389\n","Validation loss decreased (0.548672 --> 0.548600).  Saving model ...\n","441 0.5061924457550049 0.8718309998512268 0.5485997200012207 0.8426966071128845 0.563621997833252 0.8530183434486389\n","Validation loss decreased (0.548600 --> 0.548527).  Saving model ...\n","442 0.5060741901397705 0.8718309998512268 0.5485270619392395 0.8426966071128845 0.5635377764701843 0.8530183434486389\n","Validation loss decreased (0.548527 --> 0.548455).  Saving model ...\n","443 0.5059559345245361 0.8718309998512268 0.5484551191329956 0.8426966071128845 0.5634539127349854 0.8530183434486389\n","Validation loss decreased (0.548455 --> 0.548383).  Saving model ...\n","444 0.5058386325836182 0.8718309998512268 0.5483832955360413 0.8426966071128845 0.5633702874183655 0.8530183434486389\n","Validation loss decreased (0.548383 --> 0.548312).  Saving model ...\n","445 0.505720853805542 0.8718309998512268 0.5483117699623108 0.8426966071128845 0.5632869601249695 0.8530183434486389\n","Validation loss decreased (0.548312 --> 0.548241).  Saving model ...\n","446 0.5056036114692688 0.8718309998512268 0.5482407212257385 0.8426966071128845 0.5632039308547974 0.8530183434486389\n","Validation loss decreased (0.548241 --> 0.548170).  Saving model ...\n","447 0.5054866671562195 0.8718309998512268 0.5481695532798767 0.8426966071128845 0.56312096118927 0.8530183434486389\n","Validation loss decreased (0.548170 --> 0.548099).  Saving model ...\n","448 0.505370557308197 0.8718309998512268 0.5480987429618835 0.8426966071128845 0.5630385279655457 0.8530183434486389\n","Validation loss decreased (0.548099 --> 0.548028).  Saving model ...\n","449 0.5052548050880432 0.8718309998512268 0.548028290271759 0.8426966071128845 0.5629562735557556 0.8530183434486389\n","Validation loss decreased (0.548028 --> 0.547958).  Saving model ...\n","450 0.5051387548446655 0.8718309998512268 0.5479580163955688 0.8426966071128845 0.5628742575645447 0.8530183434486389\n","Validation loss decreased (0.547958 --> 0.547888).  Saving model ...\n","451 0.5050238370895386 0.8718309998512268 0.5478880405426025 0.8426966071128845 0.5627923011779785 0.8530183434486389\n","Validation loss decreased (0.547888 --> 0.547818).  Saving model ...\n","452 0.5049087405204773 0.8732394576072693 0.5478178858757019 0.8426966071128845 0.5627110004425049 0.8530183434486389\n","Validation loss decreased (0.547818 --> 0.547749).  Saving model ...\n","453 0.5047945380210876 0.8732394576072693 0.547748863697052 0.8426966071128845 0.5626295804977417 0.8530183434486389\n","Validation loss decreased (0.547749 --> 0.547680).  Saving model ...\n","454 0.5046805143356323 0.8732394576072693 0.5476795434951782 0.8426966071128845 0.5625487565994263 0.8530183434486389\n","Validation loss decreased (0.547680 --> 0.547611).  Saving model ...\n","455 0.5045661330223083 0.8732394576072693 0.5476107597351074 0.8426966071128845 0.5624680519104004 0.8530183434486389\n","Validation loss decreased (0.547611 --> 0.547542).  Saving model ...\n","456 0.5044530034065247 0.8732394576072693 0.5475420355796814 0.8426966071128845 0.5623878240585327 0.8530183434486389\n","Validation loss decreased (0.547542 --> 0.547473).  Saving model ...\n","457 0.5043399333953857 0.8732394576072693 0.5474733710289001 0.8426966071128845 0.5623075366020203 0.8530183434486389\n","Validation loss decreased (0.547473 --> 0.547405).  Saving model ...\n","458 0.5042274594306946 0.8732394576072693 0.5474052429199219 0.8426966071128845 0.5622274279594421 0.8530183434486389\n","Validation loss decreased (0.547405 --> 0.547337).  Saving model ...\n","459 0.5041149854660034 0.8732394576072693 0.5473373532295227 0.8426966071128845 0.5621477961540222 0.8530183434486389\n","Validation loss decreased (0.547337 --> 0.547270).  Saving model ...\n","460 0.5040033459663391 0.8746479153633118 0.5472699403762817 0.8426966071128845 0.5620684027671814 0.8530183434486389\n","Validation loss decreased (0.547270 --> 0.547202).  Saving model ...\n","461 0.5038911700248718 0.8746479153633118 0.5472021102905273 0.8426966071128845 0.5619890689849854 0.8530183434486389\n","Validation loss decreased (0.547202 --> 0.547135).  Saving model ...\n","462 0.5037800073623657 0.8746479153633118 0.5471349358558655 0.8426966071128845 0.5619103312492371 0.8530183434486389\n","Validation loss decreased (0.547135 --> 0.547068).  Saving model ...\n","463 0.5036691427230835 0.8746479153633118 0.5470682978630066 0.8426966071128845 0.5618317127227783 0.8530183434486389\n","Validation loss decreased (0.547068 --> 0.547001).  Saving model ...\n","464 0.5035589337348938 0.8746479153633118 0.5470013618469238 0.8426966071128845 0.5617533922195435 0.8530183434486389\n","Validation loss decreased (0.547001 --> 0.546935).  Saving model ...\n","465 0.5034489035606384 0.8746479153633118 0.5469349026679993 0.8426966071128845 0.5616750717163086 0.8530183434486389\n","Validation loss decreased (0.546935 --> 0.546869).  Saving model ...\n","466 0.503338634967804 0.8746479153633118 0.5468687415122986 0.8426966071128845 0.5615970492362976 0.8530183434486389\n","Validation loss decreased (0.546869 --> 0.546803).  Saving model ...\n","467 0.5032289028167725 0.8746479153633118 0.5468026995658875 0.8426966071128845 0.5615193843841553 0.8530183434486389\n","Validation loss decreased (0.546803 --> 0.546737).  Saving model ...\n","468 0.503119945526123 0.8746479153633118 0.5467369556427002 0.8426966071128845 0.5614420771598816 0.8530183434486389\n","Validation loss decreased (0.546737 --> 0.546671).  Saving model ...\n","469 0.5030109286308289 0.8746479153633118 0.546671450138092 0.8426966071128845 0.5613641738891602 0.8530183434486389\n","Validation loss decreased (0.546671 --> 0.546606).  Saving model ...\n","470 0.502902090549469 0.8746479153633118 0.5466060042381287 0.8426966071128845 0.5612876415252686 0.8530183434486389\n","Validation loss decreased (0.546606 --> 0.546541).  Saving model ...\n","471 0.5027943849563599 0.8746479153633118 0.5465408563613892 0.8426966071128845 0.5612110495567322 0.8530183434486389\n","Validation loss decreased (0.546541 --> 0.546476).  Saving model ...\n","472 0.5026865005493164 0.8746479153633118 0.5464761257171631 0.8426966071128845 0.5611346960067749 0.8530183434486389\n","Validation loss decreased (0.546476 --> 0.546412).  Saving model ...\n","473 0.5025789737701416 0.8746479153633118 0.5464115738868713 0.8426966071128845 0.5610583424568176 0.8530183434486389\n","Validation loss decreased (0.546412 --> 0.546347).  Saving model ...\n","474 0.5024715065956116 0.8746479153633118 0.5463473200798035 0.8426966071128845 0.5609824061393738 0.8556430339813232\n","Validation loss decreased (0.546347 --> 0.546283).  Saving model ...\n","475 0.5023651719093323 0.8746479153633118 0.5462830662727356 0.8426966071128845 0.5609062314033508 0.8556430339813232\n","Validation loss decreased (0.546283 --> 0.546219).  Saving model ...\n","476 0.5022579431533813 0.8746479153633118 0.5462192296981812 0.8426966071128845 0.56083083152771 0.8556430339813232\n","Validation loss decreased (0.546219 --> 0.546155).  Saving model ...\n","477 0.5021518468856812 0.8746479153633118 0.5461551547050476 0.8426966071128845 0.5607554316520691 0.8556430339813232\n","Validation loss decreased (0.546155 --> 0.546092).  Saving model ...\n","478 0.5020464658737183 0.8746479153633118 0.54609215259552 0.8426966071128845 0.5606804490089417 0.8556430339813232\n","Validation loss decreased (0.546092 --> 0.546029).  Saving model ...\n","479 0.5019404292106628 0.8732394576072693 0.5460286736488342 0.8426966071128845 0.5606052875518799 0.8556430339813232\n","Validation loss decreased (0.546029 --> 0.545966).  Saving model ...\n","480 0.5018354654312134 0.8732394576072693 0.5459656715393066 0.8426966071128845 0.560530960559845 0.8556430339813232\n","Validation loss decreased (0.545966 --> 0.545903).  Saving model ...\n","481 0.5017303824424744 0.8732394576072693 0.5459029078483582 0.8370786309242249 0.5604564547538757 0.8556430339813232\n","Validation loss decreased (0.545903 --> 0.545840).  Saving model ...\n","482 0.501625657081604 0.8732394576072693 0.545840322971344 0.8370786309242249 0.5603823661804199 0.8556430339813232\n","Validation loss decreased (0.545840 --> 0.545778).  Saving model ...\n","483 0.5015213489532471 0.8732394576072693 0.5457778573036194 0.8370786309242249 0.5603079795837402 0.8556430339813232\n","Validation loss decreased (0.545778 --> 0.545716).  Saving model ...\n","484 0.5014177560806274 0.8732394576072693 0.545715868473053 0.8370786309242249 0.5602344870567322 0.8556430339813232\n","Validation loss decreased (0.545716 --> 0.545654).  Saving model ...\n","485 0.5013138651847839 0.8732394576072693 0.5456538200378418 0.8370786309242249 0.560160756111145 0.8556430339813232\n","Validation loss decreased (0.545654 --> 0.545592).  Saving model ...\n","486 0.5012105703353882 0.8732394576072693 0.5455922484397888 0.8370786309242249 0.5600875616073608 0.8556430339813232\n","Validation loss decreased (0.545592 --> 0.545531).  Saving model ...\n","487 0.5011075735092163 0.8732394576072693 0.5455307364463806 0.8370786309242249 0.560014545917511 0.8556430339813232\n","Validation loss decreased (0.545531 --> 0.545469).  Saving model ...\n","488 0.5010049343109131 0.8732394576072693 0.5454692840576172 0.8370786309242249 0.5599415302276611 0.8556430339813232\n","Validation loss decreased (0.545469 --> 0.545408).  Saving model ...\n","489 0.5009023547172546 0.8732394576072693 0.5454083681106567 0.8370786309242249 0.5598689913749695 0.8556430339813232\n","Validation loss decreased (0.545408 --> 0.545348).  Saving model ...\n","490 0.5007999539375305 0.8732394576072693 0.5453475713729858 0.8370786309242249 0.5597963929176331 0.8556430339813232\n","Validation loss decreased (0.545348 --> 0.545287).  Saving model ...\n","491 0.5006985068321228 0.8732394576072693 0.5452867746353149 0.8370786309242249 0.559723973274231 0.8556430339813232\n","Validation loss decreased (0.545287 --> 0.545226).  Saving model ...\n","492 0.5005975365638733 0.8732394576072693 0.5452260375022888 0.8370786309242249 0.5596520900726318 0.8556430339813232\n","Validation loss decreased (0.545226 --> 0.545166).  Saving model ...\n","493 0.5004959106445312 0.8732394576072693 0.545166015625 0.8370786309242249 0.5595808029174805 0.8556430339813232\n","Validation loss decreased (0.545166 --> 0.545106).  Saving model ...\n","494 0.5003949403762817 0.8732394576072693 0.545106053352356 0.8370786309242249 0.5595086216926575 0.8556430339813232\n","Validation loss decreased (0.545106 --> 0.545046).  Saving model ...\n","495 0.5002938508987427 0.8732394576072693 0.545046329498291 0.8370786309242249 0.5594373941421509 0.8556430339813232\n","Validation loss decreased (0.545046 --> 0.544987).  Saving model ...\n","496 0.5001940131187439 0.8732394576072693 0.5449865460395813 0.8370786309242249 0.55936598777771 0.8556430339813232\n","Validation loss decreased (0.544987 --> 0.544927).  Saving model ...\n","497 0.5000937581062317 0.8732394576072693 0.544927179813385 0.8370786309242249 0.559295117855072 0.8556430339813232\n","Validation loss decreased (0.544927 --> 0.544868).  Saving model ...\n","498 0.49999451637268066 0.8732394576072693 0.5448679327964783 0.8370786309242249 0.5592243671417236 0.8556430339813232\n","Validation loss decreased (0.544868 --> 0.544809).  Saving model ...\n","499 0.4998946189880371 0.8746479153633118 0.5448089241981506 0.8370786309242249 0.5591540932655334 0.8556430339813232\n","Validation loss decreased (0.544809 --> 0.544750).  Saving model ...\n","500 0.4997957944869995 0.8746479153633118 0.5447500944137573 0.8370786309242249 0.5590834021568298 0.8556430339813232\n","Validation loss decreased (0.544750 --> 0.544691).  Saving model ...\n","501 0.49969691038131714 0.8746479153633118 0.5446913838386536 0.8370786309242249 0.5590133666992188 0.8556430339813232\n","Validation loss decreased (0.544691 --> 0.544633).  Saving model ...\n","502 0.49959829449653625 0.8746479153633118 0.5446328520774841 0.8370786309242249 0.5589430332183838 0.8556430339813232\n","Validation loss decreased (0.544633 --> 0.544575).  Saving model ...\n","503 0.4994998276233673 0.8746479153633118 0.5445747375488281 0.8370786309242249 0.5588734149932861 0.8556430339813232\n","Validation loss decreased (0.544575 --> 0.544517).  Saving model ...\n","504 0.4994020462036133 0.8746479153633118 0.544516921043396 0.8370786309242249 0.5588043928146362 0.8556430339813232\n","Validation loss decreased (0.544517 --> 0.544459).  Saving model ...\n","505 0.49930453300476074 0.8746479153633118 0.5444588661193848 0.8370786309242249 0.5587350726127625 0.8556430339813232\n","Validation loss decreased (0.544459 --> 0.544401).  Saving model ...\n","506 0.4992066025733948 0.8746479153633118 0.5444011688232422 0.8370786309242249 0.5586655139923096 0.8556430339813232\n","Validation loss decreased (0.544401 --> 0.544344).  Saving model ...\n","507 0.49910977482795715 0.8746479153633118 0.5443437099456787 0.8370786309242249 0.5585967302322388 0.8556430339813232\n","Validation loss decreased (0.544344 --> 0.544286).  Saving model ...\n","508 0.4990133047103882 0.8746479153633118 0.5442863702774048 0.8370786309242249 0.5585283041000366 0.8556430339813232\n","Validation loss decreased (0.544286 --> 0.544229).  Saving model ...\n","509 0.49891626834869385 0.8746479153633118 0.5442293882369995 0.8370786309242249 0.5584594011306763 0.8556430339813232\n","Validation loss decreased (0.544229 --> 0.544172).  Saving model ...\n","510 0.498820424079895 0.8746479153633118 0.5441723465919495 0.8370786309242249 0.5583910942077637 0.8556430339813232\n","Validation loss decreased (0.544172 --> 0.544116).  Saving model ...\n","511 0.4987240135669708 0.8746479153633118 0.5441157221794128 0.8370786309242249 0.5583227872848511 0.8556430339813232\n","Validation loss decreased (0.544116 --> 0.544059).  Saving model ...\n","512 0.4986286759376526 0.8746479153633118 0.5440593957901001 0.8370786309242249 0.5582547187805176 0.8582677245140076\n","Validation loss decreased (0.544059 --> 0.544003).  Saving model ...\n","513 0.4985329210758209 0.8746479153633118 0.5440027713775635 0.8370786309242249 0.5581871271133423 0.8582677245140076\n","Validation loss decreased (0.544003 --> 0.543947).  Saving model ...\n","514 0.4984377920627594 0.8746479153633118 0.5439471006393433 0.8370786309242249 0.5581195950508118 0.8582677245140076\n","Validation loss decreased (0.543947 --> 0.543891).  Saving model ...\n","515 0.49834316968917847 0.8746479153633118 0.5438907146453857 0.8370786309242249 0.558052122592926 0.8582677245140076\n","Validation loss decreased (0.543891 --> 0.543835).  Saving model ...\n","516 0.49824854731559753 0.8746479153633118 0.543834924697876 0.8370786309242249 0.5579849481582642 0.8582677245140076\n","Validation loss decreased (0.543835 --> 0.543779).  Saving model ...\n","517 0.49815407395362854 0.8746479153633118 0.5437793731689453 0.8370786309242249 0.5579180121421814 0.8582677245140076\n","Validation loss decreased (0.543779 --> 0.543724).  Saving model ...\n","518 0.4980598986148834 0.8746479153633118 0.543724000453949 0.8370786309242249 0.5578511357307434 0.8582677245140076\n","Validation loss decreased (0.543724 --> 0.543669).  Saving model ...\n","519 0.49796608090400696 0.8746479153633118 0.5436688661575317 0.8370786309242249 0.5577844977378845 0.8582677245140076\n","Validation loss decreased (0.543669 --> 0.543614).  Saving model ...\n","520 0.49787256121635437 0.8746479153633118 0.5436139702796936 0.8370786309242249 0.5577180981636047 0.8582677245140076\n","Validation loss decreased (0.543614 --> 0.543559).  Saving model ...\n","521 0.49777936935424805 0.8746479153633118 0.5435588359832764 0.8370786309242249 0.557651937007904 0.8582677245140076\n","Validation loss decreased (0.543559 --> 0.543504).  Saving model ...\n","522 0.4976861774921417 0.8746479153633118 0.5435041785240173 0.8370786309242249 0.5575857758522034 0.8582677245140076\n","Validation loss decreased (0.543504 --> 0.543450).  Saving model ...\n","523 0.49759337306022644 0.8746479153633118 0.5434497594833374 0.8370786309242249 0.5575196146965027 0.8582677245140076\n","Validation loss decreased (0.543450 --> 0.543395).  Saving model ...\n","524 0.4975011348724365 0.8746479153633118 0.543395459651947 0.8370786309242249 0.5574538707733154 0.8582677245140076\n","Validation loss decreased (0.543395 --> 0.543341).  Saving model ...\n","525 0.49740853905677795 0.8746479153633118 0.5433412194252014 0.8370786309242249 0.5573886632919312 0.8582677245140076\n","Validation loss decreased (0.543341 --> 0.543287).  Saving model ...\n","526 0.4973164200782776 0.8760563135147095 0.5432873368263245 0.8370786309242249 0.557323157787323 0.8582677245140076\n","Validation loss decreased (0.543287 --> 0.543233).  Saving model ...\n","527 0.4972247779369354 0.8760563135147095 0.5432333946228027 0.8370786309242249 0.557257890701294 0.8582677245140076\n","Validation loss decreased (0.543233 --> 0.543180).  Saving model ...\n","528 0.4971340000629425 0.8760563135147095 0.5431798100471497 0.8370786309242249 0.5571929812431335 0.8635170459747314\n","Validation loss decreased (0.543180 --> 0.543126).  Saving model ...\n","529 0.4970422387123108 0.8760563135147095 0.5431263446807861 0.8370786309242249 0.5571280121803284 0.8635170459747314\n","Validation loss decreased (0.543126 --> 0.543073).  Saving model ...\n","530 0.49695104360580444 0.8760563135147095 0.5430729389190674 0.8370786309242249 0.5570634007453918 0.8635170459747314\n","Validation loss decreased (0.543073 --> 0.543020).  Saving model ...\n","531 0.496860533952713 0.8760563135147095 0.5430199503898621 0.8370786309242249 0.5569990873336792 0.8635170459747314\n","Validation loss decreased (0.543020 --> 0.542967).  Saving model ...\n","532 0.49677008390426636 0.8760563135147095 0.5429666638374329 0.8370786309242249 0.556934654712677 0.8635170459747314\n","Validation loss decreased (0.542967 --> 0.542914).  Saving model ...\n","533 0.4966798722743988 0.8760563135147095 0.5429140329360962 0.8370786309242249 0.556870698928833 0.8635170459747314\n","Validation loss decreased (0.542914 --> 0.542862).  Saving model ...\n","534 0.4965898096561432 0.8760563135147095 0.5428616404533386 0.8370786309242249 0.5568065047264099 0.8635170459747314\n","Validation loss decreased (0.542862 --> 0.542809).  Saving model ...\n","535 0.4965006411075592 0.8760563135147095 0.5428093075752258 0.8370786309242249 0.5567429065704346 0.8635170459747314\n","Validation loss decreased (0.542809 --> 0.542757).  Saving model ...\n","536 0.4964107871055603 0.8760563135147095 0.5427566766738892 0.8370786309242249 0.5566790699958801 0.8635170459747314\n","Validation loss decreased (0.542757 --> 0.542705).  Saving model ...\n","537 0.4963216781616211 0.8760563135147095 0.5427046418190002 0.8370786309242249 0.5566158890724182 0.8635170459747314\n","Validation loss decreased (0.542705 --> 0.542653).  Saving model ...\n","538 0.4962325096130371 0.8760563135147095 0.5426527261734009 0.8370786309242249 0.5565524697303772 0.8635170459747314\n","Validation loss decreased (0.542653 --> 0.542601).  Saving model ...\n","539 0.496143639087677 0.8760563135147095 0.5426009297370911 0.8370786309242249 0.5564894676208496 0.8635170459747314\n","Validation loss decreased (0.542601 --> 0.542549).  Saving model ...\n","540 0.4960554242134094 0.8760563135147095 0.542549192905426 0.8370786309242249 0.556427001953125 0.8635170459747314\n","Validation loss decreased (0.542549 --> 0.542498).  Saving model ...\n","541 0.4959671199321747 0.8760563135147095 0.5424980521202087 0.8370786309242249 0.5563638806343079 0.8635170459747314\n","Validation loss decreased (0.542498 --> 0.542447).  Saving model ...\n","542 0.49587950110435486 0.8760563135147095 0.5424466729164124 0.8370786309242249 0.5563011765480042 0.8635170459747314\n","Validation loss decreased (0.542447 --> 0.542395).  Saving model ...\n","543 0.4957915246486664 0.8760563135147095 0.5423954129219055 0.8370786309242249 0.5562389492988586 0.8635170459747314\n","Validation loss decreased (0.542395 --> 0.542344).  Saving model ...\n","544 0.4957040250301361 0.8760563135147095 0.542344331741333 0.8370786309242249 0.5561769008636475 0.8635170459747314\n","Validation loss decreased (0.542344 --> 0.542294).  Saving model ...\n","545 0.495616614818573 0.8760563135147095 0.5422935485839844 0.8370786309242249 0.5561143159866333 0.8635170459747314\n","Validation loss decreased (0.542294 --> 0.542243).  Saving model ...\n","546 0.4955294728279114 0.8760563135147095 0.5422428846359253 0.8370786309242249 0.5560525059700012 0.8635170459747314\n","Validation loss decreased (0.542243 --> 0.542192).  Saving model ...\n","547 0.495442658662796 0.8760563135147095 0.5421923398971558 0.8370786309242249 0.5559907555580139 0.8635170459747314\n","Validation loss decreased (0.542192 --> 0.542142).  Saving model ...\n","548 0.49535617232322693 0.8760563135147095 0.542141854763031 0.8370786309242249 0.5559296011924744 0.8635170459747314\n","Validation loss decreased (0.542142 --> 0.542092).  Saving model ...\n","549 0.49526968598365784 0.8760563135147095 0.5420917868614197 0.8370786309242249 0.5558677911758423 0.8635170459747314\n","Validation loss decreased (0.542092 --> 0.542042).  Saving model ...\n","550 0.49518364667892456 0.8760563135147095 0.5420417785644531 0.8370786309242249 0.555806577205658 0.8635170459747314\n","Validation loss decreased (0.542042 --> 0.541992).  Saving model ...\n","551 0.4950979948043823 0.8760563135147095 0.5419917106628418 0.8370786309242249 0.5557454824447632 0.8635170459747314\n","Validation loss decreased (0.541992 --> 0.541942).  Saving model ...\n","552 0.49501246213912964 0.8760563135147095 0.5419421195983887 0.8370786309242249 0.5556844472885132 0.8635170459747314\n","Validation loss decreased (0.541942 --> 0.541892).  Saving model ...\n","553 0.4949265420436859 0.8760563135147095 0.5418924689292908 0.8370786309242249 0.5556237697601318 0.8635170459747314\n","Validation loss decreased (0.541892 --> 0.541843).  Saving model ...\n","554 0.49484169483184814 0.8760563135147095 0.5418432354927063 0.8370786309242249 0.5555630326271057 0.8635170459747314\n","Validation loss decreased (0.541843 --> 0.541794).  Saving model ...\n","555 0.4947565197944641 0.8760563135147095 0.5417936444282532 0.8370786309242249 0.5555025339126587 0.8635170459747314\n","Validation loss decreased (0.541794 --> 0.541745).  Saving model ...\n","556 0.49467208981513977 0.8760563135147095 0.5417448878288269 0.8370786309242249 0.5554422736167908 0.8635170459747314\n","Validation loss decreased (0.541745 --> 0.541696).  Saving model ...\n","557 0.49458765983581543 0.8760563135147095 0.541695773601532 0.8370786309242249 0.5553816556930542 0.8635170459747314\n","Validation loss decreased (0.541696 --> 0.541647).  Saving model ...\n","558 0.49450308084487915 0.8760563135147095 0.5416468977928162 0.8370786309242249 0.5553218722343445 0.8635170459747314\n","Validation loss decreased (0.541647 --> 0.541598).  Saving model ...\n","559 0.49441930651664734 0.8760563135147095 0.5415982007980347 0.8370786309242249 0.55526202917099 0.8635170459747314\n","Validation loss decreased (0.541598 --> 0.541550).  Saving model ...\n","560 0.49433520436286926 0.8760563135147095 0.5415496826171875 0.8370786309242249 0.5552023649215698 0.8635170459747314\n","Validation loss decreased (0.541550 --> 0.541501).  Saving model ...\n","561 0.4942513108253479 0.8760563135147095 0.5415012240409851 0.8370786309242249 0.555142879486084 0.8635170459747314\n","Validation loss decreased (0.541501 --> 0.541453).  Saving model ...\n","562 0.4941684305667877 0.877464771270752 0.5414530634880066 0.8370786309242249 0.555083155632019 0.8635170459747314\n","Validation loss decreased (0.541453 --> 0.541405).  Saving model ...\n","563 0.4940851628780365 0.877464771270752 0.5414049625396729 0.8426966071128845 0.5550241470336914 0.8635170459747314\n","Validation loss decreased (0.541405 --> 0.541357).  Saving model ...\n","564 0.49400192499160767 0.877464771270752 0.5413570404052734 0.8426966071128845 0.5549649000167847 0.8635170459747314\n","Validation loss decreased (0.541357 --> 0.541309).  Saving model ...\n","565 0.49391940236091614 0.877464771270752 0.5413093566894531 0.8426966071128845 0.5549060702323914 0.8635170459747314\n","Validation loss decreased (0.541309 --> 0.541261).  Saving model ...\n","566 0.4938367009162903 0.877464771270752 0.5412614941596985 0.8426966071128845 0.5548474192619324 0.8635170459747314\n","Validation loss decreased (0.541261 --> 0.541214).  Saving model ...\n","567 0.4937545955181122 0.8788732290267944 0.541214108467102 0.8426966071128845 0.5547885298728943 0.8635170459747314\n","Validation loss decreased (0.541214 --> 0.541167).  Saving model ...\n","568 0.493672251701355 0.8788732290267944 0.5411667227745056 0.8426966071128845 0.554730236530304 0.8635170459747314\n","Validation loss decreased (0.541167 --> 0.541120).  Saving model ...\n","569 0.4935905933380127 0.8788732290267944 0.5411195158958435 0.8426966071128845 0.5546720027923584 0.8635170459747314\n","Validation loss decreased (0.541120 --> 0.541072).  Saving model ...\n","570 0.49350887537002563 0.8788732290267944 0.541072428226471 0.8426966071128845 0.5546139478683472 0.8635170459747314\n","Validation loss decreased (0.541072 --> 0.541025).  Saving model ...\n","571 0.493427574634552 0.8788732290267944 0.5410253405570984 0.8426966071128845 0.5545557141304016 0.8635170459747314\n","Validation loss decreased (0.541025 --> 0.540979).  Saving model ...\n","572 0.49334627389907837 0.8788732290267944 0.5409786701202393 0.8426966071128845 0.554497480392456 0.8635170459747314\n","Validation loss decreased (0.540979 --> 0.540932).  Saving model ...\n","573 0.4932654798030853 0.8788732290267944 0.5409319400787354 0.8426966071128845 0.5544400215148926 0.8635170459747314\n","Validation loss decreased (0.540932 --> 0.540885).  Saving model ...\n","574 0.4931844174861908 0.8788732290267944 0.540885329246521 0.8426966071128845 0.55438232421875 0.8635170459747314\n","Validation loss decreased (0.540885 --> 0.540839).  Saving model ...\n","575 0.49310392141342163 0.8788732290267944 0.5408391356468201 0.8426966071128845 0.5543246269226074 0.8635170459747314\n","Validation loss decreased (0.540839 --> 0.540793).  Saving model ...\n","576 0.49302342534065247 0.8788732290267944 0.5407925844192505 0.8426966071128845 0.5542676448822021 0.8635170459747314\n","Validation loss decreased (0.540793 --> 0.540747).  Saving model ...\n","577 0.4929428696632385 0.8788732290267944 0.5407465696334839 0.8426966071128845 0.5542105436325073 0.8635170459747314\n","Validation loss decreased (0.540747 --> 0.540701).  Saving model ...\n","578 0.49286291003227234 0.8788732290267944 0.5407006740570068 0.8426966071128845 0.5541533827781677 0.8635170459747314\n","Validation loss decreased (0.540701 --> 0.540655).  Saving model ...\n","579 0.49278345704078674 0.8788732290267944 0.540654718875885 0.8426966071128845 0.5540963411331177 0.8635170459747314\n","Validation loss decreased (0.540655 --> 0.540609).  Saving model ...\n","580 0.4927038252353668 0.8788732290267944 0.5406090617179871 0.8426966071128845 0.5540394186973572 0.8635170459747314\n","Validation loss decreased (0.540609 --> 0.540563).  Saving model ...\n","581 0.49262428283691406 0.8788732290267944 0.5405634641647339 0.8426966071128845 0.5539827346801758 0.8635170459747314\n","Validation loss decreased (0.540563 --> 0.540518).  Saving model ...\n","582 0.49254530668258667 0.8788732290267944 0.5405181050300598 0.8426966071128845 0.5539263486862183 0.8635170459747314\n","Validation loss decreased (0.540518 --> 0.540473).  Saving model ...\n","583 0.4924662411212921 0.8788732290267944 0.540472686290741 0.8426966071128845 0.5538700819015503 0.8635170459747314\n","Validation loss decreased (0.540473 --> 0.540428).  Saving model ...\n","584 0.492387592792511 0.8788732290267944 0.5404275059700012 0.8426966071128845 0.5538135766983032 0.8635170459747314\n","Validation loss decreased (0.540428 --> 0.540383).  Saving model ...\n","585 0.492309033870697 0.8788732290267944 0.5403825044631958 0.8426966071128845 0.5537575483322144 0.8635170459747314\n","Validation loss decreased (0.540383 --> 0.540338).  Saving model ...\n","586 0.4922304153442383 0.8788732290267944 0.5403375029563904 0.8426966071128845 0.5537016987800598 0.8635170459747314\n","Validation loss decreased (0.540338 --> 0.540293).  Saving model ...\n","587 0.49215254187583923 0.8788732290267944 0.5402927994728088 0.8426966071128845 0.55364590883255 0.8635170459747314\n","Validation loss decreased (0.540293 --> 0.540248).  Saving model ...\n","588 0.49207445979118347 0.8788732290267944 0.5402480959892273 0.8426966071128845 0.5535901784896851 0.8635170459747314\n","Validation loss decreased (0.540248 --> 0.540204).  Saving model ...\n","589 0.4919968545436859 0.8802816867828369 0.5402036309242249 0.8426966071128845 0.5535348653793335 0.8635170459747314\n","Validation loss decreased (0.540204 --> 0.540159).  Saving model ...\n","590 0.4919188320636749 0.8802816867828369 0.5401591658592224 0.8426966071128845 0.5534793138504028 0.8635170459747314\n","Validation loss decreased (0.540159 --> 0.540115).  Saving model ...\n","591 0.4918416738510132 0.8802816867828369 0.5401148796081543 0.8426966071128845 0.5534240007400513 0.8635170459747314\n","Validation loss decreased (0.540115 --> 0.540071).  Saving model ...\n","592 0.491764634847641 0.8802816867828369 0.5400705337524414 0.8426966071128845 0.5533689856529236 0.8635170459747314\n","Validation loss decreased (0.540071 --> 0.540027).  Saving model ...\n","593 0.4916873872280121 0.8802816867828369 0.5400266051292419 0.8426966071128845 0.5533138513565063 0.8635170459747314\n","Validation loss decreased (0.540027 --> 0.539983).  Saving model ...\n","594 0.491611123085022 0.8802816867828369 0.5399825572967529 0.8426966071128845 0.5532589554786682 0.8635170459747314\n","Validation loss decreased (0.539983 --> 0.539939).  Saving model ...\n","595 0.49153420329093933 0.8802816867828369 0.5399388074874878 0.8426966071128845 0.5532045364379883 0.8635170459747314\n","Validation loss decreased (0.539939 --> 0.539895).  Saving model ...\n","596 0.49145761132240295 0.8802816867828369 0.5398952960968018 0.8426966071128845 0.5531495213508606 0.8635170459747314\n","Validation loss decreased (0.539895 --> 0.539852).  Saving model ...\n","597 0.49138143658638 0.8802816867828369 0.539851725101471 0.8426966071128845 0.5530951619148254 0.8635170459747314\n","Validation loss decreased (0.539852 --> 0.539808).  Saving model ...\n","598 0.49130526185035706 0.8802816867828369 0.5398083925247192 0.8426966071128845 0.5530409812927246 0.8635170459747314\n","Validation loss decreased (0.539808 --> 0.539765).  Saving model ...\n","599 0.49122920632362366 0.8802816867828369 0.5397651791572571 0.8426966071128845 0.5529866218566895 0.8635170459747314\n","Validation loss decreased (0.539765 --> 0.539722).  Saving model ...\n","600 0.4911539554595947 0.8802816867828369 0.5397220849990845 0.8426966071128845 0.552932858467102 0.8635170459747314\n","Validation loss decreased (0.539722 --> 0.539679).  Saving model ...\n","601 0.4910781979560852 0.8802816867828369 0.5396789908409119 0.8426966071128845 0.5528784990310669 0.8635170459747314\n","Validation loss decreased (0.539679 --> 0.539636).  Saving model ...\n","602 0.4910028576850891 0.8802816867828369 0.5396360754966736 0.8426966071128845 0.5528249144554138 0.8635170459747314\n","Validation loss decreased (0.539636 --> 0.539593).  Saving model ...\n","603 0.4909282326698303 0.8802816867828369 0.5395932197570801 0.8426966071128845 0.5527708530426025 0.8635170459747314\n","Validation loss decreased (0.539593 --> 0.539551).  Saving model ...\n","604 0.49085304141044617 0.8802816867828369 0.5395506024360657 0.8426966071128845 0.5527175068855286 0.8635170459747314\n","Validation loss decreased (0.539551 --> 0.539508).  Saving model ...\n","605 0.4907782971858978 0.8802816867828369 0.5395081639289856 0.8426966071128845 0.5526642799377441 0.8635170459747314\n","Validation loss decreased (0.539508 --> 0.539465).  Saving model ...\n","606 0.4907037317752838 0.8816901445388794 0.5394654870033264 0.8426966071128845 0.5526107549667358 0.8635170459747314\n","Validation loss decreased (0.539465 --> 0.539423).  Saving model ...\n","607 0.4906292259693146 0.8816901445388794 0.5394233465194702 0.8426966071128845 0.5525575280189514 0.8635170459747314\n","Validation loss decreased (0.539423 --> 0.539381).  Saving model ...\n","608 0.4905550479888916 0.8816901445388794 0.5393810868263245 0.8426966071128845 0.552504301071167 0.8635170459747314\n","Validation loss decreased (0.539381 --> 0.539339).  Saving model ...\n","609 0.49048128724098206 0.8816901445388794 0.5393391847610474 0.8426966071128845 0.5524511337280273 0.8635170459747314\n","Validation loss decreased (0.539339 --> 0.539297).  Saving model ...\n","610 0.49040699005126953 0.8830986022949219 0.5392971038818359 0.8426966071128845 0.5523987412452698 0.8635170459747314\n","Validation loss decreased (0.539297 --> 0.539255).  Saving model ...\n","611 0.4903336763381958 0.8830986022949219 0.5392552018165588 0.8426966071128845 0.5523458123207092 0.8635170459747314\n","Validation loss decreased (0.539255 --> 0.539214).  Saving model ...\n","612 0.4902600347995758 0.8830986022949219 0.5392135977745056 0.8426966071128845 0.5522935390472412 0.8635170459747314\n","Validation loss decreased (0.539214 --> 0.539172).  Saving model ...\n","613 0.4901867210865021 0.8830986022949219 0.5391718149185181 0.8426966071128845 0.5522408485412598 0.8635170459747314\n","Validation loss decreased (0.539172 --> 0.539131).  Saving model ...\n","614 0.49011415243148804 0.8830986022949219 0.5391305685043335 0.8426966071128845 0.5521881580352783 0.8635170459747314\n","Validation loss decreased (0.539131 --> 0.539089).  Saving model ...\n","615 0.49004045128822327 0.8830986022949219 0.539089024066925 0.8426966071128845 0.5521363615989685 0.8635170459747314\n","Validation loss decreased (0.539089 --> 0.539048).  Saving model ...\n","616 0.48996803164482117 0.8830986022949219 0.5390476584434509 0.8426966071128845 0.5520842671394348 0.8635170459747314\n","Validation loss decreased (0.539048 --> 0.539007).  Saving model ...\n","617 0.4898952543735504 0.8830986022949219 0.539006769657135 0.8426966071128845 0.5520320534706116 0.8635170459747314\n","Validation loss decreased (0.539007 --> 0.538965).  Saving model ...\n","618 0.4898228943347931 0.8830986022949219 0.5389654040336609 0.8426966071128845 0.5519804358482361 0.8635170459747314\n","Validation loss decreased (0.538965 --> 0.538925).  Saving model ...\n","619 0.48975059390068054 0.8830986022949219 0.5389246940612793 0.8426966071128845 0.5519285202026367 0.8635170459747314\n","Validation loss decreased (0.538925 --> 0.538884).  Saving model ...\n","620 0.48967865109443665 0.8830986022949219 0.5388838052749634 0.8426966071128845 0.551876962184906 0.8635170459747314\n","Validation loss decreased (0.538884 --> 0.538843).  Saving model ...\n","621 0.4896070659160614 0.8830986022949219 0.538843035697937 0.8426966071128845 0.5518255233764648 0.8635170459747314\n","Validation loss decreased (0.538843 --> 0.538803).  Saving model ...\n","622 0.48953506350517273 0.8830986022949219 0.5388026237487793 0.8426966071128845 0.5517739653587341 0.8635170459747314\n","Validation loss decreased (0.538803 --> 0.538762).  Saving model ...\n","623 0.4894635081291199 0.8830986022949219 0.5387622117996216 0.8426966071128845 0.5517228841781616 0.8635170459747314\n","Validation loss decreased (0.538762 --> 0.538722).  Saving model ...\n","624 0.4893924593925476 0.8830986022949219 0.5387217998504639 0.8426966071128845 0.5516716241836548 0.8635170459747314\n","Validation loss decreased (0.538722 --> 0.538681).  Saving model ...\n","625 0.48932114243507385 0.8830986022949219 0.5386814475059509 0.8426966071128845 0.5516207218170166 0.8635170459747314\n","Validation loss decreased (0.538681 --> 0.538641).  Saving model ...\n","626 0.489250123500824 0.8830986022949219 0.5386412739753723 0.8426966071128845 0.5515697598457336 0.8635170459747314\n","Validation loss decreased (0.538641 --> 0.538601).  Saving model ...\n","627 0.48917877674102783 0.8830986022949219 0.538601279258728 0.8426966071128845 0.5515187978744507 0.8635170459747314\n","Validation loss decreased (0.538601 --> 0.538561).  Saving model ...\n","628 0.4891081154346466 0.8830986022949219 0.5385614037513733 0.8426966071128845 0.551468014717102 0.8635170459747314\n","Validation loss decreased (0.538561 --> 0.538521).  Saving model ...\n","629 0.4890378415584564 0.8830986022949219 0.5385214686393738 0.8426966071128845 0.5514177680015564 0.8635170459747314\n","Validation loss decreased (0.538521 --> 0.538482).  Saving model ...\n","630 0.48896729946136475 0.8830986022949219 0.5384818911552429 0.8426966071128845 0.5513667464256287 0.8635170459747314\n","Validation loss decreased (0.538482 --> 0.538442).  Saving model ...\n","631 0.4888973832130432 0.8830986022949219 0.5384422540664673 0.8426966071128845 0.5513166189193726 0.8635170459747314\n","Validation loss decreased (0.538442 --> 0.538403).  Saving model ...\n","632 0.48882734775543213 0.8830986022949219 0.538402795791626 0.8426966071128845 0.5512664914131165 0.8635170459747314\n","Validation loss decreased (0.538403 --> 0.538363).  Saving model ...\n","633 0.4887569546699524 0.8830986022949219 0.5383633375167847 0.8426966071128845 0.5512163639068604 0.8635170459747314\n","Validation loss decreased (0.538363 --> 0.538324).  Saving model ...\n","634 0.48868754506111145 0.8830986022949219 0.5383239984512329 0.8426966071128845 0.5511665344238281 0.8635170459747314\n","Validation loss decreased (0.538324 --> 0.538285).  Saving model ...\n","635 0.48861825466156006 0.8830986022949219 0.5382847189903259 0.8426966071128845 0.5511162281036377 0.8635170459747314\n","Validation loss decreased (0.538285 --> 0.538246).  Saving model ...\n","636 0.48854860663414 0.8830986022949219 0.5382457971572876 0.8426966071128845 0.5510666966438293 0.8635170459747314\n","Validation loss decreased (0.538246 --> 0.538207).  Saving model ...\n","637 0.48847925662994385 0.8830986022949219 0.5382067561149597 0.8426966071128845 0.5510167479515076 0.8635170459747314\n","Validation loss decreased (0.538207 --> 0.538168).  Saving model ...\n","638 0.4884101450443268 0.8830986022949219 0.5381678342819214 0.8426966071128845 0.5509673357009888 0.8635170459747314\n","Validation loss decreased (0.538168 --> 0.538129).  Saving model ...\n","639 0.4883415102958679 0.8830986022949219 0.5381291508674622 0.8426966071128845 0.5509176850318909 0.8635170459747314\n","Validation loss decreased (0.538129 --> 0.538091).  Saving model ...\n","640 0.4882728159427643 0.8830986022949219 0.5380905270576477 0.8426966071128845 0.5508683919906616 0.8635170459747314\n","Validation loss decreased (0.538091 --> 0.538052).  Saving model ...\n","641 0.48820433020591736 0.8830986022949219 0.5380518436431885 0.8426966071128845 0.5508193969726562 0.8635170459747314\n","Validation loss decreased (0.538052 --> 0.538014).  Saving model ...\n","642 0.4881357252597809 0.8830986022949219 0.5380135178565979 0.8426966071128845 0.5507699847221375 0.8635170459747314\n","Validation loss decreased (0.538014 --> 0.537975).  Saving model ...\n","643 0.4880678057670593 0.8830986022949219 0.5379748940467834 0.8426966071128845 0.550720751285553 0.8635170459747314\n","Validation loss decreased (0.537975 --> 0.537937).  Saving model ...\n","644 0.4879990518093109 0.8830986022949219 0.5379366874694824 0.8426966071128845 0.5506718754768372 0.8635170459747314\n","Validation loss decreased (0.537937 --> 0.537899).  Saving model ...\n","645 0.4879312515258789 0.8830986022949219 0.5378986597061157 0.8426966071128845 0.55062335729599 0.8635170459747314\n","Validation loss decreased (0.537899 --> 0.537861).  Saving model ...\n","646 0.487863689661026 0.8830986022949219 0.5378605723381042 0.8426966071128845 0.5505746006965637 0.8635170459747314\n","Validation loss decreased (0.537861 --> 0.537823).  Saving model ...\n","647 0.48779600858688354 0.8830986022949219 0.5378226637840271 0.8426966071128845 0.5505260825157166 0.8635170459747314\n","Validation loss decreased (0.537823 --> 0.537785).  Saving model ...\n","648 0.4877285361289978 0.8830986022949219 0.5377846956253052 0.8426966071128845 0.5504773259162903 0.8635170459747314\n","Validation loss decreased (0.537785 --> 0.537747).  Saving model ...\n","649 0.4876609444618225 0.8830986022949219 0.5377469658851624 0.8426966071128845 0.5504288077354431 0.8635170459747314\n","Validation loss decreased (0.537747 --> 0.537709).  Saving model ...\n","650 0.4875938594341278 0.8830986022949219 0.5377092957496643 0.8426966071128845 0.550380527973175 0.8635170459747314\n","Validation loss decreased (0.537709 --> 0.537672).  Saving model ...\n","651 0.48752662539482117 0.8830986022949219 0.5376718044281006 0.8426966071128845 0.5503323078155518 0.8635170459747314\n","Validation loss decreased (0.537672 --> 0.537634).  Saving model ...\n","652 0.48746004700660706 0.8830986022949219 0.5376343727111816 0.8426966071128845 0.5502843856811523 0.8635170459747314\n","Validation loss decreased (0.537634 --> 0.537597).  Saving model ...\n","653 0.4873933792114258 0.8845070600509644 0.5375968813896179 0.8426966071128845 0.5502362847328186 0.8635170459747314\n","Validation loss decreased (0.537597 --> 0.537560).  Saving model ...\n","654 0.4873265326023102 0.8845070600509644 0.5375597476959229 0.8426966071128845 0.5501885414123535 0.8635170459747314\n","Validation loss decreased (0.537560 --> 0.537522).  Saving model ...\n","655 0.48726019263267517 0.8845070600509644 0.5375224947929382 0.8426966071128845 0.5501409769058228 0.8635170459747314\n","Validation loss decreased (0.537522 --> 0.537485).  Saving model ...\n","656 0.4871939718723297 0.8845070600509644 0.5374852418899536 0.8426966071128845 0.5500932335853577 0.8635170459747314\n","Validation loss decreased (0.537485 --> 0.537448).  Saving model ...\n","657 0.48712781071662903 0.8845070600509644 0.5374484658241272 0.8426966071128845 0.5500456690788269 0.8635170459747314\n","Validation loss decreased (0.537448 --> 0.537412).  Saving model ...\n","658 0.48706185817718506 0.8845070600509644 0.5374115109443665 0.8426966071128845 0.5499981045722961 0.8635170459747314\n","Validation loss decreased (0.537412 --> 0.537375).  Saving model ...\n","659 0.4869958162307739 0.8845070600509644 0.5373746752738953 0.8426966071128845 0.5499505996704102 0.8635170459747314\n","Validation loss decreased (0.537375 --> 0.537338).  Saving model ...\n","660 0.48693037033081055 0.8845070600509644 0.5373380780220032 0.8426966071128845 0.5499033331871033 0.8635170459747314\n","Validation loss decreased (0.537338 --> 0.537301).  Saving model ...\n","661 0.48686468601226807 0.8859155178070068 0.5373013615608215 0.8426966071128845 0.5498560667037964 0.8635170459747314\n","Validation loss decreased (0.537301 --> 0.537265).  Saving model ...\n","662 0.4867992401123047 0.8859155178070068 0.5372648239135742 0.8426966071128845 0.5498092174530029 0.8635170459747314\n","Validation loss decreased (0.537265 --> 0.537228).  Saving model ...\n","663 0.4867345988750458 0.8859155178070068 0.5372281074523926 0.8426966071128845 0.5497623682022095 0.8635170459747314\n","Validation loss decreased (0.537228 --> 0.537192).  Saving model ...\n","664 0.4866691827774048 0.8859155178070068 0.5371919870376587 0.8426966071128845 0.5497153997421265 0.8635170459747314\n","Validation loss decreased (0.537192 --> 0.537156).  Saving model ...\n","665 0.486604243516922 0.8859155178070068 0.53715580701828 0.8426966071128845 0.5496683716773987 0.8635170459747314\n","Validation loss decreased (0.537156 --> 0.537120).  Saving model ...\n","666 0.48653942346572876 0.8859155178070068 0.5371196866035461 0.8426966071128845 0.5496219992637634 0.8635170459747314\n","Validation loss decreased (0.537120 --> 0.537084).  Saving model ...\n","667 0.4864748418331146 0.8859155178070068 0.5370835661888123 0.8426966071128845 0.5495753288269043 0.8635170459747314\n","Validation loss decreased (0.537084 --> 0.537048).  Saving model ...\n","668 0.486409991979599 0.8859155178070068 0.5370475649833679 0.8426966071128845 0.5495288372039795 0.8635170459747314\n","Validation loss decreased (0.537048 --> 0.537012).  Saving model ...\n","669 0.4863457977771759 0.8859155178070068 0.5370118021965027 0.8426966071128845 0.5494821667671204 0.8635170459747314\n","Validation loss decreased (0.537012 --> 0.536976).  Saving model ...\n","670 0.48628175258636475 0.8859155178070068 0.5369759798049927 0.8426966071128845 0.5494359731674194 0.8635170459747314\n","Validation loss decreased (0.536976 --> 0.536940).  Saving model ...\n","671 0.4862174987792969 0.8859155178070068 0.5369403958320618 0.8426966071128845 0.5493898391723633 0.8635170459747314\n","Validation loss decreased (0.536940 --> 0.536905).  Saving model ...\n","672 0.4861535429954529 0.8859155178070068 0.5369048118591309 0.8426966071128845 0.5493436455726624 0.8635170459747314\n","Validation loss decreased (0.536905 --> 0.536869).  Saving model ...\n","673 0.4860895872116089 0.8859155178070068 0.5368692278862 0.8426966071128845 0.5492980480194092 0.8635170459747314\n","Validation loss decreased (0.536869 --> 0.536834).  Saving model ...\n","674 0.48602592945098877 0.8859155178070068 0.536833643913269 0.8426966071128845 0.5492520928382874 0.8635170459747314\n","Validation loss decreased (0.536834 --> 0.536799).  Saving model ...\n","675 0.4859623610973358 0.8859155178070068 0.5367985367774963 0.8426966071128845 0.5492060780525208 0.8635170459747314\n","Validation loss decreased (0.536799 --> 0.536763).  Saving model ...\n","676 0.48589909076690674 0.8859155178070068 0.5367633700370789 0.8426966071128845 0.5491602420806885 0.8635170459747314\n","Validation loss decreased (0.536763 --> 0.536728).  Saving model ...\n","677 0.48583588004112244 0.8859155178070068 0.5367281436920166 0.8426966071128845 0.549114465713501 0.8635170459747314\n","Validation loss decreased (0.536728 --> 0.536693).  Saving model ...\n","678 0.4857728183269501 0.8859155178070068 0.5366930365562439 0.8426966071128845 0.5490694642066956 0.8635170459747314\n","Validation loss decreased (0.536693 --> 0.536658).  Saving model ...\n","679 0.4857100546360016 0.8859155178070068 0.5366581678390503 0.8426966071128845 0.5490237474441528 0.8635170459747314\n","Validation loss decreased (0.536658 --> 0.536623).  Saving model ...\n","680 0.485647052526474 0.8859155178070068 0.5366230607032776 0.8426966071128845 0.5489785075187683 0.8635170459747314\n","Validation loss decreased (0.536623 --> 0.536588).  Saving model ...\n","681 0.4855844974517822 0.8859155178070068 0.5365883111953735 0.8426966071128845 0.5489333271980286 0.8635170459747314\n","Validation loss decreased (0.536588 --> 0.536553).  Saving model ...\n","682 0.4855215549468994 0.8859155178070068 0.5365533828735352 0.8426966071128845 0.5488881468772888 0.8635170459747314\n","Validation loss decreased (0.536553 --> 0.536519).  Saving model ...\n","683 0.4854591190814972 0.8859155178070068 0.5365187525749207 0.8426966071128845 0.5488430857658386 0.8635170459747314\n","Validation loss decreased (0.536519 --> 0.536484).  Saving model ...\n","684 0.48539674282073975 0.8859155178070068 0.5364843010902405 0.8426966071128845 0.5487980246543884 0.8635170459747314\n","Validation loss decreased (0.536484 --> 0.536450).  Saving model ...\n","685 0.4853348135948181 0.8859155178070068 0.5364498496055603 0.8426966071128845 0.5487531423568726 0.8635170459747314\n","Validation loss decreased (0.536450 --> 0.536415).  Saving model ...\n","686 0.48527300357818604 0.8859155178070068 0.5364153385162354 0.8426966071128845 0.5487083196640015 0.8635170459747314\n","Validation loss decreased (0.536415 --> 0.536381).  Saving model ...\n","687 0.4852111041545868 0.8859155178070068 0.536381185054779 0.8426966071128845 0.5486639142036438 0.8635170459747314\n","Validation loss decreased (0.536381 --> 0.536347).  Saving model ...\n","688 0.48514893651008606 0.8859155178070068 0.5363471508026123 0.8426966071128845 0.548618733882904 0.8635170459747314\n","Validation loss decreased (0.536347 --> 0.536313).  Saving model ...\n","689 0.48508745431900024 0.8859155178070068 0.5363128185272217 0.8426966071128845 0.5485743284225464 0.8635170459747314\n","Validation loss decreased (0.536313 --> 0.536279).  Saving model ...\n","690 0.4850260019302368 0.8859155178070068 0.5362787842750549 0.8426966071128845 0.5485299229621887 0.8635170459747314\n","Validation loss decreased (0.536279 --> 0.536245).  Saving model ...\n","691 0.4849648177623749 0.8859155178070068 0.5362447500228882 0.8426966071128845 0.5484859347343445 0.8635170459747314\n","Validation loss decreased (0.536245 --> 0.536211).  Saving model ...\n","692 0.4849034547805786 0.8859155178070068 0.536210834980011 0.8426966071128845 0.5484414100646973 0.8635170459747314\n","Validation loss decreased (0.536211 --> 0.536177).  Saving model ...\n","693 0.4848421514034271 0.8859155178070068 0.5361769199371338 0.8426966071128845 0.5483973026275635 0.8635170459747314\n","Validation loss decreased (0.536177 --> 0.536143).  Saving model ...\n","694 0.48478132486343384 0.8859155178070068 0.5361433029174805 0.8426966071128845 0.5483530759811401 0.8635170459747314\n","Validation loss decreased (0.536143 --> 0.536110).  Saving model ...\n","695 0.4847206473350525 0.8859155178070068 0.5361096858978271 0.8426966071128845 0.5483093857765198 0.8635170459747314\n","Validation loss decreased (0.536110 --> 0.536076).  Saving model ...\n","696 0.4846595823764801 0.8859155178070068 0.5360760688781738 0.8426966071128845 0.5482653975486755 0.8635170459747314\n","Validation loss decreased (0.536076 --> 0.536043).  Saving model ...\n","697 0.48459911346435547 0.8859155178070068 0.5360426306724548 0.8426966071128845 0.5482214093208313 0.8635170459747314\n","Validation loss decreased (0.536043 --> 0.536009).  Saving model ...\n","698 0.4845386743545532 0.8859155178070068 0.5360094308853149 0.8426966071128845 0.5481777191162109 0.8635170459747314\n","Validation loss decreased (0.536009 --> 0.535976).  Saving model ...\n","699 0.48447850346565247 0.8859155178070068 0.535975992679596 0.8426966071128845 0.5481340289115906 0.8635170459747314\n","Validation loss decreased (0.535976 --> 0.535943).  Saving model ...\n","700 0.4844186007976532 0.8859155178070068 0.5359426736831665 0.8426966071128845 0.5480907559394836 0.8635170459747314\n","Validation loss decreased (0.535943 --> 0.535909).  Saving model ...\n","701 0.4843583405017853 0.8859155178070068 0.5359094738960266 0.8426966071128845 0.5480470061302185 0.8635170459747314\n","Validation loss decreased (0.535909 --> 0.535876).  Saving model ...\n","702 0.48429813981056213 0.8859155178070068 0.5358763933181763 0.8426966071128845 0.5480038523674011 0.8635170459747314\n","Validation loss decreased (0.535876 --> 0.535843).  Saving model ...\n","703 0.48423832654953003 0.8859155178070068 0.5358434915542603 0.8426966071128845 0.5479606986045837 0.8635170459747314\n","Validation loss decreased (0.535843 --> 0.535811).  Saving model ...\n","704 0.484178364276886 0.8859155178070068 0.535810649394989 0.8426966071128845 0.547917366027832 0.8635170459747314\n","Validation loss decreased (0.535811 --> 0.535778).  Saving model ...\n","705 0.48411908745765686 0.8859155178070068 0.535777747631073 0.8426966071128845 0.5478742718696594 0.8635170459747314\n","Validation loss decreased (0.535778 --> 0.535745).  Saving model ...\n","706 0.4840596914291382 0.8859155178070068 0.535744845867157 0.8426966071128845 0.547831118106842 0.8635170459747314\n","Validation loss decreased (0.535745 --> 0.535712).  Saving model ...\n","707 0.48399990797042847 0.8859155178070068 0.5357122421264648 0.8426966071128845 0.5477883219718933 0.8635170459747314\n","Validation loss decreased (0.535712 --> 0.535680).  Saving model ...\n","708 0.4839410185813904 0.8859155178070068 0.5356797575950623 0.8426966071128845 0.5477451086044312 0.8635170459747314\n","Validation loss decreased (0.535680 --> 0.535647).  Saving model ...\n","709 0.48388224840164185 0.8859155178070068 0.5356471538543701 0.8426966071128845 0.5477026104927063 0.8635170459747314\n","Validation loss decreased (0.535647 --> 0.535614).  Saving model ...\n","710 0.483823299407959 0.8859155178070068 0.5356143712997437 0.8426966071128845 0.5476598739624023 0.8635170459747314\n","Validation loss decreased (0.535614 --> 0.535582).  Saving model ...\n","711 0.4837643802165985 0.8859155178070068 0.5355823636054993 0.8426966071128845 0.5476172566413879 0.8635170459747314\n","Validation loss decreased (0.535582 --> 0.535550).  Saving model ...\n","712 0.4837055802345276 0.8859155178070068 0.5355497598648071 0.8426966071128845 0.5475745797157288 0.8635170459747314\n","Validation loss decreased (0.535550 --> 0.535517).  Saving model ...\n","713 0.483646959066391 0.8859155178070068 0.5355174541473389 0.8426966071128845 0.5475323796272278 0.8635170459747314\n","Validation loss decreased (0.535517 --> 0.535486).  Saving model ...\n","714 0.48358842730522156 0.8859155178070068 0.5354855060577393 0.8426966071128845 0.5474900007247925 0.8635170459747314\n","Validation loss decreased (0.535486 --> 0.535454).  Saving model ...\n","715 0.4835299849510193 0.8859155178070068 0.5354535579681396 0.8426966071128845 0.547447681427002 0.8635170459747314\n","Validation loss decreased (0.535454 --> 0.535422).  Saving model ...\n","716 0.4834721088409424 0.8859155178070068 0.5354215502738953 0.8426966071128845 0.5474052429199219 0.8635170459747314\n","Validation loss decreased (0.535422 --> 0.535390).  Saving model ...\n","717 0.4834136664867401 0.8859155178070068 0.5353895425796509 0.8426966071128845 0.54736328125 0.8635170459747314\n","Validation loss decreased (0.535390 --> 0.535358).  Saving model ...\n","718 0.48335617780685425 0.8859155178070068 0.5353575944900513 0.8426966071128845 0.5473213195800781 0.8635170459747314\n","Validation loss decreased (0.535358 --> 0.535326).  Saving model ...\n","719 0.48329806327819824 0.8859155178070068 0.5353258848190308 0.8426966071128845 0.5472792387008667 0.8635170459747314\n","Validation loss decreased (0.535326 --> 0.535294).  Saving model ...\n","720 0.4832403361797333 0.8859155178070068 0.535294234752655 0.8426966071128845 0.5472375154495239 0.8635170459747314\n","Validation loss decreased (0.535294 --> 0.535263).  Saving model ...\n","721 0.4831823408603668 0.8859155178070068 0.5352625250816345 0.8426966071128845 0.5471956133842468 0.8635170459747314\n","Validation loss decreased (0.535263 --> 0.535231).  Saving model ...\n","722 0.48312488198280334 0.8859155178070068 0.5352311134338379 0.8426966071128845 0.5471539497375488 0.8635170459747314\n","Validation loss decreased (0.535231 --> 0.535199).  Saving model ...\n","723 0.4830676317214966 0.8859155178070068 0.5351994037628174 0.8426966071128845 0.5471121072769165 0.8635170459747314\n","Validation loss decreased (0.535199 --> 0.535168).  Saving model ...\n","724 0.4830103814601898 0.8859155178070068 0.5351681113243103 0.8426966071128845 0.5470707416534424 0.8635170459747314\n","Validation loss decreased (0.535168 --> 0.535137).  Saving model ...\n","725 0.4829533100128174 0.8873239159584045 0.5351366400718689 0.8426966071128845 0.5470290780067444 0.8635170459747314\n","Validation loss decreased (0.535137 --> 0.535105).  Saving model ...\n","726 0.4828964173793793 0.8873239159584045 0.5351054668426514 0.8426966071128845 0.5469875335693359 0.8635170459747314\n","Validation loss decreased (0.535105 --> 0.535074).  Saving model ...\n","727 0.482839435338974 0.8873239159584045 0.5350741744041443 0.8426966071128845 0.5469464659690857 0.8635170459747314\n","Validation loss decreased (0.535074 --> 0.535043).  Saving model ...\n","728 0.4827823340892792 0.8873239159584045 0.5350433588027954 0.8426966071128845 0.5469051599502563 0.8635170459747314\n","Validation loss decreased (0.535043 --> 0.535012).  Saving model ...\n","729 0.48272591829299927 0.8873239159584045 0.5350121259689331 0.8426966071128845 0.5468642115592957 0.8635170459747314\n","Validation loss decreased (0.535012 --> 0.534981).  Saving model ...\n","730 0.48266881704330444 0.8873239159584045 0.5349810719490051 0.8426966071128845 0.5468227863311768 0.8635170459747314\n","Validation loss decreased (0.534981 --> 0.534950).  Saving model ...\n","731 0.4826129972934723 0.8873239159584045 0.5349501371383667 0.8426966071128845 0.5467818379402161 0.8635170459747314\n","Validation loss decreased (0.534950 --> 0.534919).  Saving model ...\n","732 0.48255637288093567 0.8873239159584045 0.534919261932373 0.8426966071128845 0.546740710735321 0.8635170459747314\n","Validation loss decreased (0.534919 --> 0.534889).  Saving model ...\n","733 0.4825003147125244 0.8873239159584045 0.5348885655403137 0.8426966071128845 0.546700119972229 0.8635170459747314\n","Validation loss decreased (0.534889 --> 0.534858).  Saving model ...\n","734 0.48244407773017883 0.8873239159584045 0.5348578691482544 0.8426966071128845 0.5466593503952026 0.8635170459747314\n","Validation loss decreased (0.534858 --> 0.534827).  Saving model ...\n","735 0.48238807916641235 0.8873239159584045 0.5348271131515503 0.8426966071128845 0.546618640422821 0.8635170459747314\n","Validation loss decreased (0.534827 --> 0.534796).  Saving model ...\n","736 0.48233214020729065 0.8873239159584045 0.5347964763641357 0.8426966071128845 0.5465779900550842 0.8635170459747314\n","Validation loss decreased (0.534796 --> 0.534766).  Saving model ...\n","737 0.4822760820388794 0.8873239159584045 0.5347660183906555 0.8426966071128845 0.5465376377105713 0.8635170459747314\n","Validation loss decreased (0.534766 --> 0.534736).  Saving model ...\n","738 0.4822206199169159 0.8873239159584045 0.5347355008125305 0.8426966071128845 0.5464969277381897 0.8635170459747314\n","Validation loss decreased (0.534736 --> 0.534705).  Saving model ...\n","739 0.4821648597717285 0.8873239159584045 0.5347052216529846 0.8426966071128845 0.5464562773704529 0.8635170459747314\n","Validation loss decreased (0.534705 --> 0.534675).  Saving model ...\n","740 0.4821093678474426 0.8873239159584045 0.5346749424934387 0.8426966071128845 0.5464161038398743 0.8635170459747314\n","Validation loss decreased (0.534675 --> 0.534645).  Saving model ...\n","741 0.48205432295799255 0.8873239159584045 0.5346447229385376 0.8426966071128845 0.5463756918907166 0.8635170459747314\n","Validation loss decreased (0.534645 --> 0.534615).  Saving model ...\n","742 0.48199883103370667 0.8873239159584045 0.534614622592926 0.8426966071128845 0.5463358163833618 0.8635170459747314\n","Validation loss decreased (0.534615 --> 0.534584).  Saving model ...\n","743 0.4819434881210327 0.8873239159584045 0.5345844626426697 0.8426966071128845 0.5462956428527832 0.8635170459747314\n","Validation loss decreased (0.534584 --> 0.534554).  Saving model ...\n","744 0.4818885922431946 0.8873239159584045 0.5345544219017029 0.8426966071128845 0.5462554097175598 0.8635170459747314\n","Validation loss decreased (0.534554 --> 0.534525).  Saving model ...\n","745 0.48183372616767883 0.8873239159584045 0.5345246195793152 0.8426966071128845 0.5462157726287842 0.8635170459747314\n","Validation loss decreased (0.534525 --> 0.534495).  Saving model ...\n","746 0.481779009103775 0.8873239159584045 0.5344946980476379 0.8426966071128845 0.5461757779121399 0.8635170459747314\n","Validation loss decreased (0.534495 --> 0.534465).  Saving model ...\n","747 0.48172464966773987 0.8873239159584045 0.5344647169113159 0.8426966071128845 0.5461360216140747 0.8635170459747314\n","Validation loss decreased (0.534465 --> 0.534435).  Saving model ...\n","748 0.48166945576667786 0.8873239159584045 0.5344349145889282 0.8426966071128845 0.5460962057113647 0.8635170459747314\n","Validation loss decreased (0.534435 --> 0.534405).  Saving model ...\n","749 0.48161524534225464 0.8873239159584045 0.5344052910804749 0.8426966071128845 0.5460565686225891 0.8635170459747314\n","Validation loss decreased (0.534405 --> 0.534376).  Saving model ...\n","750 0.4815610349178314 0.8873239159584045 0.5343755483627319 0.8426966071128845 0.5460168719291687 0.8635170459747314\n","Validation loss decreased (0.534376 --> 0.534346).  Saving model ...\n","751 0.48150694370269775 0.8873239159584045 0.5343460440635681 0.8426966071128845 0.5459772944450378 0.8635170459747314\n","Validation loss decreased (0.534346 --> 0.534317).  Saving model ...\n","752 0.4814525246620178 0.8873239159584045 0.5343165993690491 0.8426966071128845 0.5459379553794861 0.8608924150466919\n","Validation loss decreased (0.534317 --> 0.534287).  Saving model ...\n","753 0.4813983738422394 0.8873239159584045 0.5342870354652405 0.8426966071128845 0.5458985567092896 0.8608924150466919\n","Validation loss decreased (0.534287 --> 0.534258).  Saving model ...\n","754 0.4813438951969147 0.8873239159584045 0.5342578887939453 0.8426966071128845 0.5458592176437378 0.8608924150466919\n","Validation loss decreased (0.534258 --> 0.534229).  Saving model ...\n","755 0.48129069805145264 0.8873239159584045 0.534228503704071 0.8426966071128845 0.5458202362060547 0.8608924150466919\n","Validation loss decreased (0.534229 --> 0.534199).  Saving model ...\n","756 0.4812368154525757 0.8873239159584045 0.534199059009552 0.8426966071128845 0.5457808375358582 0.8608924150466919\n","Validation loss decreased (0.534199 --> 0.534170).  Saving model ...\n","757 0.4811830520629883 0.8873239159584045 0.5341699719429016 0.8426966071128845 0.5457420349121094 0.8608924150466919\n","Validation loss decreased (0.534170 --> 0.534141).  Saving model ...\n","758 0.4811294972896576 0.8873239159584045 0.5341407656669617 0.8426966071128845 0.5457028150558472 0.8608924150466919\n","Validation loss decreased (0.534141 --> 0.534112).  Saving model ...\n","759 0.48107588291168213 0.8873239159584045 0.5341117978096008 0.8426966071128845 0.5456637740135193 0.8608924150466919\n","Validation loss decreased (0.534112 --> 0.534083).  Saving model ...\n","760 0.48102277517318726 0.8873239159584045 0.5340827107429504 0.8370786309242249 0.5456249117851257 0.8608924150466919\n","Validation loss decreased (0.534083 --> 0.534054).  Saving model ...\n","761 0.48096922039985657 0.8873239159584045 0.5340538024902344 0.8370786309242249 0.5455865263938904 0.8608924150466919\n","Validation loss decreased (0.534054 --> 0.534025).  Saving model ...\n","762 0.4809161424636841 0.8873239159584045 0.5340248942375183 0.8370786309242249 0.5455474257469177 0.8582677245140076\n","Validation loss decreased (0.534025 --> 0.533996).  Saving model ...\n","763 0.4808632433414459 0.8873239159584045 0.5339961051940918 0.8370786309242249 0.5455086827278137 0.8582677245140076\n","Validation loss decreased (0.533996 --> 0.533967).  Saving model ...\n","764 0.480810284614563 0.8873239159584045 0.5339673161506653 0.8370786309242249 0.5454699397087097 0.8582677245140076\n","Validation loss decreased (0.533967 --> 0.533939).  Saving model ...\n","765 0.48075759410858154 0.8873239159584045 0.5339389443397522 0.8370786309242249 0.5454317331314087 0.8582677245140076\n","Validation loss decreased (0.533939 --> 0.533910).  Saving model ...\n","766 0.4807049334049225 0.8873239159584045 0.5339100956916809 0.8370786309242249 0.5453930497169495 0.8582677245140076\n","Validation loss decreased (0.533910 --> 0.533882).  Saving model ...\n","767 0.4806523025035858 0.8873239159584045 0.5338816046714783 0.8370786309242249 0.5453548431396484 0.8582677245140076\n","Validation loss decreased (0.533882 --> 0.533853).  Saving model ...\n","768 0.4805994927883148 0.8873239159584045 0.5338532328605652 0.8370786309242249 0.5453162789344788 0.8582677245140076\n","Validation loss decreased (0.533853 --> 0.533825).  Saving model ...\n","769 0.48054730892181396 0.8873239159584045 0.5338246822357178 0.8370786309242249 0.5452784299850464 0.8582677245140076\n","Validation loss decreased (0.533825 --> 0.533796).  Saving model ...\n","770 0.4804949462413788 0.8873239159584045 0.5337960720062256 0.8370786309242249 0.5452399253845215 0.8582677245140076\n","Validation loss decreased (0.533796 --> 0.533768).  Saving model ...\n","771 0.48044273257255554 0.8873239159584045 0.5337678790092468 0.8370786309242249 0.54520183801651 0.8582677245140076\n","Validation loss decreased (0.533768 --> 0.533740).  Saving model ...\n","772 0.4803906977176666 0.8873239159584045 0.5337395071983337 0.8370786309242249 0.545163631439209 0.8582677245140076\n","Validation loss decreased (0.533740 --> 0.533712).  Saving model ...\n","773 0.4803386926651001 0.8873239159584045 0.5337115526199341 0.8370786309242249 0.5451257824897766 0.8582677245140076\n","Validation loss decreased (0.533712 --> 0.533683).  Saving model ...\n","774 0.48028647899627686 0.8873239159584045 0.5336832404136658 0.8370786309242249 0.545087993144989 0.8582677245140076\n","Validation loss decreased (0.533683 --> 0.533655).  Saving model ...\n","775 0.48023489117622375 0.8873239159584045 0.5336552262306213 0.8370786309242249 0.5450496673583984 0.8582677245140076\n","Validation loss decreased (0.533655 --> 0.533627).  Saving model ...\n","776 0.4801829755306244 0.8873239159584045 0.5336271524429321 0.8370786309242249 0.5450121164321899 0.8582677245140076\n","Validation loss decreased (0.533627 --> 0.533599).  Saving model ...\n","777 0.48013150691986084 0.8873239159584045 0.5335994362831116 0.8370786309242249 0.5449743866920471 0.8582677245140076\n","Validation loss decreased (0.533599 --> 0.533571).  Saving model ...\n","778 0.4800797700881958 0.8873239159584045 0.5335713028907776 0.8370786309242249 0.5449365973472595 0.8582677245140076\n","Validation loss decreased (0.533571 --> 0.533543).  Saving model ...\n","779 0.4800286293029785 0.8873239159584045 0.5335432887077332 0.8370786309242249 0.5448991656303406 0.8582677245140076\n","Validation loss decreased (0.533543 --> 0.533516).  Saving model ...\n","780 0.47997725009918213 0.8873239159584045 0.5335156917572021 0.8370786309242249 0.5448617935180664 0.8582677245140076\n","Validation loss decreased (0.533516 --> 0.533488).  Saving model ...\n","781 0.4799259603023529 0.8873239159584045 0.5334879755973816 0.8370786309242249 0.5448241829872131 0.8582677245140076\n","Validation loss decreased (0.533488 --> 0.533460).  Saving model ...\n","782 0.47987446188926697 0.8873239159584045 0.5334601998329163 0.8370786309242249 0.5447867512702942 0.8582677245140076\n","Validation loss decreased (0.533460 --> 0.533433).  Saving model ...\n","783 0.4798237085342407 0.8873239159584045 0.5334326028823853 0.8370786309242249 0.5447490811347961 0.8582677245140076\n","Validation loss decreased (0.533433 --> 0.533405).  Saving model ...\n","784 0.47977250814437866 0.8873239159584045 0.5334049463272095 0.8370786309242249 0.5447120666503906 0.8582677245140076\n","Validation loss decreased (0.533405 --> 0.533377).  Saving model ...\n","785 0.47972166538238525 0.8873239159584045 0.5333774089813232 0.8370786309242249 0.544675350189209 0.8582677245140076\n","Validation loss decreased (0.533377 --> 0.533350).  Saving model ...\n","786 0.4796711802482605 0.8873239159584045 0.5333501100540161 0.8370786309242249 0.5446380376815796 0.8582677245140076\n","Validation loss decreased (0.533350 --> 0.533323).  Saving model ...\n","787 0.4796205461025238 0.8873239159584045 0.5333226323127747 0.8370786309242249 0.5446006059646606 0.8582677245140076\n","Validation loss decreased (0.533323 --> 0.533295).  Saving model ...\n","788 0.47956982254981995 0.8873239159584045 0.5332953333854675 0.8370786309242249 0.5445636510848999 0.8582677245140076\n","Validation loss decreased (0.533295 --> 0.533268).  Saving model ...\n","789 0.4795195162296295 0.8873239159584045 0.5332679152488708 0.8370786309242249 0.544526994228363 0.8582677245140076\n","Validation loss decreased (0.533268 --> 0.533241).  Saving model ...\n","790 0.47946876287460327 0.8873239159584045 0.5332408547401428 0.8370786309242249 0.5444900989532471 0.8582677245140076\n","Validation loss decreased (0.533241 --> 0.533214).  Saving model ...\n","791 0.47941887378692627 0.8873239159584045 0.53321373462677 0.8370786309242249 0.5444533228874207 0.8582677245140076\n","Validation loss decreased (0.533214 --> 0.533187).  Saving model ...\n","792 0.47936803102493286 0.8873239159584045 0.5331865549087524 0.8370786309242249 0.5444165468215942 0.8582677245140076\n","Validation loss decreased (0.533187 --> 0.533159).  Saving model ...\n","793 0.47931843996047974 0.8873239159584045 0.5331594944000244 0.8370786309242249 0.5443795323371887 0.8582677245140076\n","Validation loss decreased (0.533159 --> 0.533132).  Saving model ...\n","794 0.479268342256546 0.8873239159584045 0.5331323742866516 0.8370786309242249 0.5443429946899414 0.8582677245140076\n","Validation loss decreased (0.533132 --> 0.533106).  Saving model ...\n","795 0.47921836376190186 0.8873239159584045 0.5331055521965027 0.8370786309242249 0.5443068742752075 0.8582677245140076\n","Validation loss decreased (0.533106 --> 0.533079).  Saving model ...\n","796 0.4791683852672577 0.8873239159584045 0.5330787897109985 0.8370786309242249 0.5442702174186707 0.8582677245140076\n","Validation loss decreased (0.533079 --> 0.533052).  Saving model ...\n","797 0.47911861538887024 0.8873239159584045 0.5330516695976257 0.8370786309242249 0.5442334413528442 0.8582677245140076\n","Validation loss decreased (0.533052 --> 0.533025).  Saving model ...\n","798 0.47906896471977234 0.8873239159584045 0.5330251455307007 0.8370786309242249 0.5441973805427551 0.8582677245140076\n","Validation loss decreased (0.533025 --> 0.532998).  Saving model ...\n","799 0.4790194630622864 0.8873239159584045 0.5329982042312622 0.8370786309242249 0.5441606640815735 0.8582677245140076\n","Validation loss decreased (0.532998 --> 0.532972).  Saving model ...\n","800 0.47897011041641235 0.8873239159584045 0.5329716801643372 0.8370786309242249 0.5441251993179321 0.8582677245140076\n","Validation loss decreased (0.532972 --> 0.532945).  Saving model ...\n","801 0.47892072796821594 0.8873239159584045 0.5329450368881226 0.8370786309242249 0.54408860206604 0.8582677245140076\n","Validation loss decreased (0.532945 --> 0.532918).  Saving model ...\n","802 0.47887101769447327 0.8873239159584045 0.5329183340072632 0.8370786309242249 0.5440528988838196 0.8582677245140076\n","Validation loss decreased (0.532918 --> 0.532892).  Saving model ...\n","803 0.478821724653244 0.8873239159584045 0.5328917503356934 0.8370786309242249 0.5440162420272827 0.8582677245140076\n","Validation loss decreased (0.532892 --> 0.532865).  Saving model ...\n","804 0.4787725508213043 0.8873239159584045 0.5328654050827026 0.8370786309242249 0.5439804196357727 0.8556430339813232\n","Validation loss decreased (0.532865 --> 0.532839).  Saving model ...\n","805 0.4787236452102661 0.8873239159584045 0.5328392386436462 0.8370786309242249 0.5439445376396179 0.8556430339813232\n","Validation loss decreased (0.532839 --> 0.532812).  Saving model ...\n","806 0.4786747992038727 0.8873239159584045 0.5328124165534973 0.8370786309242249 0.5439085960388184 0.8556430339813232\n","Validation loss decreased (0.532812 --> 0.532787).  Saving model ...\n","807 0.47862598299980164 0.8873239159584045 0.5327866077423096 0.8370786309242249 0.5438729524612427 0.8556430339813232\n","Validation loss decreased (0.532787 --> 0.532760).  Saving model ...\n","808 0.47857725620269775 0.8873239159584045 0.5327600836753845 0.8370786309242249 0.5438371300697327 0.8556430339813232\n","Validation loss decreased (0.532760 --> 0.532734).  Saving model ...\n","809 0.47852835059165955 0.8873239159584045 0.5327339172363281 0.8370786309242249 0.5438013672828674 0.8556430339813232\n","Validation loss decreased (0.532734 --> 0.532708).  Saving model ...\n","810 0.4784797728061676 0.8873239159584045 0.532707691192627 0.8370786309242249 0.5437656044960022 0.8556430339813232\n","Validation loss decreased (0.532708 --> 0.532682).  Saving model ...\n","811 0.47843137383461 0.8873239159584045 0.5326815843582153 0.8370786309242249 0.5437300801277161 0.8556430339813232\n","Validation loss decreased (0.532682 --> 0.532655).  Saving model ...\n","812 0.4783826172351837 0.8873239159584045 0.5326554179191589 0.8370786309242249 0.543694794178009 0.8556430339813232\n","Validation loss decreased (0.532655 --> 0.532630).  Saving model ...\n","813 0.4783346652984619 0.8873239159584045 0.532629668712616 0.8370786309242249 0.5436591506004333 0.8556430339813232\n","Validation loss decreased (0.532630 --> 0.532604).  Saving model ...\n","814 0.4782862961292267 0.8873239159584045 0.5326036214828491 0.8370786309242249 0.5436236262321472 0.8556430339813232\n","Validation loss decreased (0.532604 --> 0.532578).  Saving model ...\n","815 0.478238046169281 0.8873239159584045 0.5325778722763062 0.8370786309242249 0.5435881614685059 0.8556430339813232\n","Validation loss decreased (0.532578 --> 0.532552).  Saving model ...\n","816 0.4781901240348816 0.8873239159584045 0.5325518250465393 0.8370786309242249 0.5435531139373779 0.8556430339813232\n","Validation loss decreased (0.532552 --> 0.532526).  Saving model ...\n","817 0.4781418442726135 0.8873239159584045 0.5325261950492859 0.8370786309242249 0.5435178279876709 0.8556430339813232\n","Validation loss decreased (0.532526 --> 0.532500).  Saving model ...\n","818 0.4780941307544708 0.8873239159584045 0.5325004458427429 0.8314606547355652 0.5434825420379639 0.8556430339813232\n","Validation loss decreased (0.532500 --> 0.532475).  Saving model ...\n","819 0.4780464768409729 0.8873239159584045 0.5324748158454895 0.8314606547355652 0.543447732925415 0.8556430339813232\n","Validation loss decreased (0.532475 --> 0.532449).  Saving model ...\n","820 0.47799864411354065 0.8873239159584045 0.5324490666389465 0.8314606547355652 0.5434128046035767 0.8556430339813232\n","Validation loss decreased (0.532449 --> 0.532423).  Saving model ...\n","821 0.4779510796070099 0.8873239159584045 0.5324233174324036 0.8314606547355652 0.5433775186538696 0.8556430339813232\n","Validation loss decreased (0.532423 --> 0.532398).  Saving model ...\n","822 0.4779032766819 0.8873239159584045 0.5323976874351501 0.8314606547355652 0.543342649936676 0.8556430339813232\n","Validation loss decreased (0.532398 --> 0.532373).  Saving model ...\n","823 0.4778556823730469 0.8873239159584045 0.5323725342750549 0.8314606547355652 0.5433076024055481 0.8556430339813232\n","Validation loss decreased (0.532373 --> 0.532347).  Saving model ...\n","824 0.4778086841106415 0.8873239159584045 0.5323469638824463 0.8314606547355652 0.5432729721069336 0.8556430339813232\n","Validation loss decreased (0.532347 --> 0.532322).  Saving model ...\n","825 0.4777611196041107 0.8873239159584045 0.5323215126991272 0.8314606547355652 0.5432380437850952 0.8556430339813232\n","Validation loss decreased (0.532322 --> 0.532296).  Saving model ...\n","826 0.4777139723300934 0.8873239159584045 0.5322962403297424 0.8314606547355652 0.5432034134864807 0.8556430339813232\n","Validation loss decreased (0.532296 --> 0.532271).  Saving model ...\n","827 0.47766703367233276 0.8873239159584045 0.5322708487510681 0.8314606547355652 0.543168842792511 0.8556430339813232\n","Validation loss decreased (0.532271 --> 0.532246).  Saving model ...\n","828 0.47761958837509155 0.8873239159584045 0.5322456955909729 0.8314606547355652 0.5431339740753174 0.8556430339813232\n","Validation loss decreased (0.532246 --> 0.532220).  Saving model ...\n","829 0.47757282853126526 0.8873239159584045 0.5322203636169434 0.8314606547355652 0.5430997014045715 0.8556430339813232\n","Validation loss decreased (0.532220 --> 0.532195).  Saving model ...\n","830 0.4775254726409912 0.8873239159584045 0.5321950912475586 0.8314606547355652 0.5430650115013123 0.8556430339813232\n","Validation loss decreased (0.532195 --> 0.532170).  Saving model ...\n","831 0.477478563785553 0.8873239159584045 0.5321699976921082 0.8314606547355652 0.5430310368537903 0.8556430339813232\n","Validation loss decreased (0.532170 --> 0.532145).  Saving model ...\n","832 0.47743234038352966 0.8873239159584045 0.5321451425552368 0.8314606547355652 0.5429964661598206 0.8556430339813232\n","Validation loss decreased (0.532145 --> 0.532120).  Saving model ...\n","833 0.4773852825164795 0.8873239159584045 0.5321202874183655 0.8314606547355652 0.5429623126983643 0.8556430339813232\n","Validation loss decreased (0.532120 --> 0.532095).  Saving model ...\n","834 0.4773387908935547 0.8873239159584045 0.5320949554443359 0.8314606547355652 0.542927622795105 0.8556430339813232\n","Validation loss decreased (0.532095 --> 0.532070).  Saving model ...\n","835 0.4772928059101105 0.8873239159584045 0.5320700407028198 0.8314606547355652 0.5428938269615173 0.8556430339813232\n","Validation loss decreased (0.532070 --> 0.532045).  Saving model ...\n","836 0.47724616527557373 0.8873239159584045 0.5320450663566589 0.8314606547355652 0.5428594350814819 0.8556430339813232\n","Validation loss decreased (0.532045 --> 0.532020).  Saving model ...\n","837 0.47719958424568176 0.8873239159584045 0.5320203304290771 0.8314606547355652 0.5428256392478943 0.8556430339813232\n","Validation loss decreased (0.532020 --> 0.531996).  Saving model ...\n","838 0.4771537482738495 0.8873239159584045 0.5319957733154297 0.8314606547355652 0.5427913665771484 0.8556430339813232\n","Validation loss decreased (0.531996 --> 0.531971).  Saving model ...\n","839 0.4771072268486023 0.8873239159584045 0.5319708585739136 0.8314606547355652 0.5427574515342712 0.8556430339813232\n","Validation loss decreased (0.531971 --> 0.531946).  Saving model ...\n","840 0.47706127166748047 0.8873239159584045 0.5319461822509766 0.8314606547355652 0.5427236557006836 0.8556430339813232\n","Validation loss decreased (0.531946 --> 0.531922).  Saving model ...\n","841 0.47701552510261536 0.8873239159584045 0.5319216251373291 0.8314606547355652 0.5426896810531616 0.8556430339813232\n","Validation loss decreased (0.531922 --> 0.531897).  Saving model ...\n","842 0.4769690930843353 0.8873239159584045 0.5318968296051025 0.8314606547355652 0.5426557064056396 0.8556430339813232\n","Validation loss decreased (0.531897 --> 0.531872).  Saving model ...\n","843 0.47692304849624634 0.8873239159584045 0.5318723917007446 0.8314606547355652 0.5426220297813416 0.8556430339813232\n","Validation loss decreased (0.531872 --> 0.531848).  Saving model ...\n","844 0.4768771231174469 0.8873239159584045 0.5318480134010315 0.8314606547355652 0.5425882935523987 0.8556430339813232\n","Validation loss decreased (0.531848 --> 0.531824).  Saving model ...\n","845 0.4768318235874176 0.8873239159584045 0.5318235158920288 0.8314606547355652 0.5425546765327454 0.8556430339813232\n","Validation loss decreased (0.531824 --> 0.531799).  Saving model ...\n","846 0.4767861068248749 0.8873239159584045 0.5317991971969604 0.8314606547355652 0.5425208806991577 0.8556430339813232\n","Validation loss decreased (0.531799 --> 0.531775).  Saving model ...\n","847 0.4767407178878784 0.8873239159584045 0.531774640083313 0.8314606547355652 0.5424876809120178 0.8556430339813232\n","Validation loss decreased (0.531775 --> 0.531750).  Saving model ...\n","848 0.4766950011253357 0.8873239159584045 0.5317504405975342 0.8314606547355652 0.5424542427062988 0.8556430339813232\n","Validation loss decreased (0.531750 --> 0.531726).  Saving model ...\n","849 0.4766497313976288 0.8873239159584045 0.5317263007164001 0.8314606547355652 0.5424208641052246 0.8556430339813232\n","Validation loss decreased (0.531726 --> 0.531702).  Saving model ...\n","850 0.4766041934490204 0.8873239159584045 0.5317019820213318 0.8314606547355652 0.5423874258995056 0.8556430339813232\n","Validation loss decreased (0.531702 --> 0.531678).  Saving model ...\n","851 0.4765590727329254 0.8873239159584045 0.5316776037216187 0.8314606547355652 0.5423540472984314 0.8556430339813232\n","Validation loss decreased (0.531678 --> 0.531654).  Saving model ...\n","852 0.4765138030052185 0.8873239159584045 0.5316535830497742 0.8314606547355652 0.5423206090927124 0.8556430339813232\n","Validation loss decreased (0.531654 --> 0.531629).  Saving model ...\n","853 0.4764688313007355 0.8873239159584045 0.5316294431686401 0.8314606547355652 0.5422877073287964 0.8556430339813232\n","Validation loss decreased (0.531629 --> 0.531605).  Saving model ...\n","854 0.476423978805542 0.8873239159584045 0.5316053628921509 0.8314606547355652 0.5422542691230774 0.8556430339813232\n","Validation loss decreased (0.531605 --> 0.531581).  Saving model ...\n","855 0.476378858089447 0.888732373714447 0.5315812826156616 0.8314606547355652 0.5422213077545166 0.8556430339813232\n","Validation loss decreased (0.531581 --> 0.531557).  Saving model ...\n","856 0.47633421421051025 0.888732373714447 0.5315573811531067 0.8314606547355652 0.5421879291534424 0.8556430339813232\n","Validation loss decreased (0.531557 --> 0.531533).  Saving model ...\n","857 0.4762895107269287 0.888732373714447 0.531533420085907 0.8314606547355652 0.5421551465988159 0.8556430339813232\n","Validation loss decreased (0.531533 --> 0.531510).  Saving model ...\n","858 0.4762446880340576 0.888732373714447 0.5315095782279968 0.8314606547355652 0.5421220660209656 0.8556430339813232\n","Validation loss decreased (0.531510 --> 0.531486).  Saving model ...\n","859 0.47619980573654175 0.888732373714447 0.5314856767654419 0.8314606547355652 0.5420891046524048 0.8556430339813232\n","Validation loss decreased (0.531486 --> 0.531462).  Saving model ...\n","860 0.47615545988082886 0.888732373714447 0.5314618945121765 0.8314606547355652 0.5420564413070679 0.8556430339813232\n","Validation loss decreased (0.531462 --> 0.531438).  Saving model ...\n","861 0.4761105477809906 0.888732373714447 0.5314382910728455 0.8314606547355652 0.5420240163803101 0.8556430339813232\n","Validation loss decreased (0.531438 --> 0.531414).  Saving model ...\n","862 0.47606614232063293 0.888732373714447 0.5314144492149353 0.8314606547355652 0.5419905185699463 0.8556430339813232\n","Validation loss decreased (0.531414 --> 0.531391).  Saving model ...\n","863 0.4760223925113678 0.888732373714447 0.5313907861709595 0.8314606547355652 0.541958212852478 0.8556430339813232\n","Validation loss decreased (0.531391 --> 0.531367).  Saving model ...\n","864 0.4759780466556549 0.888732373714447 0.5313670635223389 0.8314606547355652 0.5419256091117859 0.8556430339813232\n","Validation loss decreased (0.531367 --> 0.531344).  Saving model ...\n","865 0.4759334623813629 0.888732373714447 0.5313437581062317 0.8314606547355652 0.5418930053710938 0.8556430339813232\n","Validation loss decreased (0.531344 --> 0.531320).  Saving model ...\n","866 0.4758894443511963 0.888732373714447 0.5313200354576111 0.8314606547355652 0.5418604612350464 0.8556430339813232\n","Validation loss decreased (0.531320 --> 0.531296).  Saving model ...\n","867 0.4758453667163849 0.888732373714447 0.5312963128089905 0.8314606547355652 0.5418277978897095 0.8556430339813232\n","Validation loss decreased (0.531296 --> 0.531273).  Saving model ...\n","868 0.47580137848854065 0.888732373714447 0.5312731266021729 0.8314606547355652 0.5417954921722412 0.8556430339813232\n","Validation loss decreased (0.531273 --> 0.531250).  Saving model ...\n","869 0.4757573902606964 0.888732373714447 0.5312495827674866 0.8314606547355652 0.5417628884315491 0.8556430339813232\n","Validation loss decreased (0.531250 --> 0.531226).  Saving model ...\n","870 0.4757134020328522 0.888732373714447 0.5312264561653137 0.8314606547355652 0.5417306423187256 0.8556430339813232\n","Validation loss decreased (0.531226 --> 0.531203).  Saving model ...\n","871 0.47567009925842285 0.888732373714447 0.5312029719352722 0.8314606547355652 0.5416985154151917 0.8556430339813232\n","Validation loss decreased (0.531203 --> 0.531180).  Saving model ...\n","872 0.4756263494491577 0.888732373714447 0.5311797857284546 0.8314606547355652 0.5416660904884338 0.8556430339813232\n","Validation loss decreased (0.531180 --> 0.531156).  Saving model ...\n","873 0.47558292746543884 0.888732373714447 0.5311564207077026 0.8314606547355652 0.5416337847709656 0.8556430339813232\n","Validation loss decreased (0.531156 --> 0.531133).  Saving model ...\n","874 0.47553911805152893 0.888732373714447 0.5311331748962402 0.8314606547355652 0.5416019558906555 0.8556430339813232\n","Validation loss decreased (0.531133 --> 0.531110).  Saving model ...\n","875 0.4754958748817444 0.888732373714447 0.5311100482940674 0.8314606547355652 0.5415696501731873 0.8556430339813232\n","Validation loss decreased (0.531110 --> 0.531087).  Saving model ...\n","876 0.47545212507247925 0.888732373714447 0.5310869812965393 0.8314606547355652 0.5415375828742981 0.8556430339813232\n","Validation loss decreased (0.531087 --> 0.531064).  Saving model ...\n","877 0.4754091799259186 0.888732373714447 0.5310636162757874 0.8314606547355652 0.541505753993988 0.8556430339813232\n","Validation loss decreased (0.531064 --> 0.531041).  Saving model ...\n","878 0.47536545991897583 0.888732373714447 0.5310409665107727 0.8314606547355652 0.5414736866950989 0.8556430339813232\n","Validation loss decreased (0.531041 --> 0.531018).  Saving model ...\n","879 0.4753224551677704 0.888732373714447 0.5310177206993103 0.8314606547355652 0.5414415597915649 0.8556430339813232\n","Validation loss decreased (0.531018 --> 0.530995).  Saving model ...\n","880 0.47527968883514404 0.8901408314704895 0.5309949517250061 0.8314606547355652 0.5414099097251892 0.8556430339813232\n","Validation loss decreased (0.530995 --> 0.530972).  Saving model ...\n","881 0.4752364158630371 0.8901408314704895 0.5309716463088989 0.8314606547355652 0.5413783192634583 0.8556430339813232\n","Validation loss decreased (0.530972 --> 0.530949).  Saving model ...\n","882 0.475193589925766 0.8901408314704895 0.5309489965438843 0.8314606547355652 0.5413466095924377 0.8556430339813232\n","Validation loss decreased (0.530949 --> 0.530926).  Saving model ...\n","883 0.4751507043838501 0.8901408314704895 0.5309259295463562 0.8314606547355652 0.5413150191307068 0.8556430339813232\n","Validation loss decreased (0.530926 --> 0.530903).  Saving model ...\n","884 0.4751081168651581 0.8901408314704895 0.5309032201766968 0.8314606547355652 0.541283130645752 0.8556430339813232\n","Validation loss decreased (0.530903 --> 0.530880).  Saving model ...\n","885 0.4750651717185974 0.8901408314704895 0.5308802723884583 0.8314606547355652 0.541251540184021 0.8556430339813232\n","Validation loss decreased (0.530880 --> 0.530858).  Saving model ...\n","886 0.4750221371650696 0.8901408314704895 0.5308576226234436 0.8314606547355652 0.54121994972229 0.8556430339813232\n","Validation loss decreased (0.530858 --> 0.530835).  Saving model ...\n","887 0.4749796986579895 0.8901408314704895 0.5308350324630737 0.8314606547355652 0.5411885380744934 0.8530183434486389\n","Validation loss decreased (0.530835 --> 0.530812).  Saving model ...\n","888 0.47493717074394226 0.8901408314704895 0.5308123230934143 0.8314606547355652 0.541157066822052 0.8530183434486389\n","Validation loss decreased (0.530812 --> 0.530790).  Saving model ...\n","889 0.4748947322368622 0.8901408314704895 0.5307897329330444 0.8314606547355652 0.5411258935928345 0.8530183434486389\n","Validation loss decreased (0.530790 --> 0.530767).  Saving model ...\n","890 0.47485220432281494 0.8901408314704895 0.5307671427726746 0.8314606547355652 0.5410947203636169 0.8530183434486389\n","Validation loss decreased (0.530767 --> 0.530745).  Saving model ...\n","891 0.4748096168041229 0.8901408314704895 0.5307446122169495 0.8314606547355652 0.5410628914833069 0.8530183434486389\n","Validation loss decreased (0.530745 --> 0.530722).  Saving model ...\n","892 0.4747675359249115 0.8901408314704895 0.5307220220565796 0.8314606547355652 0.541031539440155 0.8530183434486389\n","Validation loss decreased (0.530722 --> 0.530699).  Saving model ...\n","893 0.4747251272201538 0.8901408314704895 0.5306993722915649 0.8314606547355652 0.5410005450248718 0.8530183434486389\n","Validation loss decreased (0.530699 --> 0.530677).  Saving model ...\n","894 0.47468331456184387 0.8901408314704895 0.5306770205497742 0.8314606547355652 0.5409692525863647 0.8530183434486389\n","Validation loss decreased (0.530677 --> 0.530655).  Saving model ...\n","895 0.47464099526405334 0.8901408314704895 0.5306548476219177 0.8314606547355652 0.540938138961792 0.8530183434486389\n","Validation loss decreased (0.530655 --> 0.530632).  Saving model ...\n","896 0.4745989739894867 0.8901408314704895 0.5306324362754822 0.8314606547355652 0.5409072041511536 0.8530183434486389\n","Validation loss decreased (0.530632 --> 0.530610).  Saving model ...\n","897 0.4745566248893738 0.8901408314704895 0.5306101441383362 0.8314606547355652 0.5408762693405151 0.8530183434486389\n","Validation loss decreased (0.530610 --> 0.530588).  Saving model ...\n","898 0.4745149314403534 0.8901408314704895 0.5305877327919006 0.8314606547355652 0.5408452153205872 0.8530183434486389\n","Validation loss decreased (0.530588 --> 0.530566).  Saving model ...\n","899 0.4744736850261688 0.8901408314704895 0.5305655598640442 0.8314606547355652 0.5408141613006592 0.8530183434486389\n","Validation loss decreased (0.530566 --> 0.530543).  Saving model ...\n","900 0.47443151473999023 0.8901408314704895 0.5305433869361877 0.8314606547355652 0.5407835245132446 0.8530183434486389\n","Validation loss decreased (0.530543 --> 0.530521).  Saving model ...\n","901 0.4743899405002594 0.8901408314704895 0.5305211544036865 0.8314606547355652 0.5407525897026062 0.8530183434486389\n","Validation loss decreased (0.530521 --> 0.530499).  Saving model ...\n","902 0.47434836626052856 0.8901408314704895 0.5304989814758301 0.8314606547355652 0.5407215356826782 0.8530183434486389\n","Validation loss decreased (0.530499 --> 0.530477).  Saving model ...\n","903 0.47430655360221863 0.891549289226532 0.5304768681526184 0.8314606547355652 0.540691077709198 0.8530183434486389\n","Validation loss decreased (0.530477 --> 0.530455).  Saving model ...\n","904 0.4742653965950012 0.891549289226532 0.5304549336433411 0.8314606547355652 0.54066002368927 0.8530183434486389\n","Validation loss decreased (0.530455 --> 0.530433).  Saving model ...\n","905 0.47422388195991516 0.891549289226532 0.5304327607154846 0.8314606547355652 0.5406297445297241 0.8530183434486389\n","Validation loss decreased (0.530433 --> 0.530411).  Saving model ...\n","906 0.47418269515037537 0.891549289226532 0.5304107069969177 0.8314606547355652 0.5405988097190857 0.8530183434486389\n","Validation loss decreased (0.530411 --> 0.530389).  Saving model ...\n","907 0.47414126992225647 0.891549289226532 0.5303890705108643 0.8314606547355652 0.5405683517456055 0.8530183434486389\n","Validation loss decreased (0.530389 --> 0.530367).  Saving model ...\n","908 0.47410017251968384 0.891549289226532 0.5303670763969421 0.8314606547355652 0.5405381917953491 0.8530183434486389\n","Validation loss decreased (0.530367 --> 0.530345).  Saving model ...\n","909 0.47405874729156494 0.891549289226532 0.5303450226783752 0.8314606547355652 0.540507435798645 0.8530183434486389\n","Validation loss decreased (0.530345 --> 0.530323).  Saving model ...\n","910 0.4740177094936371 0.891549289226532 0.5303231477737427 0.8314606547355652 0.5404772758483887 0.8530183434486389\n","Validation loss decreased (0.530323 --> 0.530301).  Saving model ...\n","911 0.473976731300354 0.891549289226532 0.5303014516830444 0.8314606547355652 0.5404465794563293 0.8530183434486389\n","Validation loss decreased (0.530301 --> 0.530280).  Saving model ...\n","912 0.4739360213279724 0.891549289226532 0.5302795767784119 0.8314606547355652 0.5404161810874939 0.8530183434486389\n","Validation loss decreased (0.530280 --> 0.530258).  Saving model ...\n","913 0.47389453649520874 0.891549289226532 0.5302579998970032 0.8314606547355652 0.5403861999511719 0.8530183434486389\n","Validation loss decreased (0.530258 --> 0.530236).  Saving model ...\n","914 0.47385409474372864 0.891549289226532 0.5302360653877258 0.8314606547355652 0.5403557419776917 0.8530183434486389\n","Validation loss decreased (0.530236 --> 0.530215).  Saving model ...\n","915 0.47381341457366943 0.891549289226532 0.5302145481109619 0.8314606547355652 0.5403256416320801 0.8530183434486389\n","Validation loss decreased (0.530215 --> 0.530193).  Saving model ...\n","916 0.47377264499664307 0.891549289226532 0.5301927328109741 0.8314606547355652 0.5402954816818237 0.8530183434486389\n","Validation loss decreased (0.530193 --> 0.530171).  Saving model ...\n","917 0.4737318754196167 0.891549289226532 0.5301713347434998 0.8314606547355652 0.5402652025222778 0.8530183434486389\n","Validation loss decreased (0.530171 --> 0.530150).  Saving model ...\n","918 0.47369134426116943 0.891549289226532 0.5301496982574463 0.8314606547355652 0.5402353405952454 0.8530183434486389\n","Validation loss decreased (0.530150 --> 0.530128).  Saving model ...\n","919 0.4736509621143341 0.891549289226532 0.5301281809806824 0.8314606547355652 0.5402054190635681 0.8530183434486389\n","Validation loss decreased (0.530128 --> 0.530107).  Saving model ...\n","920 0.47361013293266296 0.891549289226532 0.5301065444946289 0.8314606547355652 0.5401755571365356 0.8530183434486389\n","Validation loss decreased (0.530107 --> 0.530085).  Saving model ...\n","921 0.4735700786113739 0.891549289226532 0.5300853848457336 0.8314606547355652 0.5401455163955688 0.8530183434486389\n","Validation loss decreased (0.530085 --> 0.530064).  Saving model ...\n","922 0.47352972626686096 0.891549289226532 0.5300639271736145 0.8314606547355652 0.5401154160499573 0.8530183434486389\n","Validation loss decreased (0.530064 --> 0.530042).  Saving model ...\n","923 0.47348901629447937 0.891549289226532 0.530042290687561 0.8314606547355652 0.5400854349136353 0.8530183434486389\n","Validation loss decreased (0.530042 --> 0.530021).  Saving model ...\n","924 0.47344934940338135 0.891549289226532 0.5300209522247314 0.8314606547355652 0.5400558710098267 0.8530183434486389\n","Validation loss decreased (0.530021 --> 0.530000).  Saving model ...\n","925 0.4734087288379669 0.891549289226532 0.5299996733665466 0.8314606547355652 0.5400261282920837 0.8530183434486389\n","Validation loss decreased (0.530000 --> 0.529978).  Saving model ...\n","926 0.4733687937259674 0.891549289226532 0.529978334903717 0.8314606547355652 0.5399966239929199 0.8530183434486389\n","Validation loss decreased (0.529978 --> 0.529957).  Saving model ...\n","927 0.47332900762557983 0.891549289226532 0.529957115650177 0.8314606547355652 0.5399666428565979 0.8530183434486389\n","Validation loss decreased (0.529957 --> 0.529936).  Saving model ...\n","928 0.47328898310661316 0.891549289226532 0.5299360752105713 0.8314606547355652 0.5399373173713684 0.8530183434486389\n","Validation loss decreased (0.529936 --> 0.529915).  Saving model ...\n","929 0.47324898838996887 0.891549289226532 0.5299146771430969 0.8314606547355652 0.5399075150489807 0.8530183434486389\n","Validation loss decreased (0.529915 --> 0.529894).  Saving model ...\n","930 0.4732092618942261 0.891549289226532 0.5298935174942017 0.8314606547355652 0.5398778319358826 0.8530183434486389\n","Validation loss decreased (0.529894 --> 0.529872).  Saving model ...\n","931 0.4731691777706146 0.891549289226532 0.5298722982406616 0.8314606547355652 0.5398486256599426 0.8530183434486389\n","Validation loss decreased (0.529872 --> 0.529851).  Saving model ...\n","932 0.47312983870506287 0.891549289226532 0.5298512578010559 0.8314606547355652 0.5398190021514893 0.8530183434486389\n","Validation loss decreased (0.529851 --> 0.529830).  Saving model ...\n","933 0.47309038043022156 0.891549289226532 0.5298303365707397 0.8314606547355652 0.5397897958755493 0.8530183434486389\n","Validation loss decreased (0.529830 --> 0.529809).  Saving model ...\n","934 0.47305023670196533 0.891549289226532 0.529809296131134 0.8314606547355652 0.5397604703903198 0.8530183434486389\n","Validation loss decreased (0.529809 --> 0.529788).  Saving model ...\n","935 0.4730108678340912 0.891549289226532 0.5297883749008179 0.8314606547355652 0.5397312045097351 0.8530183434486389\n","Validation loss decreased (0.529788 --> 0.529767).  Saving model ...\n","936 0.4729718267917633 0.891549289226532 0.5297673940658569 0.8314606547355652 0.5397017598152161 0.8530183434486389\n","Validation loss decreased (0.529767 --> 0.529746).  Saving model ...\n","937 0.4729319214820862 0.891549289226532 0.5297462940216064 0.8314606547355652 0.539672315120697 0.8530183434486389\n","Validation loss decreased (0.529746 --> 0.529725).  Saving model ...\n","938 0.4728925824165344 0.891549289226532 0.5297253727912903 0.8314606547355652 0.5396432876586914 0.8530183434486389\n","Validation loss decreased (0.529725 --> 0.529705).  Saving model ...\n","939 0.4728536605834961 0.891549289226532 0.5297048091888428 0.8314606547355652 0.5396140813827515 0.8530183434486389\n","Validation loss decreased (0.529705 --> 0.529684).  Saving model ...\n","940 0.47281429171562195 0.891549289226532 0.5296838879585266 0.8314606547355652 0.5395849347114563 0.8530183434486389\n","Validation loss decreased (0.529684 --> 0.529663).  Saving model ...\n","941 0.4727749228477478 0.891549289226532 0.5296627879142761 0.8314606547355652 0.5395559072494507 0.8530183434486389\n","Validation loss decreased (0.529663 --> 0.529642).  Saving model ...\n","942 0.47273603081703186 0.891549289226532 0.5296421051025391 0.8314606547355652 0.5395269393920898 0.8530183434486389\n","Validation loss decreased (0.529642 --> 0.529621).  Saving model ...\n","943 0.4726967513561249 0.891549289226532 0.5296214818954468 0.8314606547355652 0.539497971534729 0.8530183434486389\n","Validation loss decreased (0.529621 --> 0.529601).  Saving model ...\n","944 0.47265762090682983 0.891549289226532 0.529600977897644 0.8314606547355652 0.5394687056541443 0.8530183434486389\n","Validation loss decreased (0.529601 --> 0.529580).  Saving model ...\n","945 0.47261881828308105 0.891549289226532 0.5295799374580383 0.8314606547355652 0.5394400954246521 0.8530183434486389\n","Validation loss decreased (0.529580 --> 0.529559).  Saving model ...\n","946 0.4725800156593323 0.891549289226532 0.5295594930648804 0.8314606547355652 0.5394110679626465 0.8530183434486389\n","Validation loss decreased (0.529559 --> 0.529539).  Saving model ...\n","947 0.47254133224487305 0.891549289226532 0.5295387506484985 0.8314606547355652 0.5393824577331543 0.8530183434486389\n","Validation loss decreased (0.529539 --> 0.529518).  Saving model ...\n","948 0.47250229120254517 0.891549289226532 0.529518187046051 0.8314606547355652 0.539353609085083 0.8530183434486389\n","Validation loss decreased (0.529518 --> 0.529498).  Saving model ...\n","949 0.47246357798576355 0.891549289226532 0.5294976830482483 0.8314606547355652 0.5393248200416565 0.8530183434486389\n","Validation loss decreased (0.529498 --> 0.529477).  Saving model ...\n","950 0.47242486476898193 0.891549289226532 0.5294771790504456 0.8314606547355652 0.5392963886260986 0.8530183434486389\n","Validation loss decreased (0.529477 --> 0.529457).  Saving model ...\n","951 0.4723861515522003 0.891549289226532 0.5294566750526428 0.8314606547355652 0.5392674803733826 0.8530183434486389\n","Validation loss decreased (0.529457 --> 0.529436).  Saving model ...\n","952 0.47234806418418884 0.891549289226532 0.5294363498687744 0.8314606547355652 0.5392387509346008 0.8530183434486389\n","Validation loss decreased (0.529436 --> 0.529416).  Saving model ...\n","953 0.4723094403743744 0.891549289226532 0.5294159054756165 0.8314606547355652 0.5392102599143982 0.8530183434486389\n","Validation loss decreased (0.529416 --> 0.529395).  Saving model ...\n","954 0.4722709059715271 0.891549289226532 0.5293954014778137 0.8314606547355652 0.5391818881034851 0.8530183434486389\n","Validation loss decreased (0.529395 --> 0.529375).  Saving model ...\n","955 0.47223252058029175 0.891549289226532 0.5293750762939453 0.8314606547355652 0.5391536951065063 0.8530183434486389\n","Validation loss decreased (0.529375 --> 0.529355).  Saving model ...\n","956 0.4721941649913788 0.891549289226532 0.5293548107147217 0.8314606547355652 0.5391252040863037 0.8530183434486389\n","Validation loss decreased (0.529355 --> 0.529334).  Saving model ...\n","957 0.4721561074256897 0.8901408314704895 0.5293342471122742 0.8314606547355652 0.5390965938568115 0.8530183434486389\n","Validation loss decreased (0.529334 --> 0.529314).  Saving model ...\n","958 0.4721178412437439 0.8901408314704895 0.5293140411376953 0.8314606547355652 0.5390682220458984 0.8530183434486389\n","Validation loss decreased (0.529314 --> 0.529294).  Saving model ...\n","959 0.47207972407341003 0.8901408314704895 0.5292938351631165 0.8314606547355652 0.5390399694442749 0.8530183434486389\n","Validation loss decreased (0.529294 --> 0.529273).  Saving model ...\n","960 0.47204169631004333 0.8901408314704895 0.5292734503746033 0.8314606547355652 0.5390114784240723 0.8530183434486389\n","Validation loss decreased (0.529273 --> 0.529253).  Saving model ...\n","961 0.4720032513141632 0.8901408314704895 0.529253363609314 0.8314606547355652 0.5389835834503174 0.8530183434486389\n","Validation loss decreased (0.529253 --> 0.529233).  Saving model ...\n","962 0.4719654321670532 0.8901408314704895 0.5292331576347351 0.8314606547355652 0.5389552712440491 0.8530183434486389\n","Validation loss decreased (0.529233 --> 0.529213).  Saving model ...\n","963 0.4719277322292328 0.8901408314704895 0.5292131304740906 0.8314606547355652 0.5389270186424255 0.8530183434486389\n","Validation loss decreased (0.529213 --> 0.529193).  Saving model ...\n","964 0.4718901216983795 0.8901408314704895 0.5291929244995117 0.8314606547355652 0.5388988852500916 0.8556430339813232\n","Validation loss decreased (0.529193 --> 0.529173).  Saving model ...\n","965 0.47185197472572327 0.8901408314704895 0.5291728973388672 0.8314606547355652 0.5388705730438232 0.8556430339813232\n","Validation loss decreased (0.529173 --> 0.529153).  Saving model ...\n","966 0.4718146026134491 0.8901408314704895 0.5291528701782227 0.8314606547355652 0.5388427376747131 0.8556430339813232\n","Validation loss decreased (0.529153 --> 0.529133).  Saving model ...\n","967 0.4717766344547272 0.8901408314704895 0.5291329026222229 0.8314606547355652 0.5388147830963135 0.8556430339813232\n","Validation loss decreased (0.529133 --> 0.529113).  Saving model ...\n","968 0.47173887491226196 0.8901408314704895 0.5291128754615784 0.8314606547355652 0.5387868881225586 0.8556430339813232\n","Validation loss decreased (0.529113 --> 0.529093).  Saving model ...\n","969 0.4717012643814087 0.8901408314704895 0.5290929675102234 0.8314606547355652 0.5387591123580933 0.8556430339813232\n","Validation loss decreased (0.529093 --> 0.529073).  Saving model ...\n","970 0.4716640114784241 0.8901408314704895 0.5290731191635132 0.8314606547355652 0.538731038570404 0.8556430339813232\n","Validation loss decreased (0.529073 --> 0.529053).  Saving model ...\n","971 0.4716261029243469 0.8901408314704895 0.5290534496307373 0.8314606547355652 0.5387029051780701 0.8556430339813232\n","Validation loss decreased (0.529053 --> 0.529033).  Saving model ...\n","972 0.47158923745155334 0.8901408314704895 0.5290334224700928 0.8314606547355652 0.5386756658554077 0.8556430339813232\n","Validation loss decreased (0.529033 --> 0.529014).  Saving model ...\n","973 0.47155165672302246 0.8901408314704895 0.5290136337280273 0.8314606547355652 0.5386476516723633 0.8556430339813232\n","Validation loss decreased (0.529014 --> 0.528994).  Saving model ...\n","974 0.47151413559913635 0.8901408314704895 0.5289936661720276 0.8314606547355652 0.5386198163032532 0.8556430339813232\n","Validation loss decreased (0.528994 --> 0.528974).  Saving model ...\n","975 0.47147688269615173 0.8901408314704895 0.5289736986160278 0.8314606547355652 0.5385920405387878 0.8556430339813232\n","Validation loss decreased (0.528974 --> 0.528954).  Saving model ...\n","976 0.4714396893978119 0.8901408314704895 0.528954267501831 0.8314606547355652 0.5385646820068359 0.8556430339813232\n","Validation loss decreased (0.528954 --> 0.528934).  Saving model ...\n","977 0.4714025855064392 0.8901408314704895 0.5289344191551208 0.8314606547355652 0.5385371446609497 0.8582677245140076\n","Validation loss decreased (0.528934 --> 0.528915).  Saving model ...\n","978 0.4713655710220337 0.891549289226532 0.5289146304130554 0.8314606547355652 0.5385093688964844 0.8582677245140076\n","Validation loss decreased (0.528915 --> 0.528895).  Saving model ...\n","979 0.471328467130661 0.891549289226532 0.5288950800895691 0.8314606547355652 0.5384818911552429 0.8582677245140076\n","Validation loss decreased (0.528895 --> 0.528875).  Saving model ...\n","980 0.4712916314601898 0.891549289226532 0.5288752913475037 0.8314606547355652 0.5384543538093567 0.8582677245140076\n","Validation loss decreased (0.528875 --> 0.528856).  Saving model ...\n","981 0.4712546467781067 0.891549289226532 0.5288557410240173 0.8314606547355652 0.5384271740913391 0.8582677245140076\n","Validation loss decreased (0.528856 --> 0.528836).  Saving model ...\n","982 0.47121748328208923 0.891549289226532 0.5288361310958862 0.8314606547355652 0.5383995771408081 0.8582677245140076\n","Validation loss decreased (0.528836 --> 0.528816).  Saving model ...\n","983 0.47118085622787476 0.891549289226532 0.5288164615631104 0.8314606547355652 0.5383721590042114 0.8582677245140076\n","Validation loss decreased (0.528816 --> 0.528797).  Saving model ...\n","984 0.4711441695690155 0.891549289226532 0.5287970304489136 0.8314606547355652 0.5383446216583252 0.8582677245140076\n","Validation loss decreased (0.528797 --> 0.528778).  Saving model ...\n","985 0.4711074233055115 0.891549289226532 0.528777539730072 0.8314606547355652 0.5383176803588867 0.8582677245140076\n","Validation loss decreased (0.528778 --> 0.528758).  Saving model ...\n","986 0.47107115387916565 0.891549289226532 0.5287580490112305 0.8314606547355652 0.5382902026176453 0.8582677245140076\n","Validation loss decreased (0.528758 --> 0.528738).  Saving model ...\n","987 0.4710342288017273 0.8929577469825745 0.5287384390830994 0.8314606547355652 0.5382629632949829 0.8582677245140076\n","Validation loss decreased (0.528738 --> 0.528719).  Saving model ...\n","988 0.4709973931312561 0.8929577469825745 0.5287192463874817 0.8314606547355652 0.5382359027862549 0.8582677245140076\n","Validation loss decreased (0.528719 --> 0.528700).  Saving model ...\n","989 0.4709612727165222 0.8929577469825745 0.5286996960639954 0.8314606547355652 0.5382087230682373 0.8582677245140076\n","Validation loss decreased (0.528700 --> 0.528681).  Saving model ...\n","990 0.4709245562553406 0.8929577469825745 0.5286805629730225 0.8314606547355652 0.5381814241409302 0.8582677245140076\n","Validation loss decreased (0.528681 --> 0.528661).  Saving model ...\n","991 0.47088822722435 0.8929577469825745 0.5286610722541809 0.8314606547355652 0.5381543636322021 0.8582677245140076\n","Validation loss decreased (0.528661 --> 0.528641).  Saving model ...\n","992 0.470851331949234 0.8929577469825745 0.5286414623260498 0.8314606547355652 0.5381275415420532 0.8582677245140076\n","Validation loss decreased (0.528641 --> 0.528622).  Saving model ...\n","993 0.4708154499530792 0.8929577469825745 0.5286223292350769 0.8314606547355652 0.5381003618240356 0.8582677245140076\n","Validation loss decreased (0.528622 --> 0.528603).  Saving model ...\n","994 0.4707794189453125 0.8929577469825745 0.5286031365394592 0.8314606547355652 0.538073718547821 0.8582677245140076\n","Validation loss decreased (0.528603 --> 0.528584).  Saving model ...\n","995 0.4707431197166443 0.8943662047386169 0.5285841226577759 0.8314606547355652 0.5380465984344482 0.8582677245140076\n","Validation loss decreased (0.528584 --> 0.528565).  Saving model ...\n","996 0.4707069993019104 0.8943662047386169 0.5285648107528687 0.8314606547355652 0.5380196571350098 0.8582677245140076\n","Validation loss decreased (0.528565 --> 0.528546).  Saving model ...\n","997 0.470670610666275 0.8943662047386169 0.528545618057251 0.8314606547355652 0.5379932522773743 0.8582677245140076\n","Validation loss decreased (0.528546 --> 0.528526).  Saving model ...\n","998 0.4706345498561859 0.8943662047386169 0.5285263657569885 0.8314606547355652 0.537966251373291 0.8582677245140076\n","Validation loss decreased (0.528526 --> 0.528507).  Saving model ...\n","999 0.4705987870693207 0.8943662047386169 0.5285072326660156 0.8314606547355652 0.5379394888877869 0.8582677245140076\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"id":"erpioWsYtaUa","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"executionInfo":{"status":"ok","timestamp":1593325240363,"user_tz":180,"elapsed":63982,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"e87aaa3a-47c1-48af-fac9-018df03b70d7"},"source":["print(Precision(prediction, Y_train_tensor))\n","print(Precision(val_prediction, Y_valid_tensor))\n","print(Precision(test_prediction, Y_test_tensor))"],"execution_count":25,"outputs":[{"output_type":"stream","text":["[0.9571428298950195, 0.6600000262260437]\n","[0.9333333373069763, 0.5116279125213623]\n","[0.92580646276474, 0.5633803009986877]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Qu2e4Qh38lp4","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"executionInfo":{"status":"ok","timestamp":1593325240363,"user_tz":180,"elapsed":63976,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"40651b1c-8f33-4a14-e3e5-36d5b1628b51"},"source":["print(Recall(prediction, Y_train_tensor))\n","print(Recall(val_prediction, Y_valid_tensor))\n","print(Recall(test_prediction, Y_test_tensor))"],"execution_count":26,"outputs":[{"output_type":"stream","text":["[0.913117527961731, 0.8048780560493469]\n","[0.8571428656578064, 0.7096773982048035]\n","[0.902515709400177, 0.6349206566810608]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5IoA1jJGBW2Q","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"executionInfo":{"status":"ok","timestamp":1593325240364,"user_tz":180,"elapsed":63971,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"ab5ef2f9-a878-45fa-9411-bfc63a9390a8"},"source":["print(Accuracy(prediction, Y_train_tensor))\n","print(Accuracy(val_prediction, Y_valid_tensor))\n","print(Accuracy(test_prediction, Y_test_tensor))"],"execution_count":27,"outputs":[{"output_type":"stream","text":["0.8943662047386169\n","0.8314606547355652\n","0.8582677245140076\n"],"name":"stdout"}]}]}