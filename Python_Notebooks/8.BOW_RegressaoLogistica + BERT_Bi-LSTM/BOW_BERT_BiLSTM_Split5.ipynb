{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Bi-LSTM of FineTuned_Split5.ipynb","provenance":[{"file_id":"1iEtoUyt4l6WoYZKnFY4vMwGIaInqm1Z7","timestamp":1592589760254},{"file_id":"1jM_MQeWnqB4LrmlAc_rZ00W9zJK7Hw_d","timestamp":1590464112416}],"collapsed_sections":[],"authorship_tag":"ABX9TyOzidEwvtpydtco7tKjSc8m"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"KWy32B6i5zUX","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"executionInfo":{"status":"ok","timestamp":1593655912987,"user_tz":180,"elapsed":23171,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"b3bdd344-975a-4c40-eedc-24653a42033e"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IUvtjwnKQx0R","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593655915096,"user_tz":180,"elapsed":25275,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["import numpy as np\n","import torch\n","\n","class EarlyStopping:\n","    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n","    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt'):\n","        \"\"\"\n","        Args:\n","            patience (int): How long to wait after last time validation loss improved.\n","                            Default: 7\n","            verbose (bool): If True, prints a message for each validation loss improvement. \n","                            Default: False\n","            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n","                            Default: 0\n","            path (str): Path for the checkpoint to be saved to.\n","                            Default: 'checkpoint.pt'\n","        \"\"\"\n","        self.patience = patience\n","        self.verbose = verbose\n","        self.counter = 0\n","        self.best_score = None\n","        self.early_stop = False\n","        self.val_loss_min = np.Inf\n","        self.delta = delta\n","        self.path = path\n","\n","    def __call__(self, val_loss, model):\n","\n","        score = -val_loss\n","\n","        if self.best_score is None:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model)\n","        elif score < self.best_score + self.delta:\n","            self.counter += 1\n","            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n","            if self.counter >= self.patience:\n","                self.early_stop = True\n","        else:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model)\n","            self.counter = 0\n","\n","    def save_checkpoint(self, val_loss, model):\n","        '''Saves model when validation loss decrease.'''\n","        if self.verbose:\n","            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n","        torch.save(model.state_dict(), self.path)\n","        self.val_loss_min = val_loss"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"WtPr52JNXzXL","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593655915097,"user_tz":180,"elapsed":25274,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["def Accuracy(prediction, observation):\n","  prediction = prediction[:,1]\n","  prediction_class = (torch.reshape(prediction, observation.shape) > 0.5).float()\n","  correct = (prediction_class == observation).float().sum()\n","  accuracy = correct/prediction_class.shape[0]\n","  return float(accuracy.cpu())\n","\n","def Precision(prediction, observation):\n","  prediction = prediction[:,1]\n","  res = []\n","  prediction_class = (torch.reshape(prediction, observation.shape) > 0.5).float()\n","  for label in [0, 1]:\n","    correct = (prediction_class[prediction_class == label] == observation[prediction_class == label]).float().sum()\n","    precision = correct/prediction_class[prediction_class == label].shape[0]\n","    res.append(float(precision.cpu()))\n","  return res\n","\n","def Recall(prediction, observation):\n","  prediction = prediction[:,1]\n","  res = []\n","  prediction_class = (torch.reshape(prediction, observation.shape) > 0.5).float()\n","  for label in [0, 1]:\n","    correct = (prediction_class[observation == label] == observation[observation == label]).float().sum()\n","    recall = correct/prediction_class[observation == label].shape[0]\n","    res.append(float(recall.cpu()))\n","  return res"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"tLrptDIu6E6A","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593655915097,"user_tz":180,"elapsed":25272,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["n_split = 5"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"uCC2fopD6JTj","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593655915098,"user_tz":180,"elapsed":25270,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["import pickle\n","import numpy as np"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"LXHTiUtW6MJX","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593655930497,"user_tz":180,"elapsed":40667,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["with open('/content/drive/My Drive/Data Master/X_train_final', 'rb') as file:\n","    X_train = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/Y_train_final', 'rb') as file:\n","    Y_train = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/X_test_final', 'rb') as file:\n","    X_test = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/Y_test_final', 'rb') as file:\n","    Y_test = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/word_index_final', 'rb') as file:\n","    word_index = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/train_last_layer_embeddings_tail_fine_tuned_split' + str(n_split) + '.pkl', 'rb') as file:\n","    train_last_layer_embeddings = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/train_all_layers_embeddings_tail_fine_tuned_split' + str(n_split) + '.pkl', 'rb') as file:\n","    train_all_layers_embeddings = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/train_cls_token_embeddings_tail_fine_tuned_split' + str(n_split) + '.pkl', 'rb') as file:\n","    train_cls_token_embeddings = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/test_last_layer_embeddings_tail_fine_tuned_split' + str(n_split) + '.pkl', 'rb') as file:\n","    test_last_layer_embeddings = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/test_all_layers_embeddings_tail_fine_tuned_split' + str(n_split) + '.pkl', 'rb') as file:\n","    test_all_layers_embeddings = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/test_cls_token_embeddings_tail_fine_tuned_split' + str(n_split) + '.pkl', 'rb') as file:\n","    test_cls_token_embeddings = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/train_index_final_split_' + str(n_split), 'rb') as file:\n","    train_index = pickle.load(file)\n","\n","with open('/content/drive/My Drive/Data Master/valid_index_final_split_' + str(n_split), 'rb') as file:\n","    valid_index = pickle.load(file)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"3f7F7ELTH7Kc","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593655930498,"user_tz":180,"elapsed":40666,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["test_index = [i for i, _ in enumerate(X_test)]"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"7cw3aVs0tNYu","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593655930499,"user_tz":180,"elapsed":40665,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["inv_word_index = {ix : w for w, ix in word_index.items()}"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"-imDG-lFcsym","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593655935031,"user_tz":180,"elapsed":45194,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["import itertools\n","features_index = {w:ix for ix, w in enumerate(np.unique(list(itertools.chain.from_iterable(np.array(X_train)[train_index]))))}\n","inv_features_index = {ix:w for ix, w in enumerate(np.unique(list(itertools.chain.from_iterable(np.array(X_train)[train_index]))))}"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"8cMPG0UDc2LV","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593655936067,"user_tz":180,"elapsed":46228,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["X_train_matrix = np.zeros((len(X_train), len(features_index)))\n","X_test_matrix = np.zeros((len(X_test), len(features_index)))"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"weNsqkv4c5ih","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593655961106,"user_tz":180,"elapsed":71265,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["for i, x in enumerate(X_train):\n","  for w in x:\n","    if w in features_index:\n","      X_train_matrix[i,features_index[w]] += 1\n","\n","for i, x in enumerate(X_test):\n","  for w in x:\n","    if w in features_index:\n","      X_test_matrix[i,features_index[w]] += 1"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"UA9bR-8qsdkz","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593655961107,"user_tz":180,"elapsed":71264,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["data_train_doc_ids = [(i, d) for i, d in enumerate(X_train)]\n","data_test_doc_ids = [(i, d) for i, d in enumerate(X_test)]"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"fslOxq7L_dkN","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593655961107,"user_tz":180,"elapsed":71262,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["target_train_doc_ids = [(i, y) for i, y in enumerate(Y_train)]\n","target_test_doc_ids = [(i, y) for i, y in enumerate(Y_test)]"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"gBUtPIZ56-qI","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593655961108,"user_tz":180,"elapsed":71261,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["doc_train_ids = np.array([i for i, _ in data_train_doc_ids])\n","doc_test_ids = np.array([i for i, _ in data_test_doc_ids])\n","doc_train_dict = {k:v for k, v in [(i, d) for i, d in data_train_doc_ids]}\n","doc_test_dict = {k:v for k, v in [(i, d) for i, d in data_test_doc_ids]}\n","target_train_dict = {k:v for k, v in [(i, y) for i, y in target_train_doc_ids]}\n","target_test_dict = {k:v for k, v in [(i, y) for i, y in target_test_doc_ids]}"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"SNrkQqCt7wTE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":952},"executionInfo":{"status":"ok","timestamp":1593655961109,"user_tz":180,"elapsed":71254,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"ef121176-a5b8-48c3-e942-ab502547e810"},"source":["doc_train_ids[train_index]"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([  0,   1,   2,   3,   4,   5,   7,   8,   9,  10,  12,  13,  14,\n","        15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  27,  28,\n","        29,  30,  31,  32,  34,  35,  38,  42,  43,  45,  46,  47,  48,\n","        49,  50,  52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,\n","        63,  64,  65,  66,  69,  70,  71,  73,  75,  76,  77,  78,  79,\n","        80,  82,  83,  84,  85,  87,  88,  89,  90,  94,  95,  97,  99,\n","       100, 101, 103, 104, 105, 106, 109, 111, 113, 114, 115, 116, 117,\n","       118, 119, 120, 121, 122, 124, 126, 127, 129, 130, 131, 132, 133,\n","       134, 135, 137, 140, 141, 143, 144, 147, 149, 150, 152, 153, 154,\n","       155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 168,\n","       169, 170, 171, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184,\n","       185, 186, 187, 188, 189, 190, 191, 192, 193, 196, 197, 198, 199,\n","       201, 202, 203, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214,\n","       216, 217, 218, 219, 220, 221, 222, 223, 225, 226, 227, 228, 229,\n","       230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 241, 242, 243,\n","       245, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258,\n","       264, 266, 267, 268, 271, 272, 274, 275, 277, 278, 279, 280, 281,\n","       282, 283, 284, 287, 288, 290, 291, 292, 293, 294, 295, 296, 297,\n","       299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 310, 311, 313,\n","       316, 318, 319, 321, 322, 324, 325, 326, 327, 328, 329, 330, 331,\n","       332, 333, 334, 336, 337, 338, 339, 340, 342, 343, 345, 348, 349,\n","       350, 351, 354, 355, 356, 358, 359, 360, 363, 364, 366, 367, 369,\n","       371, 372, 373, 374, 375, 376, 378, 379, 382, 383, 385, 386, 387,\n","       388, 389, 390, 391, 392, 393, 394, 395, 397, 398, 399, 401, 402,\n","       403, 405, 406, 407, 408, 410, 411, 412, 413, 414, 415, 416, 417,\n","       418, 419, 420, 422, 423, 424, 426, 427, 428, 429, 430, 431, 432,\n","       433, 434, 435, 436, 437, 438, 439, 441, 442, 444, 445, 446, 447,\n","       449, 450, 452, 453, 454, 455, 456, 457, 458, 460, 461, 462, 463,\n","       464, 466, 467, 469, 470, 473, 474, 475, 477, 478, 480, 481, 482,\n","       484, 485, 486, 488, 489, 490, 491, 494, 495, 496, 497, 498, 499,\n","       500, 501, 502, 503, 504, 505, 506, 509, 511, 512, 513, 514, 517,\n","       518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530,\n","       531, 532, 533, 534, 535, 537, 538, 540, 541, 542, 543, 544, 545,\n","       547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 558, 559, 560,\n","       561, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574,\n","       575, 576, 577, 578, 579, 580, 582, 583, 584, 585, 586, 587, 588,\n","       590, 591, 592, 594, 595, 596, 598, 599, 600, 601, 602, 603, 605,\n","       606, 607, 608, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619,\n","       620, 621, 622, 623, 625, 626, 627, 629, 630, 631, 632, 634, 635,\n","       636, 637, 639, 640, 642, 643, 644, 645, 646, 647, 648, 649, 651,\n","       652, 653, 654, 655, 656, 660, 661, 662, 664, 665, 666, 667, 669,\n","       670, 671, 672, 673, 674, 675, 676, 678, 679, 680, 681, 682, 683,\n","       684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 697, 698,\n","       701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 712, 713, 714,\n","       715, 718, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730,\n","       731, 732, 733, 734, 735, 736, 737, 738, 740, 742, 743, 744, 745,\n","       747, 748, 749, 750, 752, 753, 754, 755, 756, 757, 758, 759, 760,\n","       761, 764, 765, 766, 767, 768, 769, 770, 771, 773, 774, 776, 777,\n","       779, 780, 781, 782, 784, 785, 786, 788, 789, 790, 791, 793, 794,\n","       795, 796, 797, 798, 799, 800, 802, 803, 806, 807, 808, 809, 810,\n","       811, 813, 814, 815, 816, 818, 821, 824, 826, 827, 829, 830, 831,\n","       832, 834, 835, 837, 838, 839, 840, 841, 842, 843, 844, 845, 847,\n","       848, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861,\n","       863, 864, 865, 866, 867, 868, 869, 870, 872, 873, 874, 875, 876,\n","       877, 878, 879, 880, 881, 882, 883, 884, 885, 887])"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"npzysPqN8-Pi","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":255},"executionInfo":{"status":"ok","timestamp":1593655961109,"user_tz":180,"elapsed":71248,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"8af044ed-8af6-40a2-e4e6-1a9326b66159"},"source":["doc_train_ids[valid_index]"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([  6,  11,  26,  33,  36,  37,  39,  40,  41,  44,  51,  67,  68,\n","        72,  74,  81,  86,  91,  92,  93,  96,  98, 102, 107, 108, 110,\n","       112, 123, 125, 128, 136, 138, 139, 142, 145, 146, 148, 151, 167,\n","       172, 181, 182, 194, 195, 200, 204, 215, 224, 240, 244, 246, 259,\n","       260, 261, 262, 263, 265, 269, 270, 273, 276, 285, 286, 289, 298,\n","       309, 312, 314, 315, 317, 320, 323, 335, 341, 344, 346, 347, 352,\n","       353, 357, 361, 362, 365, 368, 370, 377, 380, 381, 384, 396, 400,\n","       404, 409, 421, 425, 440, 443, 448, 451, 459, 465, 468, 471, 472,\n","       476, 479, 483, 487, 492, 493, 507, 508, 510, 515, 516, 536, 539,\n","       546, 557, 562, 581, 589, 593, 597, 604, 609, 624, 628, 633, 638,\n","       641, 650, 657, 658, 659, 663, 668, 677, 695, 696, 699, 700, 711,\n","       716, 717, 719, 739, 741, 746, 751, 762, 763, 772, 775, 778, 783,\n","       787, 792, 801, 804, 805, 812, 817, 819, 820, 822, 823, 825, 828,\n","       833, 836, 846, 849, 862, 871, 886])"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"N2LDzB_2755O","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":527},"executionInfo":{"status":"ok","timestamp":1593655961110,"user_tz":180,"elapsed":71243,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"d875c6bd-7d0b-4791-8e4a-c1eba753612f"},"source":["doc_test_ids[test_index]"],"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n","        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n","        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n","        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n","        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n","        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n","        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n","        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n","       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n","       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n","       130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n","       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n","       156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n","       169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n","       182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n","       195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n","       208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n","       221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n","       234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246,\n","       247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259,\n","       260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272,\n","       273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n","       286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298,\n","       299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n","       312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324,\n","       325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337,\n","       338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350,\n","       351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n","       364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376,\n","       377, 378, 379, 380])"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"9hORlMAi41vy","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":615},"executionInfo":{"status":"ok","timestamp":1593655969529,"user_tz":180,"elapsed":79656,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"e3aafbf2-8d4d-4743-fa37-c8f8e46a252c"},"source":["!pip install transformers"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/35/1c3f6e62d81f5f0daff1384e6d5e6c5758682a8357ebc765ece2b9def62b/transformers-3.0.0-py3-none-any.whl (754kB)\n","\u001b[K     |████████████████████████████████| 757kB 7.9MB/s \n","\u001b[?25hCollecting tokenizers==0.8.0-rc4\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e8/bd/e5abec46af977c8a1375c1dca7cb1e5b3ec392ef279067af7f6bc50491a0/tokenizers-0.8.0rc4-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n","\u001b[K     |████████████████████████████████| 3.0MB 23.2MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n","Collecting sentencepiece\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n","\u001b[K     |████████████████████████████████| 1.1MB 55.1MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 48.6MB/s \n","\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.12.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.15.1)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=bfd54833b7e17445d0e86723a9312e0c0303ad40997a32a3c66706dd819d012d\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built sacremoses\n","Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n","Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.0rc4 transformers-3.0.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"x0bQcArrMwCk","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593655972543,"user_tz":180,"elapsed":82667,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["import pandas as pd\n","import numpy as np\n","import itertools\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import transformers\n","import torch.utils.data as tdata\n","import torch.optim as optim\n","\n","import tqdm\n","\n","torch.manual_seed(0)\n","np.random.seed(0)"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"FDhmJ8RY4-St","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593655972544,"user_tz":180,"elapsed":82666,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"oSU-aTSudTA4","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593655972957,"user_tz":180,"elapsed":83077,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["X0_train_tensor = torch.from_numpy(X_train_matrix[train_index]).float().to(device)\n","X0_valid_tensor = torch.from_numpy(X_train_matrix[valid_index]).float().to(device)\n","X0_test_tensor = torch.from_numpy(X_test_matrix).float().to(device)"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"4lzOGqwU3lLq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593655972958,"user_tz":180,"elapsed":83072,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"4e375d40-cba0-4c78-a901-1a97b30198d2"},"source":["np.max([len(clss) for doc, clss in train_cls_token_embeddings.items()])"],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["285"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"VvRh2dHK5Hmr","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593655972958,"user_tz":180,"elapsed":83070,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["max_len = 50"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"9Fq3PgQB7NgF","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593655972959,"user_tz":180,"elapsed":83068,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["def manual_padding(sent, max_len = 200):\n","  pad_tensor = [torch.from_numpy(np.zeros((1, 768))).float()]\n","  if len(sent) > max_len:\n","    res = sent[-max_len:]\n","  else:\n","    res = (pad_tensor * (max_len - len(sent))) + sent\n","  return res"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"id":"U6iFCg7p9011","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593655972959,"user_tz":180,"elapsed":83065,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["X1_train_tensor = torch.stack([torch.stack(manual_padding(sent=train_cls_token_embeddings[i], max_len = max_len)) for i in train_index]).squeeze(2).to(device)\n","X2_train_tensor = torch.stack([train_last_layer_embeddings[i] for i in train_index]).squeeze(1).to(device)\n","X3_train_tensor = torch.stack([torch.flatten(train_all_layers_embeddings[i].permute(1, 0, 2), start_dim=1) for i in train_index]).squeeze(1).to(device)"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"5nLhw-oqKViw","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593655972960,"user_tz":180,"elapsed":83064,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["X1_valid_tensor = torch.stack([torch.stack(manual_padding(sent=train_cls_token_embeddings[i], max_len = max_len)) for i in valid_index]).squeeze(2).to(device)\n","X2_valid_tensor = torch.stack([train_last_layer_embeddings[i] for i in valid_index]).squeeze(1).to(device)\n","X3_valid_tensor = torch.stack([torch.flatten(train_all_layers_embeddings[i].permute(1, 0, 2), start_dim=1) for i in valid_index]).squeeze(1).to(device)"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"id":"9AYQ7TYfO_uR","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593655973512,"user_tz":180,"elapsed":83614,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["X1_test_tensor = torch.stack([torch.stack(manual_padding(sent=test_cls_token_embeddings[i], max_len = max_len)) for i in test_index]).squeeze(2).to(device)\n","X2_test_tensor = torch.stack([test_last_layer_embeddings[i] for i in test_index]).squeeze(1).to(device)\n","X3_test_tensor = torch.stack([torch.flatten(test_all_layers_embeddings[i].permute(1, 0, 2), start_dim=1) for i in test_index]).squeeze(1).to(device)"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"pSOM62CnKVct","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593655973512,"user_tz":180,"elapsed":83611,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["Y_train_tensor = torch.LongTensor(np.array(Y_train)[train_index]).to(device)\n","Y_valid_tensor = torch.LongTensor(np.array(Y_train)[valid_index]).to(device)\n","Y_test_tensor = torch.LongTensor(np.array(Y_test)).to(device)"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"TxXNnfKaBXbK","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593655973513,"user_tz":180,"elapsed":83606,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"f1ca2169-814a-4539-e1ac-15b936b0e275"},"source":["X0_train_tensor.shape"],"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([712, 239262])"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"code","metadata":{"id":"7lwdtYzhStJH","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593655973513,"user_tz":180,"elapsed":83600,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"3f098b07-7641-4666-f8bb-ef0d76e99328"},"source":["X1_train_tensor.shape"],"execution_count":30,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([712, 50, 768])"]},"metadata":{"tags":[]},"execution_count":30}]},{"cell_type":"code","metadata":{"id":"4cbKWwZ7StDF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593655973514,"user_tz":180,"elapsed":83594,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"0c575953-9f5b-4564-ca08-b98decda2e6d"},"source":["X2_train_tensor.shape"],"execution_count":31,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([712, 768])"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"code","metadata":{"id":"YK-km_HcSsjM","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593655973514,"user_tz":180,"elapsed":83588,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"49d6e667-c510-4443-9297-fb2fc2809d89"},"source":["X3_train_tensor.shape"],"execution_count":32,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([712, 9984])"]},"metadata":{"tags":[]},"execution_count":32}]},{"cell_type":"code","metadata":{"id":"OnRUTIxRQRoT","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593655973515,"user_tz":180,"elapsed":83587,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["input_dim_0 = X0_train_tensor.shape[1]\n","input_dim_2 = X2_train_tensor.shape[1]\n","input_dim_3 = X3_train_tensor.shape[1]\n","EMBEDDING_DIM = X1_train_tensor.shape[2]"],"execution_count":33,"outputs":[]},{"cell_type":"code","metadata":{"id":"fBO0s-eUTqYk","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593655973517,"user_tz":180,"elapsed":83582,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"74224ed7-a415-409f-a2e3-d8c14eca051f"},"source":["input_dim_0"],"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/plain":["239262"]},"metadata":{"tags":[]},"execution_count":34}]},{"cell_type":"code","metadata":{"id":"BM9kem7rTqR7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593655973517,"user_tz":180,"elapsed":83576,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"a1011a1d-3933-4403-f325-3ea171223039"},"source":["input_dim_2"],"execution_count":35,"outputs":[{"output_type":"execute_result","data":{"text/plain":["768"]},"metadata":{"tags":[]},"execution_count":35}]},{"cell_type":"code","metadata":{"id":"zPtu--rCRZI7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593655973518,"user_tz":180,"elapsed":83570,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"430b22e1-0a14-47df-8d15-197f05246c9b"},"source":["input_dim_3"],"execution_count":36,"outputs":[{"output_type":"execute_result","data":{"text/plain":["9984"]},"metadata":{"tags":[]},"execution_count":36}]},{"cell_type":"code","metadata":{"id":"Gm3d5UPCBh8g","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593655973519,"user_tz":180,"elapsed":83564,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"5ea900fd-01e2-49ec-ec19-78a61fe7ca73"},"source":["EMBEDDING_DIM"],"execution_count":37,"outputs":[{"output_type":"execute_result","data":{"text/plain":["768"]},"metadata":{"tags":[]},"execution_count":37}]},{"cell_type":"code","metadata":{"id":"Qbh-533qOJ2M","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593655973519,"user_tz":180,"elapsed":83562,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["class MyModel(nn.Module):\n","    def __init__(self):\n","        super(MyModel, self).__init__()\n","\n","        self.hidden_dim = 50\n","        num_layers = 1\n","\n","        self.fc1 = nn.Linear(input_dim_0, 50)\n","\n","        #self.lstm = nn.LSTM(EMBEDDING_DIM, self.hidden_dim, num_layers)\n","        self.lstm = nn.LSTM(EMBEDDING_DIM, self.hidden_dim, num_layers, bidirectional=True)\n","        \n","        #self.fc_out = nn.Linear(50 + self.hidden_dim, 2)\n","        self.fc_out = nn.Linear(50 + (self.hidden_dim * 2), 2)\n","\n","        self.softmax = nn.Softmax(dim=1)\n","\n","        self.dropout = nn.Dropout(0.3)\n","        \n","    def forward(self, x1, x2):\n","        x1 = F.normalize(x1)\n","        h1 = self.dropout(self.fc1(x1))\n","\n","        x2 = F.normalize(x2)\n","        x2 = x2.permute(1,0,2)\n","        lstm_out, hidden = self.lstm(x2)\n","        h21 = self.dropout(lstm_out[0, :, self.hidden_dim:])\n","        h22 = self.dropout(lstm_out[-1, :, :self.hidden_dim])\n","        h2 = torch.cat((h21, h22), 1)\n","\n","        # Concatenate in dim1 (feature dimension)\n","        x = torch.cat((h1, h2), 1)\n","\n","        y = self.softmax(self.fc_out(x))\n","        return y"],"execution_count":38,"outputs":[]},{"cell_type":"code","metadata":{"id":"i1bYTYLVQONx","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":136},"executionInfo":{"status":"ok","timestamp":1593655973520,"user_tz":180,"elapsed":83556,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"d4c3642f-b1d1-4961-c100-7c66973dd055"},"source":["model = MyModel()\n","model.to(device)"],"execution_count":39,"outputs":[{"output_type":"execute_result","data":{"text/plain":["MyModel(\n","  (fc1): Linear(in_features=239262, out_features=50, bias=True)\n","  (lstm): LSTM(768, 50, bidirectional=True)\n","  (fc_out): Linear(in_features=150, out_features=2, bias=True)\n","  (softmax): Softmax(dim=1)\n","  (dropout): Dropout(p=0.3, inplace=False)\n",")"]},"metadata":{"tags":[]},"execution_count":39}]},{"cell_type":"code","metadata":{"id":"6NvnlU24DsVb","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593655973520,"user_tz":180,"elapsed":83550,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"09757849-c55c-406a-bdc1-c023d5389c64"},"source":["X0_train_tensor.shape"],"execution_count":40,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([712, 239262])"]},"metadata":{"tags":[]},"execution_count":40}]},{"cell_type":"code","metadata":{"id":"dY6VwvOBTc-K","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593655973521,"user_tz":180,"elapsed":83545,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"a48d0a03-a070-4d06-ebf2-d1449b6063b1"},"source":["X1_train_tensor.shape"],"execution_count":41,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([712, 50, 768])"]},"metadata":{"tags":[]},"execution_count":41}]},{"cell_type":"code","metadata":{"id":"XyyWGhv0Tc3d","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593655973521,"user_tz":180,"elapsed":83539,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"106f681f-619b-47d5-8ba4-719020f6c564"},"source":["X2_train_tensor.shape"],"execution_count":42,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([712, 768])"]},"metadata":{"tags":[]},"execution_count":42}]},{"cell_type":"code","metadata":{"id":"rCMfNXulTcvs","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593655973522,"user_tz":180,"elapsed":83534,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"e425e950-9c65-44d8-9b7e-ad00c1685e8c"},"source":["X3_train_tensor.shape"],"execution_count":43,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([712, 9984])"]},"metadata":{"tags":[]},"execution_count":43}]},{"cell_type":"code","metadata":{"id":"acr1hz5FQmT5","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593655973522,"user_tz":180,"elapsed":83531,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["import torch.optim as optim\n","optimizer = optim.AdamW(model.parameters(), lr=0.01)"],"execution_count":44,"outputs":[]},{"cell_type":"code","metadata":{"id":"fp5F7lhtULiq","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593655973523,"user_tz":180,"elapsed":83530,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["from torch.optim.lr_scheduler import ReduceLROnPlateau\n","scheduler = ReduceLROnPlateau(optimizer, 'min')"],"execution_count":45,"outputs":[]},{"cell_type":"code","metadata":{"id":"fGkOOoMZJ4GF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593655973524,"user_tz":180,"elapsed":83525,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"7a7813bb-42ca-48e5-becf-4d43f6eccb16"},"source":["weights = [sum(Y_train)/len(Y_train), 1-sum(Y_train)/len(Y_train)]\n","class_weights = torch.FloatTensor(weights)\n","class_weights"],"execution_count":46,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0.1734, 0.8266])"]},"metadata":{"tags":[]},"execution_count":46}]},{"cell_type":"code","metadata":{"id":"nWrjkNzQQqW5","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593655973524,"user_tz":180,"elapsed":83523,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}}},"source":["criterion = nn.CrossEntropyLoss(weight=class_weights)"],"execution_count":47,"outputs":[]},{"cell_type":"code","metadata":{"id":"jtbi4GvTQta7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1593656342280,"user_tz":180,"elapsed":452273,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"3f8cb8a9-9f1c-4dfa-ffbb-a0c73ff52ed1"},"source":["patience = 20\n","early_stopping = EarlyStopping(patience=patience, verbose=True)\n","\n","\n","for i in range(100):\n","  model.train()\n","  optimizer.zero_grad()\n","  prediction = model(X0_train_tensor, X1_train_tensor)\n","  loss = criterion(prediction, Y_train_tensor)\n","  loss.backward()\n","  optimizer.step()\n","\n","  accuracy = Accuracy(prediction, Y_train_tensor)\n","\n","  model.eval()\n","\n","  val_prediction = model(X0_valid_tensor, X1_valid_tensor)\n","  test_prediction = model(X0_test_tensor, X1_test_tensor)\n","  val_loss = criterion(val_prediction, Y_valid_tensor)\n","  test_loss = criterion(test_prediction, Y_test_tensor)\n","\n","  val_accuracy = Accuracy(val_prediction, Y_valid_tensor)\n","  test_accuracy = Accuracy(test_prediction, Y_test_tensor)\n","\n","  early_stopping(val_loss, model)\n","\n","  if early_stopping.early_stop:\n","    print(\"Early stopping\")\n","    break\n","\n","  print(i, float(loss.cpu()), accuracy, float(val_loss.cpu()), val_accuracy, float(test_loss.cpu()), test_accuracy)\n","\n","  scheduler.step(val_loss)\n","\n","model.load_state_dict(torch.load('checkpoint.pt'))"],"execution_count":48,"outputs":[{"output_type":"stream","text":["Validation loss decreased (inf --> 0.569304).  Saving model ...\n","0 0.6958470344543457 0.5224719047546387 0.5693039894104004 0.8522727489471436 0.6016250252723694 0.8503937125205994\n","Validation loss decreased (0.569304 --> 0.494678).  Saving model ...\n","1 0.5670533180236816 0.8735954761505127 0.4946781098842621 0.8465909361839294 0.5480978488922119 0.8320209980010986\n","Validation loss decreased (0.494678 --> 0.479782).  Saving model ...\n","2 0.502694308757782 0.841292142868042 0.4797821342945099 0.875 0.5219438672065735 0.8766404390335083\n","Validation loss decreased (0.479782 --> 0.463020).  Saving model ...\n","3 0.48244085907936096 0.8848314881324768 0.4630204439163208 0.8693181872367859 0.5062259435653687 0.8687664270401001\n","Validation loss decreased (0.463020 --> 0.452519).  Saving model ...\n","4 0.45962944626808167 0.8932584524154663 0.4525185227394104 0.8693181872367859 0.49097904562950134 0.8766404390335083\n","Validation loss decreased (0.452519 --> 0.446978).  Saving model ...\n","5 0.4391855299472809 0.9002808928489685 0.44697844982147217 0.8693181872367859 0.4831007122993469 0.8635170459747314\n","Validation loss decreased (0.446978 --> 0.441848).  Saving model ...\n","6 0.4282362461090088 0.8890449404716492 0.44184786081314087 0.8806818127632141 0.4747316539287567 0.8818897604942322\n","EarlyStopping counter: 1 out of 20\n","7 0.4137701690196991 0.9129213690757751 0.44761285185813904 0.875 0.48117563128471375 0.8451443314552307\n","Validation loss decreased (0.441848 --> 0.441158).  Saving model ...\n","8 0.4102380871772766 0.882022500038147 0.44115790724754333 0.9204545617103577 0.47570890188217163 0.9160104990005493\n","Validation loss decreased (0.441158 --> 0.440879).  Saving model ...\n","9 0.40575891733169556 0.9410112500190735 0.44087857007980347 0.9261363744735718 0.4740169942378998 0.9212598204612732\n","Validation loss decreased (0.440879 --> 0.435332).  Saving model ...\n","10 0.39677858352661133 0.9522472023963928 0.43533235788345337 0.9034090638160706 0.4687221050262451 0.9081364870071411\n","EarlyStopping counter: 1 out of 20\n","11 0.38142526149749756 0.9536516666412354 0.43573564291000366 0.875 0.47131043672561646 0.8818897604942322\n","Validation loss decreased (0.435332 --> 0.435040).  Saving model ...\n","12 0.3757142424583435 0.9452247023582458 0.4350399971008301 0.875 0.47277823090553284 0.8635170459747314\n","Validation loss decreased (0.435040 --> 0.428671).  Saving model ...\n","13 0.37173768877983093 0.9466292262077332 0.42867085337638855 0.8863636255264282 0.4651827812194824 0.9002624750137329\n","Validation loss decreased (0.428671 --> 0.425193).  Saving model ...\n","14 0.3575812578201294 0.9648876190185547 0.42519330978393555 0.9261363744735718 0.46095165610313416 0.9212598204612732\n","EarlyStopping counter: 1 out of 20\n","15 0.3496282696723938 0.9719101190567017 0.4272681474685669 0.9318181872367859 0.46247830986976624 0.9212598204612732\n","EarlyStopping counter: 2 out of 20\n","16 0.3471162021160126 0.976123571395874 0.42918887734413147 0.9375 0.46425437927246094 0.9317585229873657\n","EarlyStopping counter: 3 out of 20\n","17 0.3439862132072449 0.9775280952453613 0.4272027611732483 0.9375 0.4631403386592865 0.9291338324546814\n","Validation loss decreased (0.425193 --> 0.421687).  Saving model ...\n","18 0.33520832657814026 0.9845505356788635 0.42168742418289185 0.9431818127632141 0.46020936965942383 0.9317585229873657\n","Validation loss decreased (0.421687 --> 0.416669).  Saving model ...\n","19 0.3311885893344879 0.983146071434021 0.41666850447654724 0.9375 0.45846983790397644 0.9265092015266418\n","Validation loss decreased (0.416669 --> 0.414164).  Saving model ...\n","20 0.3294588327407837 0.9845505356788635 0.4141642153263092 0.9375 0.4584280252456665 0.9212598204612732\n","Validation loss decreased (0.414164 --> 0.413660).  Saving model ...\n","21 0.3283834159374237 0.9789325594902039 0.41365954279899597 0.9431818127632141 0.45931336283683777 0.9186351895332336\n","EarlyStopping counter: 1 out of 20\n","22 0.3263491690158844 0.9859550595283508 0.416027694940567 0.9431818127632141 0.4620846211910248 0.9265092015266418\n","EarlyStopping counter: 2 out of 20\n","23 0.3247196674346924 0.9859550595283508 0.4227306842803955 0.9545454382896423 0.4675469398498535 0.9317585229873657\n","EarlyStopping counter: 3 out of 20\n","24 0.3224886357784271 0.9887640476226807 0.43263953924179077 0.9488636255264282 0.4754330515861511 0.9291338324546814\n","EarlyStopping counter: 4 out of 20\n","25 0.32082095742225647 0.9901685118675232 0.44135919213294983 0.9375 0.48364678025245667 0.9238845109939575\n","EarlyStopping counter: 5 out of 20\n","26 0.32016071677207947 0.992977499961853 0.4473794102668762 0.9375 0.4905294179916382 0.9265092015266418\n","EarlyStopping counter: 6 out of 20\n","27 0.3220457434654236 0.9943820238113403 0.4489375352859497 0.9375 0.4930141270160675 0.9291338324546814\n","EarlyStopping counter: 7 out of 20\n","28 0.31853798031806946 0.9985954761505127 0.44857096672058105 0.9375 0.4933972656726837 0.9291338324546814\n","EarlyStopping counter: 8 out of 20\n","29 0.3172764778137207 0.9957864880561829 0.4469456970691681 0.9375 0.49224594235420227 0.9265092015266418\n","EarlyStopping counter: 9 out of 20\n","30 0.31728997826576233 0.9971910119056702 0.44378504157066345 0.9431818127632141 0.4892512261867523 0.9291338324546814\n","EarlyStopping counter: 10 out of 20\n","31 0.3157263398170471 0.9985954761505127 0.4401945173740387 0.9431818127632141 0.4855499267578125 0.9265092015266418\n","EarlyStopping counter: 11 out of 20\n","32 0.3163491189479828 0.9957864880561829 0.4373184144496918 0.9431818127632141 0.48239704966545105 0.9291338324546814\n","EarlyStopping counter: 12 out of 20\n","33 0.3157758414745331 0.9971910119056702 0.4370962977409363 0.9431818127632141 0.48213863372802734 0.9265092015266418\n","EarlyStopping counter: 13 out of 20\n","34 0.31578031182289124 0.9957864880561829 0.4369717240333557 0.9431818127632141 0.48196443915367126 0.9238845109939575\n","EarlyStopping counter: 14 out of 20\n","35 0.3157077133655548 0.9971910119056702 0.4369438588619232 0.9431818127632141 0.4818775951862335 0.9238845109939575\n","EarlyStopping counter: 15 out of 20\n","36 0.315571129322052 0.9971910119056702 0.4369378387928009 0.9431818127632141 0.48180681467056274 0.9238845109939575\n","EarlyStopping counter: 16 out of 20\n","37 0.315323144197464 0.9971910119056702 0.4369642436504364 0.9431818127632141 0.48176059126853943 0.9238845109939575\n","EarlyStopping counter: 17 out of 20\n","38 0.3153206706047058 0.9971910119056702 0.43705087900161743 0.9431818127632141 0.48177164793014526 0.9238845109939575\n","EarlyStopping counter: 18 out of 20\n","39 0.31556394696235657 0.9971910119056702 0.437172532081604 0.9431818127632141 0.4818143844604492 0.9265092015266418\n","EarlyStopping counter: 19 out of 20\n","40 0.31544601917266846 0.9971910119056702 0.43733489513397217 0.9431818127632141 0.4818914830684662 0.9265092015266418\n","EarlyStopping counter: 20 out of 20\n","Early stopping\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{"tags":[]},"execution_count":48}]},{"cell_type":"code","metadata":{"id":"_ar8xXFbYwzN","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"executionInfo":{"status":"ok","timestamp":1593656342281,"user_tz":180,"elapsed":452268,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"fa0e79cf-4121-41e4-d1df-893e7838a263"},"source":["print(Precision(prediction, Y_train_tensor))\n","print(Precision(val_prediction, Y_valid_tensor))\n","print(Precision(test_prediction, Y_test_tensor))"],"execution_count":49,"outputs":[{"output_type":"stream","text":["[1.0, 0.9841269850730896]\n","[0.9473684430122375, 0.9166666865348816]\n","[0.9343283772468567, 0.8913043737411499]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Noxe6JaLYxag","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"executionInfo":{"status":"ok","timestamp":1593656342281,"user_tz":180,"elapsed":452262,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"a1706e6d-0596-437e-9834-ffbbe3da24ca"},"source":["print(Recall(prediction, Y_train_tensor))\n","print(Recall(val_prediction, Y_valid_tensor))\n","print(Recall(test_prediction, Y_test_tensor))"],"execution_count":50,"outputs":[{"output_type":"stream","text":["[0.9965986609458923, 1.0]\n","[0.9863013625144958, 0.7333333492279053]\n","[0.9842767119407654, 0.6507936716079712]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5an2w6BsYxL2","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"executionInfo":{"status":"ok","timestamp":1593656342282,"user_tz":180,"elapsed":452255,"user":{"displayName":"Bruno Leme","photoUrl":"","userId":"11849490065144642495"}},"outputId":"456ae90a-4234-4ce5-c896-9918d3d6258a"},"source":["print(Accuracy(prediction, Y_train_tensor))\n","print(Accuracy(val_prediction, Y_valid_tensor))\n","print(Accuracy(test_prediction, Y_test_tensor))"],"execution_count":51,"outputs":[{"output_type":"stream","text":["0.9971910119056702\n","0.9431818127632141\n","0.9291338324546814\n"],"name":"stdout"}]}]}